{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a71810a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yo\\.conda\\envs\\transformers\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import (\n",
    "    TokenClassificationPipeline,\n",
    "    SummarizationPipeline,\n",
    "    AutoModelForTokenClassification,\n",
    "    AutoTokenizer,BigBirdPegasusForConditionalGeneration\n",
    ")\n",
    "from transformers.pipelines import AggregationStrategy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.stem import PorterStemmer\n",
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba1ebaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# *inicio de sesion en mongo y listado de colecciones.\n",
    "# *Otros user_name [Miguel, Lucas, Julieta, Guillermo]\n",
    "# def inicio_sesion(user_name, password):\n",
    "def inicio_sesion():\n",
    "    user_name = 'Guillermo'\n",
    "    password = 'aplicacionesytendenciasdelanalisisdedatos2022'\n",
    "    cluster = MongoClient(f'mongodb+srv://{user_name}:{password}@cluster0.rnxayot.mongodb.net/?retryWrites=true&w=majority')\n",
    "    # *seleccion de la coleccion de datos\n",
    "    db = cluster['papers']\n",
    "    db.list_collection_names()\n",
    "    return(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02c96f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Acceso a todas las colecciones. Devuelve una lista con las colecciones\n",
    "# nombres colecciones: papers   final_distances  tockenizador  refinded_paper  final_paper   papers_2\n",
    "def acceder_una_coleccion(nombre_col):\n",
    "    db = inicio_sesion()\n",
    "    collection = db[nombre_col]\n",
    "    return(collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfd9ac6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Debe pasarsele un datos en formato json y una coleccion como acceder_coleccion[x] \n",
    "def save_mongo(data, collection):\n",
    "    # *guarda data en mongo db, si la coleccion esta vacia inserta el primero, \n",
    "    # *si no esta vacio compara si alguno de los documentos en la coleccion tiene \n",
    "    # *el mismo titulo que el que se va a insertar, si no es asi se inserta.\n",
    "    cantidad_inicial = collection.count_documents({})\n",
    "    try:\n",
    "        for i in range(len(data)):\n",
    "            if collection.count_documents({}) == 0:\n",
    "                collection.insert_one(data[i])\n",
    "            try:\n",
    "                collection.find({'titulo':data[i]['titulo']})[0]\n",
    "            except:\n",
    "                collection.insert_one(data[i])\n",
    "        print('Creación correcta') \n",
    "    except Exception as exception:\n",
    "        print(exception)\n",
    "    #print('Se han realizado', collection.count_documents({}) - cantidad_inicial , 'nuevas insercciones')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6719bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "985f99fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_mongo(identificadores, collection):\n",
    "    for i in identificadores:\n",
    "        myquery = { \"_id\": i }\n",
    "        collection.delete_one(myquery)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d65fb180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_to_json(df):\n",
    "    return json.loads(df.apply(lambda x: decode_encode(x) if type(x) == type([\"x\"]) else x ).to_json(orient=\"records\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cd9e06b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class cleaner():\n",
    "    def __init__(self):\n",
    "        nltk.download('stopwords')\n",
    "        self.word_list = stopwords.words('english')\n",
    "        self.stemmer = PorterStemmer() \n",
    "    def __call__(self, text):\n",
    "        res = \"\"\n",
    "        words = re.sub( \"[()-/%\"\"”“?''’]\",\"\" ,re.sub(\"\\d+\", \"\", text.lower().replace(\"\\n\",\"\").replace(\".\",\"\").replace(\",\",\"\").replace(\"b'\",\"\") )).split(\" \")\n",
    "        palabras = [h for h in words  ] # if h not in self.word_list\n",
    "        frase = ' '.join(palabras)\n",
    "        return frase\n",
    "    def flat_clean(self, text):\n",
    "        res = \"\"\n",
    "        words = re.sub( \"[()-/%\"\"”“?''’]\",\"\" ,re.sub(\"\\d+\", \"\", text.lower().replace(\"\\n\",\"\").replace(\".\",\"\").replace(\",\",\"\").replace(\"b'\",\"\") )).split(\" \")\n",
    "        palabras = [self.stemmer.stem(h) for h in words if h not in self.word_list ]\n",
    "        frase = ' '.join(palabras)\n",
    "        return frase\n",
    "        \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8be4767e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KeyphraseExtractionPipeline(TokenClassificationPipeline):\n",
    "    def __init__(self, model, *args, **kwargs):\n",
    "        super().__init__(\n",
    "            model=AutoModelForTokenClassification.from_pretrained(model),\n",
    "            tokenizer=AutoTokenizer.from_pretrained(model),\n",
    "            *args,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def postprocess(self, model_outputs):\n",
    "        results = super().postprocess(\n",
    "            model_outputs=model_outputs,\n",
    "            aggregation_strategy=AggregationStrategy.SIMPLE,\n",
    "        )\n",
    "        return np.unique([result.get(\"word\").strip() for result in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b85c829",
   "metadata": {},
   "outputs": [],
   "source": [
    "class summary(SummarizationPipeline):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(\n",
    "            model = BigBirdPegasusForConditionalGeneration.from_pretrained(\"google/bigbird-pegasus-large-arxiv\", attention_type=\"original_full\", max_length=50),\n",
    "            tokenizer = AutoTokenizer.from_pretrained(\"google/bigbird-pegasus-large-arxiv\"),\n",
    "            *args,\n",
    "            **kwargs\n",
    "        )\n",
    "    def postprocess(self, model_outputs):\n",
    "        results = super().postprocess(\n",
    "            model_outputs=model_outputs,\n",
    "        )\n",
    "        res = \"none data\"\n",
    "        if len(results) > 0 :\n",
    "            res = results[0].get(\"summary_text\") \n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "190611bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class keyword_extractor(TokenClassificationPipeline):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(\n",
    "            model=AutoModelForTokenClassification.from_pretrained(\"ml6team/keyphrase-extraction-distilbert-inspec\"),\n",
    "            tokenizer=AutoTokenizer.from_pretrained(\"ml6team/keyphrase-extraction-distilbert-inspec\"),\n",
    "            *args,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def postprocess(self, model_outputs):\n",
    "        results = super().postprocess(\n",
    "            model_outputs=model_outputs,\n",
    "            aggregation_strategy=AggregationStrategy.SIMPLE,\n",
    "        )\n",
    "        return np.unique([result.get(\"word\").strip() for result in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "19d53306",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def suma(lista):\n",
    "    lista_tem = \" \".join(lista)\n",
    "    return(lista_tem )\n",
    "def decode_encode(lista):\n",
    "    lista_tem = [x.decode('utf-8','ignore').encode(\"utf-8\") if type(x) == type(\"x\") else x for x in lista   ]\n",
    "    return(lista_tem )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12f3b838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inicio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\yo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cleaner cargado\n",
      "keyword_extractor cargado\n",
      "summary cargado\n",
      "primera ejecucion terminada\n",
      "segunda ejecucion terminada\n",
      "tercera ejecucion terminada\n",
      "cuarta ejecucion terminada\n",
      "quinta ejecucion terminada\n",
      "sexta ejecucion terminada\n",
      "Creación correcta\n",
      "FIN\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    print(\"inicio\")\n",
    "    limpiador = cleaner()\n",
    "    print(\"cleaner cargado\")\n",
    "    extractor_keywords = keyword_extractor()\n",
    "    print(\"keyword_extractor cargado\")\n",
    "    resumidor = summary()\n",
    "    print(\"summary cargado\")\n",
    "    print(\"FIN\")\n",
    "      \n",
    "    \n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820352e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
