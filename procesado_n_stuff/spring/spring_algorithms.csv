identifier,language,title,genre,abstract,subjects
doi:10.1007/s42064-022-0149-x,en,Adaptive connected hierarchical optimization algorithm for minimum energy spacecraft attitude maneuver path planning,"['OriginalPaper', 'Research Article']","Space object observation requirements and the avoidance of specific attitudes produce pointing constraints that increase the complexity of the attitude maneuver path-planning problem. To deal with this issue, a feasible attitude trajectory generation method is proposed that utilizes a multiresolution technique and local attitude node adjustment to obtain sufficient time and quaternion nodes to satisfy the pointing constraints. These nodes are further used to calculate the continuous attitude trajectory based on quaternion polynomial interpolation and the inverse dynamics method. Then, the characteristic parameters of these nodes are extracted to transform the path-planning problem into a parameter optimization problem aimed at minimizing energy consumption. This problem is solved by an improved hierarchical optimization algorithm, in which an adaptive parameter-tuning mechanism is introduced to improve the performance of the original algorithm. A numerical simulation is performed, and the results confirm the feasibility and effectiveness of the proposed method.","['Engineering', 'Aerospace Technology and Astronautics', 'Space Sciences (including Extraterrestrial Physics, Space Exploration and Astronautics)', 'Vibration, Dynamical Systems, Control']"
doi:10.1007/s42064-022-0153-1,en,Closed-loop deep neural network optimal control algorithm and error analysis for powered landing under uncertainties,"['OriginalPaper', 'Research Article']","Real-time guidance is critical for the vertical recovery of rockets. However, traditional sequential convex optimization algorithms suffer from shortcomings in terms of their poor real-time performance. This work focuses on applying the deep learning-based closed-loop guidance algorithm and error propagation analysis for powered landing, thereby significantly improving the real-time performance. First, a controller consisting of two deep neural networks is constructed to map the thrust direction and magnitude of the rocket according to the state variables. Thereafter, the analytical transition relationships between different uncertainty sources and the state propagation error in a single guidance period are analyzed by adopting linear covariance analysis. Finally, the accuracy of the proposed methods is verified via a comparison with the indirect method and Monte Carlo simulations. Compared with the traditional sequential convex optimization algorithm, our method reduces the computation time from 75 ms to less than 1 ms. Therefore, it shows potential for online applications.","['Engineering', 'Aerospace Technology and Astronautics', 'Space Sciences (including Extraterrestrial Physics, Space Exploration and Astronautics)', 'Vibration, Dynamical Systems, Control']"
doi:10.1007/s42064-022-0154-0,en,Natural coupled orbit—attitude periodic motions in the perturbed-CRTBP including radiated primary and oblate secondary,"['OriginalPaper', 'Research Article']","This study investigated periodic coupled orbit—attitude motions within the perturbed circular restricted three-body problem (P-CRTBP) concerning the perturbations of a radiated massive primary and an oblate secondary. The radiated massive primary was the Sun, and each planet in the solar system could be considered an oblate secondary. Because the problem has no closed-form solution, numerical methods were employed. Nevertheless, the general response of the problem could be non-periodic or periodic, which is significantly depended on the initial conditions of the orbit-attitude states. Therefore, the simultaneous orbit and attitude initial states correction (SOAISC) algorithm was introduced to achieve precise initial conditions. On the other side, the conventional initial guess vector was essential as the input of the correction algorithm and increased the probability of reaching more precise initial conditions. Thus, a new practical approach was developed in the form of an orbital correction algorithm to obtain the initial conditions for the periodic orbit of the P-CRTBP. This new proposed algorithm may be distinguished from previously presented orbital correction algorithms by its ability to propagate the P-CRTBP family orbits around the Lagrangian points using only one of the periodic orbits of the unperturbed CRTBP (U-CRTBP). In addition, the Poincaré map and Floquet theory search methods were used to recognize the various initial guesses for attitude parameters. Each of these search methods was able to identify different initial guesses for attitude states. Moreover, as a new innovation, these search methods were applied as a powerful tool to select the appropriate inertia ratio for a satellite to deliver periodic responses from the coupled model. Adding the mentioned perturbations to the U-CRTBP could lead to the more accurate modeling of the examination environment and a better understanding of a spacecraft’s natural motion. A comparison between the orbit-attitude natural motions in the unperturbed and perturbed models was also conducted to show this claim.","['Engineering', 'Aerospace Technology and Astronautics', 'Space Sciences (including Extraterrestrial Physics, Space Exploration and Astronautics)', 'Vibration, Dynamical Systems, Control']"
doi:10.1007/s42064-022-0152-2,en,Review of space relative navigation based on angles-only measurements,"['ReviewPaper', 'Review Article']","Relative navigation is a key enabling technology for space missions such as on-orbit servicing and space situational awareness. Given that there are several special advantages of space relative navigation using angles-only measurements from passive optical sensors, angles-only relative navigation is considered as one of the best potential approaches in the field of space relative navigation. However, angles-only relative navigation is well-known for its range observability problem. To overcome this observability problem, many studies have been conducted over the past decades. In this study, we present a comprehensive review of state-of-the-art space relative navigation based on angles-only measurements. The emphasis is on the observability problem and solutions to angles-only relative navigation, where the review of the solutions is categorized into four classes based on the intrinsic principle: complicated dynamics approach, multi-line of sight (multi-LOS) approach, sensor offset center-of-mass approach, and orbit maneuver approach. Then, the flight demonstration results of angles-only relative navigation in the two projects are briefly reviewed. Finally, conclusions of this study and recommendations for further research are presented.","['Engineering', 'Aerospace Technology and Astronautics', 'Space Sciences (including Extraterrestrial Physics, Space Exploration and Astronautics)', 'Vibration, Dynamical Systems, Control']"
doi:10.1007/s42064-022-0148-y,en,Feasibility analysis of angles-only navigation algorithm with multisensor data fusion for spacecraft noncooperative rendezvous,"['OriginalPaper', 'Research Article']","Relative navigation is crucial for spacecraft noncooperative rendezvous, and angles-only navigation using visible and infrared cameras provides a feasible solution. Herein, an angles-only navigation algorithm with multisensor data fusion is proposed to derive the relative motion states between two noncooperative spacecraft. First, the design model of the proposed algorithm is introduced, including the derivation of the state propagation and measurement equations. Subsequently, models for the sensor and actuator are introduced, and the effects of various factors on the sensors and actuators are considered. The square-root unscented Kalman filter is used to design the angles-only navigation filtering scheme. Additionally, the Clohessy—Wiltshire terminal guidance algorithm is introduced to obtain the theoretical relative motion trajectories during the rendezvous operations of two noncooperative spacecraft. Finally, the effectiveness of the proposed angles-only navigation algorithm is verified using a semi-physical simulation platform. The results prove that an optical navigation camera combined with average accelerometers and occasional orbital maneuvers is feasible for spacecraft noncooperative rendezvous using angles-only navigation.","['Engineering', 'Aerospace Technology and Astronautics', 'Space Sciences (including Extraterrestrial Physics, Space Exploration and Astronautics)', 'Vibration, Dynamical Systems, Control']"
doi:10.1007/s42757-021-0122-3,en,A multiphase approach for pyrolysis modelling of polymeric materials,"['OriginalPaper', 'Research Article']","In this study, a multiphase pyrolysis model has been proposed under the large eddy simulation (LES) framework incorporating moving boundary surface tracking, char formation, and detailed chemical kinetics combustion modelling. The proposed numerical model was applied to simulate the cone calorimeter test of two kinds of materials: (i) pinewood (charring) and (ii) low-density polyethylene (non-charring). Using a cone calorimeter setup, good agreement has been achieved between the computational and the experimental results. The model is capable of predicting the formation of the char layer and thus replicating the flame suppressing thermal and barrier effects. Furthermore, with the application of detailed chemical kinetics, the fire model was able to aptly predict the generation of asphyxiant gas such as CO/CO 2 during the burning process. However, the pinewood experiments showed significant CO/CO 2 emissions post flame extinguishment attributed to char oxidation effects, which were not considered by the fire model. Despite the limitation, the fully coupled LES model proposed in this study was capable of predicting the fluid mechanics and heat transfer for the turbulent reacting flow, solid-phase decomposition, and gaseous products under flaming conditions. In the future, it can be further extended to include char oxidation mechanisms to improve predictions for charring materials.","['Engineering', 'Engineering Fluid Dynamics', 'Fluid- and Aerodynamics', 'Environmental Engineering/Biotechnology']"
doi:10.1007/s42064-022-0147-z,en,Stretching directions in cislunar space: Applications for departures and transfer design,"['OriginalPaper', 'Research Article']","Stable or nearly stable orbits do not generally possess well-distinguished manifold structures that assist in designing trajectories for departing from or arriving onto a periodic orbit. For some potential missions, the orbits of interest are selected as nearly stable to reduce the possibility of rapid departure. However, the linearly stable nature of these orbits is also a drawback for their timely insertion into or departure from the orbit. Stable or nearly stable near rectilinear halo orbits (NRHOs), distant retrograde orbits (DROs), and lunar orbits offer potential long-horizon trajectories for exploration missions and demand efficient operations. The current investigation focuses on leveraging stretching directions as a tool for departure and trajectory design applications. The magnitude of the state variations along the maximum stretching direction is expected to grow rapidly and, therefore, offers information for efficient departure from the orbit. Similarly, maximum stretching in reverse time enables arrival with a minimal maneuver magnitude.","['Engineering', 'Aerospace Technology and Astronautics', 'Space Sciences (including Extraterrestrial Physics, Space Exploration and Astronautics)', 'Vibration, Dynamical Systems, Control']"
doi:10.1007/s42757-022-0137-7,en,Numerical simulation of oil dewatering in a disc centrifuge based on PBM model,"['OriginalPaper', 'Research Article']","Disc centrifuges have been widely applied, particularly in oil dewatering. Literatures are sparsely particularly that of test work and simulation with PBM model on this aspect. The oil dewatering performance of a disc centrifuge has been studied with both test and simulation, which was based on population balance model (PBM). The gradient of the concentration and size of water droplets has been revealed. The results show that the simulation of PBM model is more realistic; the coalescence probability of water droplets is much greater than the fragmentation probability; due to the coalescence behavior of water droplets, the oil—water separation process will be easier; and the separation efficiency will be 1%–2% higher than that of conventional Euler—Euler model. In addition, when the separation efficiency reaches the peak, the optimal disc gap is about 0.5 mm.","['Engineering', 'Engineering Fluid Dynamics', 'Fluid- and Aerodynamics', 'Environmental Engineering/Biotechnology']"
doi:10.1007/s42064-022-0144-2,en,A review of dynamic analysis on space solar power station,"['ReviewPaper', 'Review Article']","The concept of a space solar power station (SSPS) was proposed in 1968 as a potential approach for solving the energy crisis. In the past 50 years, several structural concepts have been proposed, but none have been sent into orbit. One of the main challenges of the SSPS is dynamic behavior prediction, which can supply the necessary information for control strategy design. The ultra-large size of the SSPS causes difficulties in its dynamic analysis, such as the ultra-low vibration frequency and large flexibility. In this paper, four approaches for the numerical analysis of the dynamic problems associated with the SSPS are reviewed: the finite element, absolute nodal coordinate, floating frame formulation, and structure-preserving methods. Both the merits and shortcomings of the above four approaches are introduced when they are employed in dynamic problems associated with the SSPS. Synthesizing the merits of the aforementioned four approaches, we believe that embedding the structure-preserving method into finite element software may be an effective way to perform a numerical analysis of the dynamic problems associated with the SSPS.","['Engineering', 'Aerospace Technology and Astronautics', 'Space Sciences (including Extraterrestrial Physics, Space Exploration and Astronautics)', 'Vibration, Dynamical Systems, Control']"
doi:10.1007/s42757-022-0133-y,en,Assessment of simplified momentum equations for free surface flows through rigid porous media,"['OriginalPaper', 'Research Article']","In many applications, free surface flow through rigid porous media has to be modeled. Examples refer to coastal engineering applications as well as geotechnical or biomedical applications. Albeit the frequent applications, slight inconsistencies in the formulation of the governing equations can be found in the literature. The main goal of this paper is to identify these differences and provide a quantitative assessment of different approaches. Following a review of the different formulations, simulation results obtained from three alternative formulations are compared with experimental and numerical data. Results obtained by 2D and 3D test cases indicate that the predictive differences returned by the different formulations remain small for most applications, in particular for small porous Reynolds number Re P < 5000. Thus it seems justified to select a simplified formulation that supports an efficient algorithm and coding structure in a computational fluid dynamics environment. An estimated accuracy depending on the porous Reynolds number or the mean grain diameter is given for the simplified formulation.","['Engineering', 'Engineering Fluid Dynamics', 'Fluid- and Aerodynamics', 'Environmental Engineering/Biotechnology']"
doi:10.1007/s42757-021-0109-3,en,A review for measurements and simulations of swirling gas-particle flows,"['ReviewPaper', 'Review Article']","Swirling gas-particle (droplet) flows are commonly encountered in gas-turbine combustors, cyclone combustors, and furnace burners. To better understand the flow behavior, many investigators did measurements, RANS (Reynolds-averaged Navier-Stokes) simulation, and LES (large-eddy simulation) of these types of flows. Most studies were done for weakly swirling gas-particle flows with swirl numbers less than unity. Experimental and numerical studies were done by the present author and his colleagues for PDPA measurements of swirling gas-particle flows with swirl numbers greater than unity, Reynolds-averaged two-fluid (Eulerian-Eulerian) simulation using k-ε-k p and USM (unified second-order moment) two-phase turbulence models, and two-fluid LES using a two-phase sub-grid stress model. The measurement and simulation results give the two-phase time-averaged and RMS fluctuation velocities, and particle concentration distribution, showing the complex recirculation structures in the two-phase axial velocities and the Rankine-vortex structures in the two-phase tangential velocities, the anisotropic two-phase turbulence properties, and the effect of swirl number on the two-phase flow behavior. The simulation results show that the two-fluid approach using the k-ε-k p and USM two-phase turbulence models are better than the Eulerian-Lagrangian approach for simulating swirling gas-particle flows","['Engineering', 'Engineering Fluid Dynamics', 'Fluid- and Aerodynamics', 'Environmental Engineering/Biotechnology']"
doi:10.1007/s42757-021-0107-5,en,Numerical modeling of wet steam infused fluid mixture for potential fire suppression applications,"['OriginalPaper', 'Research Article']","An advanced numerical model for modeling spontaneous condensation phenomena of water vapor was presented to investigate the flow behaviors in a converging-diverging nozzle for potential application in fire suppression using steam ejectors. The numerical model is validated against existing experimental data, which shows a good agreement. The proposed model was then compared against the ideal gas model in terms of various flow behaviors, including static pressure and Mach number in a newly designed nozzle. The condensing behaviors were accurately captured by the proposed model, while the idea gas model failed to do so. The condensation phenomena, including nucleation rate, droplet number, etc., in the nozzle, were discussed in detail. The accurate prediction results proved the possibility and demonstrated potential of applying the proposed model to broader fields of applications, especially into a steam ejector.","['Engineering', 'Engineering Fluid Dynamics', 'Fluid- and Aerodynamics', 'Environmental Engineering/Biotechnology']"
doi:10.1007/s42757-022-0138-6,en,Effect of two-group void fraction covariance correlations on interfacial drag predictions for two-fluid model calculations in large diameter pipes,"['OriginalPaper', 'Research Article']","Void fraction covariance has been introduced into the interfacial drag calculation used to close the one-dimensional two-fluid model. A model for void fraction covariance has been developed for large diameter pipes. The newly developed model has been compared with two previously developed models in terms of void fraction prediction accuracy. The effects of these additions on the void fraction prediction uncertainty have been evaluated utilizing a computational tool developed in MATLAB. The results indicate that there are small differences in the void fraction prediction between the models evaluated and the two-fluid model without void fraction covariance. Higher void fractions above 0.7 show the most significant changes. However, the differences in the uncertainty are not significant when compared to the uncertainty in the data used for the comparison. The results highlight a need for additional data for higher void fractions, collected with steam-water systems in large diameter pipes.","['Engineering', 'Engineering Fluid Dynamics', 'Fluid- and Aerodynamics', 'Environmental Engineering/Biotechnology']"
doi:10.1007/s42757-021-0131-5,en,Effect of thermal radiation on magnetohydrodynamics heat transfer micropolar fluid flow over a vertical moving porous plate,"['OriginalPaper', 'Research Article']","An analysis is investigated for this study of the magnetohydrodynamics heat transfer flow of the micropolar fluid over a vertical porous moving plate in the existence of the radiation effect. The numerical elucidations of the governing equations achieved for various values of flow fields are taken out for the several parameters inflowing into the problem and solved by raising the Galerkin finite element technique. By taking the range of the magnetic field parameter 0 ≤ M ≤ 5, the range of viscosity ratio parameter is 0 ≤ β ≤ 5, and micro-gyration parameter is 0 ≤ n ≤ 5, whereas the value of Grashof number lies in 0 ≤ Gr ≤ 2 and −2 ≤ Gr ≤ 0. The numerical results and impact on the translation velocity and temperature are presented and discussed through graphs and listed in the tables. With an increase of β and Gr , the velocity increases, and the reverse effect is found with enhancing of M and n . With enhanced values of M, n, Pr , and R , the result in C f rises.","['Engineering', 'Engineering Fluid Dynamics', 'Fluid- and Aerodynamics', 'Environmental Engineering/Biotechnology']"
doi:10.1007/s41095-021-0265-1,en,A Voronoi diagram approach for detecting defects in 3D printed fiber-reinforced polymers from microscope images,"['OriginalPaper', 'Research Article']","Fiber-reinforced polymer (FRP) composites are increasingly popular due to their superior strength to weight ratio. In contrast to significant recent advances in automating the FRP manufacturing process via 3D printing, quality inspection and defect detection remain largely manual and inefficient. In this paper, we propose a new approach to automatically detect, from microscope images, one of the major defects in 3D printed FRP parts: fiber-deficient areas (or equivalently, resin-rich areas). From cross-sectional microscope images, we detect the locations and sizes of fibers, construct their Voronoi diagram, and employ α -shape theory to determine fiber-deficient areas. Our Voronoi diagram and α -shape construction algorithms are specialized to exploit typical characteristics of 3D printed FRP parts, giving significant efficiency gains. Our algorithms robustly handle real-world inputs containing hundreds of thousands of fiber cross-sections, whether in general or non-general position.","['Computer Science', 'Computer Graphics', 'User Interfaces and Human Computer Interaction', 'Artificial Intelligence', 'Image Processing and Computer Vision']"
doi:10.1007/s41095-021-0266-0,en,AR assistance for efficient dynamic target search,"['OriginalPaper', 'Research Article']","When searching for a dynamic target in an unknown real world scene, search efficiency is greatly reduced if users lack information about the spatial structure of the scene. Most target search studies, especially in robotics, focus on determining either the shortest path when the target’s position is known, or a strategy to find the target as quickly as possible when the target’s position is unknown. However, the target’s position is often known intermittently in the real world, e.g., in the case of using surveillance cameras. Our goal is to help user find a dynamic target efficiently in the real world when the target’s position is intermittently known. In order to achieve this purpose, we have designed an AR guidance assistance system to provide optimal current directional guidance to users, based on searching a prediction graph. We assume that a certain number of depth cameras are fixed in a real scene to obtain dynamic target’s position. The system automatically analyzes all possible meetings between the user and the target, and generates optimal directional guidance to help the user catch up with the target. A user study was used to evaluate our method, and its results showed that compared to free search and a top-view method, our method significantly improves target search efficiency.","['Computer Science', 'Computer Graphics', 'User Interfaces and Human Computer Interaction', 'Artificial Intelligence', 'Image Processing and Computer Vision']"
doi:10.1007/s42064-022-0143-3,en,Integrated visual navigation based on angles-only measurements for asteroid final landing phase,"['OriginalPaper', 'Research Article']","Visual navigation is imperative for successful asteroid exploration missions. In this study, an integrated visual navigation system was proposed based on angles-only measurements to robustly and accurately determine the pose of the lander during the final landing phase. The system used the lander’s global pose information provided by an orbiter, which was deployed in space in advance, and its relative motion information in adjacent images to jointly estimate its optimal state. First, the landmarks on the asteroid surface and markers on the lander were identified from the images acquired by the orbiter. Subsequently, an angles-only measurement model concerning the landmarks and markers was constructed to estimate the orbiter’s position and lander’s pose. Subsequently, a method based on the epipolar constraint was proposed to estimate the lander’s inter-frame motion. Then, the absolute pose and relative motion of the lander were fused using an extended Kalman filter. Additionally, the observability criterion and covariance of the state error were provided. Finally, synthetic image sequences were generated to validate the proposed navigation system, and numerical results demonstrated its advance in terms of robustness and accuracy.","['Engineering', 'Aerospace Technology and Astronautics', 'Space Sciences (including Extraterrestrial Physics, Space Exploration and Astronautics)', 'Vibration, Dynamical Systems, Control']"
doi:10.1007/s42757-021-0119-1,en,A conservative level set method for liquid-gas flows with application in liquid jet atomisation,"['OriginalPaper', 'Research Article']","In this paper, a methodology for modelling two-phase flows based on a conservative level set method in the framework of finite volume method is presented. The novelty of the interface capturing method used here lies on the advection of level set which is solved with a WENO scheme and corrected with a novel re-initialisation method for retaining its signed distance function character. The coupling with the volume of fluid method is done with a simple algebraic approach, and with the new algorithm the accumulated mass conservation errors remain reasonably low. The paper presents a unique coupling between the level set method and the Eulerian–Lagrangian Spray Atomisation approach for modelling spray dispersion in liquid atomisation systems. The method is shown to have good accuracy providing similar results to other numerical codes for the classical tests presented. Preliminary results are also shown for three-dimensional simulations of the primary break-up of a turbulent liquid jet obtaining results comparable to direct numerical simulations. Consequently, the coupled method can be used for simulating various two-phase flow applications offering an accurate representation of the interface dynamics.","['Engineering', 'Engineering Fluid Dynamics', 'Fluid- and Aerodynamics', 'Environmental Engineering/Biotechnology']"
doi:10.1007/s41095-022-0270-z,en,A two-step surface-based 3D deep learning pipeline for segmentation of intracranial aneurysms,"['OriginalPaper', 'Research Article']","The exact shape of intracranial aneurysms is critical in medical diagnosis and surgical planning. While voxel-based deep learning frameworks have been proposed for this segmentation task, their performance remains limited. In this study, we offer a two-step surface-based deep learning pipeline that achieves significantly better results. Our proposed model takes a surface model of an entire set of principal brain arteries containing aneurysms as input and returns aneurysm surfaces as output. A user first generates a surface model by manually specifying multiple thresholds for time-of-flight magnetic resonance angiography images. The system then samples small surface fragments from the entire set of brain arteries and classifies the surface fragments according to whether aneurysms are present using a point-based deep learning network (PointNet++). Finally, the system applies surface segmentation (SO-Net) to surface fragments containing aneurysms. We conduct a direct comparison of the segmentation performance of our proposed surface-based framework and an existing voxel-based method by counting voxels: our framework achieves a much higher Dice similarity (72%) than the prior approach (46%).","['Computer Science', 'Computer Graphics', 'User Interfaces and Human Computer Interaction', 'Artificial Intelligence', 'Image Processing and Computer Vision']"
doi:10.1007/s41095-021-0263-3,en,Focusing on your subject: Deep subject-aware image composition recommendation networks,"['OriginalPaper', 'Research Article']","Photo composition is one of the most important factors in the aesthetics of photographs. As a popular application, composition recommendation for a photo focusing on a specific subject has been ignored by recent deep-learning-based composition recommendation approaches. In this paper, we propose a subject-aware image composition recommendation method, SAC-Net, which takes an RGB image and a binary subject window mask as input, and returns good compositions as crops containing the subject. Our model first determines candidate scores for all possible coarse cropping windows. The crops with high candidate scores are selected and further refined by regressing their corner points to generate the output recommended cropping windows. The final scores of the refined crops are predicted by a final score regression module. Unlike existing methods that need to preset several cropping windows, our network is able to automatically regress cropping windows with arbitrary aspect ratios and sizes. We propose novel stability losses for maximizing smoothness when changing cropping windows along with view changes. Experimental results show that our method outperforms state-of-the-art methods not only on the subject-aware image composition recommendation task, but also for general purpose composition recommendation. We also have designed a multistage labeling scheme so that a large amount of ranked pairs can be produced economically. We use this scheme to propose the first subject-aware composition dataset SACD, which contains 2777 images, and more than 5 million composition ranked pairs. The SACD dataset is publicly available at https://cg.cs.tsinghua.edu.cn/SACD/ .","['Computer Science', 'Computer Graphics', 'User Interfaces and Human Computer Interaction', 'Artificial Intelligence', 'Image Processing and Computer Vision']"
doi:10.1007/s41095-022-0275-7,en,A survey of urban visual analytics: Advances and future directions,"['ReviewPaper', 'Review Article']","Developing effective visual analytics systems demands care in characterization of domain problems and integration of visualization techniques and computational models. Urban visual analytics has already achieved remarkable success in tackling urban problems and providing fundamental services for smart cities. To promote further academic research and assist the development of industrial urban analytics systems, we comprehensively review urban visual analytics studies from four perspectives. In particular, we identify 8 urban domains and 22 types of popular visualization, analyze 7 types of computational method, and categorize existing systems into 4 types based on their integration of visualization techniques and computational models. We conclude with potential research directions and opportunities.","['Computer Science', 'Computer Graphics', 'User Interfaces and Human Computer Interaction', 'Artificial Intelligence', 'Image Processing and Computer Vision']"
doi:10.1007/s41095-022-0272-x,en,Imposing temporal consistency on deep monocular body shape and pose estimation,"['OriginalPaper', 'Research Article']","Accurate and temporally consistent modeling of human bodies is essential for a wide range of applications, including character animation, understanding human social behavior, and AR/VR interfaces. Capturing human motion accurately from a monocular image sequence remains challenging; modeling quality is strongly influenced by temporal consistency of the captured body motion. Our work presents an elegant solution to integrating temporal constraints during fitting. This increases both temporal consistency and robustness during optimization. In detail, we derive parameters of a sequence of body models, representing shape and motion of a person. We optimize these parameters over the complete image sequence, fitting a single consistent body shape while imposing temporal consistency on the body motion, assuming body joint trajectories to be linear over short time. Our approach enables the derivation of realistic 3D body models from image sequences, including jaw pose, facial expression, and articulated hands. Our experiments show that our approach accurately estimates body shape and motion, even for challenging movements and poses. Further, we apply it to the particular application of sign language analysis, where accurate and temporally consistent motion modelling is essential, and show that the approach is well-suited to this kind of application.","['Computer Science', 'Computer Graphics', 'User Interfaces and Human Computer Interaction', 'Artificial Intelligence', 'Image Processing and Computer Vision']"
doi:10.1007/s42757-021-0125-3,en,Towards the efficient modelling of trapped air pockets during squeeze flow,"['OriginalPaper', 'Research Article']","In most bonding processes, an adhesive is applied to a substrate in a specific pattern before the second substrate is subsequently pressed against it. During this, the adhesive flows in such a way that, ideally, it completely fills the joint. In practice, however, areas with entrapped air frequently remain in the bonded adhesive layer. Within the scope of a research project, these flows are systematically analyzed in order to identify optimal initial application patterns for the adhesive and substrate geometry to minimise such risks. For this purpose, the authors use an efficient flow model, the partially filled gaps model (PFGM), extended in this study to include the functionality of trapped air pockets. Depending on the volume fractions of air and adhesive, the flow of both phases is computed. Therefore, the model is introduced and fully described, benchmarked with respect to its plausibility and functionality, and results obtained are compared with a CFD calculation. Thereafter, the functionality of openings and closings of the pockets are analyzed. Lastly, the model is then applied to a real scenario created with a Hele–Shaw cell measurement. The benchmark as well as the comparison with the measurement results show the high potential of this technique.","['Engineering', 'Engineering Fluid Dynamics', 'Fluid- and Aerodynamics', 'Environmental Engineering/Biotechnology']"
doi:10.1007/s41095-022-0273-9,en,Joint specular highlight detection and removal in single images via Unet-Transformer,"['OriginalPaper', 'Research Article']","Specular highlight detection and removal is a fundamental problem in computer vision and image processing. In this paper, we present an efficient end-to-end deep learning model for automatically detecting and removing specular highlights in a single image. In particular, an encoder—decoder network is utilized to detect specular highlights, and then a novel Unet-Transformer network performs highlight removal; we append transformer modules instead of feature maps in the Unet architecture. We also introduce a highlight detection module as a mask to guide the removal task. Thus, these two networks can be jointly trained in an effective manner. Thanks to the hierarchical and global properties of the transformer mechanism, our framework is able to establish relationships between continuous self-attention layers, making it possible to directly model the mapping between the diffuse area and the specular highlight area, and reduce indeterminacy within areas containing strong specular highlight reflection. Experiments on public benchmark and real-world images demonstrate that our approach outperforms state-of-the-art methods for both highlight detection and removal tasks.","['Computer Science', 'Computer Graphics', 'User Interfaces and Human Computer Interaction', 'Artificial Intelligence', 'Image Processing and Computer Vision']"
doi:10.1007/s42757-021-0124-4,en,Soot: A review of computational models at different length scales,"['ReviewPaper', 'Review Article']","The computational modelling of soot formation and destruction during the combustion process is one of the most challenging topics in combustion research. This paper reviews the numerical soot models constructed at different length scales, including macroscale, mesoscale, and microscale. The four key stages of soot evolution, including nucleation, surface growth and coagulation, agglomeration, and oxidation, are first described with the generally accepted mathematical formulations in each stage explained. Different computational frameworks and their pros and cons are then reviewed, including the one-equation empirical soot model (macroscale), two-equation semi-empirical soot model (macroscale), different variations of population balance model (mesoscale), discrete element model (microscale), and molecular dynamics model (microscale). It is concluded that the accuracy required and the computational cost available are the two major influencing factors to be considered when selecting the appropriate computational model. The user needs to assess the priorities in their specific application and evaluate different modelling options to find the optimal balance between the level of accuracy and computation resources required.","['Engineering', 'Engineering Fluid Dynamics', 'Fluid- and Aerodynamics', 'Environmental Engineering/Biotechnology']"
doi:10.1007/s42064-022-0132-6,en,Resonant orbit search and stability analysis for elongated asteroids,"['OriginalPaper', 'Research Article']","Periodic orbits are crucial in facilitating the understanding of the dynamical behavior of elongated asteroids. As a specific type of periodic orbit, resonant orbits can enrich the orbit design method of deep-space exploration missions. Herein, a dipole segment model for investigating the orbital dynamics of elongated asteroids is briefly introduced. A new numerical algorithm named the modified path searching method for identifying spin-orbit resonant orbits is proposed. Using the modified path searching and pseudo-arclength continuation methods, four spin-orbit resonant families for asteroid 2063 Bacchus are obtained. The distribution of eigenvalues and stability curves for the four resonant families are presented. In particular, some critical points corresponding to period-doubling and tangent bifurcations appear in the stability curves.","['Engineering', 'Aerospace Technology and Astronautics', 'Space Sciences (including Extraterrestrial Physics, Space Exploration and Astronautics)', 'Vibration, Dynamical Systems, Control']"
doi:10.1007/s41095-021-0262-4,en,Full-duplex strategy for video object segmentation,"['OriginalPaper', 'Research Article']","Previous video object segmentation approaches mainly focus on simplex solutions linking appearance and motion, limiting effective feature collaboration between these two cues. In this work, we study a novel and efficient full-duplex strategy network ( FSNet ) to address this issue, by considering a better mutual restraint scheme linking motion and appearance allowing exploitation of cross-modal features from the fusion and decoding stage. Specifically, we introduce a relational cross-attention module (RCAM) to achieve bidirectional message propagation across embedding sub-spaces. To improve the model’s robustness and update inconsistent features from the spatiotemporal embeddings, we adopt a bidirectional purification module after the RCAM. Extensive experiments on five popular benchmarks show that our FSNet is robust to various challenging scenarios (e.g., motion blur and occlusion), and compares well to leading methods both for video object segmentation and video salient object detection. The project is publicly available at https://github.com/GewelsJI/FSNet .","['Computer Science', 'Computer Graphics', 'User Interfaces and Human Computer Interaction', 'Artificial Intelligence', 'Image Processing and Computer Vision']"
doi:10.1007/s40544-022-0604-y,en,Carbon fiber cannot always reduce the wear of PEEK for orthopedic implants under DPPC lubrication,"['OriginalPaper', 'Research Article']","Excellent wear resistance is an important feature of orthopedic implants. However, although pure polyetheretherketone (PEEK) is outperformed by carbon fiber-reinforced PEEK (CF-PEEK) for stability and durability under laboratory conditions, it is not clear whether CF-PEEK should be preferred in all real-world applications. Results indicate that, under dipalmitoylphosphatidylcholine (DPPC) lubrication, the wear rates of PEEK are 35%—80% lower than the wear rates of CF-PEEK for different implant materials, speeds, loadings, and DPPC concentrations. Molecular dynamics calculations confirm that DPPC self-assembles on the PEEK surface to form an easily adsorbed continuous phospholipid lubricating film. In contrast, the carbon fibers on the CF-PEEK surface hinder the formation of the protective DPPC film and the CF-PEEK surface is thus subject to faster wear.","['Engineering', 'Mechanical Engineering', 'Nanotechnology', 'Tribology, Corrosion and Coatings', 'Physical Chemistry', 'Surfaces and Interfaces, Thin Films']"
doi:10.1007/s42064-022-0146-0,en,Robust template feature matching method using motion-constrained DCF designed for visual navigation in asteroid landing,"['OriginalPaper', 'Research Article']","A robust and efficient feature matching method is necessary for visual navigation in asteroid-landing missions. Based on the visual navigation framework and motion characteristics of asteroids, a robust and efficient template feature matching method is proposed to adapt to feature distortion and scale change cases for visual navigation of asteroids. The proposed method is primarily based on a motion-constrained discriminative correlation filter (DCF). The prior information provided by the motion constraints between sequence images is used to provide a predicted search region for template feature matching. Additionally, some specific template feature samples are generated using the motion constraints for correlation filter learning, which is beneficial for training a scale and feature distortion adaptive correlation filter for accurate feature matching. Moreover, average peak-to-correlation energy (APCE) and jointly consistent measurements (JCMs) were used to eliminate false matching. Images captured by the Touch And Go Camera System (TAGCAMS) of the Bennu asteroid were used to evaluate the performance of the proposed method. In particular, both the robustness and accuracy of region matching and template center matching are evaluated. The qualitative and quantitative results illustrate the advancement of the proposed method in adapting to feature distortions and large-scale changes during spacecraft landing.","['Engineering', 'Aerospace Technology and Astronautics', 'Space Sciences (including Extraterrestrial Physics, Space Exploration and Astronautics)', 'Vibration, Dynamical Systems, Control']"
doi:10.1007/s42064-022-0151-3,en,On-board modeling of gravity fields of elongated asteroids using Hopfield neural networks,"['OriginalPaper', 'Research Article']","To rapidly model the gravity field near elongated asteroids, an intelligent inversion method using Hopfield neural networks (HNNs) is proposed to estimate on-orbit simplified model parameters. First, based on a rotating mass dipole model, the gravitational field of asteroids is characterized using a few parameters. To solve all the parameters of this simplified model, a stepped parameter estimation model is constructed based on different gravity field models. Second, to overcome linearization difficulties caused by the coupling of the parameters to be estimated and the system state, a dynamic parameter linearization technique is proposed such that all terms except the parameter terms are known or available. Moreover, the Lyapunov function of the HNNs is matched to the problem of minimizing parameter estimation errors. Equilibrium values of the Lyapunov function are used as estimated values. The proposed method is applied to natural elongated asteroids 216 Kleopatra, 951 Gaspra, and 433 Eros. Simulation results indicate that this method can estimate the simplified model parameters rapidly, and that the estimated simplified model provides a good approximation of the gravity field of elongated asteroids.","['Engineering', 'Aerospace Technology and Astronautics', 'Space Sciences (including Extraterrestrial Physics, Space Exploration and Astronautics)', 'Vibration, Dynamical Systems, Control']"
doi:10.1007/s42757-021-0112-8,en,Numerical assessment of LES subgrid-scale turbulence models for expandable particles in fire suppression,"['OriginalPaper', 'Research Article']","Owing to the well-established Eulerian-Lagrangian framework on mixture fluids, computational fluid dynamics coupled with discrete element model (CFD-DEM) is an effective while appropriate tool to predict the complex interactive fire behaviours associate with suppression effects. Although suppression behaviours between hydrocarbon-fuelled fire and water-based suppression agents were extensively studied both numerically and experimentally, lack of numerical studies was conducted on fires involving water-reactive chemicals (i.e., Na, Li, and LiH), where extinguishment is barely performed by water-based active suppression system, as violent and explosive decomposition occurred between water and reactive fuel. In this research, a numerical investigation has been conducted on expandable graphite (EG) application for water-reactive fire suppression. Based on the discrete phase model (DPM) framework, a novel EG particle model is proposed to characterise the particle expansion that couples with superior thermal properties and chemical stability. A numerical assessment on large eddy simulation (LES) has been performed to study the temporal fire behaviours and the suppression effect of EG against the flame plume in various subgrid-scale (SGS) models. Four SGS models were adopted, which were namely Smagorinsky-Lilly, WALE, dynamic kinetic energy, and dynamic Smagorinsky-Lilly. As a result, the WALE SGS model was observed to be in a better agreement compared with the experimental data owing to its significant enhancement in flow diffusivity modelling. The WALE SGS model has achieved a more accurate temperature prediction and finer resolved turbulence compared with other SGS models.","['Engineering', 'Engineering Fluid Dynamics', 'Fluid- and Aerodynamics', 'Environmental Engineering/Biotechnology']"
doi:10.1007/s42757-021-0110-x,en,Interfacial area concentration in gas-liquid metal two-phase flow,"['OriginalPaper', 'Research Article']","The characterization and modelling of the flow features in gas and heavy liquid metal two-phase flow are required for the development of next generation nuclear reactor systems. In this study, the past experimental studies performed in the gas-liquid metal two-phase flow are reviewed, and the void fraction and interfacial area concentration (IAC) database taken in the N 2 -Pb/Bi (nitrogen and lead/bismuth eutectic alloy) two-phase flow in a vertical circular flow channel are collected. In order to obtain the flow characteristics of the gas-liquid metal two-phase flow, the experimental data of the N 2 -Pb/Bi two-phase flow are compared with experimental data of the air-water two-phase flow. The void fraction gradient along the height (namely the flow direction) and the bubble diameter in the N 2 -Pb/Bi two-phase flow are found to be much larger than those in the air-water two-phase flow. These two unique flow characteristics can be explained, respectively, by the large density and surface tension of the Pb/Bi eutectic alloy in the N 2 -Pb/Bi two-phase flow. This study also reviewed the available IAC correlations and found that so far no IAC correlation has been developed for the gas-liquid metal two-phase flow. So, the available major IAC correlations for air- and steam-water two-phase flows are collected and compared with the collected experimental data of the N 2 -Pb/Bi two-phase flow. The comparison shows that these IAC correlations cannot give reliable predictions for the experimental data of the N 2 -Pb/Bi two-phase flow. So, a new IAC correlation has been developed based on the experimental data of the N 2 -Pb/Bi two-phase flow by taking into account the properties and flow characteristics of the two phases. The newly-developed IAC correlation can satisfactorily predict the experimental data of the N 2 -Pb/Bi two-phase flow with the mean relative error of 0.0609.","['Engineering', 'Engineering Fluid Dynamics', 'Fluid- and Aerodynamics', 'Environmental Engineering/Biotechnology']"
doi:10.1007/s41095-022-0276-6,en,Point cloud completion via structured feature maps using a feedback network,"['OriginalPaper', 'Research Article']","In this paper, we tackle the challenging problem of point cloud completion from the perspective of feature learning. Our key observation is that to recover the underlying structures as well as surface details, given partial input, a fundamental component is a good feature representation that can capture both global structure and local geometric details. We accordingly first propose FSNet, a feature structuring module that can adaptively aggregate point-wise features into a 2D structured feature map by learning multiple latent patterns from local regions. We then integrate FSNet into a coarse-to-fine pipeline for point cloud completion. Specifically, a 2D convolutional neural network is adopted to decode feature maps from FSNet into a coarse and complete point cloud. Next, a point cloud upsampling network is used to generate a dense point cloud from the partial input and the coarse intermediate output. To efficiently exploit local structures and enhance point distribution uniformity, we propose IFNet, a point upsampling module with a self-correction mechanism that can progressively refine details of the generated dense point cloud. We have conducted qualitative and quantitative experiments on ShapeNet, MVP, and KITTI datasets, which demonstrate that our method outperforms state-of-the-art point cloud completion approaches.","['Computer Science', 'Computer Graphics', 'User Interfaces and Human Computer Interaction', 'Artificial Intelligence', 'Image Processing and Computer Vision']"
doi:10.1007/s41095-021-0267-z,en,Facial optical flow estimation via neural non-rigid registration,"['OriginalPaper', 'Research Article']","Optical flow estimation in human facial video, which provides 2D correspondences between adjacent frames, is a fundamental pre-processing step for many applications, like facial expression capture and recognition. However, it is quite challenging as human facial images contain large areas of similar textures, rich expressions, and large rotations. These characteristics also result in the scarcity of large, annotated real-world datasets. We propose a robust and accurate method to learn facial optical flow in a self-supervised manner. Specifically, we utilize various shape priors, including face depth, landmarks, and parsing, to guide the self-supervised learning task via a differentiable nonrigid registration framework. Extensive experiments demonstrate that our method achieves remarkable improvements for facial optical flow estimation in the presence of significant expressions and large rotations.","['Computer Science', 'Computer Graphics', 'User Interfaces and Human Computer Interaction', 'Artificial Intelligence', 'Image Processing and Computer Vision']"
doi:10.1007/s42832-022-0148-0,en,"Soil microbes-mediated enzymes promoted the secondary succession in post-mining plantations on the Loess Plateau, China","['OriginalPaper', 'Research Article']","The diversity of vegetation configuration is the key to ecological restoration in open-pit coal mine dump. However, the recovery outcomes of different areas with the same vegetation assemblage pattern are completely different after long-term evolution. Therefore, understanding the causes of differential vegetation recovery and the mechanism of plant succession is of great significance to the ecological restoration of mines. Three Pinus tabulaeformis plantations with similar initial site conditions and restoration measures but with different secondary succession processes were selected from the open-pit coal mine dump that has been restored for 30 years. Soil physicochemical properties, enzyme activities, vegetation and microbial features were investigated, while the structural equation models were established to explore the interactions between plants, soil and microbes. The results showed that original vegetation configuration and soil nutrient conditions were altered due to secondary succession. With the advancement of the secondary succession process, the coverage of plants increased from 34.8% to 95.5% ( P < 0.05), soil organic matter increased from 9.30 g kg −1 to 21.13 g kg −1 ( P < 0.05), and total nitrogen increased from 0.38 g kg −1 to 1.01 g kg −1 ( P < 0.05). The activities of soil urease and β-glucosidase were increased by 1.7-fold and 53.26%, respectively. Besides, the secondary succession also changed the soil microbial community structure and function. The relative abundance of Nitrospira genus which dominates the nitrification increased 5.2-fold. The results showed that urease and β-glucosidase promoted the increase of vegetation diversity and biomass by promoting the accumulation of soil organic matter and nitrate nitrogen, which promoted the ecological restoration of mine dumps.","['Environment', 'Soil Science & Conservation', 'Ecology']"
doi:10.1007/s40544-022-0624-7,en,On the origin of plasticity-induced microstructure change under sliding contacts,"['OriginalPaper', 'Research Article']","Discrete dislocation plasticity (DDP) calculations are carried out to investigate the response of a single crystal contacted by a rigid sinusoidal asperity under sliding loading conditions to look for causes of microstructure change in the dislocation structure. The mechanistic driver is identified as the development of lattice rotations and stored energy in the subsurface, which can be quantitatively correlated to recent tribological experimental observations. Maps of surface slip initiation and substrate permanent deformation obtained from DDP calculations for varying contact size and normal load suggest ways of optimally tailoring the interface and microstructural material properties for various frictional loads.","['Engineering', 'Mechanical Engineering', 'Nanotechnology', 'Tribology, Corrosion and Coatings', 'Physical Chemistry', 'Surfaces and Interfaces, Thin Films']"
doi:10.1007/s42757-021-0117-3,en,Full cell mathematical models of air cathode microbial fuel cells,"['OriginalPaper', 'Research Article']","Microbial fuel cells (MFCs) as a renewable energy conversion technology have been attracting increasing attention in the past decades. However, a deeper understanding of bioelectrochemical reaction in electrodes is urgent to improve the cell performance towards practical applications. In this paper, a mathematical model of air cathode MFCs was proposed by coupling mass transport and charge conservation with bioelectrochemical/electrochemical reactions. The model was validated based on experimental results and further used to predict the performance of MFCs. The effect of mass transport including oxygen and substrate on electrode kinetics was studied based on the model. The results showed that enhancing mass transport in both anode and cathode remarkably facilitated the electrode current and hence the cell performance, and oxygen transfer in catalyst layer of cathode is the dominating factor limiting the cell performance. The proposed model can provide a facile avenue to capture the interdependence of electrode variables and help guide electrode design for optimizing the performance of MFCs in practical applications.","['Engineering', 'Engineering Fluid Dynamics', 'Fluid- and Aerodynamics', 'Environmental Engineering/Biotechnology']"
doi:10.1007/s42064-022-0131-7,en,Geophysical and orbital environments of asteroid 469219 2016 HO3,"['OriginalPaper', 'Research Article']","Asteroid 469219 Kamo’oalewa, also named 2016 HO3, is a small-size fast-rotating near-Earth asteroid, which is a potential target for future explorations. Owing to its weak gravity and fast spin rate, the dynamics on the surface or in the vicinity of 2016 HO3 are significantly different from those of planets or other small bodies explored in previous missions. In this study, the geophysical and orbital environments of 2016 HO3 were investigated to facilitate a potential mission design. First, the geometric and geopotential topographies of 2016 HO3 were examined using different shape models. The lift-off and escape conditions on its fast-rotating surface were investigated. Then, the periodic orbits around 2016 HO3 were studied in the asteroid-fixed frame and the Sun—asteroid frame considering the solar radiation pressure. The stable regions of the terminator orbits were discussed using different parameters. Finally, the influence of the nonspherical shape on the terminator orbits was examined. The precise terminator orbits around a real shape model of 2016 HO3 were obtained and verified in the high-fidelity model. This study shows that the polar region of 2016 HO3 is the primary region for landing or sampling, and the terminator orbits are well suited for global mapping and measurements of 2016 HO3. The analysis and methods can also serve as references for the exploration of other small fast-rotating bodies.","['Engineering', 'Aerospace Technology and Astronautics', 'Space Sciences (including Extraterrestrial Physics, Space Exploration and Astronautics)', 'Vibration, Dynamical Systems, Control']"
doi:10.1007/s42064-021-0122-0,en,Co-orbital transition of 2016 HO3,"['OriginalPaper', 'Research Article']","In this paper, we investigate the orbital behavior of the transition between the quasisatellite (QS) and horseshoe (HS) motions of 2016 HO 3 . Based on the phase space structure in the Sun–Earth circular restricted three-body problem, we find that the surface of 2016 HO 3 in the torus space is a compound surface formed by QS and HS portions. Its co-orbital motion is therefore a QS–HS transition. 2016 HO 3 is currently located in a QS state, and its locus clings to the QS portion in the isosurface in agreement with the semi-analytical results. We provide a criterion to separate the QS and HS stages in the transition and obtain accurate incoming and outgoing epochs of the QS motion. We then propose an approximate curve to describe the locus of 2016 HO 3 in the ω − e projection. Virtual asteroids (VAs) near 2016 HO 3 in the isosurface were created to study the influence of the initial state of the QS–HS transition. We find that the duration of the QS state is mainly influenced by the loci in the ω − e projection. The VAs with large QS durations usually have longer loci across the QS region than those with shorter durations. In addition, although some VAs are close to 2016 HO 3 in the ω − e projection, their co-orbital behaviors are significantly different from that of the latter. This indicates that the QS–HS transition of 2016 HO 3 is sensitive to the ( ω , e ) position.","['Engineering', 'Aerospace Technology and Astronautics', 'Space Sciences (including Extraterrestrial Physics, Space Exploration and Astronautics)', 'Vibration, Dynamical Systems, Control']"
doi:10.1007/s42832-022-0130-x,en,Assessment of residual chlorine in soil microbial community using metagenomics,"['OriginalPaper', 'Research Article']","Chlorine-containing disinfectants have been widely used around the world for the prevention and control of the COVID-19 pandemic. However, at present, little is known about the impact of residual chlorine on the soil micro-ecological environment. Herein, we treated an experimental soil-plant-microbiome microcosm system by continuous irrigation with a low concentration of chlorine-containing water, and then analyzed the influence on the soil microbial community using metagenomics. After 14-d continuous chlorine treatment, there were no significant lasting effect on soil microbial community diversity and composition either in the rhizosphere or in bulk soil. Although metabolic functions of the rhizosphere microbial community were affected slightly by continuous chlorine treatment, it recovered to the original status. The abundance of several resistance genes changed by 7 d and recovered by 14 d. According to our results, the chlorine residue resulting from daily disinfection may present a slight long-term effect on plant growth (shoot length and fresh weight) and soil micro-ecology. In general, our study assisted with environmental risk assessments relating to the application ofchlorine-containing disinfectants and minimization of risks to the environment during disease control, such as COVID-19.","['Environment', 'Soil Science & Conservation', 'Ecology']"
doi:10.1007/s12273-022-0941-9,en,Framework on low-carbon retrofit of rural residential buildings in arid areas of northwest China: A case study of Turpan residential buildings,"['OriginalPaper', 'Research Article']","At present, buildings in arid and hot regions are facing severe challenges of indoor comfort improvement and carbon emission reduction, especially in rural areas. Multi-objective optimization could be an effective tool for tackling the aforementioned challenges. Therefore, this paper proposes a life-cycle optimization framework considering thermal comfort, which is beneficial to promoting residents’ motivation for low-carbon retrofit in arid climate regions. First, in response to the above problems, three objective functions are specified in the framework, which are global warming potential (GWP), life cycle cost (LCC), and thermal discomfort hours (TDH). To improve the optimization efficiency, this research uses Deep Neural Networks (DNN) combined with NSGA-II to construct a high-precision prediction model (meta-model for optimization) based on the energy consumption simulation database formed by the orthogonal multi-dimensional design parameters. The accuracy index of the modified model is R 2 > 0.99, cv(RMSE) ≤ 1%, and NMBE ≤ 0.2%, which gets rid of the dilemma of low prediction accuracy of traditional machine learning models. In the scheme comparison and selection stage, the TOPSIS based on two empowerment methods is applied to meet different design tendencies, where the entropy-based method can avoid the interference of subjective preference and significantly improve the objectivity and scientific nature of decision analysis. Additionally, sensitivity analysis is conducted on the variables, which supports guidance for practitioners to carry out the low-carbon design. Finally, the multi-objective optimization analysis for a farmhouse in Turpan is taken as a case study to evaluate the performance of the framework. The results show that the framework could significantly improve the building performance, with 60.8%, 52.5%, and 14.2% reduction in GWP, LCC, and TDH, respectively.","['Engineering', 'Building Construction and Design', 'Engineering Thermodynamics, Heat and Mass Transfer', 'Atmospheric Protection/Air Quality Control/Air Pollution', 'Monitoring/Environmental Analysis']"
doi:10.1007/s12273-022-0935-7,en,Validation of virtual sensor-assisted Bayesian inference-based in-situ sensor calibration strategy for building HVAC systems,"['OriginalPaper', 'Research Article']","For building heating, ventilation and air-conditioning systems (HVACs), sensor faults significantly affect the operation and control. Sensors with accurate and reliable measurements are critical for ensuring the precise indoor thermal demand. Owing to its high calibration accuracy and in-situ effectiveness, a virtual sensor (VS)-assisted Bayesian inference (VS-BI) sensor calibration strategy has been applied for HVACs. However, the application feasibility of this strategy for wider ranges of different sensor types (within-control-loop and out-of-control-loop) with various sensor bias fault amplitudes, and influencing factors that affect the practical in-situ calibration performance are still remained to be explored. Hence, to further validate its in-situ calibration performance and analyze the influencing factors, this study applied the VS-BI strategy in a HVAC system including a chiller plant with air handle unit (AHU) terminal. Three target sensors including air supply (SAT), chilled water supply (CHS) and cooling water return (CWR) temperatures are investigated using introduced sensor bias faults with eight different amplitudes of [−2 °C, +2 °C] with a 0.5 °C interval. Calibration performance is evaluated by considering three influencing factors: (1) performance of different data-driven VSs, (2) the influence of prior standard deviations σ on in-situ sensor calibration and (3) the influence of data quality on in-situ sensor calibration from the perspective of energy conservation and data volumes. After comparison, a long short term memory (LSTM) is adopted for VS construction with determination coefficient R -squared of 0.984. Results indicate that σ has almost no impact on calibration accuracy of CHS but scanty impact on that of SAT and CWR. The potential of using a prior standard deviation σ to improve the calibration accuracy is limited, only 8.61% on average. For system within-control-loop sensors like SAT and CHS, VS-BI obtains relatively high in-situ sensor calibration accuracy if the data quality is relatively high.","['Engineering', 'Building Construction and Design', 'Engineering Thermodynamics, Heat and Mass Transfer', 'Atmospheric Protection/Air Quality Control/Air Pollution', 'Monitoring/Environmental Analysis']"
doi:10.1007/s12273-022-0933-9,en,A demand side management approach to increase self-consumption in buildings,"['OriginalPaper', 'Research Article']","There is a growing interest in increasing the presence of renewable energy in the electric network. Photovoltaic production from grid-connected systems is leading this growth in terms of households. Alongside this development, concern about network security has emerged, because excesses of intermittent renewable energy on the grid could exceed voltage limits. Self-consumption, understood as the capacity of the producer to consume his or her own production, can partially solve these problems. Thermostatic controllable loads, such as heating and cooling, represent 50% of the total amount of energy consumed by buildings; the proper allocation of these loads could be a driving force for self-consumption. In this study, a demand side management strategy is proposed based on a building energy model equipped with an inverter heat pump coupled with a photovoltaic plant. The goal is to maximize the use of local energy from the photovoltaic plant (self-consumption), reducing the export and import of energy to and from the grid. This goal is achieved by optimizing the set-points in each room. An array of optimal set-points over six years is presented. The results show the capacity of the methodology to match similar values of self-consumption (70% in winter and 50% in summer) obtained by strategies based on chemical batteries. The findings are shown in an energy matching chart at different levels of detail (yearly and monthly). Color bubbles are added to the matching chart to help visualize the unmatched energy of the system graphically. In comparison with actual model predictive control technologies, this study’s strategy offers great simplicity and a large saving in computational time.","['Engineering', 'Building Construction and Design', 'Engineering Thermodynamics, Heat and Mass Transfer', 'Atmospheric Protection/Air Quality Control/Air Pollution', 'Monitoring/Environmental Analysis']"
doi:10.1007/s12273-022-0936-6,en,Nationwide evaluation of energy and indoor air quality predictive control and impact on infection risk for cooling season,"['OriginalPaper', 'Research Article']","Since the coronavirus disease 2019, the extended time indoors makes people more concerned about indoor air quality, while the increased ventilation in seeks of reducing infection probability has increased the energy usage from heating, ventilation, and air-conditioning systems. In this study, to represent the dynamics of indoor temperature and air quality, a coupled grey-box model is developed. The model is identified and validated using a data-driven approach and real-time measured data of a campus office. To manage building energy usage and indoor air quality, a model predictive control strategy is proposed and developed. The simulation study demonstrated 18.92% energy saving while maintaining good indoor air quality at the testing site. Two nationwide simulation studies assessed the overall energy saving potential and the impact on the infection probability of the proposed strategy in different climate zones. The results showed 20%–40% energy saving in general while maintaining a predetermined indoor air quality setpoint. Although the infection risk is increased due to the reduced ventilation rate, it is still less than the suggested threshold (2%) in general.","['Engineering', 'Building Construction and Design', 'Engineering Thermodynamics, Heat and Mass Transfer', 'Atmospheric Protection/Air Quality Control/Air Pollution', 'Monitoring/Environmental Analysis']"
doi:10.1007/s12273-022-0927-7,en,Monitoring the green evolution of vernacular buildings based on deep learning and multi-temporal remote sensing images,"['OriginalPaper', 'Cover Article']","The increasingly mature computer vision (CV) technology represented by convolutional neural networks (CNN) and available high-resolution remote sensing images (HR-RSIs) provide opportunities to accurately measure the evolution of natural and artificial environments on Earth at a large scale. Based on the advanced CNN method high-resolution net (HRNet) and multi-temporal HR-RSIs, a framework is proposed for monitoring a green evolution of courtyard buildings characterized by their courtyards being roofed (CBR). The proposed framework consists of an expert module focusing on scenes analysis, a CV module for automatic detection, an evaluation module containing thresholds, and an output module for data analysis. Based on this, the changes in the adoption of different CBR technologies (CBRTs), including light-translucent CBRTs (LT-CBRTs) and non-light-translucent CBRTs (NLT-CBRTs), in 24 villages in southern Hebei were identified from 2007 to 2021. The evolution of CBRTs was featured as an inverse S-curve, and differences were found in their evolution stage, adoption ratio, and development speed for different villages. LT-CBRTs are the dominant type but are being replaced and surpassed by NLT-CBRTs in some villages, characterizing different preferences for the technology type of villages. The proposed research framework provides a reference for the evolution monitoring of vernacular buildings, and the identified evolution laws enable to trace and predict the adoption of different CBRTs in a particular village. This work lays a foundation for future exploration of the occurrence and development mechanism of the CBR phenomenon and provides an important reference for the optimization and promotion of CBRTs.","['Engineering', 'Building Construction and Design', 'Engineering Thermodynamics, Heat and Mass Transfer', 'Atmospheric Protection/Air Quality Control/Air Pollution', 'Monitoring/Environmental Analysis']"
doi:10.1007/s12273-022-0938-4,en,Timetabling optimization of classrooms and self-study rooms in university teaching buildings based on the building controls virtual test bed platform considering energy efficiency,"['OriginalPaper', 'Research Article']","The energy consumption of a teaching building can be effectively reduced by timetable optimization. However, in most studies that explore methods to reduce building energy consumption by course timetable optimization, self-study activities are not considered. In this study, an MATLAB-EnergyPlus joint simulation model was constructed based on the Building Controls Virtual Test Bed platform to reduce building energy consumption by optimizing the course schedule and opening strategy of self-study rooms in a holistic way. The following results were obtained by taking a university in Xi’an as an example: (1) The energy saving percentages obtained by timetabling optimization during the heating season examination week, heating season non-examination week, cooling season examination week, and cooling season non-examination week are 35%, 29.4%, 13.4%, and 13.4%, respectively. (2) Regarding the temporal arrangement, most courses are scheduled in the morning during the cooling season and afternoon during the heating season. Regarding the spatial arrangement, most courses are arranged in the central section of the middle floors of the building. (3) During the heating season, the additional building energy consumption incurred by the opening of self-study rooms decreases when duty heating temperature increases.","['Engineering', 'Building Construction and Design', 'Engineering Thermodynamics, Heat and Mass Transfer', 'Atmospheric Protection/Air Quality Control/Air Pollution', 'Monitoring/Environmental Analysis']"
doi:10.1007/s00376-022-2037-y,en,Objective Identification and Climatic Characteristics of Heavy-Precipitation Northeastern China Cold Vortexes,"['OriginalPaper', 'Original Paper']","The northeastern China cold vortex (NCCV) plays an important role in regional rainstorms over East Asia. Using the National Centers for Environmental Prediction Final reanalysis dataset and the Global Precipitation Measurement product, an objective algorithm for identifying heavy-precipitation NCCV (HPCV) events was designed, and the climatological features of 164 HPCV events from 2001 to 2019 were investigated. The number of HPCV events showed an upward linear trend, with the highest frequency of occurrence in summer. The most active region of HPCV samples was the Northeast China Plain between 40°–55°N. Most HPCV events lasted 3–5 days and had radii ranging from 250 to 1000 km. The duration of HPCV events with larger sizes was longer. About half of the HPCV events moved into (moved out of) the definition region (35°–60°N, 115°–145°E), and half initiated (dissipated) within the region. The initial position was close to the western boundary of the definition region, and the final position was mainly near the eastern boundary. The locations associated with the precipitation were mostly concentrated within 2000 km southeast of the HPCV systems, and they were farther from the center in the cold season than in the warm season. 东北冷涡(NCCV)是影响东亚地区暴雨的重要环流系统。本文利用美国国家环境预测中心的全球再分析资料(NCEP_FNL)和全球降水测量计划卫星反演的降水数据(GPM_IMERG),建立了一套强降水型东北冷涡(Heavy-Precipitation NCCV, HPCV)的客观识别算法,并对2001–19年共164个HPCV过程的特征进行了分析研究。结果表明,HPCV呈现增加的趋势,且夏季发生频次最高。HPCV主要活动于40°–55° N的东北平原上。大部分HPCV过程的持续时间是3–5天,半径在250–1000 km之间。尺度较大的HPCV过程持续时间也较长。在本文的研究区域(35°–60°N, 115°–145°E)内,55.83% (51.53%)的HPCV过程是移入(移出)的,其余的则是在原地生成(消亡)的。在研究区域内,HPCV过程的初始位置主要在西边界,而结束位置则在东边界附近。强降水主要落在HPCV系统东南方向2000 km的范围内,与暖季相比,冷季强降水落区与HPCV中心的距离更远。","['Earth Sciences', 'Atmospheric Sciences', 'Meteorology', 'Geophysics/Geodesy']"
doi:10.1007/s00376-022-1445-3,en,A New Sensitivity Analysis Approach Using Conditional Nonlinear Optimal Perturbations and Its Preliminary Application,"['OriginalPaper', 'Original Paper']","Simulations and predictions using numerical models show considerable uncertainties, and parameter uncertainty is one of the most important sources. It is impractical to improve the simulation and prediction abilities by reducing the uncertainties of all parameters. Therefore, identifying the sensitive parameters or parameter combinations is crucial. This study proposes a novel approach: conditional nonlinear optimal perturbations sensitivity analysis (CNOPSA) method. The CNOPSA method fully considers the nonlinear synergistic effects of parameters in the whole parameter space and quantitatively estimates the maximum effects of parameter uncertainties, prone to extreme events. Results of the analytical g-function test indicate that the CNOPSA method can effectively identify the sensitivity of variables. Numerical results of the theoretical five-variable grassland ecosystem model show that the maximum influence of the simulated wilted biomass caused by parameter uncertainty can be estimated and computed by employing the CNOPSA method. The identified sensitive parameters can easily change the simulation or prediction of the wilted biomass, which affects the transformation of the grassland state in the grassland ecosystem. The variance-based approach may underestimate the parameter sensitivity because it only considers the influence of limited parameter samples from a statistical view. This study verifies that the CNOPSA method is effective and feasible for exploring the important and sensitive physical parameters or parameter combinations in numerical models. 数值模式中物理参数的不确定性是数值模拟和预测不确定性的重要来源之一。由于数值模式中包含大量的物理过程和参数，通过减少所有物理参数的不确定性以提高数值模式的模拟能力和预测技巧将花费大量的人力和物力。因此，识别敏感的参数或参数组合至关重要。本研究提出了一种识别物理参数敏感性的新方法：条件非线性最优扰动敏感性分析（CNOPSA）方法。该方法克服了传统方法的局限性，在参数不确定性范围内充分考虑了物理参数间的非线性协同效应，可识别出相对敏感和重要的物理参数和参数组合，并定量估计出由物理参数变化导致的数值模拟和预测不确定性的最大程度，因而适用于对极端事件的研究。 利用理论的g-函数和五变量草原生态系统模型检验了CNOPSA方法的可行性和有效性，结果表明CNOPSA方法可以有效地识别物理变量和物理参数的敏感性。本文进一步利用该方法，定量地估计了由物理参数不确定性导致的该草原生态系统模型中枯草量模拟和预测不确定性的最大程度，识别出的敏感参数的变化易使得草原生态系统发生突变。然而，基于方差分析的参数敏感性分析方法，仅从统计的角度考虑有限的参数样本，易低估物理参数的敏感性。","['Earth Sciences', 'Atmospheric Sciences', 'Meteorology', 'Geophysics/Geodesy']"
doi:10.1007/s12273-022-0939-3,en,Modelling occupant behaviour for urban scale simulation: Review of available approaches and tools,"['ReviewPaper', 'Review Article']","Urban building energy modelling (UBEM) is considered one of the high-performance computational tools that enable analyzing energy use and the corresponding emission of different building sectors at large scales. However, the efficiency of these models relies on their capability to estimate more realistic building performance indicators at different temporal and spatial scales. The uncertainty of modelling occupants’ behaviours (OB) aspects is one of the main reasons for the discrepancy between the UBEM predicted results and the building’s actual performance. As a result, research efforts focused on improving the approaches to model OB at an urban scale considering different diversity factors. On the other hand, the impact of occupants in the current practice is still considered through fixed schedules and behaviours pattern. To bridge the gap between academic efforts and practice, the applicability of OB models to be integrated into the available UBEM tools needs to be analyzed. To this end, this paper aims to investigate the flexibility and extensibility of existing UBEM tools to model OB with different approaches by (1) reviewing UBEM’s current workflow and the main characteristics of its inputs, (2) reviewing the existing OB models and identifying their main characteristics and level of details that can contribute to UBEM accuracy, (3) providing a breakdown of the occupant-related features in the commonly used tools. The results of this investigation are relevant to researchers and tool developers to identify areas for improvements, as well as urban energy modellers to understand the different approaches to model OB in available tools.","['Engineering', 'Building Construction and Design', 'Engineering Thermodynamics, Heat and Mass Transfer', 'Atmospheric Protection/Air Quality Control/Air Pollution', 'Monitoring/Environmental Analysis']"
doi:10.1007/s00376-022-2116-0,en,"Ground-Based Atmospheric CO2, CH4, and CO Column Measurements at Golmud in the Qinghai-Tibetan Plateau and Comparisons with TROPOMI/S5P Satellite Observations","['OriginalPaper', 'Original Paper']","Measurements of carbon dioxide (CO 2 ), methane (CH 4 ), and carbon monoxide (CO) are of great importance in the Qinghai-Tibetan region, as it is the highest and largest plateau in the world affecting global weather and climate systems. In this study, for the first time, we present CO 2 , CH 4 , and CO column measurements carried out by a Bruker EM27/SUN Fourier-transform infrared spectrometer (FTIR) at Golmud (36.42°E, 94.91°N, 2808 m) in August 2021. The mean and standard deviation of the column-average dry-air mixing ratio of CO 2 , CH 4 , and CO (XCO 2 , XCH 4 , and XCO) are 409.3 ± 0.4 ppm, 1905.5 ± 19.4 ppb, and 103.1 ± 7.7 ppb, respectively. The differences between the FTIR co-located TROPOMI/S5P satellite measurements at Golmud are 0.68 ± 0.64% (13.1 ± 12.2 ppb) for XCH 4 and 9.81 ± 3.48% (−10.7 ± 3.8 ppb) for XCO, which are within their retrieval uncertainties. High correlations for both XCH 4 and XCO are observed between the FTIR and S5P satellite measurements. Using the FLEXPART model and satellite measurements, we find that enhanced CH 4 and CO columns in Golmud are affected by anthropogenic emissions transported from North India. This study provides an insight into the variations of the CO 2 , CH 4 , and CO columns in the Qinghai-Tibetan Plateau. 由于其独特的地质地貌与海拔高度,青藏高原对全球天气与气候系统影响显著。研究青藏高原地区大气中的二氧化碳（CO2）、甲烷（CH4）和一氧化碳（CO）浓度变化特征对全球气候变化分析具有重要的科学意义。在此背景下,我们于2021年8月,在青海省格尔木市气象局（36.42ºE, 94.91ºN, 2808 米）开展了地基红外傅里叶光谱仪（Bruker EM27/SUN）高光谱观测实验,反演获得了高精度的CO2、CH4和CO柱浓度资料,并对欧洲哨兵-5P号TROPOMI卫星在该地区的观测进行了误差分析。研究发现,2021年8月份格尔木地区上空CO2、CH4和CO柱平均浓度分别为409.3 ± 0.4 ppm, 1905.5 ± 19.4 ppb, 与 103.1 ± 7.7 ppb；TROPOMI卫星在格尔木地区的观测误差满足其设计的观测精度要求,卫星与地基的CH4柱平均浓度相差为0.68 ± 0.64% (13.1 ± 12.2 ppb),CO柱平均浓度相差为9.81 ± 3.48% (–10.7 ± 3.8 ppb)；TROPOMI卫星与地基的观测具有很高的相关性（R>0.85）,表明卫星观测资料在青海格尔木地区能获得大气中CH4和CO柱浓度的变化信号；利用大气传输模式（FLEXPART）,揭示了格尔木地区CH4和CO柱浓度的升高受到来自印度地区的传输影响。本研究为青藏高原温室气体浓度变化提供了新的观测资料与研究思路。","['Earth Sciences', 'Atmospheric Sciences', 'Meteorology', 'Geophysics/Geodesy']"
doi:10.1007/s00376-022-1472-0,en,Possibility of Solid Hydrometeor Growth Zone Identification Using Radar Spectrum Width,"['OriginalPaper', 'Original Paper']","In this study, the correlation between simulated and measured radar velocity spectrum width ( σ v ) is investigated. The results show that the dendrites growth zones (DGZs) and needles growth zones (NGZs) mostly contain dendrites (DN) and needles (NE), respectively. Clear σ v zones (1.1 < σ v (m s −1 ) < 1.3 and 0.3 < σ v (m s −1 ) < 0.7 for the DGZ and NGZ, respectively) could be identified in the case studies (27 and 28 February 2016) near altitudes corresponding to temperatures of −15°C and −5°C, according to the Japan Meteorological Agency and mesoscale model reanalysis data. Oblate particles with diverse particle shapes were observed in the DGZ with σ V > 1.2 m s −1 , a differential reflectivity (Z DR ) higher than 0 dB, and a cross-correlation coefficient ( ρ hv ) less than 0.96. In contrast, prolate particles with relatively uniform shapes were observed in the NGZ with σ v < 0.6 m s −1 , a Z DR less than 0 dB, and ρ hv higher than 0.97. The simulation results show that the DN exhibited a larger σ v compared to the NE, and this observed σ v was strongly dependent on the wind fluctuations ( v ’) due to turbulence or wind shear. In contrast, the NE exhibited a significantly small σ v ∼ 0.55 m s −1 , which converges irrespective of v ’. In addition, a strong correlation between the measured σ v values at five radar elevation angles ( θ = 6.2°, 9.1°, 13.1°, 19°, and 80°) and those simulated in this study confirmed the significance of the analysis results. 本文研究了模拟和实测雷达速度谱宽之间的相关性。结果表明,枝状固态水凝物增长区（DGZs）和针状固态水凝物增长区（NGZs）主要分别含有枝状冰晶（DN）和针状冰晶（NE）。 根据日本气象厅和中尺度模式再分析数据,在与-15°C和-5°C温度相对应的高度附近案例（2016年2月27日和28日）的研究中,雷达速度谱宽区（DGZ的雷达速度谱宽范围是1.1 m s –1 至 1.3 m s –1 ,NGZ的雷达速度谱宽范围是0.3 m s –1 至 0.7 m s –1 ）可以被清晰地识别出来。在DGZ中观察到具有不同颗粒形状的扁椭球粒子,其雷达速度谱宽大于1.2 m s –1 ,差分反射率高于0 dB,互相关系数小于0.96。相比之下,在NGZ中,观察到具有相对均匀形状的长椭球粒子,其雷达速度谱宽小于0.6 m s –1 ,差分反射率小于0 dB,互相关系数高于0.97。 模拟结果表明,与NE相比,DN对应着更大的雷达速度谱宽,并且观测到的雷达速度谱宽强烈依赖于湍流或风切变引起的风波动。相比之下,NE表现出明显较小的雷达速度谱宽~ 0.55 m s –1 ,其收敛与风波动无关。此外,在五个雷达仰角（θ=6.2°、9.1°、13.1°、19°和80°）下测得的雷达速度谱宽值与本研究中模拟得到的雷达速度谱宽值之间表现出一种强相关性,印证了分析结果的重要性。","['Earth Sciences', 'Atmospheric Sciences', 'Meteorology', 'Geophysics/Geodesy']"
doi:10.1007/s12273-022-0931-y,en,Physics-informed machine learning for metamodeling thermal comfort in non-air-conditioned buildings,"['OriginalPaper', 'Research Article']","There is a growing need for accurate and interpretable machine learning models of thermal comfort in buildings. Physics-informed machine learning could address this need by adding physical consistency to such models. This paper presents metamodeling of thermal comfort in non-air-conditioned buildings using physics-informed machine learning. The studied metamodel incorporated knowledge of both quasi-steady-state heat transfer and dynamic simulation results. Adaptive thermal comfort in an office located in cold and hot European climates was studied with the number of overheating hours as index. A one-at-a-time method was used to gain knowledge from dynamic simulation with TRNSYS software. This knowledge was used to filter the training data and to choose probability distributions for metamodel forms alternative to polynomial. The response of the dynamic model was positively skewed; and thus, the symmetric logistic and hyperbolic secant distributions were inappropriate and outperformed by positively skewed distributions. Incorporating physical knowledge into the metamodel was much more effective than doubling the size of the training sample. The highly flexible Kumaraswamy distribution provided the best performance with R 2 equal to 0.9994 for the cold climate and 0.9975 for the hot climate. Physics-informed machine learning could combine the strength of both physics and machine learning models, and could therefore support building design with flexible, accurate and interpretable metamodels.","['Engineering', 'Building Construction and Design', 'Engineering Thermodynamics, Heat and Mass Transfer', 'Atmospheric Protection/Air Quality Control/Air Pollution', 'Monitoring/Environmental Analysis']"
doi:10.1007/s00376-022-2091-5,en,Elucidating Dominant Factors Affecting Land Surface Hydrological Simulations of the Community Land Model over China,"['OriginalPaper', 'Original Paper']","In order to compare the impacts of the choice of land surface model (LSM) parameterization schemes, meteorological forcing, and land surface parameters on land surface hydrological simulations, and explore to what extent the quality can be improved, a series of experiments with different LSMs, forcing datasets, and parameter datasets concerning soil texture and land cover were conducted. Six simulations are run for the Chinese mainland on 0.1° × 0.1° grids from 1979 to 2008, and the simulated monthly soil moisture (SM), evapotranspiration (ET), and snow depth (SD) are then compared and assessed against observations. The results show that the meteorological forcing is the most important factor governing output. Beyond that, SM seems to be also very sensitive to soil texture information; SD is also very sensitive to snow parameterization scheme in the LSM. The Community Land Model version 4.5 (CLM4.5), driven by newly developed observation-based regional meteorological forcing and land surface parameters (referred to as CMFD_CLM4.5_NEW), significantly improved the simulations in most cases over the Chinese mainland and its eight basins. It increased the correlation coefficient values from 0.46 to 0.54 for the SM modeling and from 0.54 to 0.67 for the SD simulations, and it decreased the root-mean-square error (RMSE) from 0.093 to 0.085 for the SM simulation and reduced the normalized RMSE from 1.277 to 0.201 for the SD simulations. This study indicates that the offline LSM simulation using a refined LSM driven by newly developed observation-based regional meteorological forcing and land surface parameters can better model reginal land surface hydrological processes. 本文利用不同模式参数化方案、气象强迫和地表参数设计了六个模拟试验，并与观测进行对比分析，揭示了影响中国区域陆面水文要素（土壤湿度、蒸散发和雪深等）模拟的主要因子。结果表明，气象强迫是陆面水文过程模拟的主要影响因子，土壤湿度和雪深的模拟分别与土壤质地信息和陆面模式参数化方案紧密相关。利用新发展的融合观测信息的中国区域气象强迫和地表参数信息驱动陆面模式模拟，显著提高了中国大部分区域陆面水文过程模拟精度，并减少了模拟的不确定性。土壤湿度模拟与观测的相关系数从0.46提高到0.54，雪深模拟与观测的相关系数从0.54提高到0.67；土壤湿度模拟与观测的均方根误差从0.093降低到0.085，雪深模拟与观测的均方根误差从1.277降低到0.201。","['Earth Sciences', 'Atmospheric Sciences', 'Meteorology', 'Geophysics/Geodesy']"
doi:10.1007/s00376-022-2267-z,en,Ground-Space-Sky Observing System Experiment during Tropical Cyclone Mulan in August 2022,"['News', 'News & Views']","Forecasting tropical cyclone track and intensity is a great challenge for the meteorological community, and safeguarding the life and property of people living near the coast is an important issue. One major reason for challenging forecasts is the lack of observations over the vast oceans. During tropical cyclone Mulan between 8 and 10 August 2022 over the northern part of the South China Sea, the meteorological authority and research institutes of Chinese mainland collaborated with the meteorological service in Hong Kong on conducting the first-ever ground-space-sky observing system experiment on tropical cyclone Mulan. The enhanced targeted observations collected during the experiment include Geostationary Interferometric Infrared Sounder, round-trip radiosondes, and aircraft-launched dropsondes. This paper describes the campaign, technical details of the meteorological models used, and impact of the additional targeted observation data on the tropical cyclone forecast. Ideally, similar enhanced observation campaigns could be conducted in the future, not only in the northern part of the South China Sea, but also in other ocean basins. 缺乏观测数据是台风路径和强度预报面临的一个巨大挑战。2022年8月8−10日间，中国气象局地球系统数值预报中心，联合国家卫星气象中心、国家气象中心、中国气象局大气探测中心，以及中国科学院大气物理研究所大气科学与地球流体力学数值模拟国家重点实验室、复旦大学大气海洋科学系和香港天文台等高校与科研业务单位，在我国南海上空、针对台风木兰（2022）开展了首次地空天观测系统试验。通过风云四号卫星高光谱探测仪、机载下投探空仪、和往返平飘式探空仪获得了宝贵的观测资料。文章对试验方法、试验过程及观测数据对台风实时预报的改进进行了介绍，并以此将推动相关台风观测试验在我国海域的实施。","['Earth Sciences', 'Atmospheric Sciences', 'Meteorology', 'Geophysics/Geodesy']"
doi:10.1007/s40544-022-0610-0,en,Molecules with a TEMPO-based head group as high-performance organic friction modifiers,"['OriginalPaper', 'Research Article']","High-performance organic friction modifiers (OFMs) added to lubricating oils are crucial for reducing energy loss and carbon footprint. To establish a new class of OFMs, we measured the friction and wear properties of N-(2,2,6,6-tetramethyl-1-oxyl-4-piperidinyl)dodecaneamide referred to as C 12 Amide-TEMPO. The effect of its head group chemistry, which is characterized by a rigid six-membered ring sandwiched by an amide group and a terminal free oxygen radical, was also investigated with both experiments and quantum mechanical (QM) calculations. The measurement results show that C 12 Amide-TEMPO outperforms the conventional OFMs of glyceryl monooleate (GMO) and stearic acid, particularly for load-carrying capacity, wear reduction, and stability of friction over time. The friction and wear reduction effect of C 12 Amide-TEMPO is also greatly superior to those of C 12 Ester-TEMPO and C 12 Amino-TEMPO, in which ester and amino groups replace the amide group, highlighting the critical role of the amide group. The QM calculation results suggest that, in contrast to C 12 Ester-TEMPO, C 12 Amino-TEMPO, and the conventional OFMs of GMO and stearic acid, C 12 Amide-TEMPO can form effective boundary films on iron oxide surfaces with a unique double-layer structure: a strong surface adsorption layer owing to the chemical interactions of the amide oxygen and free radical with iron oxide surfaces, and an upper layer owing to the interlayer hydrogen-bonding between the amide hydrogen and free radical or between the amide hydrogen and oxygen. Moreover, the intralayer hydrogen-bonding in each of the two layers is also possible. We suggest that in addition to strong surface adsorption, the interlayer and intralayer hydrogen-bonding also increases the strength of the boundary films by enhancing the cohesion strength, thereby resulting in the high tribological performance of C 12 Amide-TEMPO. The findings in this study are expected to provide new hints for the optimal molecular design of OFMs.","['Engineering', 'Mechanical Engineering', 'Nanotechnology', 'Tribology, Corrosion and Coatings', 'Physical Chemistry', 'Surfaces and Interfaces, Thin Films']"
doi:10.1007/s12273-022-0942-8,en,A modelling method for large-scale open spaces orientated toward coordinated control of multiple air-terminal units,"['OriginalPaper', 'Research Article']","The temperature distribution is always assumed to be homogeneous in a traditional single-input-single-output (SISO) air conditioning control strategy. However, the airflow inside is more complicated and unpredictable. This study proposes a zonal temperature control strategy with a thermal coupling effect integrated for air-conditioned large-scale open spaces. The target space was split into several subzones based on the minimum controllable air terminal units in the proposed method, and each zone can be controlled to its own set-point while considering the thermal coupling effect from its adjacent zones. A numerical method resorting to computational fluid dynamics was presented to obtain the heat transfer coefficients (HTCs) under different air supply scenarios. The relationship between heat transfer coefficient and zonal temperature difference was linearized. Thus, currently available zonal models in popular software can be used to simulate the dynamic response of temperatures in large-scale indoor open spaces. Case studies showed that the introduction of HTCs across the adjacent zones was capable of enhancing the precision of temperature control of large-scale open spaces. It could satisfy the temperature requirements of different zones, improve thermal comfort and at least 11% of energy saving can be achieved by comparing with the conventional control strategy.","['Engineering', 'Building Construction and Design', 'Engineering Thermodynamics, Heat and Mass Transfer', 'Atmospheric Protection/Air Quality Control/Air Pollution', 'Monitoring/Environmental Analysis']"
doi:10.1007/s12273-022-0943-7,en,Numerical evaluation of the use of vegetation as a shelterbelt for enhancing the wind and thermal comfort in peripheral and lateral-type skygardens in highrise buildings,"['OriginalPaper', 'Research Article']","Skygardens or skycourts are a unique architectural intervention in the built environment, enhancing the social, economic, and environmental values of the building. It allows occupants to connect and experience outdoor freshness within a semi-enclosed environment. However, skygardens located on a highrise building may generate intense wind gusts, endangering the safety of occupants. Using a validated computational fluid dynamics model, this study investigates the potential of various vegetative barriers or shelterbelts in attenuating the high wind speeds encountered in such spaces and the impact on wind and thermal comfort. Three skygarden configurations were investigated with and without vegetative barriers, simplified and modelled as porous zones, and their effect was studied on the velocity and temperature profile at the occupants’ level. The results indicate that while hedges and trees can offer resistance to airflow, trees provide higher temperature reduction. However, a combination of vegetative and geometrical barriers provides the most optimal condition in the skygarden. The study has identified the importance of assessing wind attenuation characteristics of tree plantations on highrise skygarden, and the results can be used in designing intervention strategies. Moreover, vegetation can attenuate pollutants and mitigate poor air quality by surface deposition, and future studies should investigate in that direction.","['Engineering', 'Building Construction and Design', 'Engineering Thermodynamics, Heat and Mass Transfer', 'Atmospheric Protection/Air Quality Control/Air Pollution', 'Monitoring/Environmental Analysis']"
doi:10.1007/s40544-022-0602-0,en,A new mechanism for friction-induced vibration and noise,"['OriginalPaper', 'Research Article']","For years, friction-induced vibration and noise (FIVN) has puzzled many researchers in academia and industry. Several mechanisms have been proposed for explaining its occurrence and quantifying its frequencies, notably for automotive brake squeal, clutch squeal, and even rail corrugation. However, due to the complex and complicated nature of FIVN, there is not yet one fundamental mechanism that can explain all phenomena of FIVN. Based on experimental results obtained on a simple test structure and corresponding numerical validation using both complex eigenvalue analysis (CEA) and transient dynamic analysis (TDA), this study attempts to propose a new fundamental mechanism for FIVN, which is the repeated cycles of partial detachment and then reattachment of the contact surfaces. Since friction is ubiquitous and FIVN is very common, the insight into FIVN reported in this paper is highly significant and will help establish effective means to control FIVN in engineering and daily life.","['Engineering', 'Mechanical Engineering', 'Nanotechnology', 'Tribology, Corrosion and Coatings', 'Physical Chemistry', 'Surfaces and Interfaces, Thin Films']"
doi:10.1007/s40544-021-0592-3,en,Investigation on the oil transfer behaviors and the air-oil interfacial flow patterns in a ball bearing under different capillary conditions,"['OriginalPaper', 'Research Article']","Lubricant oil is crucial to the rolling bearings as the main medium of lubricating, cooling, cleaning, and so on. The oil starvation in and around the contacts is harmful to the performance and fatigue life of rolling bearings. Therefore, it is of necessity to understand the behaviors of oil transfer and the patterns of air-oil two-phase flow in bearings, especially with the influence of different capillary properties. This work established a transient air-oil two-phase flow model in a ball bearing based on computational fluid dynamics (CFD). Groups of cases are implemented to investigate the behaviors of oil transfer and air-oil flow under different capillary conditions with speed, surface tension, and viscosity. Flow patterns are classified by the morphological features of the air-oil flow. Staged phenomena are analyzed with flow patterns and reach good agreements with the observations from experiments. It is found that the oil distribution and air-oil flow behaviors in a ball bearing are strongly related to the speed and the ratio of oil viscosity and air-oil surface tension ( μ oil / σ ). The flow maps imply that the levels of capillary number (Ca) may be the boundaries and the critical points of flow pattern transition between the different flow patterns in bearing.","['Engineering', 'Mechanical Engineering', 'Nanotechnology', 'Tribology, Corrosion and Coatings', 'Physical Chemistry', 'Surfaces and Interfaces, Thin Films']"
doi:10.1007/978-3-031-11089-4_5,en,Understanding Algorithms,OriginalPaper,"Algorithms account for an ever-larger component of the central government’s operations and actions, and hence perform an ever-important role in the delivery of public services to citizens and businesses. We analysed the activities and processes for which central government and its associated organisations use algorithms, classified these into categories, and identified the risks involved in the use of algorithms. In addition, we examined how central government and its associated organisations manage the operation and control the quality of algorithms. Most of the algorithms used by central government are relatively simple. They have a limited effect on private individuals, as it is only such relatively simple algorithms that take automatic decisions. Many of these decisions involve the automation of certain administrative activities, for example the automated sending of letters confirming the receipt of a communication. We did not find any fully self-learning algorithms in central government, only learning algorithms. We urge governments to evaluate algorithms on basis of a predetermined set of criteria and present a framework for such evaluations.","['Business and Management', 'IT in Business', 'Software Management', 'Risk Management', 'Systems and Data Security']"
doi:10.1007/978-981-19-7636-0_4,en,Current Application Fields,OriginalPaper,"With the rapid social and technological development in recent years, a torrent of new applications continue to emerge, demanding computing power far beyond the past.","['Engineering', 'Electronics and Microelectronics, Instrumentation', 'Circuits and Systems', 'Processor Architectures', 'Control Structures and Microprogramming', 'Logic Design']"
doi:10.1007/978-3-031-17544-2_1,en,Nature-Inspired Optimization Algorithms: Past to Present,OriginalPaper,"Nature-inspired algorithms are class of novel methods and processes for computing, analyzing, and solving various optimization problems. Nature-Inspired Optimization Algorithms (NIOAs) are bio inspired computational intelligence techniques gives an enormous drive for solving many complex problem as it exploits an exceptionally unique, strong, convincing and engaging behavior which is competent to give ideal outcomes. In the past few decades, several Nature-Inspired Optimization Algorithms has been proposed. However, very limited efforts have been made to provide a comprehensive investigation of NIOAs. In this chapter we present an overview of most significant NIOAs established from past to present days and their role in resolving complex computationally hard problems in various field of application. This overview endeavors to give a more extensive point of view and significant illumination to comprehend NIOAs. This also features the achievement, challenges and future research direction concerning recent NIOAs.","['Engineering', 'Computational Intelligence', 'Biomedical Engineering and Bioengineering', 'Health Informatics']"
doi:10.1007/978-981-19-6379-7_7,en,Overview and Classification of Swarm Intelligence-Based Nature-Inspired Computing Algorithms and Their Applications in Cancer Detection and Diagnosis,OriginalPaper,"With the emergence of nature-inspired computing (NIC) techniques, researchers have understood and modeled solutions for realistic and complex problems. NIC, a branch of artificial intelligence worked on the transferring of knowledge from natural phenomenon to engineered systems, applicable in various fields. Although there are many techniques to be used in disease diagnosis, NIC algorithms are very efficient and have gained more attention to problems of modern research. In recent years, these algorithms gained popularity in the detection and diagnosis of cancer, a life-threatening disease that led to a high rate of mortality in individuals. Swarm Intelligence (SI), one of the most used NIC-based algorithms motivated by the collection of social insects’ behavior such as termites, bees, wasps, etc. helps in solving various bioinformatics-related problems. Herein, a chapter has presented various nature-inspired computing intelligence algorithms, with more focus on different types of SI-based nature-inspired algorithms that focus on principles, developments, and application scopes. Further, the chapter has also described applications of SI-based algorithms in detecting and diagnosing different stages and types of cancers. Finally, it has focused on strengths and limitations followed by future directions of these techniques in cancer diagnosis.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Health Informatics', 'Cancer Research', 'Genetics and Genomics', 'Bioinformatics']"
doi:10.1007/978-3-031-15858-2_4,en,Model-Free Stabilization in the Presence of Actuator Saturation,OriginalPaper,"This chapter focuses on constrained control problems involving actuator saturation. A low gain feedback approach is adopted in the context of reinforcement learning (RL) to enable semi-global/global stabilization of a class of linear systems. The key to the connection between low gain feedback and RL is a novel low gain parameterized reward/utility function. Global results are obtained by scheduling the low gain design parameter. First, state feedback RL algorithms are developed that achieve model-free stabilization in the presence of actuator saturation. Output feedback schemes are developed based on the state parameterization results presented in Chap. 2. Effectiveness of the presented algorithms is demonstrated by numerical examples.","['Mathematics', 'Systems Theory, Control', 'Control and Systems Theory', 'Optimization']"
doi:10.1007/978-3-031-11089-4_7,en,Algorithm Assurance: Auditing Applications of Artificial Intelligence,OriginalPaper,"Algorithm assurance is a specific form of IT assurance that supports risk management and control on applications of risky algorithms in products and in organizations. These algorithms will often be characterized in organizations as applications of Artificial Intelligence (AI), as advanced analytics, or—simply—as predictive models. The aim of this chapter is to introduce the concept of algorithm assurance, to give some background on the relevance and importance of algorithm assurance, and to prepare the auditor for the basic skills needed to organize and execute an algorithm audit. In this chapter we will introduce the algorithm assurance engagement as a specific type of IT audit. After a general discussion of the background of algorithm assurance and the type of IT applications we are concerned with in this type of engagement, we will extensively discuss the scope of an algorithm assurance engagement, how to approach the risk assessment that should take place initially, how to set up and audit plan, and the audit techniques and tools that play a role in an audit plan.","['Business and Management', 'IT in Business', 'Software Management', 'Risk Management', 'Systems and Data Security']"
doi:10.1007/978-981-19-7636-0_5,en,Future Application Prospects,OriginalPaper,"Driven by artificial intelligence, cloud computing, autonomous driving, the Internet of Things, blockchain, quantum computing, and other emerging technologies and applications, computing systems are becoming data-driven, flexible and self-adaptive, diversified for different requirements and personalized scenarios.","['Engineering', 'Electronics and Microelectronics, Instrumentation', 'Circuits and Systems', 'Processor Architectures', 'Control Structures and Microprogramming', 'Logic Design']"
doi:10.1007/978-3-031-09835-2_12,en,A Comprehensive Review of the Firefly Algorithms for Data Clustering,OriginalPaper,"Separating a given data set into groups (clusters) based on their natural similar characteristics is one of the main concerns in data clustering. A cluster can be defined as a collection of objects which are “homogeneous” between them and are “heterogeneous” to the objects belonging to other clusters. Many areas encounter clustering based applications including the fields of medical, image processing, engineering, economics, social sciences, biology, machine learning and data mining. Clustering goes under unsupervised learning where no labels are given to the learning algorithm, leaving it on its own to find structure in its input. Even though many classical clustering algorithms can be found, most of such suffer from severe drawbacks such as sensitivity over initial cluster centroids and hence can be easily trapped in local optimum solutions. The other main problem with the data clustering algorithms is that it cannot be standardized. On the other hand, clustering can be considered under optimizations which goes to the category of NP hard optimization making more difficult in solving. Addressing such NP hard problems, meta-heuristics play a remarkable role in optimization. Since its appearance from more than a decade ago, Firefly Algorithm (FA), a stochastic meta- heuristic in nature inspired algorithms has shown significant performance in giving solutions to many optimization problems. Hence FA has been used in research addressing the problem of clustering optimization. This chapter forestalls the ability of firefly algorithm in solving data clustering problem. It presents an introduction to clustering and the performance of FA, briefly reviews and summarizes some of the recent firefly-based algorithms used for data clustering with the emphasis on how FA has been combined/ hybridized with other methods to contribute to the problem of data clustering. Further it discusses on different representations, initializations, and the used cluster validation criteria in FA based clustering methods. The chapter also discusses why FA is to be more useful for clustering over other methods and what features made it more suitable for handling the clustering problem compared with other meta-heuristics. Finally, it focuses on the limitations that have been found in the literature on clustering grounded on FA-based applications and discusses possible avenues in future.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5579-2_6,en,Active Control of Vehicle Interior Sound Quality,OriginalPaper,"The control methods for sound quality can be divided into PNC and ANC (active noise control), and the energy of vehicle interior noise is mainly concentrated in the middle and low-frequency range. The PNC method is mainly introduced in the last chapter. The traditional PNC method based on sound absorption and isolation is ineffective because of the long acoustic wave of low-frequency noise, while the ANC method shows great potential, and the control algorithms play an important role in studying this method. In this chapter, various ANC algorithms and simulation analyses are introduced to present the effectiveness of the ANC method on vehicle interior SQ. First, based on sine function, an improved FxLMS algorithm with variable step size (VS-FxLMS) is proposed, which avoids the inherent defect that traditional FxLMS algorithm cannot simultaneously improve convergence speed and reduce steady-state error. The improved VS-FxLMS algorithm is realized by modifying the traditional FxLMS algorithm and the original VS-FxLMS algorithm. In the research of the ANC method, the application of ANC algorithm and strategy is the key to affecting the control effect of vehicle SQ. The time-domain FxLMS (TD-FxLMS) algorithm is effective in suppressing low-frequency noise, the frequency domain block FxLMS (FB-FxLMS) algorithm is effective in suppressing middle and high-frequency noise, and the time and frequency domain FxLMS algorithm can effectively deal with unsteady noise. This chapter proposes a new normalized FB-FxLMS (NFB-FxLMS) algorithm based on the Fast Fourier Transform (FFT) and overlapping retention method, and the algorithm’s effectiveness is verified by simulation analysis. In addition, the DWT-FxLMS (discrete-wavelet-transform-based FxLMS) algorithm based on piezoelectric effect and ANC algorithm combining piezoelectric equations and the improved fuzzy control algorithm are introduced, and the simulations are carried out.","['Engineering', 'Mechanical Engineering', 'Engineering Acoustics', 'Signal, Image and Speech Processing']"
doi:10.1007/978-3-031-15858-2_3,en,Model-Free H∞ Disturbance Rejection and Linear Quadratic Zero-Sum Games,OriginalPaper,"This chapter deals with the design of reinforcement learning algorithms for solving the optimal/sub-optimal disturbance rejection problem of linear systems. We consider the classical H ∞ control problem (the partial information case) by bringing ideas from game theory to arrive at a two-player zero-sum game formulation, which sets itself apart from the single agent design in the previous chapter. Output feedback results build upon the state parameterization approach introduced in Chap. 2 by including the disturbance in the state reconstruction. The corresponding rank conditions for this extended parameterization are then discussed. New learning equations are obtained that enable us to solve the problem using only the input-output data without requiring any knowledge of the internal state or the system model. Simulation studies are presented that validate the efficacy of the presented algorithms.","['Mathematics', 'Systems Theory, Control', 'Control and Systems Theory', 'Optimization']"
doi:10.1007/978-981-19-6379-7_8,en,Nature-Inspired Computing: Scope and Applications of Artificial Immune Systems Toward Analysis and Diagnosis of Complex Problems,OriginalPaper,"The interdisciplinary field of nature-inspired computing is a combination of combining nature computing science of biology, chemistry, physics, engineering, and mathematics which allows the development of new computational hardware, algorithms, or wetware for diagnosing, problem-solving, behaviors of organisms, and synthesis of patterns. Artificial immune systems (AIS) are a sub-field of biologically-inspired computing through machine learning and artificial intelligence (AI). AIS is new algorithm developed from the principles of the human immune system. The AIS is conceptualizing the structure and function of the immune system to computational systems and investigating the applications of the immune system toward solving computational problems. AIS is a dynamic research area used for fault detection, diagnosis, optimization problems, and various approaches to AIS have wide applications. In this chapter, we made an attempt to describe the role of AIS in data analysis and providing solutions for complex diagnostic problems.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Health Informatics', 'Cancer Research', 'Genetics and Genomics', 'Bioinformatics']"
doi:10.1007/978-3-031-19715-4_6,en,Artificial Intelligence and Learning Algorithms,OriginalPaper,"This chapter outlines vividly the details of Artificial Intelligence and Learning algorithms. It elaborates the types of AI and the operating principle along with intricate details about the sub domains, ML and DL. This section provides a basic comprehension on the fundamentals of AI.","['Engineering', 'Biomedical Engineering and Bioengineering', 'Dentistry', 'Artificial Intelligence', 'Machine Learning']"
doi:10.1007/978-3-031-11089-4_6,en,Keeping Control on Deep Learning Image Recognition Algorithms,OriginalPaper,"In this chapter a framework is presented to control machine learning applications. This framework is based on the case of a major insurance company that applied a machine learning application to supports damage reports after a major hailstorm. This hailstorm caused severe damage to greenhouses in two provinces in the Netherlands. The study concludes that the internal control framework of the Courts of Audit presented in chapter “Understanding Algorithms” provides a solid basis for risk management. Furthermore, several additional risk areas are presented.","['Business and Management', 'IT in Business', 'Software Management', 'Risk Management', 'Systems and Data Security']"
doi:10.1007/978-3-031-18344-7_2,en,Hybrid Meta-heuristic Genetic Algorithm: Differential Evolution Algorithms for Scientific Workflow Scheduling in Heterogeneous Cloud Environment,OriginalPaper,"The gaint cabailities of cloud computing in providing online services via Internet attract the attention of the distributed sector due to its huge abilities that include storage, processing, software, databases, and servers that are shared simultaneously over the Internet by remote users geographically dispersed. Increasing the enormous amount of generating data through big data platforms and the use of IoT devices connected via the network have exploited the computational power of the cloud. However, the high utilization of the cloud leads to a longer execution time for a specific task. This paper proposing the hybrid strategy of scheduling the workflow in cloud computing called Genetic Algorithm with Differential Evolution (GA-DE). This research aims to investigate how heterogeneous cloud computing affects workflow scheduling. This study is aimed at reducing makespan and verifying if the metaheuristic technology is more suitable for the distributed environment by comparing it to existing heuristics, such as HEFT-Downward Rank,HEFT-Upward Rank,HEFT-Level Rank, and meta-heuristic algorithm GA. The proposed algorithm is validated through extensive experiments compared to three scientific workflows (Epigenomics,Cybershake,and Montage). Based on the simulation result GA-DE algorithm proves its superiority against the other comparing algorithms in term of makespan. Furthermore, the conducted experiment proves that montage scientific workflow is more proper for executing workflow scheduling in heterogeneous cloud computing.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-6379-7_3,en,"Nature-Inspired Computing in Breast Cancer Research: Overview, Perspective, and Challenges of the State-of-the-Art Techniques",OriginalPaper,"Nature-inspired computing (NIC) is a relatively new concept to design new algorithms for solving complex problems based on natural phenomenon. It is a stochastic search technique that is successfully applied in diverse applications in the medical domain and predominantly provides small to large-scale problem-solving solutions. NIC is an emerging approach having different computing techniques to address complex problems in an improved manner. Breast cancer is the second most common cancer in women after skin cancer. Breast cancer research is in prime focus due to its high rate of mortality. One can analyze the large-scale data produced in breast cancer using NIC methods more efficiently in the early prediction of the disease. The objective of this chapter is to present the application, challenges, and advancements in nature-inspired computing for timely diagnosis of breast cancer and also motivate research in this new trend-setting direction.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Health Informatics', 'Cancer Research', 'Genetics and Genomics', 'Bioinformatics']"
doi:10.1007/978-3-031-09835-2_6,en,Optimum Design and Tuning Applications in Structural Engineering via Swarm Intelligence,OriginalPaper,"As all engineering disciplines, structural engineering problems are needed to be optimized and due to the nonlinear behavior of these problems, it is not possible to solve them mathematically, but metaheuristic methods are very successful in iterative optimization by assuming values for the design variables within a desired range of the user. In structural engineering problems, metaheuristic methods including swarm-intelligence-based algorithms are used in two groups of problems. Design optimization is the first group and the design like dimension, amount of material and orientations are optimally found for minimizing objectives related to cost, weight, CO 2 emission and others. In these problems, constraints are found via design codes like steel and reinforced concrete structure design regulations. This group belongs to a design of a structure. The second group includes optimum tuning and it generally covers structural control applications. This group involves the optimum tuning of the additional control system of the structure that can be added to the newly constructed structure for better performance or existing ones to correct the failure or increase the existing performance. The role of engineers is to make the best possible structural design and optimization is important. More especially, tuning optimization is a must to provide acceptable performance. In this chapter, a review of existing studies about the design optimization of structural systems is presented for swarm intelligence-based algorithms. Then, optimum tuning applications are mentioned including the most important studies about tuned mass dampers. Finally, optimization problems are presented for design and tuning optimization. The RC retaining wall optimization was presented for two cases with and without toe projection and the optimization of a toe is 5% effective on reduction of cost. In span length optimization of frame structures, frame models with different stories have similar optimum span lengths. Active tuned mass dampers are up to 22.08% more effective than passive tuned mass dampers.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2704-1_6,en,Joint Activity and Data Detection for Grant-Free Massive Access,OriginalPaper,"This chapter explores effective solutions for the joint activity and data detection problem to enable grant-free massive IoT access. For the typical massive connectivity, we propose a beacon-aided grant-free access scheme, in which two orthogonal approximate message passing-based detection algorithms are designed to leverage the structured sparsity of uplink massive access signals among multiple time slots. Furthermore, channel coding and successive interference cancellation are adopted to improve the detection performance. Finally, the state evolution of the proposed algorithms is derived to predict the performance theoretically. Simulation results verify that the proposed solutions outperform various state-of-the-art baseline schemes, achieving low-latency random access and high-reliable massive IoT connectivity with overloading.","['Engineering', 'Wireless and Mobile Communication', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-15858-2_2,en,Model-Free Design of Linear Quadratic Regulator,OriginalPaper,"In this chapter, we present some of the fundamental developments in the output feedback reinforcement learning control of linear dynamical systems. The linear quadratic problem in both the discrete-time and the continuous-time settings is considered. Classical output feedback reinforcement learning (RL) approaches based on discounted cost functions are first reviewed and the associated stability issues are highlighted. A state approach is introduced that serves as a bridge to developing improved RL algorithms that build upon the state feedback learning equations. Rank conditions pertaining to these state are established that are critical for the convergence of the presented output feedback algorithms. A comprehensive numerical study is carried out with practical control problems to demonstrate the applicability and effectiveness of these algorithms.","['Mathematics', 'Systems Theory, Control', 'Control and Systems Theory', 'Optimization']"
doi:10.1007/978-3-031-09835-2_11,en,Automatic Data Clustering Using Farmland Fertility Metaheuristic Algorithm,OriginalPaper,"Data clustering is a data mining task, and it means finding clusters from among data whose labels are not predetermined. It is a popular analytics tool for statistical data in various domains. The k-means algorithm is a basic algorithm for data clustering, which has initial problems such as dependence on the cluster centers’ initial value, sensitivity to outliers, and non-guaranteed optimal solutions to unbalanced cluster formation. This book chapter uses Farmland Fertility Algorithm (FFA) for the data clustering algorithm. Ten standard data sets used to evaluate the effectiveness of FFA are compared Harmony Search (HS), Monarch Butterfly Optimization (MBO), Artificial Bee Colony (ABC), Symbiotic Organism Search (SOS), Differential Evolution (DE), and Crow Search Algorithm (CSA) in terms of statistical criteria such as analysis of variance (ANOVA) and the convergence rate. Experimental results demonstrate that FFA has better performance than other optimization algorithms and is more stable than these algorithms.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-07422-6_11,en,International Report,OriginalPaper,"This report deals with the legal challenges and opportunities that come with new trends in commercial practices and the increased role played by artificial intelligence (AI) in product marketing. It is based on National Reports from Austria, Belgium, Brazil, Germany and Hungary.","['Law', 'Private International Law, International & Foreign Law, Comparative Law', 'IT Law, Media Law, Intellectual Property', 'Artificial Intelligence', 'Online Marketing/Social Media', 'Big Data', 'International Economic Law, Trade Law']"
doi:10.1007/978-981-19-2821-5_12,en,Process-Based Multi-level Homogeneous Ensemble Predictive Model for Analysing Student’s Academic Performance,OriginalPaper,"The aim of this study is to undertake an empirical inquiry and comparison of the effectiveness of various classifiers with ensembles classifiers in the prediction of student academic performance. A single classifier algorithm will be compared against the performance and efficiency of ensemble classifiers. Reducing student attrition is a major problem for educational institutions all over the world. The search for solutions to increase student retention and graduation rates continues for educators. This is only possible if at-risk students are identified and intervened with as soon as possible. However, the majority of regularly used prediction models are inefficient and inaccurate as a result of inherent classifier limitations and the inclusion of insignificant inputs in their calculations. The majority of data mining and machine learning researcher focused on developing an algorithm that can extract useful information from massive amounts of data after being processed by a computer. The most difficult problem in predictive modelling is identifying the most effective prediction algorithms that are also accurate enough to be useful. Therefore, a multi-level homogeneous ensemble predictive (MLHoEP) model is designed, which uses the different techniques of data mining like feature selection, ensemble learning techniques like boosting and bagging. Seven distinct machine learning algorithms were used on this model to predict and analyse the academic performance of the students. The performance of the classification algorithms in terms of prediction was evaluated using k -fold cross-validation. The study contributes to the body of knowledge by suggesting the development of homogeneous classifiers that may be used to accurately predict students’ academic success. It also proposes the construction of homogeneous classifiers, which may be deployed for accurate student performance prediction, in order to provide a better explanation for the poor performance prediction. As a result of this research, it has been demonstrated that the technique of applying homogeneous ensemble approaches is incredibly efficient and accurate in terms of predicting student performance and assisting in identifying students, who are in danger of dropping out of school. The study compared the accuracy and efficiency of single classifiers to ensembles of classifiers in terms of performance. It was discovered in the research that a homogeneous model with excellent accuracy and efficiency might be developed for anticipating student performance. These key problems have been successfully addressed by the findings of this research study: Which characteristics of students are the most effective predictors of academic performance? How accurate are approaches such as bagging and boosting ensembles for predicting student academic performance? The approach offered in this study will aid educational administrators and policymakers in designing new policies and curriculum-linked to student retention in higher education. This research can also aid in the identification of students who are at risk of dropping out of school early, providing for timely intervention and support. Prospective research will examine the creation and implementation of an automated prediction system known as the students’ academic performance forecast framework, which will collect data from students via online submission and produce a prediction result for their academic performance.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-7083-2_1,en,Introduction,OriginalPaper,"This chapter introduces the background knowledge of the book, including the most widely used artificial neural network models and decision trees, gradient based learning methods, evolutionary algorithms and their applications to single- and multi-objective machine learning, traditional privacy-preserving computing methods such as multi-party secure computation, differential privacy, and homomorphic encryption, and the federated learning paradigm for privacy-preserving machine learning. An overview of horizontal and vertical federated learning, together with a description of the basic federated learning algorithm, known as federated averaging, is presented, before knowledge transfer in federated learning is briefly explained. Finally, the main challenges of federated learning over non independent and identically distributed data are discussed in detail.","['Computer Science', 'Machine Learning', 'Privacy', 'Cryptology']"
doi:10.1007/978-981-19-6379-7_5,en,Potential Role of the Nature-Inspired Algorithms for Classification of High-Dimensional and Complex Gene Expression Data,OriginalPaper,"Gene expression has helped researchers in many ways—from identifying novel biomarkers to classifying different sub-types and stages of the disease from rectifying epigenetic network associations in disease to the examination of signature patterns and motifs present in the data set. However, it is also famous for its high dimensionality and difficult interpretation which is a time-consuming process. Normalization and pre-processing of gene expression data are not easy as it is gigantic data. Therefore, many computational algorithms usually fail when it comes to optimizing the high-dimensional gene expression data. Nature-inspired/bio-inspired algorithms have been a talk of the computational society for the past decade because of their robust and effective solutions to apex problems with high dimensionality issues and time complexity. Studies suggest these nature-inspired algorithms have a better potential in dealing with complex problems with a bigger search space. This chapter provides a detailed description of nature-inspired algorithms that can tackle high-dimensional and complex gene expression data, thus assisting in the better classification of diseases.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Health Informatics', 'Cancer Research', 'Genetics and Genomics', 'Bioinformatics']"
doi:10.1007/978-981-19-1645-8_9,en,Experimental Analysis of ACO with Modified Firefly and Modified Genetic Algorithm for Routing in FANETs,OriginalPaper,"The paper presents the performance evaluation of Nature-Inspired algorithms (NIA) namely Ant Colony Optimization (ACO) with newly implemented modified Firefly algorithm (MFA) and modified Genetic algorithm (MGA) for routing in Flying ad-hoc network (FANET). The use of NIA in FANET is required because FANET has quite different characteristics than that of other ad-hoc networks. The major area of concern in FANET is routing and no efficient routing algorithm has been developed for this issue. NIA is an optimization algorithm which process on the basis of nature of animals. NIA is divided into swarm based and evolutionary algorithm. This paper performs the evaluation and comparison of swarm-based algorithms and evolutionary algorithm on the performance parameters like successful packet delivery, end-to-end delay, overhead and throughput. As per the simulation results, MFA outperforms ACO and is the most efficient algorithm with MGA being the least efficient one.","['Engineering', 'Microwaves, RF and Optical Engineering', 'Wireless and Mobile Communication', 'Optics, Lasers, Photonics, Optical Devices']"
doi:10.1007/978-3-031-09835-2_2,en,Introductory Review of Swarm Intelligence Techniques,OriginalPaper,"With the rapid upliftment of technology, there has emerged a dire need to ‘fine-tune’ or ‘optimize’ certain processes, software, models or structures, with utmost accuracy and efficiency. Optimization algorithms are preferred over other methods of optimization through experimentation or simulation, for their generic problem-solving abilities and promising efficacy with the least human intervention. In recent times, the inducement of natural phenomena into algorithm design has immensely triggered the efficiency of optimization process for even complex multi-dimensional, non-continuous, non-differentiable and noisy problem search spaces. This chapter deals with the Swarm intelligence (SI) based algorithms or Swarm Optimization Algorithms, which are a subset of the greater Nature Inspired Optimization Algorithms (NIOAs). Swarm intelligence involves the collective study of individuals and their mutual interactions leading to intelligent behavior of the swarm. The chapter presents various population-based SI algorithms, their fundamental structures along with their mathematical models.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-11047-4_2,en,Graph fundamentals,OriginalPaper,"To enhance the understanding of graph theoretic techniques and algorithms discussed in this book, a brief review of graph theory is provided. Fundamental concepts in graph theory frequently encountered in the IC design process are reviewed. The basic concepts of graph theory are explained, such as the different components belonging to a graph and types of nodes and edges. The taxonomy of graphs commonly encountered in the design of VLSI systems is described, including bipartite graphs, directed acyclic graphs, and trees. Common problems in graph theory are discussed, including pathfinding, minimum spanning trees, Steiner trees, and coloring.","['Engineering', 'Circuits and Systems']"
doi:10.1007/978-3-031-09835-2_13,en,A Hybrid African Vulture Optimization Algorithm and Harmony Search: Algorithm and Application in Clustering,OriginalPaper,"Data clustering is one of the necessary research fields in data analysis. Clustering is an unsupervised classification method for assigning data objects to separate groups, which are called clusters. So that the similarity of the data within each cluster and the difference between the cluster data is high, a variety of meta-heuristic algorithms can be used to solve this problem. In this paper, a new algorithm created using a combination of African Vulture Optimization Algorithm (AVOA) and Harmony Search (HA) is used. The proposed algorithm is implemented on the clustering dataset of the UCI machine learning repository. Furthermore, the results obtained from the proposed algorithm are compared with other meta-heuristic algorithms. The experiments show that the proposed method has good and better performance than other optimization algorithms.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16832-1_2,en,Metaheuristic Algorithms in IoT: Optimized Edge Node Localization,OriginalPaper,"In this study, a new hybrid method is proposed by using the advantages of Grey Wolf Optimizer (GWO) and Moth-Flame Optimization (MFO) algorithms. The proposed hybrid metaheuristic algorithm tries to find the near-optimal solution with high efficiency by using the advantage of both algorithms. At the same time, the shortcomings of each will be eliminated. The proposed algorithm is used to solve the edge computing node localization problem, which is one of the important problems on the Internet of Things (IoT) systems, with the least error rate. This algorithm has shown a successful performance in solving this problem with a smooth and efficient position update mechanism. It was also applied to 30 famous benchmark functions (CEC2015 and CEC2019) to prove the accuracy and general use of the proposed method. It has been proven from the results that it is the best algorithm with a success rate of 54% and 57%, respectively.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Engineering']"
doi:10.1007/978-3-031-07422-6_12,en,Austria,OriginalPaper,"The digital economy has not only led to the emergence of new data-driven business models but also changed advertising and pricing strategies. Although the increasing digitisation undoubtedly creates efficiencies for both consumers and suppliers, it raises new legal challenges. In this paper, some of the most topical issues will be discussed from a competition law perspective. The first part deals with new advertising strategies under Austrian unfair competition law, in particular native advertising, influencer marketing and related labelling obligations (see Sect. 12.2). The second part assesses innovative pricing strategies under Austrian antitrust law, namely the use of artificial intelligence (AI) and algorithms as a means for anticompetitive collusion as well as personalised pricing (see Sect. 12.3).","['Law', 'Private International Law, International & Foreign Law, Comparative Law', 'IT Law, Media Law, Intellectual Property', 'Artificial Intelligence', 'Online Marketing/Social Media', 'Big Data', 'International Economic Law, Trade Law']"
doi:10.1007/978-3-031-21203-1_28,en,Dynamic Continuous Distributed Constraint Optimization Problems,OriginalPaper,"The Distributed Constraint Optimization Problem (DCOP) formulation is a powerful tool to model multi-agent coordination problems that are distributed by nature. While DCOPs assume that variables are discrete and the environment does not change over time, agents often interact in a more dynamic and complex environment. To address these limiting assumptions, researchers have proposed Dynamic DCOPs (D-DCOPs) to model how DCOPs dynamically change over time and Continuous DCOPs (C-DCOPs) to model DCOPs with continuous variables and constraints in functional form. However, these models address each limiting assumption of DCOPs in isolation, and it remains a challenge to model problems that both have continuous variables and are in dynamic environment. Therefore, in this paper, we propose Dynamic Continuous DCOPs (DC-DCOPs) , a novel formulation that models both dynamic nature of the environment and continuous nature of the variables, which are inherent in many multi-agent problems. In addition, we introduce several greedy algorithms to solve DC-DCOPs and discuss their theoretical properties. Finally, we empirically evaluate the algorithms in random networks and in distributed sensor network application.","['Computer Science', 'Artificial Intelligence']"
doi:10.1007/978-3-031-15211-5_58,en,"Vehicle Routing for Municipal Waste Collection Systems: Analysis, Comparison and Application of Heuristic Methods",OriginalPaper,"Optimization refers to finding the optimal value or best possible option. With optimization, the resource utilization can be planned to be the most effective and cost-efficient, especially in the vehicles sector, where cost and quality are both important factors. However, when dealing with complex systems, findings the best solution is considered almost impossible due to the time and the resources consumed. Therefore, optimization algorithms are used to find an optimum solution as much as possible within a relatively short time. The optimization algorithms evolved from conventional mathematical approaches to modern developed methods that use heuristic and metaheuristic approaches. Within the frame of this paper, the authors present a study that describes the effectiveness of three metaheuristic algorithms and show a municipal waste collection case study in Miskolc. After an introduction and theoretical background about the optimization algorithms development, the authors describe three metaheuristic algorithms: genetic, particle swarm, and simulated annealing. Five benchmarks are used to compare the results and consumed time for the mentioned algorithms. A Traveling Salesman Problem case study is solved to find the shortest real route of twenty locations for a municipal waste collection system in Miskolc city center by using the analyzed three algorithms. After that. The results are compared with a random solution. Particle swarm showed the best results, while simulated annealing was the fastest algorithm in the average execution time.","['Engineering', 'Automotive Engineering']"
doi:10.1007/978-981-19-5845-8_25,en,"Lightweight Block Cipher for Resource Constrained IoT Environment—An Survey, Performance, Cryptanalysis and Research Challenges",OriginalPaper,"Nowadays IoT (Internet of Things) is becoming a more popular environment and has a variety of applications like Smart Home, Smart Healthcare, Vehicles, and many Industries. There is plenty of information shared among the devices with the use of the internet. Due to this importance of data sharing, there is a possibility of security attacks, and threats. IoT environments have many security challenges including Providing Confidentiality, Integrity, and Availability in addition Privacy, Authentication. These challenges can be fulfilled by many cryptographic algorithms. Since IoT has limited memory, resources, power, those cryptographic primitives may not be suitable. The best solution for this problem is lightweight cryptographic algorithms. This paper presents the importance of lightweight cryptography algorithms. We analysed the performance of current algorithms in terms of throughput, latency, ROM/RAM, software efficiency, and energy. We are comparing the cryptanalysis of some popular algorithms. Also, we are discussing the research challenges and research gaps in the area of lightweight cryptography for providing better performance, cost and software implementation without affecting high security.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3951-8_54,en,Comparative Study of Machine Learning Models Implemented on Stock Market Datasets,OriginalPaper,"Aim of this paper is to analyze some machine learning algorithms,: k-nearest neighbor (KNN), linear regression, random forest (RF), support vector regression (SVR), and implement them on two different datasets of stock market IT sector companies TCS and Wipro. Result shows that the accuracy of the model doesn’t always increase on the size of data. K-fold cross validation is applied for evaluating the performance of the models. Comparison among different ML algorithms is based on training and testing accuracy, training and testing RMSE, and K-fold accuracy using datasets. Results obtained from different algorithms based on R 2 score of each dataset are compared using graphs. It suggests that random forest is a best-fitted algorithm among all considered ML algorithms implemented on datasets for stock market prediction. Moreover, ensemble learning approach argues about the best considerations and enhances the overall accuracy of model.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-3-031-09835-2_18,en,Graph Structure Optimization for Agent Control Problems Using ACO,OriginalPaper,"Ant Colony Optimization (ACO) is one of the powerful swarm intelligence algorithms capable of solving various problems. In this research, ACO is used to optimize individuals with graph structure. This structure is exactly like the approach taken by genetic network programming (GNP) for individual representation for solving agent control problems. However, in some types of environments such as stochastic environments, calculated fitness of an individual is not the same in each evaluation. Therefore, to estimate the true fitness of an individual, several times of evaluation are needed leading to increased process time of the evolution. In this research, a method is proposed to avoid slowing down the progress speed of the algorithm using ACO. This method can be well adapted on graph structures and in each iteration, it enhances the fitness of individuals using a constructive mechanism. In constructive mechanism, an individual is produced according to the experience of previous generations. In this research, the experience is the achieved fitness and it is distributed on the corresponding paths in the graph structure. This new method was used to solve an agent control problem called Pursuit-Domain while the environment is deterministic or stochastic. The experimental results showed high capabilities of this algorithm in generation of efficient strategies for agents in an agent control problem.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3579-4_3,en,Community Detection on Proximity Networks,OriginalPaper,"Bluetooth or Wi-Fi access point connections allow us to discover people’s physical proximity. However, their analysis is often difficult because the collected data is noisy and misleading. In this study, we use network modeling to analyze proximity information from these types of data sets. We extracted proximity networks from three different systems: Haggle Infocomm conference and MIT Reality Mining Bluetooth connections; and Sabanci University Wi-Fi access point connections, such that it is extracted as a static proximity network for the first time in this study. We explored both the extracted networks’ properties and the 12 community detection algorithms’ results. According to the descriptive analysis and statistical tests of all the setups, the performance of the algorithms depends on the data sets. The Haggle Infocomm network is noisy enough to make community detection difficult. However, the other two networks are suitable for the analysis. They contain a distinguishable community structure. Partitioning algorithms find large communities, while overlapping algorithms can detect smaller ones. The EMOC, which we proposed in our previous work, is able to find tiny communities with more overlapping nodes than any other algorithm. Such communities may correspond to small groups of friends in the same place in proximity networks.","['Engineering', 'Industrial and Production Engineering', 'Computer Communication Networks', 'Electrical Engineering', 'Mathematical Modeling and Industrial Mathematics']"
doi:10.1007/978-981-19-4606-6_78,en,A Review of Routing Algorithms for Intelligent Route Planning and Path Optimization in Road Navigation,OriginalPaper,"Finding the best route for route planning can help travelers to make better choice decisions. Routing systems for outdoor as well as indoor spaces have become the focus of many researchers. Outdoor routing takes the account of spatial road networks, where a moving object can be affected by traffic movement or traffic jams. On the other hand, indoor routing gets affected by indoor space features such as walls, room, and equipment. In this paper, we will discuss the routing algorithms that adapt to dynamically changing environments. In this paper, bio-inspired algorithms for the shortest path to optimize road navigation have been discussed. These algorithms will be useful to researchers and practitioners in operation research, management, transportation, and the geographic information system.","['Engineering', 'Industrial and Production Engineering', 'Machinery and Machine Elements', 'Materials Engineering']"
doi:10.1007/978-3-031-08246-7_5,en,Efficient Archiving Method for Handling Preferences in Constrained Multi-objective Evolutionary Optimization,OriginalPaper,"This chapter presents a method for Preferences-Handling in Multi-objective Evolutionary Algorithms called Archiving Solutions in Regions of Interest, which consists of archiving solutions during the evolutionary process which are in areas of interest from the Decision Maker without considering the algorithm as the base searching engine. The method requires three input parameters: (1) a Multi-objective Evolutionary Algorithm has been adapted by adding the proposed archiving method after the Environmental Selection; (2) a set of reference directions used to determine the areas of interest of the Pareto Front; and (3) a set of thresholds associated with each component from the reference direction vectors, which intuitively determine the boundaries from the area of interest being covered. Four representative evolutionary algorithms have been considered to analyse the effect of our proposal, one coevolution inspired algorithm paradigm (CCMO) which is a domineering sorting genetic algorithm (NSGA2), and the SMS-EMOA and SPEA2 belonging to techniques that incorporate Quality Indicators of Multi objective Optimization. The results suggest that our proposed archiving approach allows generating solutions within the regions of interest on unconstrained, constrained, and real-world problems.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-21203-1_25,en,The FastMap Pipeline for Facility Location Problems,OriginalPaper,"Facility Location Problems (FLPs) involve the placement of facilities in a shared environment for serving multiple customers while minimizing transportation and other costs. FLPs defined on graphs are very general and broadly applicable. Two such fundamental FLPs are the Vertex K -Center (VKC) and the Vertex K -Median (VKM) problems. Although both these problems are NP-hard, many heuristic and approximation algorithms have been developed for solving them in practice. However, state-of-the-art heuristic algorithms require the input graph G to be complete, in which the edge joining two vertices is also the shortest path between them. When G doesn’t satisfy this property, these heuristic algorithms have to be invoked only after computing the metric closure of G , which in turn requires the computation of all-pairs shortest-path (APSP) distances. Existing APSP algorithms, such as the Floyd-Warshall algorithm, have a poor time complexity, making APSP computations a bottleneck for deploying the heuristic algorithms on large VKC and VKM instances. To remedy this, we propose the use of a novel algorithmic pipeline based on a graph embedding algorithm called FastMap. FastMap is a near-linear-time algorithm that embeds the vertices of G in a Euclidean space while approximately preserving the shortest-path distances as Euclidean distances for all pairs of vertices. The FastMap embedding can be used to circumvent the barrier of APSP computations, creating a very efficient pipeline for solving FLPs. On the empirical front, we provide test results that demonstrate the efficiency and effectiveness of our novel approach.","['Computer Science', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2879-6_2,en,Machine Learning,OriginalPaper,"Machine learning is currently a mainstream research hotspot in the AI industry, entailing multiple disciplines such as probability theory, statistics, and convex optimization. This chapter first introduces the definition of “learning” in learning algorithms and the process of machine learning. On this basis, it offers some commonly used machine learning algorithms. Our readers will learn about some key concepts such as hyperparameters, gradient descent, and cross-validation.","['Computer Science', 'Artificial Intelligence']"
doi:10.1007/978-981-19-6379-7_4,en,Advances in Genomic Profiling of Colorectal Cancer Using Nature-Inspired Computing Techniques,OriginalPaper,"The mix of cutting-edge sequencing and the ever-progressing computational approach has changed our comprehension of the genomic underpinnings of malignant growth. With the advent of nature-inspired computational techniques, it is easier nowadays to approach the molecular basis of disease pathogenesis. Nature-inspired computational techniques have fueled the progress of genomic investigations into clinical use in patients with cancers, particularly colorectal cancer (CRC). In the genomics landscape, the mutations and epi-mutation increase the risk of CRC and are classified according to dysregulated signaling pathways, aberrant expression, distinct mutational profile of pathogenic genes, copy number alteration, and changes in histone architecture. Furthermore, the advancement in genomic analysis through computational knowledge opens a new gateway to understanding the different drivers that may help predict the clinically relevant biomarker. The expanding significance of nature-inspired computing involves various techniques inspired by different behavioral patterns present in nature that target multiple areas like disease diagnosis, query optimization, clustering, sentiment analysis, etc. In this chapter, we attempt to discuss various integrative approaches that lead to the identification of different nature-inspired computing drivers that may help in the genomic characterization of tumors which may further improve the clinical management of tumors in the future.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Health Informatics', 'Cancer Research', 'Genetics and Genomics', 'Bioinformatics']"
doi:10.1007/978-981-19-5579-2_7,en,Active Vibro-Acoustic Control of Sound Quality,OriginalPaper,"Active Sound Quality Control (ASQC) method provides a new perspective for the subjective feeling satisfaction of the passengers during the vehicle interior noise control. While the existing ANC and AVC methods focus on noise or vibration control, the impact of vibration control on noise control is rarely considered. Therefore, in this chapter, the ASQC and the AVC methods are combined to design hybrid active vibro-acoustic control methods for the SQC of the vehicle interior noise. Based on the vibration-acoustic transfer function, a Hybrid Vibro-Acoustic algorithm combined with Filter-u and Filter-x Least Mean Square (HVA-FuxLMS) is proposed. Considering the error in the calculation of radiated noise, a Hybrid Vibro-Acoustic Delay-time Least Mean Square (HVA-DeLMS) algorithm is carried out. A sound retention factor is introduced for SQC, and a Hybrid Vibro-Acoustic Adaptive Noise Equalizer (HVA-ANE) algorithm is proposed based on the ANE algorithm. Then, the Empirical Mode Decomposition (EMD) method and the frequency-domain block method are presented to design a HVA-EMD frequency-domain Block Adaptive Noise Equalizer (HVA-EB-ANE) algorithm. Furthermore, a Hybrid Vibro-Acoustic EMD frequency-domain Block Filter-error Least Mean Square (HVA-EB-FeLMS) algorithm is put forward. Simulations of HVA-ANE and HVA-EB-FeLMS algorithms are performed for three psychoacoustic indicators of loudness, roughness and sharpness. The algorithms can effectively improve the vehicle interior SQ, and provides theoretical and application value for the active control of vehicle noise.","['Engineering', 'Mechanical Engineering', 'Engineering Acoustics', 'Signal, Image and Speech Processing']"
doi:10.1007/978-981-19-0151-5_6,en,Comparative Analysis of Machine Learning Algorithms with Ensemble Techniques and Forecasting COVID-19 Cases in India,OriginalPaper,"Unanticipated information in December 2019 changed the world around us. A relatively contagious disease unfolded through the SARS-CoV-2 virus that travelled throughout the globe and was declared an epidemic by WHO in March 2020. The need of examining the scenario became the inducement behind this research. The assessment of COVID-19 in India is performed from 1 April 2020 to 20 May 2021 which amassed a total of 415 instances. Further, preprocessing of the dataset is executed with the use of normalization. The experimentation is executed through the use of four ensemble strategies which are bagging, boosting, stacking and voting with four distinct machine learning algorithms linear regression, sequential minimal optimizer for regression, multilayer perceptron and Gaussian process. The splitting of the dataset is completed at 75%, and machine learning algorithms with ensemble techniques are applied. Linear regression with the bagging ensemble method gives satisfactory outcomes with the correlation coefficient of 0.935 and 0.919 for confirmed cases and recovered cases, respectively, and Gaussian process presented the best results for deceased cases. In the case of ensemble strategies, bagging indicates the best correlation coefficient in each case. Therefore, with the help of the three best algorithms, confirmed cases, recovered cases and deceased cases predictions are performed. The paper has potential implementations that can foresee the COVID-19 confirmed cases, recovered cases and deceased cases based on historic data and subsequently structure the plan for the future.","['Engineering', 'Biomedical Engineering and Bioengineering', 'Artificial Intelligence', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Biological and Medical Physics, Biophysics', 'Information Storage and Retrieval']"
doi:10.1007/978-3-031-07422-6_15,en,Germany,OriginalPaper,"The development of artificial intelligence (AI) leads to new challenges in all legal fields. The application possibilities of algorithms are becoming more and more extensive. While algorithms were once only used for recognising patterns in data sets, today they are increasingly making forecasting decisions and thus taking on human tasks. From a competition law perspective, it is worth taking a look at the use of AI for marketing purposes, which often includes native advertising and personal pricing, but the role of influencers is also in focus.","['Law', 'Private International Law, International & Foreign Law, Comparative Law', 'IT Law, Media Law, Intellectual Property', 'Artificial Intelligence', 'Online Marketing/Social Media', 'Big Data', 'International Economic Law, Trade Law']"
doi:10.1007/978-3-031-11748-0_5,en,A Unifying Framework for Federated Learning,OriginalPaper,"There have been multiple federated learning ( FL ) algorithms proposed in the FL community during the recent years. However, a thorough comparison of these algorithms has not been done, and our understanding of the theory of FL is still limited. The lack of a unifying view in practice has also led to the reinvention of the same algorithms under different names. Motivated by this gap, we develop a unifying scheme for FL and demonstrate that many of the algorithms that exist in the FL literature are special cases of this scheme. The unification allows us to get a deeper understanding of different FL algorithms, to compare them easier, to improve the previous results for their convergence analysis and to find new FL algorithms. In particular, we demonstrate the important role that step size plays in the convergence of FL algorithms. Further, based on our unifying scheme, we propose an efficient and economic method for accelerating FL algorithms. This streamlined acceleration method does not incur any communication overheads. We evaluate our findings by performing extensive experiments on both nonconvex and convex problems.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Machine Learning']"
doi:10.1007/978-981-19-3951-8_11,en,Applying Partition Method to Adopt Spark-Based Eclat Algorithm for Large Transactional Datasets,OriginalPaper,"In discovering association rules and correlations from transactional datasets, frequent itemset mining (FIM) has emerged as a key data mining technique. Finding frequent itemsets becomes a tedious task for large-scale datasets because of the huge demand for computational resources. To meet the demands of the ever-growing data, recently, a variety of MapReduce-based algorithms on Hadoop and Spark clusters have been redesigned to achieve efficiency in terms of runtime and scalability. These are developed to overcome the limits imposed by data size, mining speed, and cluster synchronization. However, because of the iterative nature of the FIM algorithms, existing methods still lack scalability due to the large size of intermediate data produced, high disk I/O and network I/O, workload skewness, etc. In this paper, we propose a Spark-based algorithm named Parallel-Eclat (pEclat) that uses Eclat as the base method. The benefits of the vertical layout of the input dataset in combination with the partition method are utilized to improve the efficiency. It helps to limit the movement of key-value pairs across the cluster nodes (shuffle overheads) during iterations. It deals with the issues arising due to large transaction ID (TID) sets while processing large datasets in a vertical layout. The computational overhead imposed in computing the intersection of these large TID sets or diffsets is also managed. Extensive experiments with benchmark datasets have been conducted to explore the efficiency and scalability performance. Experimental results show that the proposed scheme outperforms other state-of-the-art methods. A significant speedup can be observed for some lower minimum support values.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16832-1_4,en,Minimum Transmission Power Control for the Internet of Things with Swarm Intelligence Algorithms,OriginalPaper,"More than 212 billion devices will use the internet at the end of 2020. According to this information, more accurate artificial intelligence (AI) approaches are required for more efficient Internet of Things (IoT) usage. Wireless sensor networks (WSNs) contain energy-limited devices and calculating the minimum transmission power control (TPC) is a tackling process. Swarm intelligence is a subsection of AI and in the last four decades, many swarm intelligence algorithms are proposed for solving optimization problems. The minimization of energy usage and maximizing the network lifetime are many useful and essential for IoT. In this work, four different swarm intelligence algorithms—particle swarm optimization (PSO), artificial bee colony (ABC), salp swarm algorithm (SSA), and tree-seed algorithm (TSA)—are used for solving the minimum TPC optimization problem. The obtained results, convergence graphs, and standard deviations are showed that ABC is the best swarm intelligence algorithm, and the TSA is the most robust algorithm in this experimental environment.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Engineering']"
doi:10.1007/978-3-031-05347-4_8,en,An Efficient Regression Test Cases Selection & Optimization Using Mayfly Optimization Algorithm,OriginalPaper,"Testing has been an inevitable activity in the software development life cycle. In the current scenario, software development has become evolutionary in nature where software is released in cycles, each cycle fulfilling the requirements of the customer on a priority basis. This evolutionary development of software also demands high maintenance in the form of retesting. This re-testing is called regression testing and the literature reveals that it is a proven N-P hard problem that attracts the application of approximation algorithms such as meta-heuristics. In this paper, Mayfly Optimization Algorithm has been adopted to solve the regression test case selection problem to minimize the maintenance cost. The aim is to optimize the number of test cases to re-execute to reduce the execution time and cost. The performance of the adopted approach is further compared with state-of-the-art approaches with the help of statistical tests. The shows that the adopted approach performs well in comparison to state of art approaches.","['Mathematics', 'Mathematical Modeling and Industrial Mathematics', 'Risk Management', 'Engineering Economics, Organization, Logistics, Marketing']"
doi:10.1007/978-3-031-13433-3_3,en,Empowering Machines to Learn,OriginalPaper,"This chapter firstly introduces the basic idea of computer simulation of the human brain and analyzes the essential characteristics, implementation steps, and machine learning methods. It then focuses on the ANN method’s learning process, introduces the weighting adjustment process in detail, and deduces the calculation method. A simple example is given. This chapter also includes a brief introduction to deep learning. On this basis, it introduces some other machine learning algorithms, including supervised learning, unsupervised learning, reinforced learning, etc. It finally analyzes the current artificial intelligence and illustrates the basic principles for applying machine learning in engineering construction.","['Engineering', 'Transportation Technology and Traffic Engineering', 'Data Engineering', 'Building Construction and Design', 'Sustainable Development', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-5303-3_2,en,Existing Methods to Evaluate Pacemaker Device Performance,OriginalPaper,"With the alarming rise in deaths due to cardiovascular diseases (CVD), the present medical research scenario emphasizes techniques and methods to detect CVDs. As the world health organization adduced, technological proceeds in cardiac function assessment have become the nucleus and heart of all leading research studies on CVDs. Electrocardiogram (ECG) analysis is the most functional and convenient tool used to test the range of heart-related irregularities. Most of the approaches present in the literature on ECG signal analysis consider noise removal, rhythm-based analysis, and heartbeat detection to improve the performance of a cardiac pacemaker. Advancements in ECG segment detection and beat classification have a limited evaluation and still require clinical approvals. This chapter discusses approaches and techniques to implement an on-chip ECG detector for a cardiac pacemaker system. Moreover, different challenges regarding the ECG signal morphology analysis deriving from the medical literature are extensively reviewed.","['Engineering', 'Circuits and Systems', 'Biomedical Engineering and Bioengineering', 'Signal, Image and Speech Processing']"
doi:10.1007/978-3-031-08246-7_7,en,Implementation of Reinforcement-Learning Algorithms in Autonomous Robot Navigation,OriginalPaper,"The problem of autonomous robot navigation in indoor environments must overcome various difficulties such as the dimensionality of the data, the computational cost, and the possible presence of mobile objects. This chapter addresses the implementation of an algorithm for autonomous navigation of robots in indoor environments based on machine learning. It characterizes some strategies that the literature reports and specifies a Deep Q-Network reinforcement-learning algorithm to implement on the Turtlebot robotic platform of the Gazebo simulator. Besides, a series of experiments changing the parameters of algorithm to validate the strategy shows how the robotic platform, through the exploration of the environment and the subsequent exploitation of the information, creates effective route planning.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-18344-7_13,en,Analysis of Load Balancing Algorithms Used in the Cloud Computing Environment: Advantages and Limitations,OriginalPaper,"Cloud computing as an advanced technology in the IT infrastructure presents nowadays a big concern of researches. It’s no longer a matter of on-demand successful delivery of computing resources. Throughput, performance, server response time, and cost had become the metrics that enable the quality-of-service agreement. Technically, cloud service provider guarantees to deliver computing resources (storage, servers and applications) through back-end data center. It consists of several hosts distributed geographically to answer the client requests. To ensure the service level agreement between clients and providers, cloud infrastructure software need to schedule and optimally manage the workload of several demands. Here, Load balancing technology enters as a major key with a set of algorithms to handle the most effectively and fairly the allocation and scheduling of computational resources, to serve the large amount of calling jobs. This review presents a comparative and comprehensive study that covers the principal concepts of cloud computing, and the well-known algorithms used for load balancing which are classified into static and dynamic sets. The objectives of this survey are to (1) mention, explain, compare and analyze some developed methods for load balancing by systematically reviewing papers from the years 2018 to 2021, (2) analyze the level of maturity of the solutions proposed in the literature and (3) present an insight into the actual solutions which may help with future improvements.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-3-031-08815-5_11,en,Neural Network Based Task Scheduling in Cloud Using Harmony Search Algorithm,OriginalPaper,"Cloud computing is a field that is growing in popularity every passing day for computation and storage purposes. Having already been adopted by companies like Google, Microsoft, IBM, etc., it is slowly but steadily making its way into the mainstream market, which is evident from the exponential increase in the size of the cloud servers over the past few years. Being a computational process where extensible resources are conveyed as facilities to customers using online methods, Cloud computing needs to have a method for choosing the correct resources for executing processes within a given framework. This is called task-scheduling. Various task-scheduling models are in use currently, but the one that we will be focusing on is the NN (Neural Network)-based model. This model was set up to estimate the task execution status for resource allotment among the candidates. An NN-based model makes use of various scheduling algorithms to formulate optimum results in terms of quality of service (QoS), total cost, service satisfaction, etc. Through our work, we are simulating various task-scheduling algorithms in a virtual environment and comparing their efficiency based on the results we obtain from these simulations. While our focus will be on an emerging metaheuristic optimization algorithm called the Harmony Search Algorithm, we are also running simulations for the Moth algorithm, and the Genetic Algorithm.","['Engineering', 'Computational Intelligence', 'Transportation Technology and Traffic Engineering']"
doi:10.1007/978-3-031-15858-2_1,en,Introduction to Optimal Control and Reinforcement Learning,OriginalPaper,"This chapter presents the motivation of developing reinforcement learning algorithms for solving optimal control problems of dynamical systems. An overview of model-based methods to solve linear optimal control problems is first provided. Dynamic programming-based approaches are reviewed. Reinforcement learning (RL) is then introduced as a data-driven approach to solving such problems with their advantages over the model-based approaches discussed. Some classical RL algorithms are recalled in the context of solving linear optimal control problems. We discuss some of the recent challenges encountered in the application of these algorithms in practical control systems, which sets the tone for the new developments to be presented in the remainder of book.","['Mathematics', 'Systems Theory, Control', 'Control and Systems Theory', 'Optimization']"
doi:10.1007/978-3-031-17544-2_6,en,NIANN: Integration of ANN with Nature-Inspired Optimization Algorithms,OriginalPaper,"Artificial neural networks (ANNs) are stimulated according to the biological brain's connection of axons and dendrons. These neural networks perform a major part in the advancement of artificial intelligence and learning algorithms. Though initially used for image classification, in modern times applications of ANNs have been useful over numerous fields such as medical data mining, bioinformatics, natural language processing, time series forecasting, and in various optimization problems as well. Nature-inspired algorithms are a set of novel problem-solving approaches that are derived from various incidents occurring in nature around us. Each of the methods such as the BAT, genetic algorithm, or colony optimization methods were created by keeping a specific hard problem in mind. In recent times general purpose use of these nature-inspired algorithms has become widely popular in solving mainly optimization problems derived from the fields of NLP, machine learning, deep learning, classification, and feature selection as well. Nature-inspired algorithms mainly work by mimicking phenomena occurring in nature among various species on a macro scale. A set of nature-inspired algorithms such as the genetic algorithm family mimics the processes that occur in a microorganism such as a cell division, mutation, etc. Since these algorithms are inspired by nature and were developed keeping in mind achieving an optimal solution of a given hard problem, their application in general-purpose problems also yields satisfactory results. If an algorithm fails to achieve a satisfactory solution to a problem, it is easy to modify them according to the need of the given problem to overcome any obstacle. In this chapter, an approach is introduced that aims to combine the nature-inspired optimization algorithm with the learning model of artificial neural networks to provide a more accurate and streamlined output generation of the neural network. Nature-inspired algorithms can be used as a learning method in the ANN model. In contrast to that, an ANN can also be used as an objective function to a nature-inspired algorithm to improve its capability to generate an optimal solution. This chapter aims to explore both approaches in detail.","['Engineering', 'Computational Intelligence', 'Biomedical Engineering and Bioengineering', 'Health Informatics']"
doi:10.1007/978-3-031-17544-2_10,en,Advance Machine Learning and Nature-Inspired Optimization in Heart Failure Clinical Records Dataset,OriginalPaper,"ML is a subset of computing procedures that aims to imitate human astuteness by swotting from its surroundings. It has become a challenging task to diagnose the ailment and provide the appropriate treatment at the right time because of the increasing population and disease. The recent technological advancements have propelled the adoption of innovative functional biomedical solutions in the public health sector. Procedures based on traditional ML have been applied effectively in computational biology to biomedical and medical applications. Biomedical solutions entail a complex series of procedures ranging from consultation to treatment and beyond to ensure that patients react optimally. These are considered the working horse in the new era of the so-called big data. The process's complexity can vary and encompass multiple phases of nuanced human–machine interplay with decision-making, which certainly derive the application of ML algorithms to enhance and systematize the automate processes. A population-based Natured inspired swarm algorithms is proposed to extract the relevant parameters of Tree-based ML algorithms by using hyperparameter tuning. The proposed framework attains the desired performance by using “Heart failure clinical records dataset” prediction from the UCI ML data repository.","['Engineering', 'Computational Intelligence', 'Biomedical Engineering and Bioengineering', 'Health Informatics']"
doi:10.1007/978-981-19-6379-7_12,en,Role of Nature-Inspired Intelligence in Genomic Diagnosis of Antimicrobial Resistance,OriginalPaper,"The emerging antimicrobial resistance (AMR) to current antimicrobial agents is the foremost public health concern that continues to pose challenges in the selection of therapeutic regimens to treat infectious diseases. The bacterial pathogens develop AMR by two types of mechanisms, one is intrinsic resistance due to the mutations in chromosomal genes and another is extrinsic resistance by the acquisition of external plasmid-mediated genes. The key to diagnose AMR lies in the DNA sequence of bacteria harboring the resistance-conferring mechanisms. The advancements in technology have generated a plethora of genomics data that can be utilized for the identification of diagnostic markers. Moreover, machine learning (ML) has created novel opportunities to significantly solve healthcare problems using bioinformatics techniques. In the last decade, nature-inspired intelligence (NII) has aided the development of machine learning tools for diagnosing antibacterial resistance gene patterns. The successful implementation of these algorithms, especially on complex and intricate problems, indicates their importance in artificial intelligence (AI). This review addresses the role of NII in combating infectious diseases using genomic data as well as the future perspective of its use in information processing, decision-making, and optimization for the diagnosis of AMR. The key problems in the practical application of NII using genomic markers and microbiological parameters are extensively discussed. This will aid in bridging the gap between theoretical researchers, medical practitioners, professionals, and engineers interested in the use of NII to solve AMR.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Health Informatics', 'Cancer Research', 'Genetics and Genomics', 'Bioinformatics']"
doi:10.1007/978-981-19-5845-8_15,en,Analysis of Different Cryptographic Algorithms in Cloud-Based Multi-robot Systems,OriginalPaper,"Nowadays, securing data over the network become an important concern. When the data is travelled between Robots and the Cloud then there is high chance of the eavesdropping of the data by the attacker. To protect the data secrecy and confidentiality that arises because of the threat, cryptography is used. At first, data is converted into unreadable text (Cipher Text) known as encryption and after receiving the data, receiver performs reverse encryption (decryption). There are many algorithms for performing the encryption and decryption process. That’s why it is necessary to find out which algorithm performs better with resource-constrained and limited computing ability devices. In this paper, various encryption techniques like DES, 3DES, AES, Blowfish and ECIES are analysed based on encryption and decryption time. This encryption mechanism consumes significant number of resources like memory utilisation, CPU time, computation time, etc. In this paper, we compared different cryptographic algorithms in terms of key size, block size, Power consumption and speed. The simulation results will be calculated in terms of encryption and decryption time of the algorithms.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-6379-7_15,en,Illustrious Implications of Nature-Inspired Computing Methods in Therapeutics and Computer-Aided Drug Design,OriginalPaper,"The Nature-inspired computing (NIC) techniques have been effectively applied to research pharmaceutical components and compounds. NIC includes problem-solving methods based on abstractions of natural processes and provides new ways to understand, model, and analyse natural complexity. These algorithms mimic biological systems to create new computation paradigms, such as swarm intelligence, neural networks, and evolutionary computing. Nowadays, the NIC algorithms are becoming very popular in solving complex optimisation in most academic and industrial fields, including drug design, development, therapeutics, molecular modelling, and peptide design. These algorithms work on a combinatorial approach for small molecules and compound designs that rely on the pharmacological properties of novel drug candidates. Over the last decade, NIIC techniques have been successfully applied in each drug discovery and development pipeline stage to overrule the obstacle of complex and big data from genomics, proteomics, microarray data, and clinical trials. This chapter summarised the recent applications of NIC methods in therapeutics and computer-aided drug design.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Health Informatics', 'Cancer Research', 'Genetics and Genomics', 'Bioinformatics']"
doi:10.1007/978-981-19-2300-5_6,en,Identifying Cyberspace Users’ Tendency in Blog Writing Using Machine Learning Algorithms,OriginalPaper,"A blog is a form of direct interactive communication technology, which allows users to interact and communicate with each other through posting comments and sharing links as well. A blog is a platform where a writer or group of writers gives their opinion on a specific topic. Many issues and topics that are in a certain country being censored and controlled by the government from being presented through the mass media. Nevertheless, blogs have the space to provide a wide platform for exchanging ideas and opinions on various issues. There is a specific proportion between blog features and bloggers’ tendency to social, political, and cultural patterns of different countries and nations that create trends among the bloggers in these countries. In this paper, we use an existing data set from previous research, which has 100 records of data, and manipulate the data by applying three machine learning algorithms for implementing classification and regression tasks. The algorithms are Decision Tree (c4.5), Linear Regression (LR), and Decision Forest (DF) with a 10-fold cross-validation method for training and testing. The results showed that C4.5 achieves the best overall results of 81% accuracy, 83% precision, and 91% recall, compared with the other two algorithms.","['Mathematics', 'Mathematical Applications in Computer Science', 'Engineering Mathematics', 'Operations Research/Decision Theory', 'Mathematical Modeling and Industrial Mathematics', 'Artificial Intelligence', 'Optimization']"
doi:10.1007/978-3-031-16075-2_52,en,Recognition of Similar Habits Using Smartwatches and Supervised Learning,OriginalPaper,"Especially in the healthcare system, there is a lot of potential to use wearables to create an even more efficient way to care for patients and have important data available at all times. Wearables, for example, could allow nurses to spend more time with their patients instead of spending their time collecting data and performing other technical tasks. The aim of this project was to track, label and analyze daily activities that people with dementia might perform, by using smartwatches and supervised learning. The analysis is carried out on the basis of sensor systems and classification algorithms and in this framework the performance and predictive power of each algorithm was analyzed after data collection. In this work, it can be stated for all test subjects and in all activity categories that the Fast Forest algorithm generally performs best.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-3-031-15944-2_15,en,Assessment of Methods for Fan Blades Arrangement for Static Balancing of the Fan of a Turbofan Engine,OriginalPaper,"The fan blades of a high by-pass ratio turbofan engines require frequent maintenance actions due to erosion and foreign object damage. To keep the fan disk imbalance within limits when repairing or replacing fan blades a fan blades rearrangement procedure must be applied. In this work various methods of fan blades (re)arrangement are suggested and evaluated by applying them on large number of randomly generated sets of fan blades for a typical commercial turbo fan engine. A special attention is payed to the subsequent minimization of the resultant moment of imbalance by applying all to all blade switch recursive algorithms. The optimum values of the recursive algorithm parameters are determined. The results of the investigation show that the resultant moment of imbalance of the fan can be significantly reduced, compared to the standard methods used in the most of the airplane maintenance and repair organizations.","['Engineering', 'Mechatronics', 'Engineering Economics, Organization, Logistics, Marketing', 'Computer Hardware', 'Computational Intelligence']"
doi:10.1007/978-981-19-2635-8_68,en,A Comparison of Deep Learning-Based Monocular Visual Odometry Algorithms,OriginalPaper,"Visual odometry (VO) has recently attracted significant attention, as evidenced by the increasing interest in the development of autonomous mobile robots and vehicles. Studies have traditionally focused on geometry-based VO algorithms. These algorithms exhibit robust results under a restrictive setup, such as static and well-textured scenes. However, they are not accurate in challenging environments, such as changing illumination and dynamic environments. In recent years, VO algorithms based on deep learning methods have been developed and studied to overcome these limitations. However, there remains a lack of literature that provides a thorough comparative analysis of state-of-the-art deep learning-based monocular VO algorithms in challenging environments. This paper presents a comparison of four state-of-the-art monocular VO algorithms based on deep learning (DeepVO, SfMLearner, SC-SfMLearner, and DF-VO) in environments with glass walls, illumination changes, and dynamic objects. These monocular VO algorithms are based on supervised, unsupervised, and self-supervised learning integrated with multiview geometry. Based on the results of the evaluation on a variety of datasets, we conclude that DF-VO is the most suitable algorithm for challenging real-world environments.","['Engineering', 'Aerospace Technology and Astronautics', 'Engine Technology', 'Automotive Engineering', 'Mechanical Engineering']"
doi:10.1007/978-3-031-18050-7_10,en,Estimation of Distribution Algorithms Applied to the Next Release Problem,OriginalPaper,"The Next Release Problem (NRP) is a combinatorial optimization problem that aims to find a subset of software requirements to be delivered in the next software release, which maximize the satisfaction of a list of clients and minimize the effort required by developers to implement them. Previous studies have applied various metaheuristics and procedures, being many of them evolutionary algorithms. However, no Estimation of Distribution Algorithms (EDA) have been applied to the NRP. This subfamily of evolutionary algorithms, based on probability modelling, have been proved to obtain good results in problems where genetic algorithms struggle. In this paper we adapted two EDAs to tackle the multi-objective NRP, and compared them against widely used genetic algorithms. Results showed that EDA approaches have the potential to generate solutions of similar or even better quality than those of genetic algorithms in the most crowded areas of the Pareto front, while keeping a shorter execution time.","['Engineering', 'Computational Intelligence', 'Industrial and Production Engineering']"
doi:10.1007/978-981-16-9967-2_10,en,Analysis of Algorithms for Effective Cryptography for Enhancement of IoT Security,OriginalPaper,"The Internet of Things has emerged as one of the most prevalent technologies of the current times, finding its place in a myriad of applications and is widely used for digitization and automation applications such as smart city development, automated monitoring systems, healthcare, energy management and much more. With more devices being connected to the Internet, one of the biggest challenges faced by the Internet of Things surfaces—privacy and security risks. The vulnerability of IoT devices and networks have been brought to light, presenting a threat to the integrity of data. Cryptography has proved itself as a method to secure communication channels and data, as a way to ensure IoT security. In this paper, we aim to compare cryptographic algorithms, namely—AES, DES, RSA and lightweight cryptographic algorithm Fernet, to determine which cryptographic algorithm is the most efficient and secure, and can thereby minimize the risk to data integrity and security in IoT applications.","['Computer Science', 'Computer Systems Organization and Communication Networks', 'Computational Intelligence', 'Artificial Intelligence', 'Wireless and Mobile Communication', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-4990-6_52,en,Predictive Analysis for Prognostication of Breast Cancer,OriginalPaper,"Nowadays, most of the women affected by one of the type of cancer is Breast Cancer (BC). The main objective is to identify and prognosis of the Breast Cancer at its earlier stages using supervised machine learning (ML) techniques like Naive Bayes (NB) classifier, support vector machine (SVM), random forest classifier (RFC), K-nearest neighbor (KNN) and decision tree classifier (DT). The data are collected from the Wisconsin Diagnostic Breast Cancer dataset then malignant and benign tumors are classified based on the dataset and using various ML techniques to predict the Breast Cancer in advance manner. Various parameters like accuracy, precision, sensitivity (recall), F-measure (specificity), regression score, variance measure, maximum error and balanced accuracy are measured in each algorithms. Using Python experimental tool PyCharm to execute ML algorithms for predicts the Breast Cancer. Our final result indicates that support vector machine is the best one for predictive Breast Cancer efficiently with accuracy of 99%.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Wireless and Mobile Communication']"
doi:10.1007/978-3-031-18458-1_52,en,A Qualitative Investigation of Optical Flow Algorithms for Video Denoising,OriginalPaper,"A good optical flow estimation is crucial in many video analysis and restoration algorithms employed in application fields like media industry, industrial inspection and automotive. In this work, we investigate how well optical flow algorithms perform qualitatively when integrated into a state of the art video denoising algorithm. Both classic optical flow algorithms (e.g. TV-L1) as well as recent deep learning based algorithm (like RAFT or BMBC) will be taken into account. For the qualitative investigation, we will employ realistic content with challenging characteristic (noisy content, large motion etc.) instead of the standard images used in most publications.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-6379-7_11,en,Applications of Nature-Inspired Computing and Artificial Intelligence Algorithms in Solving Personalized Therapy Complications,OriginalPaper,"Personalized medicine involves the practice to deliver customized service to the recipients based on some specific factors related to the patients. Knowledge of proper genetic information, lifestyle, and environment may help to select the proper therapy, dose, or regimen. Precision medicine has the potential to modify the treatment procedure as per the requirement of the individual patients by ensuring the maximum therapeutic value with an increased safety margin. Nature-inspired computing (NIC) allows the development of new computational techniques by observing the naturally occurring phenomenon to solve complex problems in different environmental settings. The last decade has proven the application of NIC and artificial intelligence (AI) techniques in the development of personalized medicine specifically for the identification of disease patterns and their proper therapy for précised treatment. The control of adverse drug reactions and enzyme metabolism differences in individuals is also considered by advanced NIC and AI computing tools. They aid in solving various problems of personalized medicine including the diagnosis of disease and their treatments. The theory and applications of selected nature-inspired algorithms for precision medicine are reviewed, together with practical applications and a discussion of their advantages and limitations.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Health Informatics', 'Cancer Research', 'Genetics and Genomics', 'Bioinformatics']"
doi:10.1007/978-3-031-17544-2_12,en,GACO: A Genetic Algorithm with Ant Colony Optimization—Based Feature Selection for Breast Cancer Diagnosis,OriginalPaper,"Breast cancer is the most prevalent cancer diagnosed and the basis of mortality among women worldwide. However, the early prognosis and treatment can avoid the death rate of the patients. Since the traditional method of detecting cancer is error-prone, machine learning has shown significant promise in aiding the accurate diagnosis. Moreover, using a minimal number of features is highly pertinent in decision-making. Therefore, this chapter proposes a novel evolutionary algorithm-based feature selection method to identify the most appropriate attributes. The suggested model fuses the Genetic Algorithm with Ant Colony Optimization to increase the search operation in the global search space. Finally, the Random Forest classifier is employed on the reduced attribute subset to examine and determine the nature of breast tumors. The developed system is evaluated on the Wisconsin Diagnostic Breast Cancer dataset. The experimental outcomes demonstrate the efficiency of the proposed method over other popular single algorithms and ensemble learners.","['Engineering', 'Computational Intelligence', 'Biomedical Engineering and Bioengineering', 'Health Informatics']"
doi:10.1007/978-981-19-2535-1_32,en,Comparative Study of Enhanced Round Robin Algorithms with Drrha and Other Metaheuristic Algorithms,OriginalPaper,"CPU scheduling has a substantial influence on system resource usage and overall performance. Scheduling Algorithms are a technique for reducing CPU resource deprivation while simultaneously maintaining fairness among the numerous programs that utilize the resources. Round Robin is a preemptive scheduling method that significantly improves response time by restricting each operation to a certain length of time known as the Time Quantum. Various efforts have been made to calculate a time quantum value to optimize these Round Robin algorithm parameters. However, this gain in response time comes at the expense of turnaround and waiting time. In this paper, we compare the conventional Round Robin CPU scheduling algorithm to updated Round Robin algorithms such as DRRHA, as well as our suggested approaches termed MDRRHA and NDRRHA, which seek to reduce process waiting time. The Quantum value for MDRRHA and NDRRHA is derived dynamically using the arithmetic mean and the normal distribution of execution time values of tasks, respectively. The recommended solutions decrease average turnaround time and average waiting time values by up to 13%. In this research, we compare different job scheduling approaches by simulating them in a variety of test situations.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-3-031-11089-4_3,en,Introduction to Advanced Information Technology,OriginalPaper,"Over the years Information Systems (IS) have become increasingly complex and are difficult to grapple. The complexity of recent novel technologies like blockchain (BCT), artificial intelligence (AI), and cloud computing constitutes a genuine challenge to IT-auditors tasked with auditing these IS to provide assurance. This chapter discusses the inner-workings, intricacies, and concepts related to these technologies to provide the background necessary to perform an audit.","['Business and Management', 'IT in Business', 'Software Management', 'Risk Management', 'Systems and Data Security']"
doi:10.1007/978-981-19-2065-3_1,en,Analysis and Comparison of Swarm Intelligence Algorithm in IoT: A Survey,OriginalPaper,"In this era of new technology, a daily changing Internet of Things (IoT) is the revolutionary technique which makes everyone’s life simple as it provides smart homes, smart city, autonomous vehicles and various new applications which take the society to the new heights. As different technologies like sensors, actuator, RFID tags and smart grids, etc., are required to make complete IoT, several challenges arise. So, in order to provide better facilities to the end-users, energy consumption should be less. In this regard, this paper presents brief and meticulous review on various swarm intelligence (SI) algorithms like particle swarm optimization (PSO), cat swarm optimization, simulated annealing (SA), ant colony optimization (ACO). SI is based on the collective behavior of different creatures like ant, birds and bee colonies. The group behavior of these insects exhibits collective intelligence from their interaction and provide optimized results globally in multidiscipline. Further paper presents discussion of various SI-based hybrid algorithms of resource allocation and task completion, for less energy consumption and comparison table of various algorithms proposed by profuse researchers.","['Engineering', 'Communications Engineering, Networks', 'Artificial Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Machine Learning']"
doi:10.1007/978-3-031-04435-9_6,en,A New Home Energy Management System for Smart Home Using Improved Multi-objective Antlion Optimization Algorithm,OriginalPaper,"Lack of knowledge on how to use energy properly has led to a significant increase in energy demand relative to its production in recent years. Electricity companies have also come up with various plans to solve this problem, such as consumption management. In this study, we present an optimized home energy management scheme to overcome major barriers to implementing demand response programs. The main goal is to find the minimum energy cost by considering variable pricing for at least one period during the day and based on shifting loads out of peak hours while maintaining user comfort. Due to the complexity of the problem, an improved meta-heuristic optimization approach is used, which we call OBLALO. The proposed scheme for CPP pricing is simulated and the results are compared with PSO, GOA and ALO algorithms. The simulation results show the advantage of using the proposed scheme in the home energy management system.","['Social Sciences', 'Science and Technology Studies']"
doi:10.1007/978-3-030-89822-9_77-1,en,Applying Artifical Intelligence in the Supply Chain,ReviewPaper,"This chapter covers the applications of artificial intelligence (AI) in supply chain management (SCM). We elaborate on the applications of seven categories of AI – namely, artificial neural networks, expert systems, machine learning, genetic algorithms, agent-based systems, fuzzy logic, and rough set theory – to supply chain management processes using the supply chain operations reference (SCOR) model which are elaborated. A framework for SCM practitioners is provided. This framework highlights the AI task context and the AI knowledge source context (the What) in the SCOR activity (the Where ). The framework also includes an algorithmic description (the How ).","['Business and Management', 'Supply Chain Management']"
doi:10.1007/978-3-031-14537-7_10,en,The Effect of Harmony Memory Integration into the Bees Algorithm,OriginalPaper,"The advent of optimization algorithms facilitated finding good solutions for engineering problems. This paper presents a comparative case study between two algorithms relevant to bee search methods. One of the algorithms was modified by adding harmonic memory, which is a stage of the Harmonic Search Algorithm. Both algorithms were applied to a spherical four-link Four -link mechanism for gripper design as a case study. The results in terms of the coupler trajectory of the mechanism showed the superiority of integrating harmony memory Harmony Memory into the Bees Algorithm. A prototype is manufactured to show the success of rapid design and production.","['Engineering', 'Robotics and Automation', 'Artificial Intelligence', 'Industrial and Production Engineering', 'Professional Computing', 'Robotics', 'Machine Learning']"
doi:10.1007/978-3-031-20105-9_4,en,Comparison Study of Novel Evolutionary Algorithms for Elliptical Shapes in Images,OriginalPaper,"Shape recognition in digital image processing describes one of the difficult and hard-solving situations in artificial vision due to its nonlinear and stochastic structure. Traditional image processing methods have been commonly employed to solve this situation. Additionally, shape recognition considers evolutionary computation techniques. They have been exposed to better performance in terms of accurateness than traditional optimization methods.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-08815-5_12,en,Neural Inspired Ant Lion Algorithm for Resource Optimization in Cloud,OriginalPaper,"There are various task scheduling models that are in use currently, but the one which we will be focusing on is the ANN (Artificial Neural Network) based model. This model was set up to estimate the task execution status for resource allotment among the candidates. An ANN-based model makes use of various scheduling algorithms to find the best results possible in terms of quality of service (QoS), total cost, service satisfaction, etc. Through our paper, we are simulating various task scheduling algorithms in a virtual environment and comparing their efficiency based on the results we obtain from these simulations. While our focus will be on an emerging meta-heuristic optimization algorithm called the Ant lion Algorithm, we are also running simulations for the Whale Optimization algorithm, and the Genetic Algorithm. For the prediction and allocation of cloud resources we use the Ant Lion Optimization Algorithm. Artificial Neural Network (ANN) is used for resource allocation. We discuss the results that depicts we get better results compared to the existing methods with proper allocation of resources and minimal cost.","['Engineering', 'Computational Intelligence', 'Transportation Technology and Traffic Engineering']"
doi:10.1007/978-981-19-5217-3_101,en,Comparison of Stability of Four Numerical Integration Methods Under Negative Stiffness,OriginalPaper,"Numerical Integration Algorithm plays a very important role in real-time hybrid experiments. Based on the Newmark (γ = 1/2, β = 1/4) average constant acceleration algorithm, the stability analysis equations of Chang Algorithm, CR Algorithm and TL Algorithm under the condition of negative stiffness were derived by using the principle of positive stiffness analysis. The stability of the four algorithms under the condition of negative stiffness was analyzed by Matlab, and the stability characteristics of the four algorithms were studied by changing the integral time interval, damping ratio and stiffness ratio. The research findings indicate that when stiffness is negative, the Newmark average constant acceleration algorithm (γ = 1/2, β = 1/4) is no longer unconditionally stable, whearas the other three algorithms are all unconditionally stable. The Chang Algorithm has the best stability, while the CR algorithm is nearly as stable as the TL algorithm. It is suggested that while performing hybrid testing with probable negative stiffness, the numerical integration algorithm should be carefully chosen.","['Engineering', 'Civil Engineering', 'Public Policy', 'Arts']"
doi:10.1007/978-3-031-09835-2_19,en,A Bumble Bees Mating Optimization Algorithm for the Discrete and Dynamic Berth Allocation Problem,OriginalPaper,"In maritime supply chain, there is a large number of significant optimization problems that have to be modeled and solved. One of them is the Berth Allocation Problem (BAP). In BAP, the assignment and scheduling of incoming ships to berth positions are studied. In literature, several variations and connections with other maritime problems can be found. In this paper, we present an efficient methodology for solving the discrete and dynamic version of BAP (DDBAP). We formulate the DDBAP as a heterogeneous vehicle routing problem with time windows (HVRPTW). In this formulation, berths correspond to vehicles, ships correspond to customers/nodes and the sequence of serviced ships at a particular berth represent a vehicle route. Each one of these sequences must start and end at a specific point such as the depot in VRP. The sequence of serviced ships starts at the origin and finishes at the destination point. Time windows can be imposed on each one of the ships. The time windows for each ship correspond to the availability time in order to be served properly in one of the available berths. In order to solve DDBAP, we apply a modified Bumble Bees Mating Optimization (BBMO) algorithm. BBMO belongs to the nature inspired optimization algorithms and it simulates the mating behavior of the bumble bees. It is an algorithm that its basis is the Honey Bees Mating Optimization (HBMO) algorithm but with a number of different steps that make the algorithm a completely different and competitive algorithm with other nature inspired algorithms. We applied the algorithm to benchmark instances from the literature and the obtained computational results proved the efficiency of BBMO with respect to the quality of solutions and the computational time needed to find these solutions.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-030-96025-4_4,en,Optimal Placement of PMUs in Smart Power Systems,OriginalPaper,"This chapter presents a multi-stage method to make the power system complete observability by the optimal placement of phasor measurement units (PMUs) taking into account the minimum availability of PMUs measuring channels. In order to solve the optimization problem, a two-stage optimal method is introduced with and without considering zero injection buses (ZIBs). In stage-1, the ant colony optimization (ACO) algorithm is applied to find the optimal number and locations of PMUs considering measuring channels and maximize the measurement redundancy (MR) at normal operating condition as well as emergency conditions such as any single line or PMU outage. In Stage-2, the reduction strategy (RS) is proposed to reduce the number of PMUs measuring channels with keeping the complete observability. The proposed method is tested on different standard test systems, namely IEEE 14-bus, 24-bus, 30-bus, New England (NE) 39-bus, 57-bus and 118-bus. In addition, the application of the proposed method is employed on a real power system of the West Delta Network (WDN) as a part of the Unified Egyptian Network (UEN) which is considered as a test system. To prove the robustness and the superiority of the proposed method, the results are compared with other optimization techniques. This comparison show the great capability of the proposed method to find the optimal PMU placement for significant saving in the total cost with more accuracy and efficiency, especially with increasing in the power system sizing.","['Engineering', 'Power Electronics, Electrical Machines and Networks', 'Energy Systems', 'Renewable and Green Energy']"
doi:10.1007/978-3-031-14537-7_4,en,A Case Study with the BEE-Miner Algorithm: Defects on the Production Line,OriginalPaper,"Classification Classification which is used to predict the classes of objects has the disadvantage of ignoring the costs Cost incurred in false predictions Prediction . However, wrong predictions Prediction can cause different degrees of costs Cost . Therefore, cost-sensitive Cost-sensitive classification Classification algorithms are in demand in order to improve quality Quality of the classification. In this study, rule-based cost sensitive Cost-sensitive BEE-miner BEE-miner algorithm which was developed by making use of Bees Algorithm Bees Algorithm and MEPAR-miner MEPAR-miner algorithms are used to classify the defects Defects in the production line of a textile Textile,Production,Rule-based company in a considerably better way. When results on the quality Quality defect dataset are analysed, it is observed that BEE-miner BEE-miner algorithm outperforms the MEPAR-miner MEPAR-miner algorithm in terms of classification Classification cost Cost and accuracy.","['Engineering', 'Robotics and Automation', 'Artificial Intelligence', 'Industrial and Production Engineering', 'Professional Computing', 'Robotics', 'Machine Learning']"
doi:10.1007/978-3-319-63962-8_193-3,en,Types of Stream Processing Algorithms,ReviewPaper,,"['Computer Science', 'Big Data', 'Information Systems and Communication Service', 'Big Data/Analytics']"
doi:10.1007/978-981-19-2821-5_59,en,Performance Comparison of Machine Learning and Deep Learning Algorithms in Detecting Online Hate Speech,OriginalPaper,"The main objective of this research is to analyze and compare the performance of machine learning (ML) and deep learning (DL) algorithms in detecting online hate speech. Therefore, Support Vector Machine (SVM), Random Forest (RF), Decision Tree (DT), Logistic Regression (LR), Convolution Neural Network (CNN), Recurrent Neural Network_Long Short-Term Memory (RNN_LSTM), BERT (Bidirectional Encoder Representations from Transformers), and Distil BERT algorithms have been explored and analyzed in this research. This research has applied the dataset on hate speech which was developed by Andry Samoshyn which is publicly available in Kaggle. ML algorithms and DL algorithms have got good scores in accuracy. In ML, SVM, RF, and LR have got top accuracy values. In DL algorithms, RNN_LSTM, Distil BERT, and BERT have performed well in accuracy. Based on F-measurement, DL classifiers have outperformed ML algorithms. Distil BERT has obtained the highest F-measurement scores. When we compare the overall performances, DL is performed well rather than ML in detecting hate speech. Especially transformer-based models of DL are more efficient than other DL and ML algorithms.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-3-031-07422-6_14,en,Brazil,OriginalPaper,"Like the European Union and several other countries, Brazil has its own legal regulation on personal data, the General Data Protection Law (Portuguese acronym: LGPD). Enacted on 14 August 2018, the law entered into force in August 2020. Hence, since the mid-2020s, Brazil has had a Data Protection Law in place and a National Data Protection Authority (Portuguese acronym: ANPD) that regulates and supervises compliance with this law. The appointments for the board of the ANPD were approved by the Brazilian Senate on 20 October 2020, and the Authority is currently operational, including through its website, where anyone can file a complaint related to violations of personal data rights.","['Law', 'Private International Law, International & Foreign Law, Comparative Law', 'IT Law, Media Law, Intellectual Property', 'Artificial Intelligence', 'Online Marketing/Social Media', 'Big Data', 'International Economic Law, Trade Law']"
doi:10.1007/978-3-031-16075-2_28,en,Evaluating Suitability of a Blockchain Platform for a Smart Education Environment,OriginalPaper,"Recently, blockchain technology has been used in diverse systems and applications beyond cryptocurrencies. With features such as data immutability and a decentralized structure, blockchain technology is increasingly being adopted in various governance use cases where trust and security are essential concerns, particularly in smart campus areas. Education or learning is a field that offers several opportunities to integrate blockchain into its systems. However, there is a luck of studies into which blockchain platforms, based on consensus algorithms, are most suitable for adopting into a smart education environment. Further study is required to guide education informatics researchers in selecting and developing a suitable blockchain platform for experimenting with their applications. This paper will evaluate which consensus algorithm and blockchain platform are appropriate to apply to such an environment based on its quality requirements.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-3-031-20601-6_4,en,Overview of Gradient Descent Algorithms: Application to Railway Regularity,OriginalPaper,"Optimization is an important branch which aims to conceptualize, analyze, and solve problems of minimization or maximization of a function on a specific dataset. Several optimization algorithms are discussed in machine learning and particularly in deep learning (DL) based systems such as the Gradient Descent (GD) algorithm. Given the importance and the efficiency of the gradient descent algorithm, several research works have made it possible to optimize it and demonstrate its performance, Otherwise, regularity of a train is essential to ensure the continuity of the entire rail system. Non-regularity can spread quickly and influence the rest of the means of transport: rail, road, air, navy etc. In this paper, we perform a comparative study of different optimizations algorithms which are largely used in context of machine learning on the prediction of the regularity of trains, the data used is publicly available. The optimization algorithms studied are Momentum, Adagrad, RMSprop Adam and Adamax. In our context, the overall experimental results obtained show that RMSprop performed better compared to other optimization techniques, while Momentum represents the lowest performances to improve regularity.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-17697-5_33,en,Predicting the Value of Cryptocurrencies Using Machine Learning Algorithms,OriginalPaper,"Cryptocurrencies are a type of unregulated, digital money, issued and most often controlled by its founders, used and accepted between members of a particular virtual community. Since values of cryptocurrencies can be presented as time series, the aim of this paper is to use recurrent neural networks (RNN) in the prediction model of cryptocurrencies values. Real-world data for three cryptocurrencies (Bitcoin, Ethereum, and Litecoin) were used in the experiments. Data were split for training and test set. Three different layer types of RNNs have been applied per each cryptocurrency: long-short term memory - LSTM, Simple, and gated-recurrent unit - GRU. Results of the experiment conducted within this paper show that machine learning algorithms can be used for cryptocurrencies values prediction. Values of mean square errors are very small (ranges from 0.03 to 0.42) which indicates promising model prediction capabilities.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1412-6_59,en,A Road Map for Classification of Heart Disease Using Machine Learning Classifier,OriginalPaper,"Heart disease becomes one of the most influential diseases that cause a large number of deaths every year around the world. A report by WHO shows in the year 2016 nearly 17 million people gets died due to heart disease every year. The death rate is increasing rapidly day-by-day and it is estimated by WHO that this death ratio will reach the peak of 75 million by 2030. Despite the availability of modern technology and health care system, prediction and diagnosis of heart disease are still beyond the limitations. Currently, the clinical industries and diagnosis centers have a huge of amount data for the diagnosis of heart disease patients. Machine learning algorithms are more useful to find the hidden patterns, discover knowledge from the dataset, and predict correct outcomes. This research proposed an efficient machine learning-based classifier methodology that outperforms the existing similar methodologies. To evaluate the proposed machine learning classifier, we have taken data from the UCI repository. In this study, we have used ZeroR, bagging, M5, and decision table classifier. The M5 classifier produced a good result compared to other classifiers with 0.2726 mean absolute errors.","['Engineering', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security']"
doi:10.1007/978-3-031-08246-7_6,en,Evaluation of Machine Learning Techniques for Malware Detection,OriginalPaper,"Currently, there is a security breach in technological systems, attacks on computers and mobile devices through malicious software (also called malware) continue to increase. Malicious software attacks occur at all levels and all types of devices, affecting computer users, corporations, industry, and government. Therefore, the detection of malware continues to be a challenge in computer science. Algorithms based on machine learning and deep learning are being used recently to build software solutions that allow the identification of malicious data in real-time. In this paper, we evaluate three classic machine learning algorithms and one neural network-based algorithm for malware detection and classification using different public data sets. The support vector machine (SVM) and the J48 decision tree (DT) algorithms obtain the best results in all the experiments with values equal to the results available in state-of-the-art. The extreme learning machine (ELM) algorithm obtains very acceptable results in experimentation. The results successfully validate the effectiveness of the implemented algorithms, improving the generalization performance of detecting a new instance of malicious software.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2188-9_40,en,Fractional System Modeling of Liquid–Liquid Heat Exchanger Using Various Optimization Techniques,OriginalPaper,This paper presents a comparison among various metaheuristic optimization algorithms for carrying out the system modeling of a liquid–liquid heat exchanger system. The system has been modeled in first-order and second-order fractional template with time delay. The simulation results are carried out using MATLAB Simulink. It can be seen from the results that the second-order estimated models better fit the original data than the first-order estimated models. The maximum percentage fit achieved is 70.5% with a root mean square error of 0.0055. The presented system modeling procedure utilizing optimization algorithms can be used for modeling various industrial processes.,"['Engineering', 'Industrial and Production Engineering', 'Mechatronics', 'Engineering Thermodynamics, Heat and Mass Transfer', 'Energy Storage', 'Materials Engineering']"
doi:10.1007/978-3-031-08246-7_3,en,Analysis of Canonical Heuristic Methods for the Optimization of an Investment Portfolio,OriginalPaper,"An investment portfolio is a collection of financial assets in which an individual or a financial institution called an investor has decided to invest its capital based on criteria such as its risk aversion, the experience of a financial advisor or the formulation of an optimization problem. This last approach was the object of study of Harry Markowitz, an American economist who wrote the Theory of the optimal portfolio, in this, the amounts to be invested in the assets are determined in such a way that allows the maximum possible profit with the minimum possible risk. In this work it is proposed, as an optimization problem based on the Markowitz model, the obtaining of investment amounts of a six financial assets portfolio through the maximization of the profit ratio and the risk of loss. To determine the best possible solution, two genetic algorithms are compared with different percentage of cross, a clonal immunological algorithm and a differential evolution algorithm. The comparison criteria are the stability of the algorithm (obtainable with the coefficient of variability) and the hypothesis of normality and homoscedasticity obtainable from 60 executions of each of the proposed algorithms. It also determines the convergence of the algorithms used in this work. The results obtained allow to obtain a diversified portfolio, the first requirement of an investment portfolio according to Markowitz's theory.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-11047-4_3,en,Graphs in VLSI circuits and systems,OriginalPaper,"Large scale VLSI systems are highly complex, combining a diverse range of expertise, such as device physics, circuit design, computer architecture, and physical design. Abstraction is an effective tool for managing the complexity of these integrated systems. The abstract models described in this chapter exclusively focus on information relevant to a specific design objective. A graph is an effective tool for managing the complexity of large scale VLSI systems. By reducing the complex components of a VLSI system into nodes and edges, the design effort can be concentrated on the key features of a system while discarding extraneous information. The significance of graph theory at every abstraction layer of the VLSI design process is discussed in this chapter. At the register transfer layer, register allocation is often achieved by graph coloring, minimizing the communication between the CPU and memory. Ordered binary decision diagrams and AND-inverter graphs enable efficient graph-based processing of logic circuits. Graph-based techniques, such as random walks and network flow theory, facilitate the circuit analysis process of VLSI systems. Physical design is greatly enhanced by applying graph optimization algorithms to circuit partitioning, floorplanning, placement, and routing.","['Engineering', 'Circuits and Systems']"
doi:10.1007/978-981-19-4990-6_48,en,A Comparative Study for Determining the Vehicle Routing Optimal Path,OriginalPaper,"The Vehicle Routing Problem requires the determination of the optimum set of routes to be carried out through a fleet of automobiles to assist a given set of customers. It is an important benchmark issue of logistic management and has been widely studied and used in transportation systems, logistics distribution systems, and express delivery systems. It is a subset of the Travelling Salesman Problem and is considered a NP–hard problem. This problem can be solved using meta-heuristic algorithms—Genetic Algorithm and Ant Colony Optimization. In this paper, we will be comparing the above-mentioned optimization techniques for interpreting the vehicle routing problem and arriving at a solution.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Wireless and Mobile Communication']"
doi:10.1007/978-981-19-2821-5_1,en,Constructing Interval Type-2 Fuzzy Systems (IT2FS) with Memetic Algorithm: Elucidating Performance with Noisy Data,OriginalPaper,"Fuzzy modeling is a challenging task and becomes more complex when designing T2FS, which requires identification of more parameters as compared to T1FS. The problem of fuzzy modeling can be expressed as a high-dimensional search and optimization process, and EAs have the ability to search for optimal solutions in high-dimensional search space, so researchers used various EAs for fuzzy modeling. GAs are widely used for finding solutions in large search spaces, and MAs have characteristics of both global and local optimizations. This paper describes how to use MAs and GAs to identify IT2FS, including how to build MFs for both input and output, as well as how to generate a rule base from a data collection. The efficiency of T1FS and IT2FS for noisy data is also compared with GAs and MAs in the paper. For comparison, we consider four different problems: a rapid Ni–Cd battery charger, data from Box and Jenkins’s gas furnace, and the iris and wine classification datasets. In the presence of noise, the results imply that IT2FS is more efficient than T1FS, and MAs are more efficient than GAs.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-3-031-09835-2_1,en,"A Brief Tutorial on Optimization Problems, Optimization Algorithms, Meta-Heuristics, and Swarm Intelligence",OriginalPaper,"This chapter provides preliminaries and essential definitions in optimization, meta-heuristics, and swarm intelligence. It starts with different components of optimization problems, formulations, and categories. Conventional and recent optimization algorithms to optimize such problems are then discussed. The chapter is finished by focusing on meta-heuristics and swarm intelligence algorithms as the emerging and most widely used optimization algorithms lately in both science and industry.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-6379-7_2,en,Leveraging Healthcare System with Nature-Inspired Computing Techniques: An Overview and Future Perspective,OriginalPaper,"Nature-inspired computing (NIC) computer optimization algorithms are an emerging approach that relies on the principles and inspiration of the biological development of nature to build new and strong competitive tactics. Given the success of NIC approaches and techniques in big data analytic applications, it is expected that they may also be effectively applied in health care. The application of NIC in the management of the ongoing COVID-19 pandemic is a beneficial tool that may be widely employed in clinical and public health decision-making. Recent developments in artificial intelligence, machine learning, and bio-inspired optimization algorithms have boosted the relevance of biomedical signal and image processing research. Biomedical image processing is comparable in theory to biomedical signal processing in many aspects. It comprises the analysis, enhancement, and display of photographs collected via X-rays, ultrasound, magnetic resonance imaging (MRI), nuclear medicine, and visual imaging technologies. NIC is presently quickly emerging in many scientific and technological research domains, including biomedical sciences. In this perspective, nature optimization algorithms may play a key role in addressing the multiple elements of health care. Researchers, healthcare policymakers, physicians, and other interested parties might use the insights of our chapter to better prioritize research and development for the operationalization of AI in the event of future pandemics.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Health Informatics', 'Cancer Research', 'Genetics and Genomics', 'Bioinformatics']"
doi:10.1007/978-3-031-08782-0_9,en,Retention Prediction in the Gaming Industry: Fuzzy Machine Learning Approach,OriginalPaper,"Traditional machine learning algorithms may not produce satisfactory results on high-dimensional and imbalanced datasets. Therefore, the popularity of the concept of ensemble learning has increased, especially in recent years. Standard machine learning algorithms try to learn a single hypothesis from the training dataset, while ensemble-learning algorithms create a set of hypotheses and try to combine them. In this way, they can produce better results than the common machine learning algorithms. The fuzzy logic concept is also used in machine learning problems, especially in clustering problems in recent years. The fuzzy logic approach, by its nature, is used to solve problems that do not have a definite result, such as real-life problems, brings this approach to the fore, especially in machine learning problems. In this paper, we survey the latest status of ensemble learning and fuzzy clustering methods. Also, we proposed a new approach that combines fuzzy clustering and ensemble learning. This approach is applied in a case study, and results are compared with existing ensemble learning algorithms in the methodology section.","['Engineering', 'Engineering Economics, Organization, Logistics, Marketing', 'Business and Management, general', 'Computational Intelligence']"
doi:10.1007/978-3-031-18050-7_16,en,Compression of Clustered Ship Trajectories for Context Learning and Anomaly Detection,OriginalPaper,"This paper presents a context information extraction process over Automatic Identification System (AIS) real world ship data, building a system with the capability to extract representative points of a trajectory cluster. With the trajectory cluster, the study proposes the use of trajectory segmentation algorithms to extract representative points of each trajectory and then use the K-means algorithm to obtain a series of centroids over all the representative points. These centroids combined, form a new representative trajectory of the cluster. The results show a suitable approach with several compression algorithms that are compared with a metric based on the Perpendicular Euclidean Distance.","['Engineering', 'Computational Intelligence', 'Industrial and Production Engineering']"
doi:10.1007/978-3-031-13714-3_10,en,Population Management,OriginalPaper,"After having generated several solutions, we can seek to learn how to combine them. This chapter review techniques for generating new solution from existing ones and for managing a population of solution. The most popular method in this field is undoubtedly genetic algorithms. However, the latter are less advanced metaheuristics than memetic algorithms or scatter search. The path relinking technique is also part of this chapter. Finally, among the last metaheuristics invented, we find the particle swarm methods, which seem adapted to continuous optimization.","['Business and Management', 'Operations Research/Decision Theory', 'Optimization', 'Computational Mathematics and Numerical Analysis', 'Algorithms', 'Computational Science and Engineering', 'Artificial Intelligence']"
doi:10.1007/978-981-19-6379-7_1,en,"The Scope and Applications of Nature-Inspired Computing in Bioinformatics
",OriginalPaper,"Charles Darwin postulated the concept of “survival-of-the-fittest” and evolution in general. He discussed how nature selects the best candidate under different situations who are fit enough to survive and reproduce. This analogy has inspired many computational scientists, bioinformaticians, and computational biologists to develop techniques that can learn, adapt, and evolve to find optimal solutions for complex problems. Biologists are heavily dependent on computational methods and strategies to analyze humongous biological and medical data. Nature-inspired computing (NIC) encapsulates an ensemble of myriad studies of computer science, statistics, mathematics, and biological sciences where the essence is to adapt and develop robust competing techniques just like nature. It is a novel approach to optimization algorithms that are motivated by the dynamics of the biological evolution of our natural milieu. Over the past decade, various nature-inspired optimization algorithms have been deployed to solve complex problems in bioinformatics, engineering, and other sciences. With the glorious artificial intelligence (AI) revolution in biological sciences, there have been times when some problems are nonlinear in nature with multiple constraints and some techniques are hard to deploy. To solve high dimensionality issues and time complexity in such cases, NIC algorithms are the best choice to be used to solve complex optimization problems. This chapter highlights the commonly used NIC algorithms and their applications in biological sciences and bioinformatics.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Health Informatics', 'Cancer Research', 'Genetics and Genomics', 'Bioinformatics']"
doi:10.1007/978-3-031-16078-3_50,en,Hybrid Evolutionary Algorithm for Optimal Control Problem,OriginalPaper,"The optimal control problem is well known long time ago, but there is no a general numerical method for it. More precisely researchers try always to solve this problem various numerical methods. Recently it was established, that if the optimal control problem has phase constraints included in quality criterion, then a functional is multimodal and this optimization problem belongs to global class optimization. Therefore, to solve the optimal control problem it is better to use evolutionary algorithms. But this proposition doesn’t give useful information for researcher, because now there are huge quantity evolutionary algorithms. In this paper the best evolutionary algorithm for the optimal control problem is proposed. It is constructed on the base three evolutionary algorithms, genetic algorithm, particle swarm optimization, and grey wolf optimizer. It is shown computational experiments, where this hybrid algorithm is compared with everyone from listed above on the complex problem with phase constraints.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-3-031-17576-3_12,en,Arabic Text Classification Using Modified Artificial Bee Colony Algorithm for Sentiment Analysis: The Case of Jordanian Dialect,OriginalPaper,"Arab customers give their comments and opinions daily, and it increases dramatically through online reviews of products or services from companies, in both Arabic, and its dialects. This text describes the user’s condition or needs for satisfaction or dissatisfaction, and this evaluation is either negative or positive polarity. Based on the need to work on Arabic text sentiment analysis problem, the case of the Jordanian dialect. The main purpose of this paper is to classify text into two classes: negative or positive which may help the business to maintain a report about service or product. The first phase has tools used in natural language processing; the stemming, stop word removal, and tokenization to filtering the text. The second phase, modified the Artificial Bee Colony (ABC) Algorithm, with Upper Confidence Bound (UCB) Algorithm, to promote the exploitation ability for the minimum dimension, to get the minimum number of the optimal feature, then using forward feature selection strategy by four classifiers of machine learning algorithms: (K-Nearest Neighbors (KNN), Support vector machines (SVM), Naïve-Bayes (NB), and Polynomial Neural Networks (PNN). This proposed model has been applied to the Jordanian dialect database, which contains comments from Jordanian telecom company’s customers. Based on the results of sentiment analysis few suggestions can be provided to the products or services to discontinue or drop, or upgrades it. Moreover, the proposed model is applied to the database of the Algerian dialect, which contains long Arabic texts, in order to see the efficiency of the proposed model for short and long texts. Four performance evaluation criteria were used: precision, recall, f1-score, and accuracy. For a future step, in order to build on or use for the classification of Arabic dialects, the experimental results show that the proposed model gives height accuracy up to 99% by applying to the Jordanian dialect, and a 82% by applying to the Algerian dialect.","['Engineering', 'Computational Intelligence', 'Machine Learning', 'Big Data']"
doi:10.1007/s10473-023-0112-9,en,A Relaxed Inertial Factor of the Modified Subgradient Extragradient Method for Solving Pseudo Monotone Variational Inequalities in Hilbert Spaces,OriginalPaper,"In this paper, we investigate pseudomonotone and Lipschitz continuous variational inequalities in real Hilbert spaces. For solving this problem, we propose a new method that combines the advantages of the subgradient extragradient method and the projection contraction method. Some very recent papers have considered different inertial algorithms which allowed the inertial factor is chosen in [0; 1]. The purpose of this work is to continue working in this direction, we propose another inertial subgradient extragradient method that the inertial factor can be chosen in a special case to be 1. Under suitable mild conditions, we establish the weak convergence of the proposed algorithm. Moreover, linear convergence is obtained under strong pseudomonotonicity and Lipschitz continuity assumptions. Finally, some numerical illustrations are given to confirm the theoretical analysis.","['Mathematics', 'Mathematics, general', 'Analysis']"
doi:10.1007/978-981-19-4502-1_1,en,Artificial Intelligence Based Integrated Renewable Energy Management in Smart City,OriginalPaper,"Optimal management of energy in a smart city is facing challenges due to changing supply and demand patterns. Renewable energy (RE) is a powerful source for future global development in times of energy scarcity. The use of Integrated Renewable Energy Systems (IRES) to extract maximum energy from available sources is a challenging area of research. AI technology has evolved rapidly over the last several decades and its applications in modern systems have grown rapidly. The size of the IRES has been customized using different algorithms of artificial intelligence (AI). This chapter covers the use of AI algorithms to overcome the technical, financial, and size issues that come with IRES. This chapter studies the different algorithms used to manage the sizing of IRES in smart city. This chapter explains use of genetic algorithms, particle swarm optimization, ant colony optimization, hill climbing optimization, and neural network algorithms have been used to manage IRES.","['Energy', 'Energy Storage', 'Optical and Electronic Materials', 'Renewable and Green Energy', 'Electrochemistry']"
doi:10.1007/978-3-031-15858-2_5,en,Model-Free Control of Time Delay Systems,OriginalPaper,"In this chapter, we present delay compensation schemes for the stabilization of time delay systems using reinforcement learning (RL). An extended state augmentation approach is developed to relax the requirement of the knowledge of the delays encountered in the state and input channels. Controllability and observability conditions are first established for the augmented system to guarantee the solvability of the optimal control problem. Delay-free learning equations are then obtained based on this augmentation approach that enable us to design model-free RL algorithms. Both state feedback and output feedback results for the linear quadratic regulation of discrete-time systems with delays are presented. Comprehensive simulation studies are carried to validate these algorithms.","['Mathematics', 'Systems Theory, Control', 'Control and Systems Theory', 'Optimization']"
doi:10.1007/978-981-19-3951-8_14,en,Comparison Between Genetic Algorithm and Grey Wolf Optimiser to Solve Capacitated Vehicle Routing Problem,OriginalPaper,"The vehicle routing problem (VRP) is one of the commonly faced problems by the vendors in their daily routine. There are different variants of VRP. One such variant is capacitated vehicle routing problem. To meet client needs for a particular commodity, CVRP requires a group of identical carriers in terms of capacity. The aim is to minimise the cost incurred by vehicles taking into account a variety of restrictions such as the vehicle's capacity and other constraints. The most prevalent approach for solving this problem is the cluster-first route-second strategy. In this process, clients are grouped into several clusters, and one vehicle serves one cluster. This problem can be solved by nature-inspired grey wolf optimiser, genetic algorithm, etc. In this paper, K-GWO (GWO combined with K-means cluster algorithm) and genetic algorithm are used to solve CVRP. Both the algorithms are tested on a number of test cases.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-3-031-14537-7_8,en,Global Optimisation for Point Cloud Registration with the Bees Algorithm,OriginalPaper,"The problem of 3D 3D registration entails the estimation of spatial transformation which best aligns two point sets. Iterative Closest Point Iterative Closest Point (ICP) is arguably the most popular and one of the most effective algorithms for 3D 3D registration at present. This algorithm uses singular value decomposition Decomposition to obtain a least squares alignment of two point sets. As a greedy alignment procedure, Iterative Closest Point Iterative Closest Point (ICP) is liable to converge to sub-optimal solutions. In this study, the problem of 3D 3D registration is addressed using the popular Bees Algorithm Bees Algorithm metaheuristics Metaheuristics . Thanks to its global search Global Search approach, the Bees Algorithm Bees Algorithm, THE is known to be highly impervious to sub-optimal convergence. To increase the efficiency of the search, singular value decomposition Decomposition is used to exploit the search results of the Bees Bees Algorithm. Experimental evidence showed that the proposed algorithm outperformed Iterative Closest Point Iterative Closest Point (ICP) in terms of consistency and precision and showed high robustness to noise Noise in the point sets.","['Engineering', 'Robotics and Automation', 'Artificial Intelligence', 'Industrial and Production Engineering', 'Professional Computing', 'Robotics', 'Machine Learning']"
doi:10.1007/978-3-030-03009-4_90-3,en,The Potts Model with Different Piecewise Constant Representations and Fast Algorithms: A Survey,ReviewPaper,"Markov random fields (MRF) and the Potts model have many applications in different areas. Especially, conditional random fields (CRF) and Potts model have been used in connection with classifiers. In this work, we focus on the Potts model and use image segmentation and data classification as examples to show some new techniques and fast algorithms for this model. We survey different piecewise constant representation techniques. Many of these representations can be interpreted as min-cut and max-flow problems on some special graphs. We will concentrate especially on the continuous setting and formulate continuous min-cut and max-flow models. When the min-cut/max-flow models are discretized, they give corresponding discrete min-cut/max-flow models on grids. Using these connections, we are able to turn the non-convex Potts model into some simple convex minimization problems with solutions that can be obtained by properly designed fast algorithms. In this survey, we will start by introducing some widely studied variational segmentation models and the classical level-set approaches to solve them. Then, we will describe three different piecewise constant representations for the general Potts model and their corresponding convex relaxations and fast algorithms. In the end, we will also generalize the method to a graph setting for high-dimensional data classifications. This survey presents the different techniques and algorithms in an integrated and self-contained manner.","['Mathematics', 'Computational Mathematics and Numerical Analysis', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Optimization', 'Partial Differential Equations', 'Mathematical Models of Cognitive Processes and Neural Networks']"
doi:10.1007/978-3-031-18516-8_19,en,A Comparative Study of Metaheuristics Based Task Scheduling in Cloud Computing,OriginalPaper,"Cloud computing is a standard way of hosting software applications and services that is booming day by day thanks to the different utilities offered to users according to their needs and contracts. Most of these services are in the form of tasks and their execution in such environments requires efficient scheduling strategies that take into account both algorithmic and architectural features. The objective is to orchestrate the suitable assignment of the submitted tasks to the available resources on the basis of various functional requirements of end users. To overcome the scheduling issue, which is an NP-hard problem, various metaheuristic algorithms are used in literature to achieve near optimal solution. For this purpose, this paper aims to perform a comparative investigation of three common metaheuristic algorithms in the optimization process such as Shuffled Frog Leaping Algorithm (SFLA), Flower Pollination Algorithm (FPA) and Gray Wolf Optimization (GWO). Both standard and synthetic workloads are employed to analyze the performance of these algorithms by evaluating its objective function in term of two metrics which are makespan and resource utilization rate. The simulation results obtained using the CloudSim framework are very satisfactory and clearly show the value of our study.","['Engineering', 'Complexity', 'Computational Intelligence', 'Control and Systems Theory']"
doi:10.1007/978-3-031-20105-9_8,en,Comparison of Metaheuristics Techniques and Agent-Based Approaches,OriginalPaper,"Agent-based models represent new approaches to characterize systems through simple rules. Under such techniques, complex global behavioral patterns emerge from the agent interactions produced by the rules.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-09835-2_16,en,Novel Chaotic Best Firefly Algorithm: COVID-19 Fake News Detection Application,OriginalPaper,"The COVID-19 pandemic period is approaching the two-year mark of its lifetime. During the pandemic, the people experienced various restrictions and different problems were raised unlike before. While the people stayed in their homes, electronic device usage had a decisive spike. This increased time spent on the internet and the amount of misinformation followed the same trend. The problem with the information on the COVID-19 is that there are too many different sources presenting different data. While some are just trying to help and do not have the latest or the most accurate information, some sources are malicious. Either way, everything but the latest and the most accurate data needs to be filtered when regarding a serious matter as such. The research proposed in this manuscript is aimed to identify COVID-19 fake news by performing wrapper-based feature by using an improved version of the well-known firefly algorithm. Practical simulations were done against a well-known dataset used in the domain of this problem, Koirala. The proposed method managed to achieve high accuracy of classification by using a smaller number of features in comparison with the state-of-the-art methods tested in the same experimental environment.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-030-96025-4_2,en,Optimization Techniques,OriginalPaper,"This chapter presents a comparison between conventional, artificial intelligence (AI) and modern optimization techniques. The mathematics of conventional optimization techniques such as linear programming (LP), quadratic programming (QP), integer programming (IP) and dynamic programming (DP) are considered. The AI techniques such as artificial neural network (ANN), fuzzy linear programming (FLP) and expert systems (ES) are also introduced. In addition, modern optimization techniques such as genetic algorithm (GA), differential evolution (DE) algorithm, particle swarm optimization (PSO), seeker optimization algorithm (SOA) and ant colony optimization (ACO) algorithm are considered. The description of each technique with its mathematical model and the steps for solving the problem are presented in this chapter.","['Engineering', 'Power Electronics, Electrical Machines and Networks', 'Energy Systems', 'Renewable and Green Energy']"
doi:10.1007/978-981-19-2126-1_36,en,A Comprehensive Review Analysis on PSO and GA Techniques for Mathematical Programming Problems,OriginalPaper,"Mathematical programming problems (MPPs) having unique mathematical format usually treated as hard problems are important optimization problems. On the other hand, particle swarm optimization (PSO) and genetic algorithm (GA) are important optimization approaches used in solving complex optimization problems. PSO and GA are nature-inspired techniques based on the social behavior of species and operations of human chromosomes, respectively. During past decades, PSO, GA, and their hybrid techniques were extensively used in solving different types of mathematical programming problems. But there is a lack of comprehensive review analysis on PSO, GA, and associated hybrid techniques for solving various types of mathematical programming problems. In this article, we present a systematic detailed review on these techniques in context of solving mathematical programming problems along with comprehensive review analysis. A systematic review procedure has been used for analysis of sixty-eight articles of reputed databases like Thomson Reuters, Web of Science, Scopus, and IEEE. The research gaps and future research scope for the researcher who inclines to solve different types of mathematical programming problems with these techniques are also identified. Relevance of the work : Mathematical programming problems (e.g., linear programming problem (LPP), NLPP, MOPP, etc.) are important optimization problems in which many types of real-world problems are formulated. On other hand, PSO and GA are prominent natured-inspired techniques used to solve complex optimization problems. This article presents comprehensive review analysis on PSO and GA in context of solving different types of mathematical programming problems. This review work also narrates the unique linkage between GA–PSO techniques and mathematical programming problems. This systematic and in-depth review analysis will be useful to the researchers and scientists working in the related areas of mathematical programming and natured-inspired optimization techniques to pursue carrying out further research in these areas.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Machine Learning', 'Big Data', 'Computer Systems Organization and Communication Networks']"
doi:10.1007/978-981-19-4606-6_85,en,A Hybrid Algorithm Based Static Obstacle Avoidance for a Wheeled Base,OriginalPaper,"Most of the path planning algorithms used for avoiding obstacles are prone to higher computational complexity. Hybrid algorithms employed for the static obstacle collision avoidance are proved to be efficient as compared to conventional algorithms. In this paper, a hybrid algorithm that consumes less computational time during static obstacle avoidance is introduced. A hybrid algorithm combining Lazy Probabilistic Road Map (PRM) algorithm as well as Life Long Planning (LPA) star algorithm is employed for generating an optimized path from start node to end node. Lazy PRM technique reduces the computational time for generating nodes and edges connecting the generated nodes. LPA star algorithm determines the optimized path connecting the local edges formed using Lazy PRM technique. A non-holonomic mobile platform designed for carrying upper body humanoid robot is used in this paper for the experimental evaluation of the proposed hybrid algorithm.","['Engineering', 'Industrial and Production Engineering', 'Machinery and Machine Elements', 'Materials Engineering']"
doi:10.1007/978-3-031-14537-7_14,en,Application of the Dual-population Bees Algorithm in a Parallel Machine Scheduling Problem with a Time Window,OriginalPaper,"The parallel machine scheduling problem with time windows Parallel machine scheduling problem with time windows (PMSP-TW) belongs to a category of production scheduling problems. Due to the time window Time window characteristics of each machine, it becomes difficult to solve this problem. For the PMSP Parallel machine scheduling problem with time windows -TW problem, we proposed Dual-population Bees Algorithm a dual-population Dual-population Bees Algorithm Bees Algorithm . Two types of search populations and supplementary populations are set in the Bees Algorithm Bees Algorithm, THE . The propose of dual populations Dual-population is mainly aimed at the situation of poor convergence performance of the traditional Bees Algorithm. If the optimization process is inefficient, the population to which the food source belongs will be updated through the population performance evaluation. Experiments can verify the scheduling Scheduling effect of our proposed algorithm.","['Engineering', 'Robotics and Automation', 'Artificial Intelligence', 'Industrial and Production Engineering', 'Professional Computing', 'Robotics', 'Machine Learning']"
doi:10.1007/978-3-031-20545-3_2,en,Routing in Wireless Sensor Networks—Energy Welfare,OriginalPaper,"This chapter presents the application of a social welfare Social welfare function to distributed Distributed routing Routing decisions in wireless sensor networks Wireless sensor networks . The function is incorporated into an algorithm Algorithm , originally called MaxEW MaxEW algorithm , which allows to route data efficiently on a distributed Distributed control approach maximizing the lifetime Lifetime of the network. Robustness and efficiency are achieved by emergence of the system, where each sensor makes routing Routing decisions based on maximization of an energy welfare Energy welfare metric of its local neighborhood Neighborhood . The chapter presents the principles of this algorithm Algorithm using numerical examples and also shows how to implement it in VBA code. The performance Performance evaluation of the MaxEW MaxEW algorithm and its advantages over other routing Routing algorithms is also discussed.","['Engineering', 'Computational Intelligence', 'Social Choice/Welfare Economics/Public Choice/Political Economy', 'Robotics and Automation', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5217-3_43,en,Numerical Simulation of Substructure Shake Table Testing for Base-Isolated Structure Using Model-Based Integration Algorithm,OriginalPaper,"Base isolation is an effective method of reducing the seismic responses of structures. As a promising experimental measure, substructure shake table testing (SSTT) can be used to investigate the seismic performance of base-isolated structures. Model-based integration algorithms have the advantages of explicit formulation and unconditional stability, and thus they are very suitable for SSTT. In this study, the SSTT using a family of generalized CR (GCR) algorithms for the base-isolated structures is numerically studied. Firstly, time history analyses of a six-story base-isolated structure are conducted and compared with the corresponding non-isolated structure. Then, the SSTT approach using the GCR algorithms is proposed for the base-isolated structures. The numerical simulation of a series of SSTTs with different time steps, integration coefficients and time lags are finally conducted. The results indicate that the GCR algorithms with relative large time step still have excellent accuracy. The SSTT results of using the subfamily of κ 1  = 1 are less accurate than the subfamily of κ 1  = 1/2. In addition, the time lag has obvious adverse effect on the SSTT results. There is an instable tendency of the SSTT results as the time lag increases.","['Engineering', 'Civil Engineering', 'Public Policy', 'Arts']"
doi:10.1007/978-981-19-5224-1_23,en,Understanding and Comparative Analysis of Consensus Algorithms,OriginalPaper,"Blockchain technology has emerged as a new security technology that offers a variety of benefits to numerous businesses. Blockchain is working on the concept of distributed ledger technology. Multiple industries are adopting blockchain technology due to its different features like distributed networks, consensus mechanisms, and transparency. Blockchain technology gives a great impact on the business environment. Blockchain technology does not involve third-party interference and provides security and transparency to data. The data inside the blockchain is immutable, and no one will be modified it or delete it. Smart contracts and consensus algorithms are the major components of blockchain technology. A smart contract is a sort of computer software that establishes agreements between the nodes of a blockchain network’s participants. Few major consensus algorithms are PoW, PoS, PBFT, DPoS, and tendermint. This paper evaluates the different consensus algorithms and principles behind using it. Paper demonstrates the steps to be followed for the implementation of consensus algorithms.","['Engineering', 'Communications Engineering, Networks', 'Statistics, general', 'Cyber-physical systems, IoT', 'Sociology, general', 'Professional Computing']"
doi:10.1007/978-3-031-16368-5_14,en,Multipoint Data Transmission Issues in High Bandwidth-Delay Product TCP/IP Networks,OriginalPaper,"Modern network hardware is nowadays ready to provide high-speed channels across the countries and between continents providing wide network resources to end-users. In presence of this, algorithms of multipoint data transmission become more and more a bottleneck, utilizing available network resources not optimally, which can be a consequence of the flaws of modern software solutions and data transport protocols. In the meanwhile, several promising solutions for traffic control have been proposed in the last decade, however the area of multipoint high-speed data transmission remains an insufficiently researched field. This work is aimed to observe the main issues of the data transmission in TCP/IP based wide area networks focusing mainly on congestion control algorithms and software issues in point-to-multipoint solutions. In this paper, the main issues of congestion control algorithms have been reviewed and compared in different network delay and loss probability cases. Proposed earlier Bottleneck Queue Level congestion control (BQL) algorithm has been observed in the context of decreasing the negative impact provided by widely used algorithms on the end-user side. The problem of underutilization of existing channels is described and several software methods of increasing the data throughput have been touched. Several issues of point-to-multipoint data transmission and application-layer multicast solution based on RMDT have been discussion. A final performance evaluation and comparison of TCP BBR and RMDT BQL were made with a tuned Linux TCP/IP stack. The evaluation of introduced algorithms and their prototyping were made with Reliable Multi-Destination Transport Protocol (RMDT), a UDP-based, high-speed transport protocol. All tests have been performed in the emulated WAN environment of Future Internet Lab Anhalt (FILA).","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks']"
doi:10.1007/978-3-031-09016-5_5,en,Algorithms and Computational Complexity,OriginalPaper,"In this chapter, we discuss computational problems related to ABC rules and algorithms that solve these problems. We start by discussing the computational complexity of ABC rules. As many ABC rules are computationally difficult, a thorough algorithmic analysis is paramount to a practical application of these rules.","['Computer Science', 'Artificial Intelligence', 'Social Choice/Welfare Economics/Public Choice/Political Economy', 'Theory of Computation', 'Multiagent Systems']"
doi:10.1007/978-3-319-75479-6_18-1,en,Gene Regulatory Network Reconstruction Using Single-Cell RNA-Sequencing,ReviewPaper,"Gene regulatory networks (GRNs) describe the relationship between transcription factors and their target genes, offering a platform to discover new pathways for complex diseases such as neurodegenerative diseases. These methods are usually based on gene expression experiments from transcriptomics studies. In recent years, at the molecular biology level, the emerging single-cell RNA-sequencing (scRNAseq) technology has revolutionized the way complex diseases are studied. This technology offers gene expressions for each cell separately, offering molecular information at a tremendous scale and resolution. In this chapter, the state-of-the-art GRN methods that are based on scRNAseq data are described, analyzed, and compared. These algorithms were applied to Alzheimer’s Disease (AD), showing that current GRN methods have displayed an essential contribution; however, as the scRNAseq data increases, the need for novel GRN tools able to cope with the challenges of various complex diseases such as AD arises.","['Biomedicine', 'Neurosciences', 'Computational Biology/Bioinformatics', 'Health Informatics', 'Mathematical Models of Cognitive Processes and Neural Networks']"
doi:10.1007/978-981-19-4052-1_19,en,Comparative Analysis of Machine Learning Classification Algorithms for Predictive Models Using WEKA,OriginalPaper,"The world is becoming progressively more dependent on technology. Artificial intelligence (AI), part of such technology is the simulation and emulation of human intelligence by machine and computer systems. Machine learning, one of the most significant branches of AI, makes it possible for machines to learn from experience and historical data using simple and complex algorithms. Predictive algorithm is a scientific idea of empirically establishing a relationship between the historical set of data which can then be used to make future decision in an attempt to solve some real-life problems. The action of predictive algorithm on big data results into predictive modeling which has been applied by various researchers to solve numerous problems including prediction of weather condition, rate of disease spread, birth rate, death rate, rate of road accident, and in population prediction too. In this paper, we have presented a comparative analysis on the performance of four major machine learning classification algorithms, namely K-nearest neighbor, naïve Bayes, random forest, and SVM on three case studies of predictive modeling using WEKA tool. The case studies selected for this paper are station-wise rainfall prediction, life time of a car prediction, and detection of breast cancer.","['Engineering', 'Computational Intelligence', 'Information Storage and Retrieval', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Data Structures and Information Theory', 'Artificial Intelligence']"
doi:10.1007/978-3-031-21333-5_77,en,Clustering Study of Vehicle Behaviors Using License Plate Recognition,OriginalPaper,"Ubiquitous computing and artificial intelligence contribute to deploying intelligent environments. Sensor networks in cities generate large amounts of data that can be analyzed to provide relevant information in different fields, such as traffic control. We propose an analysis of vehicular behavior based on license plate recognition (LPR) in a rural region of three small villages. The contribution is twofold. First, we extend an existing taxonomy of the most widely used clustering algorithms in machine learning with additional classes. Second, we compare the performance of algorithms from each class of the taxonomy, extracting behavioral patterns. Partitional and hierarchical algorithms obtain the best results, while density-based algorithms have poor results. The results show four differentiated patterns in vehicular behavior, distinguishing different patterns in both residents and tourists. Our work can help policymakers develop strategies to improve services in rural villages, and developers choose the correct algorithm for a similar study.","['Engineering', 'Data Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-6379-7_13,en,Consequential Innovations in Nature-Inspired Intelligent Computing Techniques for Biomarkers and Potential Therapeutics Identification,OriginalPaper,"Computational biology has changed how healthcare systems and biomedical engineering work. Nature-inspired intelligent computing (NIIC) approaches in predicting potential biomarkers and drug targets could be an astonishing bridge between biology/nature with today’s advanced and sophisticated areas like artificial intelligence, deep learning, computer vision, and others. Analyzing disease biomarkers is an emerging field of interest. Several molecular evaluations have been developed to detect biomarkers that indicate disease response to specific therapies. Recognition of these molecules and understanding their molecular mechanisms is critical for disease prognosis and late-stage therapeutics development. Breakthroughs in genomics and transcriptional analyses have significantly increased our understanding of the poorly understood genomic matter or dark matter. The systematic identification of disease-associated lncRNAs has expanded our understanding of the underlying molecular mechanisms of complex diseases, but it has also been shown to have an inherent advantage over protein-coding genes in disease diagnosis, prognosis, and treatment. Given the lower efficiency and increased time and cost of biological experiments, computer-aided inference of disease-associated RNAs using nature-inspired intelligent computing methods has emerged as a promising approach for expediting the study of lncRNA functions and providing complementary value for experimental analyses. In this chapter, we have discussed the fundamentals of NIIC techniques, their role in the diagnosis of various diseases, and their futuristic role in the healthcare industry.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Health Informatics', 'Cancer Research', 'Genetics and Genomics', 'Bioinformatics']"
doi:10.1007/978-1-0716-2617-7_15,en,Computational Methods and Deep Learning for Elucidating Protein Interaction Networks,OriginalPaper,"Protein interactions play a critical role in all biological processes, but experimental identification of protein interactions is a time- and resource-intensive process. The advances in next-generation sequencing and multi-omics technologies have greatly benefited large-scale predictions of protein interactions using machine learning methods. A wide range of tools have been developed to predict protein-protein, protein-nucleic acid, and protein-drug interactions. Here, we discuss the applications, methods, and challenges faced when employing the various prediction methods. We also briefly describe ways to overcome the challenges and prospective future developments in the field of protein interaction biology.","['Life Sciences', 'Bioinformatics']"
doi:10.1007/978-3-031-16075-2_43,en,Ambient Intelligence Security Checks: Identifying Integrity Vulnerabilities in Industry Scripts,OriginalPaper,"Organizations, small offices, and home offices are deploying ambient intelligent systems at an unprecedented rate. These systems can interface with automation and data science scripts for many different reasons. Scripts can be written in many different languages and may unknowingly include deprecated or vulnerable code. Static analysis has been increasingly adopted and developed to identify software vulnerabilities with trends towards security detections. Tools can assist in identifying faults in programs during different development phases of the secure Software Development Lifecycle (sSDLC); and, can thus be employed on the source, intermediate, and executable codes to identify different (security) concern categories. This research identifies both static analysis tools as well as a category of integrity risks useful to adopt for more secure scripting of PowerShell scripts. The research also builds foundational knowledge for extending future analyses of further language-specific integrity concerns as well as other security concerns in scripting languages.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3575-6_49,en,Crop Decision Using Various Machine Learning Classification Algorithms,OriginalPaper,"Agriculture is the backbone of a country's economic development. Crop decision is the most fundamental decision for every farmer. Digital transformation in agriculture has enabled many farmers in the country to make the right decisions of crops according to their location conditions. Modern techniques like machine learning can be used for this purpose. There are many algorithms involved in this technique. A comparison of various classification algorithms based on accuracy parameters is presented in this paper to determine an appropriate crop depending on field conditions. Machine learning algorithms like Naive Bayes, decision tree, logistic regression, K-nearest neighbors (K-NN), support vector machine, and random forest are used for this process. The analysis is performed using the WEKA software. The open-source dataset consisted of location parameters such as nitrogen, phosphorus, potassium, temperature, humidity, Ph, and rainfall along with labels of 22 crops. By this comparison, it has been concluded that both random forest and Naive Bayes are good algorithms for crop decisions based on accuracy parameters. Many parameters such as root mean squared error, precision, recall, TP rate and FP rate, and F-measures along with accuracy. This analysis can be used for proper agri-inputs for farmers and can be also used in many agricultural applications comprising location parameter measurement for weather prediction, etc.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-15030-2_11,en,Artificial Intelligence Enabled Radio Signal Intelligence,OriginalPaper,"Radio signal intelligence has very important roles in the world of wireless communications. Automatic modulation classification (AMC) as a crucial part of radio signal intelligence has been evolving with the development in machine learning (ML) and artificial intelligence. Being a pattern recognition problem, AMC provides a good entry point for developing ML based solutions for radio signal intelligence where ML algorithms have great potential competing against traditional methods. Yet, to release the potential of ML algorithms, some basic understanding of a wireless system and the common constraints imposed on a system is required. In this chapter, essential background information for developing ML based AMC solution is provided. AMC features and feature based ML classifiers are listed. Recent developments in deep learning based AMC solutions are also discussed.","['Computer Science', 'Artificial Intelligence', 'Privacy', 'Cryptology', 'Mobile and Network Security']"
doi:10.1007/978-981-19-2840-6_34,en,Performance Analysis of Various Asymmetric Public-Key Cryptosystem,OriginalPaper,"Today, public-key cryptosystems have brought a significant change to the world of computers. Cryptosystems like the RSA and the ECC algorithm tend to top the table regarding usage and reliability. This study aims at meticulous and nuanced research on asymmetric public-key cryptosystems and compares them based on performance-based parameters and metrics. This research involves a comprehensive, comparative, and detailed study of the RSA, ElGamal, and the ECC-ElGamal Public-key Cryptosystems. Performance analysis has been performed considering the wall time, CPU, and memory used for both encryption and decryption of the algorithms. Security has also been measured by finding the similarity between plaintext and ciphertext obtained from these algorithms. The study aims to provide definitive results about the performance characteristics of the algorithms surveyed.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-11686-5_5,en,Search-Based Variability Model Synthesis from Variant Configurations,OriginalPaper,"The parallel maintenance of independent system variants, developed to supply a wide range of customer-specific demands, is a complex activity. To alleviate this problem and ease the creation of new products, the consolidation of such variants into a Software Product Line (SPL) is an effective solution. For this, a fundamental step is to construct a variability model that represents the combinations of features of all the existing variants. However, the process of extracting an SPL from independent variants, and consequently constructing a variability model, is acknowledged as costly and error-prone. Instead of starting from scratch, many approaches have been proposed for reverse engineering variability models, but they have two limitations. These approaches usually optimize a single objective that does not allow software engineers to consider design trade-offs and do not exploit knowledge from implementation artifacts. This chapter presents our approach to address these limitations. Our approach applies a multi-objective optimization strategy and uses source code dependencies to reverse engineer variability models. The resulting model not only represents the desired feature combinations but are also well-formed regarding source code dependencies, i.e., variability safe. The approach, using two multi-objective evolutionary algorithms, namely NSGA-II and SPEA2, and a single-objective algorithm was evaluated with twelve subject systems. For comparisons, we rely on widely adopted performance indicators. The results indicate that the performance of the multi-objective algorithms is similar in most cases, and that both clearly outperform the single-objective algorithm. Also, the trade-off among different solutions is important to support engineers during decision making.","['Computer Science', 'Software Engineering/Programming and Operating Systems', 'Software Management', 'Computer System Implementation']"
doi:10.1007/978-3-031-20105-9_3,en,Comparison of Metaheuristics for Chaotic Systems Estimation,OriginalPaper,In recent years Parameter Estimation (PE) has attracted the attention of the scientific community.,"['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-07654-1_4,en,Detection of Non-Technical Losses in Power Utilities Using Machine Learning,OriginalPaper,"Non-technical losses are one of the issues electricity companies face and lead to a significant source of revenue losses. The aim of this study is to use the machine learning algorithms to reach meaningful patterns and enable the businesses to make proactive, knowledge-driven decisions. This research work is proposed to detect the non-technical losses by getting the list of customers according to their probability of having an anomaly in their electricity meter using machine learning algorithms. In this study, many research papers on non-technical losses are reviewed, and their key features are summarized. Data collection is done from one of the leading electricity distribution companies in Oman, and it had monthly electricity consumption from May 2020 to May 2021 of more than 400,000 accounts. This study uses 284,737 normal and anomaly accounts of residential and commercial customers to train and test the ML algorithms. Thirty-four features are extracted from the raw data, and ten top features are selected to train and test the machine learning models. The data is modeled using three supervised learning algorithms, namely, XgBoost, ANN, and KNN. The results showed that ANN outperformed the other two algorithms when using the SMOTE method with train/test split with 85% of AUC score and 73% of recall score. Finally, the ANN algorithm using SMOTE is used to get a list of customers with an estimated probability of having anomalies in the meter.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Computer Communication Networks', 'Computational Intelligence']"
doi:10.1007/978-981-19-3391-2_8,en,Application of Machine Learning Algorithm in Identification of Anaemia Diseases,OriginalPaper,"Anaemia is the reason for lot of serious health-related issues, and if it is detected at an early stage accurately, it can help to avoid problems like fatigue, pregnancy complications, heart problems, and life-threatening complications. In this study, five supervised machine learning (ML) algorithms for detecting anaemia based on red blood cell (RBC) parameters such as haemoglobin, haematocrit or packed cell volume (PCV), RBC count, mean corpuscular volume (MCV), mean corpuscular haemoglobin (MCH) and mean corpuscular haemoglobin concentration (MCHC) were developed. The ML algorithms were applied on actual patient anaemia data, collected from a clinical laboratory, of a sample size of 2000 data samples. Multiclass classification of these data into five different conditions of anaemia, namely beta thalassemia trait (BTT), dimorphic anaemia (DA), and macrocytic blood picture (MBP), microcytic hypochromic anaemia (MHA), including normocytic normochromic blood picture (NNBP) indicating no anaemia, was performed by the five ML algorithms, and the best algorithm for accurately detecting anaemia was identified. The result indicated that the decision tree and random forest algorithms were superior to other algorithms in terms of accuracy, sensitivity, and specificity of the identification process.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Statistics, general', 'Cyber-physical systems, IoT', 'Professional Computing', 'Communications Engineering, Networks']"
doi:10.1007/978-3-031-20036-6_10,en,Machine Learning for Strategic Trade Analysis,OriginalPaper,"Machine learning techniques are supporting advances in more effectively gaining knowledge from data in many fields—strategic trade analysis should be no exception. This chapter introduces some potential uses of machine learning approaches to support identifying illicit strategic trade from within international trade data. First, an overview is provided of three case studies that utilized various machine learning algorithms for similar purposes, demonstrating the effectiveness of different approaches that could be tailored to strategic trade analysis. The majority of the chapter focuses on three types of machine learning techniques: supervised classification, unsupervised learning, and natural language processing. Within each of these, multiple methods are introduced with a focus of how analysts can specifically use international trade data and other information sources to investigate strategic trade. This discussion represents attempts to introduce machine learning into this field and serve as a starting point for future research and applications in this area.","['Political Science and International Relations', 'International Security Studies', 'Military and Defence Studies', 'Political Science']"
doi:10.1007/978-981-19-3035-5_33,en,A Prediction System for Agricultural Crops Using Supervised Learning,OriginalPaper,"The prices of agricultural commodities are constantly varying. It is affected by various factors such as weather conditions, plant diseases, labor charges, production, demand, and supply of agricultural products. The farmers face problems when the crop is not worth the price and when unaware of the marketing price. This makes it difficult for them to do agriculture. Future crop prices can be estimated using machine learning algorithms such as decision trees, logistic regression, and support vector machine (SVM). In this paper, we analyzed five supervised algorithms and chose SVM as it gave better results. The dataset contains the prices of agricultural commodities from various states and their nutrient value. At last, the XGBoost boosting algorithm is applied to improve the performance of the model.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Statistics, general']"
doi:10.1007/978-3-031-12851-6_30,en,Estimation of Soil Water Retention Curves by Inversion of the Richards Equation: A Comparison of Nature-Inspired and Gradient Algorithms,OriginalPaper,"Inverting the Richards equation has been shown to be a potentially viable method for estimating the water retention curve and hydraulic conductivity of soil in geomechanics. However, robust inversion algorithms are required to achieve accurate predictions. This paper compares the performance of three nature-inspired algorithms, namely a genetic algorithm (GA), particle swarm optimisation (PSO), and simulated annealing (SA), to that of the more conventional Levenberg-Marquardt algorithm (LMA). The model of a simple infiltration experiment is used, with a saturated sample on top of a dry sample in a sealed environment. Synthetic data are first generated representing measurements of pressure heads mid-point in each layer. A Richards-equation inverter software (SPAS Inverse) is used next to fit predicted pressure heads to synthetic ones. It was found that PSO performed best in terms of robustness and accuracy and that there was significant scope for hybridising algorithms to further improve performance.","['Engineering', 'Geoengineering, Foundations, Hydraulics', 'Geotechnical Engineering & Applied Earth Sciences', 'Offshore Engineering']"
doi:10.1007/978-981-19-5221-0_37,en,A Study and Analysis of Algorithms on Intelligent Systems to Recognize Hand Written Digits and Characters,OriginalPaper,"The article includes a vast survey on the algorithms applied for hand written digit and character recognition and analysis of the best effective algorithm that can be used, and the effectiveness here is measured with accuracy. The major uses of recognition of handwritten characters and digits are interpreting postal addresses, check amounts of bank, tax documents, and filled forms. In case of reading the bank check amount, the accuracy of the recognition should be high or should be 100% as it is a very sensitive information and any mistakes in recognizing that will lead to complications within the bank system. So, recognizing the handwritten digit and character accurately plays a very important role in the real-world application, and this paper includes a survey and analysis on the most effective algorithm that can be used. The algorithms considered in this study are random forest, multilayer perceptron, random tree, support vector machine, Naïve Bayes, Bayes Net, J48, CNN, hybrid CNN-SVM, KNN, NN, RFC, single layer network with PCA, multilayer network -LeNet-5 CCN architecture. Analyzing the algorithms that can be used to recognize the handwritten digit and character, it is observed that CNN algorithm produces more accuracy in recognizing the hand written digits and characters.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Sociology, general', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-18461-1_53,en,Recent Advances in Algorithmic Biases and Fairness in Financial Services: A Survey,OriginalPaper,"Artificial intelligence capabilities and machine learning algorithms have been widely used in different applications including financial services. Many financial services such as loan or credit limit approval and credit score estimation rely on automated algorithms to offer efficient and best possible services to customers. However, algorithms suffer from intentional and unintentional biases and produce unfair outcomes. This paper presents a survey of algorithmic biases and fairness in financial services. We study the sources of bias and the different instances of bias existing in the prominent areas of the financial industry. We also discuss on the detection and mitigation techniques that have been proposed, developed and used to enhance transparency and accountability.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-3-031-20601-6_6,en,Analysis of Feature Selection Methods for Network Traffic Classification,OriginalPaper,"Network traffic classification has Considerable importance with the rapid growth of current Internet networks and their online applications. In the research conducted in this area, machine learning algorithms have been widely used due to the importance of the accuracy issue at the traffic classification. One of the most essential and useful steps in machine learning algorithms is feature selection. Because it reduces redundant features, and it affects accuracy. This paper examines the impact of feature selection methods on traffic classification methods regarding the importance of this issue. In this paper, three strategies are presented for feature selection: the gain ratio, information gain, and weight by SVM models to be applied to SVM and Naïve Bayes machine learning algorithms. Also, considering the importance of encrypted data and their growing trend, this work explores separately the impact of the above-mentioned methods on encrypted and non-encrypted data from the NIMS data set separately. The results of the experiments show that the gain ratio in encrypted data obtained a better accuracy of 97.30% compared to other methods, as well as for non-encrypted data of 99.90%.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-15928-2_18,en,Skeleton and Medial Axis Functions Evaluation of Voxel Discretized Geometries,OriginalPaper,"In the field of medical image processing, the resolution capacity exhibited by the initial diagnostic investigations is becoming increasingly important. With respect to them, in fact, the row image set is subjected to three-dimensional reconstruction analysis, by partitioning the regions of interest, as well as to local investigations, aimed, for example, at the extrapolation of topological information, relating to the morphology of the object that needs to be investigated. The accuracy of these functions is, however, difficult to quantify, due to the lack of three-dimensional models that act as a reference Gold Standard. The reproduction of CT-type diagnostic acquisitions, starting from a virtual scanning procedure of a starting known three-dimensional geometry is used. To do this, triangular tessellated three-dimensional models of various geometries were examined. These were broken down into cubic elements, equal in size to those of a common voxel, thus resulting in a volume scan simulation of the original region considered. The structure thus obtained was then subjected to skeletonization and medial axis algorithms to evaluate the effectiveness of some of the most commonly used functions in medical processing. A virtual scanning model of this type can be an extremely effective evaluation analysis tool in discriminating the resolutive quality of the medical image processing functions. From a qualitative comparison of this type, it is possible to optimize automated anatomical investigation algorithms, making a significant contribution in the refinement of the techniques, now more and more demanding, of image processing in the biomedical field.","['Engineering', 'Engineering Design', 'Industrial and Production Engineering', 'Computer-Aided Engineering (CAD, CAE) and Design']"
doi:10.1007/978-3-031-19620-1_48,en,Development and Research of a Hybrid Algorithm for Placement of Elements of Digital Computing Equipment,OriginalPaper,"In the article, the problem of placing different-sized elements is discussed. The analysis of the current state of research on the topic has been completed, the main problems and prospects for the development of existing methods and technologies have been identified. The necessity and relevance of developing new effective approaches to solving problems of physical synthesis of elements of digital computing devices is noted. The problem statement, as well as the main constraints and optimization criterion, are formulated. A model of a hybrid algorithm for solving the placement problem has been developed. A model of a parallel multipopulation genetic algorithm is proposed. Mechanisms for parallelization of the computational process have been developed. A modified procedure for performing a migration operation to perform decision exchange between populations is proposed. A procedure that allows implementing the principle of multithreading at the local level, when calculating the values of objective functions, has been developed. The principles of operation and the structure of the fuzzy control block are described. The scheme of operation of the fuzzy logic controller is given. A model of a multilayer neural network that implements the function of a neuro-fuzzy control block is proposed. The characteristics of the current population used to evaluate the dynamics of the search for the optimal solution are determined. The control parameters of the genetic algorithm are selected. The proposed hybrid algorithm is implemented as an application program. A series of computational experiments to determine the effectiveness of the developed algorithm and the choice of optimal values of control parameters was carried out.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16832-1_6,en,A Meta-Heuristic Algorithm Based on the Happiness Model,OriginalPaper,"Recent work has attempted to determine the appropriate global minimum for complex problems. The paper presents a population and direct-based swarm optimization algorithm called the happiness optimizer (HPO) algorithm. An HPO algorithm is designed based on personal behavior and demonstrated in 30 and 100 dimensions on benchmark functions. The model includes four questions: “what do you want?”, “what do you have?”, “what do others have?”, and “what happened?”, which guide the development of a happiness behavior model. By considering the balancing between exploration and exploitation operators in the search space problem, efficiency, robustness, and stability were demonstrated for synthetic and real cases. For comparison, our proposed algorithm and some well-known algorithms will be 30 times applied on the benchmark functions and then compared with statistical value and Wilcoxon signed-rank test. As a consequence, the performance, reliability, and stability of our work have been demonstrated better than the others.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Engineering']"
doi:10.1007/978-981-19-0507-0_8,en,Optimal Design of Truss Structures with Natural Frequency Constraints Utilizing IWSA Algorithm,OriginalPaper,"Constructing structures with the lowest possible use of the material has long been an interesting topic among engineers. In this regard, the resilience of structures in the face of natural hazards and their concomitant effects, such as the resonance phenomenon, should also be taken into account. Frequency-constrained optimization problems seek to not only construct structures with the least possible material amount, but also prevent the resonance phenomenon, enhancing the sustainability of the structures by reducing the total material consumption while minimizing the future damage cost incurred by structural components due to this effect. This article assesses the truss optimization problems with natural frequency constraints using the improved version of the newly developed meta-heuristic algorithm, referred to as the water strider algorithm (WSA). Improved water strider algorithm (IWSA) utilizes two mechanisms to improve the performance of WSA. The first one is the opposition-based learning (OBL) technique, and the other is a mutation method. The OBL technique for the initial population improves the convergence rate and the accuracy of the final result, and the mutation method helps it to approach the global optimum and avoid the local one. Three benchmark spatial truss optimization problems are selected from the literature to examine the efficiency of IWSA in comparison to other well-established algorithms as well as its standard version, WSA. The results reveal the viability and competitiveness of the IWSA algorithm in the framework of design optimization with frequency constraints in comparison to its standard version and other structural optimization algorithms.","['Engineering', 'Building Construction and Design', 'Geoengineering, Foundations, Hydraulics', 'Transportation Technology and Traffic Engineering', 'Environment, general']"
doi:10.1007/978-3-031-18461-1_23,en,Path Planning and Landing for Unmanned Aerial Vehicles Using AI,OriginalPaper,"Latest trends, societal needs and technological advances have led to an unparalleled expansion in the use of Unmanned Aerial Vehicles (UAV) for military and civilian applications. Such systems are becoming increasingly popular in many operations, since they reduce costs, facilitate activities and can increase the granularity of surveillance or delivery. Beyond the Visual Line of Sight (BVLOS) capabilities are becoming recently a pivotal aspect for the UAV industry, and raise the demand for extended levels of autonomy in order to increase the efficiency of flight operations. The present study examines two main aspects of BVLOS operations, namely trajectory planning and self-landing, and demonstrates how well-established path planning techniques, such as the A* and Dijkstra algorithms, can be used to ensure the shortest trajectory length from point A to point B for a UAV under multiple obstacles and constraints and the least number of error corrections. Extensive simulation results showcase the effectiveness of the proposed method. It also provides evidence of the use of computer vision algorithms for detecting the landing site and assisting the UAV to safely land.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3895-5_15,en,"Process Parameter Optimization in Friction Stir Spot Welding of High-density Polyethylene Sheets Using GA, PSO, and ABC Algorithm",OriginalPaper,"The promising applications of high-density polyethylene (HDPE) in automotive and aerospace industries demand for more reliable and durable fabrication techniques. Friction stir spot welding is one such fabrication process which has proved to be a favorable joining technique for HDPE. In this paper, mathematical model has been developed using response surface methodology (RSM) for the friction stir spot welding (FSSW) process on commercial 4 mm HDPE sheets. The welding parameters, namely tool rotational speed, axial feed rate, plunging depth, and dwell time, were taken as decision variables for the resulting joint properties, namely the lap shear strength (LSS) and the temperature variations, are checked across the weld based on these parameters. The equations developed for LSS from experimental results with the help of RSM were used as objective function for the meta-heuristic optimization algorithms, namely genetic algorithm (GA), particle swarm optimization (PSO), and artificial bee colony (ABC) algorithm individually. The global optimum that has been deduced from GA, PSO, and ABC algorithm has come out to be consistent for LSS.","['Materials Science', 'Structural Materials', 'Nanotechnology', 'Materials Science, general']"
doi:10.1007/978-981-19-0503-2_50,en,Exploring Computing Time for Automatic Occlusion Detection: A Scan-Based Algorithm Versus a Geometry-Based Algorithm,OriginalPaper,"Research shows Virtual Reality (VR) can facilitate design review and coordination tasks in the construction industry. However, visualizing occluded objects in a VR environment is still challenging. Both geometry-based algorithms and scan-based algorithms showed potential in automatically detect occluded objects in 3D models. This paper created both algorithms and explored the key factors for the overall computing time. Results show that both algorithms can perform the occlusion detection task for a Building Information Model with 5387 objects in three hours. The number of occluded objects showed a significant impact on the computing time of the geometry-based algorithm, while the computing time of the scan-based algorithm was more influenced by the number of objects and the granularity of virtual scans of the model. This paper contributes to the body of knowledge by developing the two algorithms and measuring the performance of every activity in their workflows. The results can support the future development and optimization of automatic occlusion detection algorithms for VR applications in the construction industry.","['Engineering', 'Building Construction and Design', 'Geoengineering, Foundations, Hydraulics', 'Transportation Technology and Traffic Engineering', 'Environment, general']"
doi:10.1007/978-3-031-22200-9_18,en,An Enhanced Hybrid Jaya Algorithm for Size Optimization of Truss Structure Under Frequency Constraints,OriginalPaper,"This paper proposed an enhanced hybrid Jaya algorithm, called AEHJ. The proposed AEHJ is a new improvisation of the Jaya algorithm (Jaya) and the differential evolution algorithm (DE) with two modifications. Firstly, the local search is improved by using DE/best/1, DE/best/2, and Jaya operators. Secondly, an elitist selection approach is used for choosing the best solution for the next population. For validating the feasibility of AEHJ, the well-known benchmark example of size optimization for a 10-bar truss is performed.","['Engineering', 'Mathematical and Computational Engineering', 'Mechanical Engineering', 'Electrical Engineering']"
doi:10.1007/978-3-031-09835-2_17,en,Artificial Bee Colony and Genetic Algorithms for Parameters Estimation of Weibull Distribution,OriginalPaper,"Weibull distribution has been widely applied in many scientific disciplines such as modeling wind speed or failure rates. Various estimation methods such as maximum likelihood (ML), moment (MOM) inferences are proposed for the Weibull parameters estimation, but there has not been a comparison of performances based on swarm optimization algorithms. Therefore, this chapter investigates the performances of the artificial bee colony (ABC) and the genetic algorithm (GA) for the Weibull parameters estimation. The estimation problem of the Weibull shape parameter is solved by the proposed functions using the ABC and GA. The contribution of this chapter is to provide a comparison of the ABC and the GA for estimating the Weibull parameters using the proposed functions. To identify the performances of the ABC and the GA methods for Weibull parameters estimation, a comprehensive simulation study, and a failure data example are performed.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5224-1_74,en,Optimized Closest Pair Computation with CPU-GPU Combined Model,OriginalPaper,"Spatial data processing had been a dominant contributor in a wide assortment of applications including health care, urban planning and infrastructure designing. As the complexity of data has increased due to higher dimensions, diverse approaches have been successfully tested for nearest neighbor queries, clustering algorithms, etc. These algorithms have been optimized and adapted for CPU, GPU and hybrid models as combination of CPU and GPU. Closest pair (CP) computation is a frequently used operation in range and distance-based queries. Although there are different algorithms and optimizations available for CP computations, suitability of GPU for this operation is yet to be explored. Hereby in this paper we propose CPU-GPU Hybrid Model, to optimize the closest pair (CP) of points problem concerning two-dimensional floating point values. As part of the combined model, the sorting phase is implemented on CPU and computation of closest pair is implemented on GPU. In this work, three CP algorithms are analyzed on CPU and CPU-GPU combinations. With the proposed algorithm on the CPU-GPU combined model, up to 12 times speedup is achieved in the closest pair computation time. Several parameters were tuned to work with the device-specific features and the overhead in terms of data transfer is also analyzed.","['Engineering', 'Communications Engineering, Networks', 'Statistics, general', 'Cyber-physical systems, IoT', 'Sociology, general', 'Professional Computing']"
doi:10.1007/978-3-031-09835-2_9,en,"Grey Wolf Optimizer, Whale Optimization Algorithm, and Moth Flame Optimization for Optimizing Photonics Crystals",OriginalPaper,"In this chapter, three recent swarm intelligence algorithms are used to solve a challenging optimization problem in the field of photonics, including Grey Wolf Optimizer, Whale Optimization Algorithm, and Moth Flame Optimization Algorithm. The problem is to optimize the radii of several rods in a photonics crystal to minimize light wave loss when there is a bend corner. This problem is first presented and formulated in details. It is discussed that due to the use of complex simulations, analytics equations are ill-defined for this problem thereby justifying the use of black-box optimization algorithms. The above-mentioned algorithms are then employed to estimate the global optimal for this problem by finding the optimal values for its structural parameters. The results show that the GWO algorithm provides the best results. The chapter also considers a convergence analysis of all algorithms that led to interesting insights about the process of solution improved during the course of optimization. It is observed that GWO shows constant improvement while others tend to show steady and slow improvement.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-19958-5_78,en,A Comparative Analysis for Generating Common d-Neighborhood on Planted Motif Search Problem,OriginalPaper,"Planted Motif Searching (PMS) is considered as one of the most vital tool for finding all pair of motif on a genome sequence. In this problem, n length of string along with two integer ℓ and d are given as input and need to generate all possible sequence of length m, where each occurrence varies from at most d points. Generating Common d-Neighborhood is a vital step to find the planted motifs in every version of PMS algorithm. Particularly, in this step, we find the set of d-neighborhood between two ℓ-mers if the sufficient pruning conditions are fulfilled. In this paper, we have analyzed the previous algorithms for finding d-neighborhood and proposed a faster approach that reduces the searching time in the sample driven part of the algorithms. In particular, we have used dynamic programming techniques to reduce the repetitive calculation of the values of common subtrees and used advanced data structures to make the algorithm more time efficient.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-05445-7_4,en,Comparison of Automated Operational Modal Analysis Algorithms for Long-Span Bridge Applications,OriginalPaper,"Automated operational modal analysis allows operational modal analysis to be used without the need of a human operator to identify structural modes from a stabilisation diagram. Multiple algorithms for automating this procedure have been proposed, and this paper selects four (Magalhaes 2008, Reynders 2012, Yang 2019, and Kvåle 2020) and benchmarks them using experimental data from the monitored, and previously studied, Hardanger Bridge. It is shown that the Magalhaes 2008 and Kvåle 2020 algorithms have the highest detection rates of all the algorithms but that the Reynders 2012 and Yang 2019 algorithms have higher automation and lowest error rates, respectively.","['Engineering', 'Building Repair and Maintenance', 'Vibration, Dynamical Systems, Control', 'Fourier Analysis', 'Abstract Harmonic Analysis']"
doi:10.1007/978-981-19-2535-1_1,en,Comparative Analysis of Image Segmentation Techniques for Real Field Crop Images,OriginalPaper,"Nowadays various applications are available for plant disease identification using images. Early-stage disease identification can reduce losses and cost in cultivation. Efficient image segmentation is required to improve the performance of plant disease identification. Selecting appropriate segmentation techniques to extract an accurate object of interest while preserving original image properties is a challenging task. This paper presents the principle of image segmentation covering different techniques from traditional thresholding to the latest convolutional neural network-based approach. We reviewed the selected paper based on image segmentation and crop disease identification. Various algorithms are grouped based on the working principles like edge-based, region-based, and combining both properties. Performance evaluation of these algorithms was carried out using factors like time required, accuracy, and similarity to the original image. Holistic image segmentation based on convolutional neural network, K means clustering, etc. algorithms applied to real field crop images. The grab cut algorithm proves very useful for real field crop image segmentation as it preserves original image properties. Combining region and boundary-based techniques and automating segmentation need to be explored in future research work.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1142-2_57,en,Algorithms of AI in Deciding Optimum Mix Design of Concrete: Review,OriginalPaper,"The preparation of mix design of concrete requires a knowledge of design mix proportioning. Various properties like slump value, compressive strength are considered while preparing mix design. This traditional mix proportion method is a time-consuming and costly process. It is also done manually which may lead to different errors. To overcome this, use of artificial intelligence has been brought into this field to predict the design mix of concrete in limited time, low cost and minimum error due to use of computational algorithms as compared to traditional methods. In this paper, the studies using different algorithms of artificial intelligence are reviewed. Estimation of properties like compressive strength, slump value of concrete is done. Further, this paper also presents comparative analysis between different algorithms of AI. This research paper will be of great help to concrete technologist to explore future possibilities of AI techniques in concrete industry.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Mobile and Network Security', 'Artificial Intelligence']"
doi:10.1007/978-981-19-7842-5_17,en,A Comprehensive Study of 5th Generation Scheduling Algorithms,OriginalPaper,"Now a days, the 5th-Generation communication standard for Standalone and Non-Stand-alone mode has been released in “Release 15” to “Release 18”. This review paper is written to highlight all the key points of 5th generation communication technology covers core concepts of 5th generation communication network, its architecture for both Standalone and Non-Stand-alone mode, different existing scheduling algorithms used in 5G namely Proportional Fair (PF), Modified least weighted delay first (MLWDF), Exponential Proportional Fair (EX-PF), Frame Level Schedular (FLS), Round Robin (RR) and a detailed review of proposed scheduling algorithms anticipated by different researchers. This article is covering four different sections.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-09835-2_5,en,Performance Analysis of Hybrid Memory Based Dragonfly Algorithm in Engineering Problems,OriginalPaper,"Hybrid Memory Based Dragonfly Algorithm with Differential Evolution (DADE) is one of the most prominent swarm-based optimization techniques due to its better computational complexity and high convergence rate for achieving optimum results. In DADE, the best solution is memorized and processed with Differential Evolution (DE) for enhanced diversity and balanced exploration and exploitation rate. DADE brings two distinct advantages: First, the superior convergence rate due to continuous update of personal best individual in the search process. Second, better exploration due to the inclusion of global best and global worst individuals in the hybridization process. Comparative simulations have been performed on 24 standard benchmark functions along with the benchmark function of CEC2005 and CEC2017. Comparative analysis of the result demonstrates the competitiveness of the DADE algorithm in terms of optimal cost, computational complexity and convergence characteristics compared to other considered optimization algorithms.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-09909-0_11,en,Dark-Matter Search Optimiser,OriginalPaper,"A version of the Gravitational Search Algorithm that takes advantage of the repulsive forces of dark matter to explore the space is presented in this article. The classification of matter into dark and gravitational particles is used to balance between exploration and exploitation of the feasible set of solutions, respectively. The idea is to overcome some problems of the Gravitational Search Algorithm as, for instance, trapping into local optima and the choice of parameters. Three different problems are used to demonstrate the potential of the algorithm when compared with the Particle Swarm Optimiser. In the future, we plan to do a thorough assessment of the algorithm on benchmark problems as well as on some applications.","['Engineering', 'Robotics and Automation', 'Robotics', 'Engineering Design', 'Biomedical Engineering and Bioengineering']"
doi:10.1007/978-3-031-18050-7_9,en,A Hybrid Discrete Symbiotic Organisms Search Algorithm and List-Based Simulated Annealing Algorithm for Traveling Salesman Problem,OriginalPaper,"A discrete symbiotic organisms search (DSOS) and list-based simulated annealing (LBSA) are new metaheuristic search algorithms used for solving different complex optimization problems. DSOS mimics the symbiotic relationship strategies adopted by organisms in the ecosystem for survival, while LBSA simplify parameter tuning of the simulated annealing algorithm. In this paper, we propose a hybrid algorithm, named DSOS-LBSA, to solve the well-known traveling salesman problem (TSP) which belongs to the class of NP-hard problems. Additionally, an arbitrary insertion algorithm is introduced to produce organisms in the initial ecosystem. The proposed DSOS-LBSA is implemented in the MATLAB environment and it is tested on symmetric and asymmetric instances from TSPLIB. The overall results demonstrate that the proposed DSOS-LBSA offers promising results, particularly for small-size symmetric instances and large-size asymmetric instances.","['Engineering', 'Computational Intelligence', 'Industrial and Production Engineering']"
doi:10.1007/978-981-19-5090-2_26,en,A Short Overview on Various Bio-Inspired Algorithms,OriginalPaper,"Nature never fail to inspire us; we can learn a lot from them. Based on the inspiration acquired from the biological activities of nature, bio-inspired algorithms are developed to compete with modern rival techniques. An optimal solution can be obtained for intricate engineering and scientific problems when a bio-inspired algorithm is embedded with machine learning techniques. The problems are proposed with multiple nonlinear constraints which require huge time and high dimensionality. In this overview, various bio-inspired algorithms like artificial bee colony (ABC) algorithm, fish swarm algorithm (FSA), cat swarm optimization (CSO), whale optimization algorithm (WOA), artificial algae algorithm (AAA), elephant search algorithm (ESA), chicken swarm optimization algorithm (CSOA), moth flame optimization (MFO), and gray wolf optimization (GWO) algorithm are discussed precisely.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Artificial Intelligence', 'Data Structures and Information Theory']"
doi:10.1007/978-3-031-13714-3_2,en,A Short List of Combinatorial Optimization Problems,OriginalPaper,"This chapter reviews a number of typical combinatorial optimization problems. It illustrates the tenuous border that sometimes exists between an easy problem, for which effective algorithms are known, and an intractable one that differs merely by a small detail that may appear innocuous at first sight","['Business and Management', 'Operations Research/Decision Theory', 'Optimization', 'Computational Mathematics and Numerical Analysis', 'Algorithms', 'Computational Science and Engineering', 'Artificial Intelligence']"
doi:10.1007/978-981-19-7636-0_2,en,Hardware Security and Reliability,OriginalPaper,"The vulnerabilities of Meltdown and Spectre disclosed in early 2018 are generally considered to be one of the most serious hardware security problems so far. Because the root cause is the problem of hardware design, software can only reduce the impact and cannot solve it completely. In the face of many processors with vulnerabilities, it is not realistic to upgrade and replace the hardware in a short period of time. The attack strategies are evolving synchronously along with countermeasures, resulting in the failure of countermeasures.","['Engineering', 'Electronics and Microelectronics, Instrumentation', 'Circuits and Systems', 'Processor Architectures', 'Control Structures and Microprogramming', 'Logic Design']"
doi:10.1007/978-981-19-6072-7_4,en,Artificial Intelligence Technology in the Operation and Management of Rail Transit System,OriginalPaper,"In the twenty-first century, as a branch of the development of computer science, artificial intelligence (AI) technology began to rise and develop and has played a great role in human production and life. By studying the essence of human intelligence, people develop theories and technologies to simulate human intelligence and finally produce intelligent machines or systems that simulate human intelligence and respond in the same intelligent way. At present, artificial intelligence has been actively explored in the fields of theorem proving, medical diagnosis, intelligent automobile, voice assistant and so on. At present, AI has also been widely used in the operation and management system of rail transit.","['Engineering', 'Automotive Engineering', 'Artificial Intelligence', 'Transportation Technology and Traffic Engineering']"
doi:10.1007/978-981-19-3951-8_60,en,An Overview of Recent Nature Inspired Computational Techniques for Dynamic Economic Dispatch,OriginalPaper,"A practical power system network is highly dynamic, non-convex and nonlinear in nature subjected to various discrete and continuous variable constraints. Over the last few decades, several computational techniques, both traditional and nature inspired have been developed to solve the practical dynamic dispatch problem. A large variety of nature-inspired computational (NIC) techniques have been proposed to solve the power dispatch problem owing to their excellent performance, simple constraint handling mechanism and veracity to handle all kinds of functions. Unlike NIC techniques, the traditional methods suffer from convexity, continuity assumptions and may not always be attractive options to solve practical optimization problems of different complexities. In this paper, a review of a large variety of NIC techniques applied to solve the dynamic dispatch problem over the last decade has been summarized.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-3-030-96025-4_5,en,Optimal Capacitor Placement for Power Loss Reduction and Voltage Profile Improvement,OriginalPaper,"This chapter presents a two-stage procedure to determine the optimal locations and sizes of capacitors with an objective of power loss reduction in radial distribution systems. In first stage, the loss sensitivity analysis using two loss sensitivity indices (LSIs) is employed to select the candidate locations for the capacitors to reduce the search space in the optimization procedure. The suggested LSIs are based on the following physical quantities; the variation of the active power losses with respect to the load bus voltage at variant nodes, the variation of the active power losses with respect to the level of reactive power at variant nodes. In second stage, the ant colony optimization (ACO) algorithm is used to find the optimal locations and sizes of capacitors considering the minimization of total energy loss and total costs of capacitors as an objective function, while the security and operational constraints are fully achieved. The fixed and practical switched capacitors are considered to find the optimal solution. The backward/forward sweep (BFS) algorithm is introduced for the load flow calculations. The proposed procedure is applied to different standard test systems as 10-bus, 34-bus and 85-bus radial distribution systems. In addition, the application of the proposed procedure on a real distribution system of the East Delta Network (EDN) as a part of the Unified Egyptian Network (UEN) is used as a test system. The numerical results are compared with other methods to show the capability of the proposed procedure to find the optimal locations and sizes of capacitors for significant saving in the total cost with more accuracy and efficiency, especially with increasing in the distribution system sizing.","['Engineering', 'Power Electronics, Electrical Machines and Networks', 'Energy Systems', 'Renewable and Green Energy']"
doi:10.1007/978-981-19-2704-1_5,en,Massive Access in Media Modulation-Based Massive Machine-Type Communications,OriginalPaper,"This chapter studies the challenging device activity and data detection (DADD) problem for media modulation based mMTC. Specifically, by exploiting a doubly structured sparsity of the access signals, a doubly structured approximate message passing (DS-AMP) algorithm is proposed for reliable DADD. Also, the state evolution of the DS-AMP algorithm is derived to theoretically characterize its performance. Furthermore, this chapter develops a bit-interleaved coded media modulation scheme and proposes an iterative DS-AMP (IDS-AMP) algorithm based on SIC to improve the data decoding performance. In addition, an efficient data-aided CSI update strategy is developed to reduce the channel estimation overhead in block fading channels.","['Engineering', 'Wireless and Mobile Communication', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-14537-7_2,en,Minimising Printed Circuit Board Assembly Time Using the Bees Algorithm with TRIZ-Inspired Operators,OriginalPaper,"With the increasing use of printed circuit boards Printed Circuit Board (PCB) (PCBs) in the electronics industry, the assembly time per PCB is critical, as it affects the production time and cost Cost . This research investigates the assembly time per PCB using machines with the moving board with time delay characteristic (MBTD), which involves the complex coordination of a component feeding system System , a pick and place system System and the positioning movement Movement of the PCB Printed Circuit Board (PCB) . Many years of research work by different researchers using different optimisation algorithms were applied to obtain the shortest time possible for an MBTD Moving Board with Time Delay (MBTD) case study on a PCB assembly PCB assembly with 50 component locations with improved results in each case study. This research explores how the Bees Algorithm Bees Algorithm, THE with TRIZ TRIZ -inspired operators is applied to this case study to reduce the assembly time to 23.42 s to save significant cost Cost and time when compared to other past research work with different optimisation algorithms.","['Engineering', 'Robotics and Automation', 'Artificial Intelligence', 'Industrial and Production Engineering', 'Professional Computing', 'Robotics', 'Machine Learning']"
doi:10.1007/978-3-030-96025-4_1,en,Introduction,OriginalPaper,"This chapter presents a brief introduction of the transmission and distribution systems problems such as power system monitoring based on phasor measurement units (PMUs) and the enhancement of distribution network performance based on distributed generations (DGs) and/or capacitor banks. In addition, a brief introduction of different optimization techniques such as analytical, artificial intelligence (AI) and modern optimization techniques for solving those problems is considered. Finally, it summarizes the objectives and contributions of the book.","['Engineering', 'Power Electronics, Electrical Machines and Networks', 'Energy Systems', 'Renewable and Green Energy']"
doi:10.1007/978-3-031-17091-1_58,en,Autonomous Drone Path Scheduling and Management Strategy with Multi-agent Decision Support and Coordination,OriginalPaper,"In a harsh and isolated environment with limited communication and human interaction, e.g., Antarctica, multiple unmanned vehicles or multiple drone systems can use fuel/battery faster than normal conditions. This has led to many drone failures. Preservation of fuel level becomes an essential factor for the management of drones while performing the required set of tasks within an acceptable time. The uncertainty of the environment further challenges the autonomous task allocation and path planning for drones. The existing literature algorithm was not tested or used in these severe conditions, which creates the major gaps in the autonomous drone’s management. This paper proposes a CBS-LSA algorithm, which is a combined algorithm of conflict-based search and linear sum assignment. This algorithm considers the drones’ fuel consumption before allocating the tasks uniformly and proportionately to all the available agents whenever the new sets of tasks were generated randomly. It can proportionately allocate tasks to drones, even if the number of drones is lesser than the number of tasks while maintaining the optimal task allocation process. Moreover, the algorithm optimizes the fuel consumption of the drones by allocating them to the nearest available agents and providing the best possible path for the agents that avoid static obstacles such as mountains and terrains.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Cyber-physical systems, IoT', 'Industrial and Production Engineering']"
doi:10.1007/978-981-16-8154-7_36,en,Routing Optimization Study for LEO Satellite Networks Using the Hybrid GA-SA Algorithm,OriginalPaper,"With the rapid development of the mega-constellation networks based on the low earth orbit satellites, the shortest path issues in complex networks have gained more and more attention. In this paper, a shortest route solving algorithm based on the hybrid genetic algorithm-simulated annealing algorithm (GA-SA) is proposed. Experimental results show that the proposed hybrid GA-SA method is superior to the single traditional genetic algorithm or simulated annealing algorithm in the computation accuracy while discovering the shortest path between any satellite nodes of different types of topological networks. The new algorithm presents a faster convergence rate and higher accuracy in the simulation of large LEO satellite networks. The proposed algorithm has an advanced global search capability and universal applicability in mega LEO satellite networks.","['Engineering', 'Aerospace Technology and Astronautics', 'Communications Engineering, Networks', 'Space Sciences (including Extraterrestrial Physics, Space Exploration and Astronautics)', 'Control and Systems Theory']"
doi:10.1007/978-981-19-3679-1_52,en,Credit Card Fraud Detection Using Various Machine Learning and Deep Learning Approaches,OriginalPaper,"It is evident that the evolution in technology has surpassed expectations and reached different heights in a shorter span of time and with evolving technology; a lot of changes have been introduced in our lives, and one such change is the replacement of traditional payment methods with the credit card system. Credit card use increases the most during online shopping. With the huge demand for credit cards worldwide, credit card fraud cases to are increasing rapidly. In this paper, four machine learning algorithms that are decision tree, random forest, logistic regression, and Naïve Bayes have been used for training the models. Also, deep neural networks have been implemented for model training which is giving more promising results compared to the machine learning algorithms. The accuracy of each algorithm used in the implementation of the credit card fraud detection has been compared and analyzed.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3679-1_9,en,Liver Cirrhosis Stage Prediction Using Machine Learning: Multiclass Classification,OriginalPaper,"Liver cirrhosis is a disease that affects a large population worldwide. Liver cirrhosis is further divided into four stages. This paper aims to predict the stage of liver cirrhosis of a patient using machine learning. It is a supervised learning problem of multiclass classification. Seven different algorithms were used for this purpose, and their performance was analyzed and compared in order to find the best approach. Different scaling and feature selection strategies were used in order to study their effect on the performance of various algorithms. It was found that an ANN-based approach achieves the best performance for this particular problem. A feature selection approach based on random forest and mutual information (RF + MI) was proposed in this paper, and its performance was compared with the standard Random Forest (RF) method for feature selection in classification problems. Experimental results demonstrated that the RF + MI approach shows minor improvement in comparison with random Forest (RF) for feature selection.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-3-031-18292-1_4,en,Explainable AI (XAI): A Survey of Current and Future Opportunities,OriginalPaper,"Artificial Intelligence is the technology that is being used to develop machines that could work like humans or simply can have the intelligence relatable to that of humans. But the development of this kind of technology model that mimics humans involves a lot of complex calculations and complex algorithms that are difficult to explain and understand. For this problem, the concept of explainable artificial intelligence (XAI) is developed and introduced. It is the technology that is developed to ease the understanding process of machine learning solutions for humans. It is the concept that is being developed for making it convenient for humans to understand and interpret machine language. Black model machine learning (ML) algorithms are very hard to understand for humans who have not developed them. AI models that involve the methods like genetic algorithms or deep learning concepts are very difficult to understand. It sometimes becomes a very hard task for the domain experts too to understand the ML algorithms of the black block models, so the need for the development of this type of technology was felt. Many times, results are developed with very high accuracy are quite easy to understand for the domain experts. But Explainable artificial intelligence has a great potential to make a change in domains like finance, medicines, etc. It plays a vital role where it is important to understand the results to build trustworthy algorithms. XAI can play a great role in “third-wave AI systems” which include machines that can interact directly with the environment and that can build explanatory models that allow them to develop the characteristics of real-world phenomena. XAI has the potential to play a great role where the organizations need to build trustworthy AI models and to make them trustworthy the explainability of the AI models should be there for others as well. This technology is developed primarily to make AI understandable to those who are practitioners. This book chapter presents a wide and insightful view of XAI and its application in various fields. This chapter also includes the future scope of this technology and the need for the growth of this type of technology.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1412-6_16,en,Computational Complexity and Analysis of Supervised Machine Learning Algorithms,OriginalPaper,"Data is generated at a much faster pace, and it is increasing exponentially day by day. Machine learning methods are being used to extract patterns and trends from data to streamline different business activities for more profit with fewer resources. Machine learning models need to be trained with lots of data before being deployed for predictive analysis (Lecture notes in Computer Science, 2012 [ 1 ]). Training time depends upon the complexity of an algorithm. We are analyzing the space and time complexity of various machine learning algorithms so that it becomes easier to select and deploy the most efficient and appropriate model for a particular dataset. This research work primarily focuses on data analytics for supervised machine learning algorithms in industrial research domains.","['Engineering', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security']"
doi:10.1007/978-3-031-09640-2_5,en,Analysing the Threat Landscape Inside the Dark Web,OriginalPaper,"The Dark Web is an encrypted subset of the deep web, whose content cannot be indexed by search engines. Dark Web pages can be accessed from private networks such as TOR (The Onion Routing), I2P (Invisible Internet Project) and Freenet. TOR is widely used by the Dark Web users in a domain defined by a .onion extension. Dark Web users can communicate with each other without using their identification. However, the anonymity of these users encourages them to perform illegal activities. This requires an immediate identification of imminent criminal threats and mitigation via algorithms, techniques and tools used to protect everyone from attacks inside the Dark Web. The aim is to make timely and pre-emptive detection of Dark Web threats before the Dark Web actor(s) can put their threats into action. The accuracy of the attacks on TOR network and the use of IoT and streaming technologies require agile algorithms to monitor the forums and to limit attacks. The methodology begins with a literature review, gap analysis and a research design using quantitative research methods such as comparative analysis of Dark Web forum datasets using data science techniques and an experimental research design involving machine learning and strategies for training and development of a model. After the gap analysis of the previous research methods, it is possible to try to extend or modify these algorithms or the applied techniques to see if those gaps can be closed. The findings and conclusion to this hybrid experimental research methodology will lead to a proposal on mitigating risks via a model for real-time detection, evaluation and response.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Computational Intelligence', 'Security Science and Technology']"
doi:10.1007/978-3-031-20257-5_1,en,Teaching Data Structures and Algorithms Through Games,OriginalPaper,"Computer Science degrees are often seen as challenging by students, especially in what concerns subjects such as programming, data structures or algorithms. Many reasons can be pointed out for this, some of which related to the abstract nature of these subjects and the lack of previous related knowledge by the students. In this paper we tackle this challenge using gamification in the teaching/learning process, with two main goals in mind. The first is to increase the intrinsic motivation of students to learn, by making the whole process more fun, enjoyable and competitive. The second is to facilitate the learning process by providing intuitive tools for the visualization of data structures and algorithmic output, together with a tool for automated assessment that decreases the dependence on the teacher and allows them to work more autonomously. We validated this approach over the course of three academic years in a Computer Science degree of the Polytechnic of Porto, Portugal, through the use of a questionnaire. Results show that the effects of using games and game elements have a generally positive effect on motivation and on the overall learning process.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2821-5_19,en,Diabetes Disease Diagnosis Using Machine Learning Approach,OriginalPaper,"Diabetes is a condition in which blood glucose, called as blood sugar, is high in an abnormal way. If the prediction of disease is possible at an early stage, then the risk factors associated with diabetes can be considerably lower in severity. The main problem and highly challenging task are to predict diabetes accurately, and the reason of this challenge is the diabetes dataset’s insufficient number of labels data and the existence of outliers. This research paper proposes a strong framework to predict the disease with the help of different types of machine learning (ML) algorithms: K-nearest neighbor (KNN), support vector machine (SVM), decision trees (DTs), Naive Bayes (NB), and logistic regression (LR). For implementation, a dataset has been taken from a PIMA database consisting patient’s health record, and these five machine learning techniques are applied to that dataset. A comparison between all the algorithms is presented in this paper. The motive of the paper is to provide assistance to doctors with their practitioners for the early prediction of diabetes using ML algorithms.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-3-031-11058-0_107,en,Algorithms and Software for Detecting and Identifying Small-Sized Objects on Stereoscopic Images of Transport Systems Infrastructure,OriginalPaper,"In the modern world, special attention is paid to the tasks of digital image processing, since their importance for practical application is increasing. Naturalistic driving datasets and data analytics is very important for decision making. This is especially important when drivers make decisions in a traffic situation. It is also necessary to consider and take into account various infrastructure and transport systems. To improve the quality of digital image processing, it is necessary to develop and improve algorithms for detecting and identifying small-sized objects on stereoscopic images and their software implementation. The authors emphasize the high accuracy of detection, localization and identification of an object in real time, even if the object is partially lost. The algorithm contains a procedure for calculating the geometric characteristics and the relative location of objects in space and allows you to determine their coordinates and characterize the appearance of the object. This is possible without increasing the set of sensors used. The authors solved the problem of developing and implementing algorithms for detecting and identifying small-sized objects on stereoscopic images. Algorithms and methods for constructing stereo images for a given set of object classes in transport systems have been developed.","['Engineering', 'Control and Systems Theory', 'Control, Robotics, Mechatronics', 'Communications Engineering, Networks']"
doi:10.1007/978-3-031-16078-3_2,en,Towards Data Science for Cybersecurity: Machine Learning Advances as Glowing Perspective,OriginalPaper,"The current computing context has developed important opportunities and challenges by the new attacks that occurred recently due to the pandemic situation (COVID-19), cybersecurity has crossed and still passing through significant changes by the technology and its operation. Many computer security incident response teams (CSIRT) and cybersecurity centers had reported significant behaviors of the attacks and they raised multiple warning signs, some of them being ignored by different third parties and others were taken into consideration and new frameworks started to be translated into research directions as a cross-collaboration between researchers and professionals. As a conclusion of CSIRTs, data science is the leader and gives the tone of the change. Identifying properly the security incident patterns or different types of insights within the cybersecurity data and implementing the right data-driven model, represents the main task is to achieve for an automated and intelligent security system. In this paper, we will propose a machine learning framework for cybersecurity , focusing on data science for cybersecurity, where the data collected from trusted sources t are relevant for cybersecurity. Our work will kickstart discussion on various research challenges which are open for improvements and will also point out the most challenging future research directions. Altogether, our purpose is not limited to discussing data science within the cybersecurity context and relevant methods/algorithms, but also to focus on the applicability of taking the most intelligent decisions based on data to protect the systems against cyber attacks.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-3-031-08580-2_13,en,SDNs Delay Prediction Using Machine Learning Algorithms,OriginalPaper,"The transmitting time of a packet between two devices is an essential factor in evaluating the network quality. Previous studies have applied machine learning to predict the connection delay value between two devices in traditional networks. However, there is little research using Software-Defined Networks (SDNs) because of the lack of SDNs traffic datasets. A method for collecting SDNs traffic data with delay values is proposed in this manuscript. In addition, this paper also evaluates different learning algorithms for SDNs delay prediction using the collected data. Experimental results showed that the Bidirectional LSTM had the lowest losses and the Recurrent Neural Networks had the shortest inference time.","['Engineering', 'Computational Intelligence', 'Biomedical Engineering and Bioengineering', 'Artificial Intelligence']"
doi:10.1007/978-3-031-17697-5_36,en,Mixed Martial Arts Bout Prediction Using Artificial Intelligence,OriginalPaper,"In modern times, boxing is not the only sport that is based on martial arts. The competitor to boxing has recently risen in the form of mixed martial arts (MMA), which is becoming quite a famous sport, most notably recognized due to the Ultimate Fighting Championship promotion (UFC). As with most other competitive sports, it is never obvious who will emerge as the winner of a specific MMA bout, as the sport is very unpredictable by nature. This paper focuses on using machine learning (ML) algorithms and classifiers to predict the winners of MMA bouts in the Ultimate Fighting Championship promotion. The data used to train and test the algorithms and classifiers is sampled from the rich UFC database which includes details from all bouts that have taken place in the UFC throughout the history of the promotion. The predictions are obtained without using any data that can directly indicate the winner of a bout. The results are presented through accuracy percentages for two different types of sample sets. Successful bout prediction percentages range from 80% to just over 92% across all subsets. This model can be further expanded and modified to predict the winner for future matchups in the promotion.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-6004-8_48,en,Segmentation of Shopping Mall Customers Using Clustering,OriginalPaper,"In this modern era, everything and everyone is innovative, where everyone competes with being better than others. The emergence of many entrepreneurs, competitors, and business interested people has created a lot of insecurities and tension among competing businesses to find new customers and hold the old customers. Because of this one should need and maintain exceptional customer service and it becomes very appropriate irrespective of the business scale. And also, it is equally important to understand the needs of customers specifically to provide greater customer support and to advertise them with the most appropriate products. In the pool of these online products, customers are confused about what to buy and what not to and also the company or the business people are confused about which section of customers to be targeted for selling their particular type of products. This confusion will probably be possible by the process called “customer segmentation”. The process of segmenting the customers with similar interests and similar shopping behavior into the same segment and with different interests and different shopping patterns into different segments is called customer segmentation. Customer segmentation and pattern extraction are the major aspects of a business decision support system. Each segment has the same set of customers who most probably has the same kind of interests and shopping patterns. In this paper, we planned to do this customer segmentation using three different clustering algorithms namely K-means clustering algorithm, mini-batch means, and hierarchical clustering algorithms and also going to compare all these clustering algorithms based on their efficiency and root mean squared errors.","['Engineering', 'Computational Intelligence', 'Cognitive Psychology', 'Personality and Social Psychology', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-030-98546-2_21,en,Optimizing mHealth Interventions with a Bandit,OriginalPaper,"Mobile health (mHealth) interventions can improve health outcomes by intervening in the moment of need or in the right life circumstance. mHealth interventions are now technologically feasible because current off-the-shelf mobile phones can acquire and process data in real time to deliver relevant interventions in the moment. Learning which intervention to provide in the moment, however, is an optimization problem. This book chapter describes one algorithmic approach, a “bandit algorithm,” to optimize mHealth interventions. Bandit algorithms are well-studied and are commonly used in online recommendations (e.g., Google’s ad placement, or news recommendations). Below, we walk through simulated and real-world examples to demonstrate how bandit algorithms can be used to personalize and contextualize mHealth interventions. We conclude by discussing challenges in developing bandit-based mhealth interventions.","['Engineering', 'Biomedical Engineering and Bioengineering', 'Health Informatics', 'Health Psychology', 'User Interfaces and Human Computer Interaction']"
doi:10.1007/978-3-031-16075-2_33,en,Optimal Scheduling of Processing Unit Using Convolutional Neural Network Architecture,OriginalPaper,"CPU Scheduling is the process of allocating CPU time to various processes of different kinds. There are many existing algorithms that schedule waiting processes, but each of those algorithms achieve good results in only one of the many useful features of a scheduler. Some important features of a scheduling algorithm are to reduce the waiting time, to give a fair share of CPU time to all the processes and to give preference to higher priority processes; Shortest Job First, Round Robin and Priority scheduling algorithms do them respectively. The proposed work combines all these desired properties into one algorithm, by making use of convolution neural network architecture. Using CNN architecture is advantageous because the data is controllable in the hidden layers. The data in the hidden layers could be both understood and manipulated; hence a more powerful neural network could be designed. In comparison to these common algorithms the proposed work achieves 66% better performance, when all the above mentioned desired properties are taken into consideration.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-1-0716-2617-7_16,en,Machine Learning Methods for Survival Analysis with Clinical and Transcriptomics Data of Breast Cancer,OriginalPaper,"Breast cancer is one of the most common cancers in women worldwide, which causes an enormous number of deaths annually. However, early diagnosis of breast cancer can improve survival outcomes enabling simpler and more cost-effective treatments. The recent increase in data availability provides unprecedented opportunities to apply data-driven and machine learning methods to identify early-detection prognostic factors capable of predicting the expected survival and potential sensitivity to treatment of patients, with the final aim of enhancing clinical outcomes. This tutorial presents a protocol for applying machine learning models in survival analysis for both clinical and transcriptomic data. We show that integrating clinical and mRNA expression data is essential to explain the multiple biological processes driving cancer progression. Our results reveal that machine-learning-based models such as random survival forests, gradient boosted survival model, and survival support vector machine can outperform the traditional statistical methods, i.e., Cox proportional hazard model. The highest C-index among the machine learning models was recorded when using survival support vector machine, with a value 0.688, whereas the C-index recorded using the Cox model was 0.677. Shapley Additive Explanation (SHAP) values were also applied to identify the feature importance of the models and their impact on the prediction outcomes.","['Life Sciences', 'Bioinformatics']"
doi:10.1007/978-3-031-10784-9_22,en,Facility Layout Design Optimization of Wing Assembly of Unmanned Aerial Vehicle Based on Particle Swarm Optimization,OriginalPaper,"The complex structure, a large number of parts and diverse assembly relations of UAV (Unmanned Aerial Vehicle) wing affect its assembly efficiency, which is an urgent scientific problem to be solved. In this paper, based on the original data of facility Facility layout in wing assembly workshop, Systematic Layout Planning method was used to determine the comprehensive relationship between the work units. Then, a multi-objective optimization Optimization mathematical model was established from the perspective of minimizing the total cost of logistics operations and maximizing the degree of close relationship with non-logistics between working units. Finally, the particle swarm optimization Optimization algorithm Algorithms is used to solve the optimization Optimization model of facility Facility layout, and the layout scheme that can improve the efficiency of unmanned aerial vehicle wing assembly workshop is found. The research results not only provide technical support for the layout characteristics of UAV wing assembly workshop, but also provide specific ideas and methods for other similar production enterprises.","['Engineering', 'Computational Intelligence', 'Robotics and Automation', 'Transportation Technology and Traffic Engineering', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1412-6_27,en,An Approach for Potato Yield Prediction Using Machine Learning Regression Algorithms,OriginalPaper,"Agriculture is backbone of any country’s economy, and also, good crop yield is highly essential for supporting the growing demand of increasing population. By using machine learning, we will be able to predict the crop yield and also the right crop that can be grown in a particular area by analyzing the soil data and the weather data of the particular location. This study mainly focuses on how supervised and unsupervised machine learning approach help in the prediction. Different machine learning algorithms include KNN algorithm, SVM, linear regression, logistic regression, NB, LDA, and decision trees. Taking different dataset preprocessing operation is performed, and missing data are modified so that it does not affect the prediction. Then, the processed data are utilized by the machine learning algorithms for making the prediction. The dataset is divided into training set and test set, and the accuracy of prediction is verified. There are different performance metrics which can be used to evaluate the accuracy in prediction of the algorithms like MSE, MAE, and RMSE, coefficients of determination metrics (R 2 ), confusion matrix, accuracy, precision, recall, and F1-score.","['Engineering', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security']"
doi:10.1007/978-981-19-4975-3_26,en,Identification and Validation of Prominent Features for Predicting Mortality in Heart Patients with Left Ventricular Dysfunction Using Machine Learning,OriginalPaper,"Machine Learning (ML) is a strong tool for medical prognosis, and it has the potential to give this branch of medicine a huge boost by allowing doctors to make accurate predictions about a patient’s future health using various forms of medical data. ML algorithms have proven to be reliable and effective in decision making with good classification accuracy. They can model nonlinear relationships, which are frequent in medical data, and apply them to predictive tasks such as forecasting a future event. In this paper, an attempt has been made to predict the mortality of heart patients with left ventricular dysfunction. Feature selection methods have been used to rank the input features in the dataset and identify four prominent features. Different combinations of these prominent features have been applied to five ML algorithms namely, Decision Tree, Gradient Boost, Random Forest, Support Vector Machine and k Nearest Neighbors to find the best performing combinations using F1-Score and AUC ROC. Considering additional performance parameters, further analysis is carried out to identify the best feature combination and the most effective ML algorithm for predicting mortality and the results are provided for the same.","['Engineering', 'Power Electronics, Electrical Machines and Networks', 'Energy Policy, Economics and Management', 'Energy Systems']"
doi:10.1007/978-981-19-3590-9_34,en,A Review of Swarm Intelligence-Based Feature Selection Methods and Its Application,OriginalPaper,"SI or swarm intelligence is considered to be one of the sound computational intelligence which deals with finding solutions for the issue related to optimization problem. The feature set is optimized by utilizing the feature selection technique, which reduces the number of features by eliminating those that are not essential or redundant. This improves the classification accuracy. This paper studies to examine the optimization/selection of significant features which is the most challenging part and it reduces the performance of algorithm time, complexity of calculations. It gives an overview of optimization techniques and their applications.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security', 'Mobile and Network Security']"
doi:10.1007/978-981-19-4182-5_5,en,Analysis of Patient Tuberculosis Tenet Death Reason and Prediction in Bangladesh Using Machine Learning,OriginalPaper,"Tuberculosis disease is one of the world's top infectious diseases that leads to a huge number of patient death worldwide. Tuberculosis gradually attacks the lungs of the patients, where Mycobacterium tuberculosis is one of the main reasons for tuberculosis attacks which are caused by the bacteria. As innovation of new techniques helps generation minimize the tasks or observation period, Machine learning is one of the popular techniques by which a person or an organization can easily build a model to evaluate data, generate ideas, or prediction of values. Machine learning algorithms are used enormously in different sectors, thus using Machine learning models in the health sector increasing rapidly. Health professionals can easily predict or observe a patient's disease using the previous history of the same patient or different similar patient's history. In the paper, tuberculosis patient's death rationale is harmonized from the World Health Organization dataset of tuberculosis disease’s class called causes and deaths, where the country Bangladesh's dataset has been used. Feature of the dataset is one of the main concerns of the patient's death, which is identified using the Machine learning regression and classification algorithm. Linear Regression, Logistic Regression, Decision tree, Random forest, KNN, XGB, Adaboost and algorithms are used in the process to create a model which can identify the best features and it is figured out that Random forest provides the best results. The prediction model for finding the number of death of patients build using the machine learning regression algorithms, where linear regression prediction accuracy is 0.99943, however, the linear model's features selection for the process are not the best noticeable. The random forest algorithm's prediction accuracy was found 0.97820, which is nearest to the linear regression accuracy. In one sentence, it is figured out that Random forest is the best-observed algorithm in both prediction accuracy and feature importance detection.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Computer Systems Organization and Communication Networks', 'Statistics, general']"
doi:10.1007/978-3-031-21595-7_15,en,Compact Data Structures for Efficient Processing of Distance-Based Join Queries,OriginalPaper,"Compact data structures can represent data with usually a much smaller memory footprint than its plain representation. In addition to maintaining the data in a form that uses less space, they allow us to efficiently access and query the data in its compact form. The $$k^2$$ k 2 -tree is a self-indexed, compact data structure used to represent binary matrices, that can also be used to represent points in a spatial dataset. Efficient processing of the Distance-based Join Queries ( DJQ s) is of great importance in spatial databases due to its wide area of application. Two of the most representative and known DJQs are the K Closest Pairs Query ( K CPQ) and the $$\varepsilon $$ ε Distance Join Query ( $$\varepsilon $$ ε DJQ). These types of join queries are executed over two spatial datasets and can be solved by plane-sweep algorithms, which are efficient but with great requirements of RAM, to be able to fit the whole datasets into main memory. In this work, we present new and efficient algorithms to implement DJQs over the $$k^2$$ k 2 -tree representation of the spatial datasets, experimentally showing that these algorithms are competitive in query times, with much lower memory requirements.","['Computer Science', 'Software Engineering/Programming and Operating Systems', 'Computer Communication Networks', 'Database Management', 'Data Mining and Knowledge Discovery', 'Information Systems Applications (incl. Internet)', 'Machine Learning']"
doi:10.1007/978-981-19-3679-1_40,en,A Novel Review on Healthcare Data Encryption Techniques,OriginalPaper,"Sharing of personal digital health information is an arising idea of changing health statistics for research and different functions. Confidentiality, besides for legal users, and access auditability are sturdy safety requirements for health statistics. This paper will examine those requirements and advise a review for healthcare companies as a good way to assist in securely storing and sharing of affected persons’ statistics they host. It should additionally allow the best legitimate users to get entry to portions of the facts’ statistics they are permitted to. The recognition can be on these precise protection troubles of modern-day encryption techniques utilized in health care and the way encryption can help in addressing healthcare regulatory necessities. This paper provides an overview of encryption and decryption procedures, highlighting their security foundations, implementation regions, and strengths and limitations in the early stages of operation. Finally, the study pinpoints the existing gap based on the findings of the analysis, with a focus on a set of rules that are most acceptable for commercial use, given current cryptography trends that are moving closer to quantum computing. The focus of this study then shifts to the genuine need for a set of rules that offers no trade-off between encryption and decryption speeds, has low computation overhead, and is resilient to quantum method attacks.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16832-1_5,en,An Enhanced Gradient Based Optimized Controller for Load Frequency Control of a Two Area Automatic Generation Control System,OriginalPaper,"This work proposes the adoption of Enhanced Gradient-Based Optimizer (EGBO) as a new approach to the Load Frequency Control (LFC) problem in a two-area interconnected power system. The importance of determining the optimal parameters for the controllers for the LFC problem cannot be overstated, and the fact that estimating these parameters require complex and nonlinear computations makes the optimization procedure even more unique and challenging. Consequently, application of an efficient optimization algorithm to successfully attain optimal controller parameters is critical. To accomplish this task, the proposed EGBO algorithm is compared to the fundamental Gradient-Based Optimizer (GBO), Chimp Optimization Algorithm (ChOA), Sine Cosine Algorithm (SCA), Grey Wolf Optimization (GWO), and Particle Swarm Optimization (PSO) for optimizing an Integral-Time-multiplied-Absolute-Error (ITAE) based objective function. The relevant findings show that the EGBO algorithm is competitively superior in terms of resilience, precision, and latency when compared to other optimization methods. Lastly, the statistical comparison further strengthens the outcome of the study.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Engineering']"
doi:10.1007/978-981-19-3391-2_3,en,Dynamic Multi-objective Optimization Using Computational Intelligence Algorithms,OriginalPaper,"Multi-objective optimization problems (MOPs) have multiple, often conflicting objectives where an improvement in one objective leads to the worsening of at least one other objective. The goal of a multi-objective algorithm (MOA) is to find a set of optimal trade-off solutions that is both accurate and diverse. However, many real-world problems are dynamic in nature where at least one objective and/or constraint changes over time. A dynamic multi-objective algorithm (DMOA) must therefore be able to track the changing set of optimal trade-off solutions over time. This chapter highlights issues that have to be addressed when evaluating the performance of DMOAs. It discusses areas that require further research, including decision making and analyzing the behavior of DMOAs. Emerging areas, and how they can impact on research in the field of dynamic multi-objective optimization (DMOO), are also highlighted.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Statistics, general', 'Cyber-physical systems, IoT', 'Professional Computing', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-3035-5_4,en,A Study on Reinforcement Learning-Based Traffic Engineering in Software-Defined Networks,OriginalPaper,"Modern communication networks have grown highly complex and dynamic, making them difficult to describe, forecast, and govern. So, the software-defined networks (SDNs) have emerged. It is a centralized network, and it is flexible to route network flows. Traffic engineering (TE) technologies are used with deep reinforcement learning (RL) in SDN to make networks more agile. Different strategies for network balance, improvement, and minimizing maximum link usage in the overall network were considered. In this article, recent work on routing as well as TE in SDN and hybrid SDN is analyzed. The mathematical model and algorithm used in each method are interpreted, and an in-depth analysis has been done.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Statistics, general']"
doi:10.1007/978-3-031-16868-0_8,en,Architecture Design for Skip-Connection Based CNNs,OriginalPaper,"In this chapter, an efficient and effective algorithms employing GA is introduced, dubbed CNN-GA, to find the best CNN architectures for specific image classification tasks automatically, such that the found CNN can be directly employed without any need for manual tuning. CNN-GA is an algorithm for automating the architecture design of CNN. Please keep in note that the terms “automatic” and “automatic + manually + tuning” are discussed from the perspective of end-users, rather than developers. In developing high-performance CNN architecture design algorithms, however, adequate domain expertise should be promoted. This effort is not difficult to comprehend by comparing it to the design of the Windows Operating System by Microsoft scientists: to ensure the users could be able to effectively operate on computers even if they do not have considerable understanding of operating systems, the scientists should put as much of their professional knowledge as they possibly can while building a user-friendly operating system.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5217-3_117,en,A Comparative Study of Point Cloud Mapping Algorithms Towards Heterogeneous Traffic Scenarios,OriginalPaper,"In recent years, the traditional automobile industry has paid an increasing attention to autonomous driving. For autonomous driving, the point cloud map contains abundant information of environment and can support various algorithms such as intelligent vehicle positioning and moving obstacle detection. Therefore, it is significant to make an accurate point cloud map for driving tasks. However, the actual road conditions are complicated in practice, especially in the underground scenes where GPS is unavailable like tunnels. Meanwhile, common point cloud mapping algorithms cannot be directly applied to long and narrow underground tunnels on the grounds that the lack of feature information, where the quality of point cloud is degenerated. Dealing with the problems above, this paper adopts a 64-line mechanical lidar and applies different point cloud mapping algorithms to construct maps, so as to explore the effect of different point cloud mapping algorithms in heterogeneous traffic scenes. The main work is as follows. Firstly, point cloud data collecting platform system has been established on a vehicle. The information interaction between the system and the environment is achieved according to the requirements of specific scenes. Then data are collected in tunnels and conventional roads, and mapped via different algorithms. Empirical validations indicate that in the scene of underground scenes which lacks of geometric structure and point cloud degradation (e.g. tunnels), Lightweight and Ground-Optimized Lidar Odometry and Mapping based on scan context (SC-LeGO-LOAM) can achieve better point cloud map over normal distribution transformation (NDT).","['Engineering', 'Civil Engineering', 'Public Policy', 'Arts']"
doi:10.1007/978-981-19-7210-2_8,en,Multi-fidelity Surrogate Assisted Evolutional Optimization,OriginalPaper,"Evolution algorithms, such as multi-objective genetic algorithms (MOGAs), require a large number of function evaluations to converge to global optima or near-optimal solutions (Sun et al. in IEEE Trans Cybern 43:685–698, 2013; Cheng et al. in IEEE Trans Evol Comput 19:838–856, 2015). This aspect limits, to a certain extent, their capability of solving real-world engineering design problems, which typically involve computationally expensive simulation models, i.e., HF models. The following three strategies are commonly used to increase the algorithm efficiency: The first strategy pertains to fitness inheritance.","['Engineering', 'Engineering Design', 'Optimization', 'Engineering Mathematics', 'Mathematical Modeling and Industrial Mathematics']"
doi:10.1007/978-3-031-21595-7_5,en,Computational Microarray Gene Selection Model Using Metaheuristic Optimization Algorithm for Imbalanced Microarrays Based on Bagging and Boosting Techniques,OriginalPaper,"Genomic microarray databases encompass complex high dimensional gene expression samples. Imbalanced microarray datasets refer to uneven distribution of genomic samples among different contributed classes which can negatively affect the classification performance. Therefore, gene selection from imbalanced microarray dataset can give rise to misleading, and inconsistent nominated genes that would alter the classification performance. Such unsatisfactory classification performance is due to the skewed distribution of the samples across the microarrays toward the majority class. In this paper, we propose a modified version of Emperor Penguin Optimization (EPO) algorithm combined with Random Forest (RF) of Bagging and Boosting Classification named by EPO-RF to select the most informative genes based on classification accuracy using imbalanced microarray datasets. The modified version of EPO was built to be based on decision trees that takes in consideration the criterion of tree splitting weights to handle the imbalanced microarray datasets. Average gene expression binary values are used as a preliminary step for exploring disease trajectories with the aid of metaheuristic optimization feature selection algorithms. Results show that the proposed model revealed its superiority compared to well-known established metaheuristic optimization algorithms, e.g., Harris Hawks Optimization (HHO), Grey Wolf Optimization (GWO), Salp Swarm Optimization (SSO), Particle Swarm Optimization (PSO), and Genetic Algorithms (GA’s) using several pediatric sepsis microarray datasets for patients who admitted to the Intensive Care Unit (ICU) for the first 24 h.","['Computer Science', 'Software Engineering/Programming and Operating Systems', 'Computer Communication Networks', 'Database Management', 'Data Mining and Knowledge Discovery', 'Information Systems Applications (incl. Internet)', 'Machine Learning']"
doi:10.1007/978-981-19-6379-7_14,en,"Nature-Inspired Computing Techniques in Drug Design, Development, and Therapeutics",OriginalPaper,"Drug design and development is a long process that consumes lots of time and money. The process divides into different stages, where the most important step is to evaluate the safety and efficacy of the drugs after finding the best lead compounds. Several in-vitro methods have been developed to evaluate the toxicity of the drugs during the preclinical screening stage; however, these assays are super expensive and costly. However, the safety assessment of the drugs is very important to develop a very accurate and precise therapeutic application. Therefore, it is needed to design new alternative methods such as computational methods for high throughput drug designing and development for very precise and effective therapeutic applications. Development of highly advanced nature-inspired intelligent computing (NIC) technologies such as particle swarm optimization (PSO), ant colony optimization (ACO), DNA computing connected with the artificial immune systems, and machine learning helps in accurate drug designing, big data processing, integration of big data for the development of prediction models, disease-based image processing to evaluate pre- and post-drug effects on biological systems, etc. In this chapter, we provide a deep insight into the usage of nature-inspired intelligent computing technologies in drug design, development, and therapeutics.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Health Informatics', 'Cancer Research', 'Genetics and Genomics', 'Bioinformatics']"
doi:10.1007/978-981-19-2704-1_2,en,Grant-Free Massive Access in Cellular Massive MIMO Systems,OriginalPaper,"This chapter considers grant-free massive access in cellular massive MIMO systems and proposes an adaptive AUD and CE scheme based on CS. By exploiting the sporadic traffic of massive connected devices and the virtual angular domain sparsity of massive MIMO channels, the proposed scheme can support massive access with dramatically reduced access latency. Simulation results reveal that equipping a large number of antennas at the BS facilitates AUD and CE and demonstrate the superiority of the proposed scheme.","['Engineering', 'Wireless and Mobile Communication', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-20601-6_55,en,Energy Efficiency Routing Algorithms in IoT: A Survey,OriginalPaper,"Internet of Things (IoT) is a new paradigm. IoT consists of a complex network of smart devices that frequently exchange data over the Internet. The aim of IoT is to make everything in our world under control and also keeping them up-to-date about the state of the things. IoT devices sense the environment and send the obtained information to the Internet cloud without the necessity of human-to-human or human-to-machine connection. Wireless sensors have limited energy resources due to the use of batteries to supply energy, and since it is usually not possible to replace the batteries of these sensors. In addition, the lifespan of the Wireless Sensor Network (WSN) is limited and short. Therefore, reducing the energy consumption of sensors in IoT networks for increasing network lifespan is one of the fundamental challenges and issues in these networks. The literature included here provides an overview of some of the most current research methodologies about the most popular protocols. Also, this paper identifies the major Machine learning (ML) models and bio-inspired algorithms for reducing energy consumption in IoT and a discussion on the evaluation of their effectiveness in energy consumption prediction and expanding network life.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-0448-6_6,en,Compressive Sensing-Based Dynamic Estimation in Unified Laser TTC System,OriginalPaper,"In this chapter, we investigate the compressive sensing (CS) based dynamic estimation algorithm in a unified laser telemetry, tracking, and command (TTC) system. Section  6.1 introduces the motivation of designing the CS-based dynamic estimation algorithm for the unified laser TTC system. Section  6.2 presents the system model. Section  6.3 details the CS-based dynamic estimation algorithm, and Sect.  6.4 analyses the performance and the complexity of developed algorithm. Section 6.5 presents the simulation results, and Sect. 6.6 concludes this chapter.","['Engineering', 'Wireless and Mobile Communication', 'Energy Systems']"
doi:10.1007/978-3-030-03009-4_84-2,en,On Variable Splitting and Augmented Lagrangian Method for Total Variation-Related Image Restoration Models,ReviewPaper,"Variable splitting and augmented Lagrangian method are widely used in image processing. This chapter briefly reviews its applications for solving the total variation (TV) related image restoration problems. Due to the nonsmoothness of TV, related models and variants are nonsmooth convex or nonconvex minimization problems. Variable splitting and augmented Lagrangian method can benefit from the separable structure and efficient subsolvers, and has convergence guarantee in convex cases. We present this approach for a number of TV minimization models including TV-L 2 , TV-L 1 , TV with nonquadratic fidelity term, multichannel TV, high-order TV, and curvature minimization models.","['Mathematics', 'Computational Mathematics and Numerical Analysis', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Optimization', 'Partial Differential Equations', 'Mathematical Models of Cognitive Processes and Neural Networks']"
doi:10.1007/978-3-031-17576-3_8,en,Enhanced MapReduce Performance for the Distributed Parallel Computing: Application of the Big Data,OriginalPaper,"Now a days and previous years, the increase in the volume of data has accelerated and this requires more storage places with the increase of data, as big data has a huge number of users and cloud computing, and these users need to access data securely and privately from any device at any time. Therefore, it is important to provide a safe flow of data in the Internet of Things (IOT records file) and to reduce its size in a way that does not affect its purpose or its purpose. The most important field of data mining is the search for items and repetitive data inside storage locations. Apriori algorithm was the most common algorithm for finding a set of repeated elements from data. This needs to delete a group of data that is repeated more than once and create a number of new groups after deleting the repeated ones, which leads to an increase in the storage space and an increase in the speed of its performance. In this paper, we implemented the MapReduce Apriori (MRA) algorithm on the Apache Hadoop cluster that includes two functions (Map and Reduce) to find the repeated sets of k-elements.","['Engineering', 'Computational Intelligence', 'Machine Learning', 'Big Data']"
doi:10.1007/978-3-031-13714-3_1,en,Elements of Graphs and Complexity Theory,OriginalPaper,"This chapter recalls some elements and definitions in graph theory and complexity theory. On the one hand, basic algorithmic courses very often include graph algorithms. Some of these algorithms have simply been transposed to solve difficult optimization problems in a heuristic way. On the other hand, it is important to be able to determine whether a problem falls into the category of difficult problems. Indeed, one will not develop a heuristic algorithm if there is an efficient algorithm to find an exact solution. Another objective of this chapter is to make the book self-contained.","['Business and Management', 'Operations Research/Decision Theory', 'Optimization', 'Computational Mathematics and Numerical Analysis', 'Algorithms', 'Computational Science and Engineering', 'Artificial Intelligence']"
doi:10.1007/978-3-031-09835-2_15,en,A Novel Codebook Generation by Lévy Flight Based Firefly Algorithm,OriginalPaper,"Nature inspired metaheuristic algorithms are become more powerful and useful in image processing algorithms especially by the developments in microprocessor technology. In the last several decades the Linde-Buzo-Gray algorithm is a powerful technique for local optimum codebook generation in image compression. Fuzzy C-Means and C-Means are the alternative ones for the same process. On the other hand nature-inspired metaheuristic algorithms have also become other alternate technics for designing the optimum codebook. In this paper the Firefly technique is enhanced by the Lévy flight function to achieve the global optimum codebook. The Firefly technique contains two sub search mechanisms to reach the global minimum solution. The first one is the attraction of any firefly by a brighter one. This process strongly guides to the firefly on the global minimum way especially if it is attracted by the brightest one. The second one is the random search of a firefly in a circle with a radius of $$\alpha $$ . On the other hand if $$\alpha $$ is determined so big, the firefly may lose its way and come to a location that is much far away from the firefly group and possibly there is no brighter firefly to be followed. On the contrary, if $$\alpha $$ is determined so small, this time the fireflies fall into a local minimum and can not escape. Therefore we need to have such an $$\alpha $$ that in most of the iterations its value changes in a small random value interval, but in rare iterations its value must be relatively big in order to escape local minimums. Therefore if a firefly is captured by a local minimum point by accidentally, Lévy Flight step provides an opportunity to escape from it easily. Numerical results suggest that the new introduced Lévy Flight based Firefly Algorithm is better than the classical techniques and provides the global optimum codebook for image compression.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-15211-5_59,en,Comparative Study of Different Metaheuristics on CEC 2020 Benchmarks,OriginalPaper,"Metaheuristic algorithms have increased in usage in all the scientific fields during the last decades. Since no optimisation algorithm is valid for all optimisation problems, many metaheuristics have been developed for various applications. Accordingly, this paper presents a comparative study on CEC 2020 optimisation problems among different algorithms. The goal is to give an overall sight of selecting a specific metaheuristic algorithm for a particular application. The algorithms in this study are; dynamic differential annealed optimisation, particle swarm optimisation, fertilisation optimisation algorithm, grey wolf optimisation, whale optimisation algorithm, firefly algorithm, artificial bee colony, ant lion optimisation, harris hawks optimisation, and sine cosine optimisation algorithm. The results are discussed in the respective sections with a focus on the convergence behaviour of the algorithms.","['Engineering', 'Automotive Engineering']"
doi:10.1007/978-3-031-09360-9_7,en,Firefly and Cuckoo Search Algorithm for Scheduling Problems: A Performance Analysis,OriginalPaper,"Meta-heuristics are some of the best-known techniques to approach hard optimization problems, however, there are still questions about what makes some meta-heuristics better than others in a specific problem. This paper presents an analysis of the Firefly and Cuckoo Search Algorithm, such as others meta-heuristics. In order to assess the performance of the Firefly Algorithm and the Cuckoo Search Algorithm, they were compared with other well-known optimization techniques, such as Simulated Annealing and Local Search. Both meta-heuristics analysed in an in-depth computational study, reaching the conclusion that both techniques could be useful in Scheduling Problems and lead to satisfactory solutions quickly and efficiently. Moreover, the results of the analysis show that the Firefly Algorithm, despite having a high runtime, performs better than the other techniques.","['Engineering', 'Engineering Economics, Organization, Logistics, Marketing', 'Cyber-physical systems, IoT', 'Professional Computing', 'Engineering Design']"
doi:10.1007/978-981-19-0179-9_3,en,Algorithmic Complexity-Based Fractional-Order Derivatives in Computational Biology,OriginalPaper,"Fractional calculus approach, providing novel models through the introduction of fractional-order calculus to optimization methods, is employed in machine learning algorithms. This scheme aims to attain optimized solutions by maximizing the accuracy of the model and minimizing the functions like the computational burden. Mathematical-informed frameworks are to be employed to enable reliable, accurate, and robust understanding of various complex biological processes that involve a variety of spatial and temporal scales. This complexity requires a holistic understanding of different biological processes through multi-stage integrative models that are capable of capturing the significant attributes on the related scales. Fractional-order differential and integral equations can provide the generalization of traditional integral and differential equations through the extension of the conceptions with respect to biological processes. In addition, algorithmic complexity (computational complexity), as a way of comparing the efficiency of an algorithm, can enable a better grasping and designing of efficient algorithms in computational biology as well as other related areas of science. It also enables the classification of the computational problems based on their algorithmic complexity, as defined according to the way the resources are required for the solution of the problem, including the execution time and scale with the problem size. Based on a novel mathematical informed framework and multi-staged integrative method concerning algorithmic complexity, this study aims at establishing a robust and accurate model reliant on the combination of fractional-order derivative and Artificial Neural Network (ANN) for the diagnostic and differentiability predictive purposes for the disease, (diabetes, as a metabolic disorder, in our case) which may display various and transient biological properties. Another aim of this study is benefitting from the concept of algorithmic complexity to obtain the fractional-order derivative with the least complexity in order that it would be possible to achieve the optimized solution. To this end, the following steps were applied and integrated. Firstly, the Caputo fractional-order derivative with three-parametric Mittag-Leffler function $$(\alpha ,~\beta ,~\gamma )$$ ( α , β , γ ) was applied to the diabetes dataset. Thus, new fractional models with varying degrees were established by ensuring data fitting through the fitting algorithm Mittag-Leffler function with three parameters $$(\alpha ,~\beta ,~\gamma )$$ ( α , β , γ ) based on heavy-tailed distributions. Following this application, the new dataset, named the mfc_diabetes, was obtained. Secondly, classical derivative (calculus) was applied to the diabetes dataset, which yielded the cd_diabetes dataset. Subsequently, the performance of the new dataset as obtained from the first step and of the dataset obtained from the second step as well as of the diabetes dataset was compared through the application of the feed forward back propagation (FFBP) algorithm, which is one of the ANN algorithms. Next, the fractional order derivative model which would be the most optimal for the disease was generated. Finally, algorithmic complexity was employed to attain the Caputo fractional-order derivative with the least complexity, or to achieve the optimized solution. This approach through the application of fractional-order calculus to optimization methods and the experimental results have revealed the advantage of maximizing the model’s accuracy and minimizing the cost functions like the computational costs, which points to the applicability of the method proposed in different domains characterized by complex, dynamic and transient components.","['Engineering', 'Computational Intelligence', 'Engineering Mathematics', 'Communications Engineering, Networks', 'Statistics, general', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2768-3_28,en,Improved Cuckoo Search Algorithm with Escape Mechanism,OriginalPaper,"Aiming at the problem of weak exploitation ability of Cuckoo Search (CS) algorithm, this paper proposes a Cuckoo Search algorithm with escape mechanism (ECS). First, we introduce a search strategy that enables candidate solution move closer to the optimal. Then, we design an escape mechanism based on backward learning. Numerical tests were conducted with the results showing a great improvement in the convergence speed and accuracy of the proposed ECS compared with the original.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory', 'Operations Research/Decision Theory', 'Business and Management, general']"
doi:10.1007/978-3-031-12127-2_1,en,symKrypt: A Lightweight Symmetric-Key Cryptography for Diverse Applications,OriginalPaper,"Symmetric-key cryptography is used widely due to its capability to provide a strong defense against diverse attacks; however, it is prone to cryptanalysis attacks. Therefore, we propose a novel and highly secure symmetric-key cryptography, symKrypt for short, to defend against diverse attacks and provide tighter security than the conventional cryptography. Our proposed algorithm uses multiple private keys to encrypt a single block of a message. To generate the private keys, we again propose a true-random number generator, called Grando, and a pseudo-random number generator, called Prando. Moreover, symKrypt keeps secret about the bit mixing of the original message with the private keys. Also, the number of private keys is kept secret. In addition, the private keys are generated dynamically based on the initial inputs using a pseudo-random number generator which is highly unpredictable and secure. In this paper, we theoretically analyze the capabilities of symKrypt and provide experimental demonstration using millions of private keys to prove its correctness. Furthermore, we demonstrate the proposed pseudo-random number generator algorithm experimentally in NIST SP 800-22 statistical test suite. Our propose random number generators, Grando and Rando, pass all 15 tests in the NIST SP 800-22 test suite. To the best of our knowledge, symKrypt is the first model to use multiple private keys in encryption yet lightweight and powerful.","['Engineering', 'Computational Intelligence', 'Information Systems and Communication Service', 'Management of Computing and Information Systems']"
doi:10.1007/978-3-031-15699-1_6,en,Margin Optimization of Single Flux Quantum Logic Cells,OriginalPaper,"Single Flux Quantum (SFQ) logic family is an attractive alternative to CMOS technology with the promise of more than two orders of magnitude improvement in the energy-delay product. However, component-level parameter variations during the fabrication process of SFQ logic cells are quite high. Therefore, optimizing SFQ logic cells to maximize their operating parameter margin (and parametric yield) under variability sources is a necessity. In this chapter, a hybrid design optimization technique based on Automatic Niching Particle Swarm Optimization and Fireworks Algorithm is presented where the objective is to maximize the upper and lower bound margins of the design parameters of a SFQ logic cell. The proposed algorithm can efficiently optimize both simple and complex multi-stage logic cells with various fan-in and fan-out counts. The proposed method improves the critical margin range and parametric yield values for 6 different logic cells by 22.83% and 15.22% on average, when compared to a previously optimized open-source cell library.","['Engineering', 'Circuits and Systems', 'Electronic Circuits and Devices']"
doi:10.1007/978-981-19-7636-0_1,en,Programming Model,OriginalPaper,"The main difference between software-defined chips (SDCs) and ASIC is that SDCs need to execute user-written software like general-purpose processor. ASIC is only for specific applications. It only needs to provide special APIs without considering how programmers program it while the function of SDCs is finally realized by programmers. A necessary condition for a set of hardware to attract a large number of users to invest in the development of software is that the software on the hardware is forward compatible: even if the new generation of hardware design has changed dramatically, the software previously written by users can still run correctly on the new chip. The “language” for dialogue between software and hardware is the programming model.","['Engineering', 'Electronics and Microelectronics, Instrumentation', 'Circuits and Systems', 'Processor Architectures', 'Control Structures and Microprogramming', 'Logic Design']"
doi:10.1007/978-981-19-4143-6_4,en,Lane Visual Detection and Recognition Technology,OriginalPaper,"The purpose of lane image understanding is to perform visual navigation. Most of the early outdoor mobile robot visual navigation methods are no map methods, and the research background is mainly for structured environment, including highway vehicle automatic cruise and factory automatic guided vehicle (AGV). According to the structure of road environment, outdoor visual navigation can be divided into structured environment navigation and unstructured environment navigation.","['Engineering', 'Mechanical Engineering', 'Machinery and Machine Elements', 'Artificial Intelligence']"
doi:10.1007/978-3-031-14537-7_1,en,The Bees Algorithm—A Gentle Introduction,OriginalPaper,"The Bees Algorithm Bees Algorithm, THE is a popular optimisation method taking inspiration from the food foraging Foraging point behaviour of honey bees. The algorithm performs a kind of exploitative neighbourhood search combined with random explorative search. This chapter describes in detail the Bees Algorithm and its variants. The description of the Bees Algorithm Bees Algorithm, THE is framed in the general context of parameter optimisation, highlighting the main issues and how the Bees algorithm Bees Algorithm addresses them. The state-of-the-art of the empirical and theoretical understanding of the Bees Algorithm is discussed and areas of further work are suggested.","['Engineering', 'Robotics and Automation', 'Artificial Intelligence', 'Industrial and Production Engineering', 'Professional Computing', 'Robotics', 'Machine Learning']"
doi:10.1007/978-981-19-6379-7_9,en,Nature-Inspired Computing: Bat Echolocation to BAT Algorithm,OriginalPaper,"The analysis and disclosure of modulation in call structure dynamics of bats in prey catching serves as a raw material for developing engineering modules to solve various kinds of problems. It has always been of interest to biologists to decipher the mechanism of echolocation. There are two groups among these flying mammals old-world fruit bats which do not echolocate and new-world bats which echolocate except a few like Rousettus spp . which is an echolocating fruit bat. The new world fruit bats are smaller in size and are called microbats. They are insectivores and need to catch prey in flight in dark conditions. To perform this task for foraging, they use echolocation. High-pitched sound waves are produced by bats that hit the target and come back to them. These frequency-modulated calls from bats help them in homing their prey. However, the mathematical expression of this mechanism, developed in 2010 by Xin-She Yang is even more interesting. By simply using velocity, frequency, iteration, and loudness, he explained how bats perform homing to catch their prey. The bat echolocation-inspired BAT algorithm is an iconic hallmark of nature-inspired computing. It is a heuristic model for solving problems. New variants have been developed and used for solving problems of diverse nature. In this chapter, we go into the journey of the BAT algorithm, the development of its variants, and the various applications of this algorithm.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Health Informatics', 'Cancer Research', 'Genetics and Genomics', 'Bioinformatics']"
doi:10.1007/978-3-031-09909-0_13,en,Achievements of Artificial Intelligence in the Past and During the COVID-19 Era to Tackle Deadly Diseases,OriginalPaper,"Processing big data based on machine learning tools and deep learning models have become crucial in finding solutions to various problems in different fields. In particular, artificial intelligence systems play a key role in improving performance and increasing the speed of a clinical decision for a given clinical issue. In that respect, the outbreak of the virus caused by SARS-CoV-2 across the world has caused panic and unrest among people which required the rapid intervention of bioinformatics researchers and health professionals to discover the relevant clinical treatment. The main concern of the paper is to emphasize the usefulness of artificial intelligence and Big Data analytic for treating diseases. Thus, it discusses the past success of artificial intelligence and big data analytic for healthcare applications. It also presents the current advancements in machine learning tools as well as deep learning models for processing data sets related to the COVID-19 virus. In addition to that, the proposed work puts emphasis on the requirements of artificial intelligence models to make suitable clinical decisions. And finally, it gives a proposed analysis of the main factors that help decrease the spread of a pandemic in the world.","['Engineering', 'Robotics and Automation', 'Robotics', 'Engineering Design', 'Biomedical Engineering and Bioengineering']"
doi:10.1007/978-3-031-10507-4_6,en,A Blockchain-Based Machine Learning Intrusion Detection System for Internet of Things,OriginalPaper,"The Internet of Things (IoT) is the major evolution of Internet also known as Internet of Everything which made a network with smart sensors heterogeneous devices. Nowadays, the usability of IoT networks is increasing very rapidly from smart home, smart industry to smart everything. But, these smart devices like as traditional Internet are vulnerable to various attacks such as denial of service (DoS), spoofing attacks, ransomware attacks, and many more. There are also various protocols such as DTLS, IPv6, and many other lightweight protocols used for IoT data security. But despite these, these attacks are also occurred via sniffing or manipulating of header information to both encrypted and non-encrypted protocols. Attacks generated via header information can be mitigated by various methods as ML-based intrusion detection systems (IDSs) is one of them. These IDSs security depends on the accuracy/integrity of training data (IoT data) and trust on the ML/DL algorithms. Recently, blockchain, a new advanced technology, is emerged, which has several use cases in the IoT domain for providing security. Due to the various advantages of blockchain and ML/DL methods in IoT data security, we combine these technologies and provide a secure blockchain-ML-based framework for heterogeneous IoT data security environment.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Systems and Data Security']"
doi:10.1007/978-3-031-17746-0_34,en,The Impact of Using Smart Algorithms and Blockchain Technology on the Profits' Quality in Saudi Financial Market,OriginalPaper,"The study aimed to demonstrate the impact of using smart algorithms and blockchain technology on the profits' quality in Saudi financial market. As these forms of the recent technological revolution lead to great changes in business models and affect consequently the accounting profession, study was applied on Saudi Money (Tadawul), the shares of which were traded during the time period (2018/2021), amounted to (223) companies divided into (21) sectors, financial institutions were excluded due to the nature of the study, where a sample was taken consisting of (60) companies. The banking and insurance companies sectors were also excluded due to the different nature of the activity (10 banks + 32 insurance companies), and thus the number of observations was (240) for the years covered by the study, then the proposed model was applied using data extracted from the annual reports and financial statements of companies listed in the Saudi capital market, and the study concluded that the use of smart algorithms contributes significantly to improving the quality of profits in companies listed on the Saudi capital market as it has the ability by using its forecasting models to detect the frauds in the financial statements, also the use of blockchain technology contributes significantly to improving the quality of profits in the companies listed in the Saudi stock market as the blockchain is a system that ensures against hacking and the ability to alter records, study conclude that Saudi financial market may adopt blockchain technology in accounting information systems in the future to take advantage of the advantages and opportunities that it achieves, and for future research implications. Researchers may work to shed light on smart algorithms and block chain technology effects and changes in the accounting systems, and the need for global and Saudi regulatory authorities to issue standards and guidelines governing the application of smart algorithms and block chains in accounting information systems.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Business Information Systems']"
doi:10.1007/978-3-031-08815-5_4,en,"Point-of-Interests Recommendation Service in Location-Based Social Networks: A Survey, Research Challenges, and Future Perspectives",OriginalPaper,"The focus on accurate Point-Of-Interest (POI) recommendation, specifically in location-based services (LBS), has gained all social-network developers’ attention. This is because the POI service has a significant role in helping users to locate targeted areas, including hospitals, airports, stations, billing addresses, post-office, shopping-mall, and other POIs. Equally, many attempts have been realized to provide accurate POI recommendation solutions via commercial and academic sectors. However, the recommendation solutions have their weaknesses and abilities in terms of initial check-ins, accuracy, behavior of the users’ activities, and historical passed locations. According to the state-of-the-art, a survey of such solutions and utilized techniques is needed. Therefore, this paper aims to address most of the currently proposed solutions and implemented techniques for offering accurate POI recommendation systems. Further, this paper also presents a taxonomy of POI recommendation solutions in which the solutions are classified into content-based filtering, collaborative-based filtering, and hybrid-based filtering solutions. This is with a particular focus on the details of the implemented techniques/algorithms and utilized features. Providing an accurate POIs recommendation solution and other related issues are listed as future research attempts.","['Engineering', 'Computational Intelligence', 'Transportation Technology and Traffic Engineering']"
doi:10.1007/978-3-031-10956-0_12,en,RobotCore—A General Multi-robot Simulation Framework,OriginalPaper,"In the last decade, research targeting multi-robot systems has increased due to the advantageous properties of those systems. They might be cost-efficient, scalable, and fault-tolerant; however, the development of these systems is more complicated. These features increase the desire to create algorithms that can be hard to test and validate. Therefore, these algorithms have to be formalized; then, they can be implemented on simulators, which brings the demand for a simulation framework that can perform, execute, and validate the algorithms for multi-robot systems, even at large scales, which is still flexible enough to allow the integration of new problem sets and algorithms. With this in mind, the authors present a general robot simulation framework, called the RobotCore framework.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-18461-1_10,en,CVD: An Improved Approach of Software Vulnerability Detection for Object Oriented Programming Languages Using Deep Learning,OriginalPaper,"Software vulnerability poses a significant security threat to the simultaneous expansion of the digital revolution. With increasing numbers of software and their vulnerabilities, detecting vulnerabilities accurately is a substantial challenge. Various static and deep learning approaches are executed to make the tasks more manageable, but detection accuracy is still a significant factor. In this paper, we are introducing Common Vulnerability Detector (CVD), a deep learning-based vulnerability detection system that can analyze Object-Oriented Programming (OOP) Language assembled source codes and can detect vulnerabilities with the highest accuracy. We implemented a highly optimized Convolutional Recurrent Neural Network (CRNN) for source code analysis to achieve this. By implementing this model on a SARD dataset of C Sharp source codes, CVD could successfully detect six common and dangerous vulnerabilities with an accuracy of 96.10% and F1 score of 96.40%. We compared CVD with all the known and popular methods and CVD outperformed all of them. According to the performance and results, our proposed CVD model is a promising step in vulnerability detection. Furthermore, this model can be the stair for something revolutionary in the world of vulnerability detection.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-3-031-11051-1_123,en,Contour Extraction When Recognizing Numbers Presented as Images,OriginalPaper,"The extraction of the contours of objects in images is an integral function of systems for processing and recognition of numbers presented in the form of images. The paper considers a class of algorithms focused on the formation of a set of pixels separating objects of interest from the background, and which is resistant to certain types of noise. The main idea of ​​the proposed algorithms is the construction and analysis of fuzzy increments in the extraction of contours. The rules for calculating fuzzy increments for the considered pixel in an arbitrary direction are described. The algorithm has been tested and shown to be effective in solving the problems of recognizing car numbers. The practical significance of the obtained results lies in the fact that the proposed algorithms can be used to create a software module for preliminary image processing in image processing and recognition systems.","['Engineering', 'Control and Systems Theory', 'Control, Robotics, Mechatronics', 'Communications Engineering, Networks']"
doi:10.1007/978-3-031-14605-3_11,en,"The Algorithmic Public Decision, Between Explainability, Administrative Discretion and Data-Driven Decision Making",OriginalPaper,"The use of AI algorithms to support public decisions is spreading in public administrations while with an asymmetrical speed it has already transformed the private sector. Substantial questions are still open about the algorithmic legality of AI choices. Deep neural networks do not allow full eXplainability of the decision-making process as the programmer himself does not have the ability to be aware of the logical steps taken to achieve the proposed goal. In these cases the question arises of the “AI black box” which collides with the rules of Italian administrative law which, on the contrary, seeks total transparency as a great metaphor for a “glass house” public administration and is oriented towards a shared administration with citizens. The objective of the paper is to explore the torsion points of algorithmic decision making towards the rules of the administrative procedure, bringing the algorithmic procedure back to a transparency in line with the European Commission's choice of an anthropocentric and transparent artificial intelligence by design that aims the improvement of the algorithm's eXplainability techniques (XAI). If refining XAI will be the key to a complete application of AI in the PA, this path, in order not to slow down the spread of AI and thus increase the gap to the detriment of the public sector, will have to be preceded by a logic of experimentation and incremental input: from the widespread automation of routine activities and administrative procedures with no margin of discretion to a gradual experimentation of AI solutions in complex use cases to support public decision-making through parallel analysis and verification processes. This approach can only be guaranteed through a joint work of jurists and computer scientists in the design of transparent algorithms by design, in the dogmatic construction of an Algorithmic Decision Making to respond to the principle of enhanced transparency required to guarantee the legitimacy of A.I. in administrative activity.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3575-6_71,en,Smart Congestion Control and Path Scheduling in MPTCP,OriginalPaper,"Featuring the recent rise of mobile technology, new devices with a variety of connection ports have become more popular. Multiple communication interfaces may now be usable over a single TCP connection thanks to the multi-path transmission control protocol (MPTCP), which was developed to speed up Internet use. There are three main design aims for the MPTCP congestion management algorithms: better performance, more fairness, and congestion balancing. MPTCP congestion control algorithms now in use cannot achieve these design goals. Due to its inability to leverage the network, an MPTCP congestion-control algorithm, such as OLIA, often results in poor performance. With the current Internet’s enormous volume of transient traffic, it is difficult to keep track of MPTCP congestion management techniques. MPTCP congestion control methods may benefit from being aware of current network delay conditions. There are various sub flows in an MPTCP connection, and the schedulers are employed to deal with this heterogeneity. MPTCP’s scheduler is an important part of the software. In this study, MPTCP congestion management and MPTCP schedulers are discussed.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-3124-6_9,en,Algorithms to Reduce Depth Errors,OriginalPaper,"In SS-3D micro EDM, the depth errors of 3D micro cavity are accumulated layer by layer due to the contour scanning process with keeping discharge gaps for compensating axial tool-electrode wear in real time. In this study, the reason of the depth errors is analyzed, and then a layer depth constrained algorithm (LDCA) and an S-curve accelerating algorithm (SCAA) are proposed to reduce the depth errors. By using LDCA, over-cutting errors can be avoided by controlling a feeding maximum at every scanning spot. As a supplementary algorithm of LDCA, SCAA can compensate insufficient-machining errors at the start and end of scanning paths. Implementation process and control strategy of the algorithms are also described. The purpose of this study is to efficiently machine complex 3D micro-cavities with high accuracy of shape and surface. Machining experiments are carried out to verify the proposed algorithms. Typical 3D micro cavities <800 μm can be automatically machined. The machining accuracy of micro surfaces and edges is obviously improved. The depth errors can be controlled within 2 μm, and the material removal rate (MRR) reaches 2.0 × 10 4  μm 3 /s with a tool electrode of Φ 80 μm and its rotational speed of 1,000 rpm. In addition, the 3D micro cavities designed on unknown edges or hollow workpieces can be successfully formed.","['Engineering', 'Manufacturing, Machines, Tools, Processes', 'Industrial and Production Engineering', 'Power Electronics, Electrical Machines and Networks']"
doi:10.1007/978-3-031-16075-2_26,en,A Deep Reinforcement Learning Algorithm Using A New Graph Transformer Model for Routing Problems,OriginalPaper,"Routing problems, which belong to a classical kind of problem in combinatorial optimization, have been extensively studied for many decades by researchers from different backgrounds. In recent years, Deep Reinforcement Learning (DRL) has been applied widely in self-driving, robotics, industrial automation, video games, and other fields, showing its strong decision-making and learning ability. In this paper, we propose a new graph transformer model, based on the DRL algorithm, for minimizing the route lengths of a given routing problem. Specifically, the actor-network parameters are trained by an improved REINFORCE algorithm to effectively reduce the variance and adjust the frequency of the reward values. Further, positional encoding is used in the encoding structure to make the multiple nodes satisfy translation invariance during the embedding process and enhance the stability of the model. The aggregate operation of the graph neural network applies to transformer model decoding stage at this time, which effectively captures the topological structure of the graph and the potential relationships between nodes. We have used our model to two classical routing problems, i.e., Traveling Salesman Problem (TSP) and Capacitate Vehicle Routing Problem (CVRP). The experimental results show that the optimization effect of our model on small and medium-sized TSP and CVRP surpasses the state-of-the-art DRL-based methods and some traditional algorithms. Meanwhile, this model also provides an effective strategy for solving combinatorial optimization problems on graphs.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-6068-0_20,en,Detection of COVID-19 Infection from Clinical Findings Using Machine Learning Algorithm,OriginalPaper,"COVID-19 infection is a transmissible virus causing acute respiratory syndrome spreading worldwide. The number of patients infected by this deadly virus increases steadily, causing a high mortality rate. Hence, it is crucial to diagnose and identify the COVID-19 infection for earlier treatment of the patients. This study has applied four algorithms, namely, Logistic Regression (LR), Nu-Support Vector Machine (Nu-SVM), Multi-layer perceptron (MLP) and Naive Bayes (NB) to identify COVID-19 infection. The clinical laboratory findings of 600 individuals were taken from Hospital Isrelita Albert Einstein, Sao Paulo, Brazil, used in this study. We have selected significant features using Random forest-based recursive feature elimination for predicting the infection. Experiments are conducted with 90% training and 10% testing data. The performance result shows that the Nu-SVM algorithm obtained the prediction accuracy of 95% with 100% sensitivity and 94.23% specificity in predicting the infection. To our knowledge, the result achieved by Nu-SVM is the highest in the literature. Hence, the model can be used as a tool for the initial prediction of COVID-19 disease.","['Computer Science', 'Artificial Intelligence', 'Computational Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-16213-8_3,en,Contribution of Near- and Mid-Infrared Wavebands to Mapping Fine-Scale Coastal Ecogeomorphological Features,OriginalPaper,"Coastal ecogeomorphological features support remarkable biodiversity and provide a wide variety of ecosystem services: cultural services (recreation, tourism facilities), provisioning services (agricultural production, pastoralism), and regulating services, including carbon sequestration and natural protection against coastal erosion and marine flooding. Therefore, mapping these coastal features with very high spatial resolution is a major challenge to their preservation and to face the challenges of global change. In this study, the contribution of the near-infrared (NIR) and mid-infrared (MIR) bands from multispectral drone and super-spectral (SS) WorldView-3 (WV-3) satellite images was used to map coastal ecogeomorphological features using two supervised classification algorithms: maximum likelihood (ML) and support vector machine (SVM). Various combinations of spectral bands, visible + NIR and visible + MIR, evaluated through the overall accuracy (OA) scores, for the classification of ecogeomorphological features revealed the significant contribution of the NIR and MIR bands to the mapping of coastal features. The addition of the NIR bands to the RGB band combination significantly increased the OA scores of the classifications (by +4.99% and +6.54%, with the ML and SVM algorithms, respectively). The addition of MIR bands to the combination of these bands provides classifications with even higher OAs (up to 99.1% and 98.4%), demonstrating the relevance of MIR bands for the mapping of coastal ecogeomorphological features.","['Earth Sciences', 'Oceanography', 'Computer Applications', 'Geography, general', 'Water, general', 'Pollution, general', 'Ecology']"
doi:10.1007/978-3-031-12807-3_1,en,Black Box Models for eXplainable Artificial Intelligence,OriginalPaper,"Machine learning algorithms are becoming popular nowadays in cyber security applications like Intrusion Detection Systems (IDS). Most of these models are anticipated as a Black Box. Previously black box was a model where the user cannot see the internal logic. To reach the goal of overwhelming the crucial weakness, the cost may vary. This is related to both ethical and practical problems. Explainable Artificial Intelligence (XAI) is crucial to converting the machine learning algorithms to appreciate the management by accepting the human experts to understand the data evidence. Important role of trust management is to accept the impact of malicious data to identify the intrusions. This chapter addresses the XAI method to appreciate trust management using the decision tree models. Basic decision tree models are used to simulate a human contact to decision making by dividing the options into multiple small options for the IDS area. This chapter aims to implement the arrangement of issues labeled in the various black box methods. This survey helps the researcher to understand the classification of various black box models.","['Engineering', 'Computational Intelligence', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4815-2_5,en,Traffic Routing in Stochastic Network Function Virtualization Networks,OriginalPaper,"While virtual network function scheduling in the previous chapter assume deterministic link delay and bandwidth, the real-life network usually behaves in a stochastic manner, due to e.g., inaccurate data, expired exchanged information, insufficient estimation to the network. Motivated by this, we consider the stochastic NFV networks in this chapter, where the link bandwidth and delay are assumed to be random variables and their cumulative distribution functions are known. We first study how to calculate the delay and bandwidth value in an SFC such that their realizing probabilities are satisfied. Subsequently, we formally define the traffic routing problem in stochastic NFV networks and prove it is NP-hard. We present an exact solution and a tunable heuristic to solve this problem. The proposed heuristic is a sampling-based algorithm, and it leverages the Tunable Accuracy Multiple Constraints Routing Algorithm (TAMCRA) to find a multi-constraint path for each adjacent VNF pair. It dynamically adjusts the link weights as well as delay and bandwidth realizing probability constraint after finding the path for each VNF pair so that the cumulated probabilities will not violate the specified values. Finally, we evaluate the performance of the proposed algorithms via extensive simulations.","['Engineering', 'Communications Engineering, Networks', 'Graph Theory', 'Operations Research, Management Science', 'Theory of Computation', 'Algorithm Analysis and Problem Complexity']"
doi:10.1007/978-3-031-09382-1_14,en,Bat Algorithm for Discrete Optimization Problems: An Analysis,OriginalPaper,"In this article the application of the discrete version of the bat algorithm to flowshop scheduling problems is presented and compared with Simulated Annealing, Local Search, as well as versions of each that start from constructive heuristics (Palmer and CDS). Bat algorithm is a novel metaheuristic, developed for continuous problems that has shown exceptional results. This paper intends to assess its effectiveness and efficiency for discrete problems when compared with other optimization techniques, including Simulated Annealing and Local Search, whose results are already proven. First, it was developed a literature review about those algorithms, then they were implemented in VBA with Microsoft Excel. Once implemented, the parameterization was carried out, ensuring an adequate application of the algorithms before they can be compared. Then, the methods were applied for 30 normally distributed instances, in order to draw broader conclusions. Finally, a statistical evaluation was carried out and concluded the inferiority of the Local Search in relation to the metaheuristics and the superiority of the hybrid version of the Bat Algorithm with CDS in relation to Simulated Annealing, with significantly better solutions, in an equal computation time.","['Engineering', 'Engineering Design', 'Manufacturing, Machines, Tools, Processes', 'Complexity']"
doi:10.1007/978-3-031-15191-0_10,en,Analyze Symmetric and Asymmetric Encryption Techniques by Securing Facial Recognition System,OriginalPaper,"This paper aims to protect the facial recognition system by securing the stored images and preventing unauthorized people from accessing them. Symmetric and asymmetric encryption techniques were proposed for the image encryption process. To ensure the use of the most efficient techniques, thus, compare the results between two popular encryption algorithms. AES was chosen to represent the symmetric cipher and the RSA for asymmetric ciphers. High-resolution face images are encoded by both algorithms, as well as the ability to be analyzed by quantitative parameters such as PSNR, histogram, entropy, and elapsed time. The results showed through the proposed criteria the preference of AES, as it provided distinguished results in image coding in terms of coding quality and accuracy, processing speed and execution, coding complexity, coding efficiency, and homogeneousness. To sum up, symmetric encryption techniques protect the face recognition system faster and better than asymmetric encryption techniques.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Mobile and Network Security']"
doi:10.1007/978-981-19-3632-6_77,en,Analysis of an Intelligent Optimization Algorithm for Automatic Generation of Computer Software Test Data,OriginalPaper,"Software testing can guarantee the quality of software products, but it also takes up nearly half of the cost and resources of the entire software development cycle. The traditional test data acquisition requires manual design, but as the scale and complexity of software increases, manual design of test data can no longer meet the requirements of testing, therefore, automatic test data generation has become a hot spot and focus of many scholars’ research. In this paper, we will study and analyse the automatic generation of computer software test data based on intelligent optimisation algorithms.","['Engineering', 'Cyber-physical systems, IoT', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing']"
doi:10.1007/978-3-031-16075-2_51,en,Extractive Text Summarization for Turkish: Implementation of TF-IDF and PageRank Algorithms,OriginalPaper,"Due to the massive amount of information available on the web, reaching the desired content has become more and more difficult. Automatic text summarization helps to solve the problem by minimizing the document size while keeping its core information. In this study, two extractive single document automatic text summarization systems for Turkish are presented which implement the statistical-based TF-IDF algorithm as well as the combination of TF-IDF with the graph-based PageRank algorithm. The study aims to reveal the usability and effectiveness of these algorithms for Turkish documents. Moreover, the results of the TF-IDF implementation and the hybrid approach are compared using the co-selection measures, precision, recall, and F-score. In the evaluation phase, the system-generated summaries are categorized and tested based on their word sizes and the predetermined thresholds and compared against the human-generated summaries. The results indicate that the hybrid system performs better than the TF-IDF system even in lower thresholds, and also both systems are inclined to improve average F-scores in higher threshold generated summarization.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1412-6_44,en,Improving the Ability of Persons Identification in a Video Files Based on Hybrid Intelligence Techniques,OriginalPaper,"With the advancement in technology, the importance of person recognition in photographs or videos has grown due to its usefulness in the search for wanted persons and criminal identification using various theories and algorithms and various non-hybrid and hybrid techniques to identify the person through the face, and its features have been developed. The paper proposed a hybrid algorithm to improve the performance of person identification in video files. The system works through several steps: first, face detection using Viola–Jones algorithm; second, feature extraction by algorithm local binary pattern (LBP); final, person identification by hybrid proposed algorithm (HPBFF) by hybrid between backpropagation neural network and firefly algorithm. The results show that the system was able to identify and monitor the person with a high classification accuracy rate of 98.4%, compared to 94.7% for the approach without the hybrid. The results of the tests revealed that the system is robust and has a high recognition rate, making it suitable for use in mobile and compact identification and authentication.","['Engineering', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security']"
doi:10.1007/978-981-19-3788-0_31,en,Comparison of the Effectiveness of the MUSIC and ESPRIT Superresolution Algorithms,OriginalPaper,"In radar, it is of great importance to distinguish targets separated by a small angular distance, for example, two close-flying aircraft located at a great distance from the radar station or distinguishing a low-flying target and its antipode, arising due to signal reflection from the underlying surface. This article compares the efficiency of the MUSIC and ESPRIT superresolution algorithms for the problem of distinguishing two targets separated by a small angular distance. According to the simulation results, the ESPRIT algorithm is faster than MUSIC for the same antenna array and signal parameters, ESPRIT has a smaller RMS deviation for the same parameters, which suggests that the ESPRIT superresolution algorithm is more efficient.","['Engineering', 'Aerospace Technology and Astronautics', 'Engine Technology', 'Engineering Thermodynamics, Heat and Mass Transfer']"
doi:10.1007/978-981-19-7808-1_6,en,A Feasibility Review of Novel Avian-Based Optimization Algorithms for Damage Detection in a Truss Bridge,OriginalPaper,"During their lifecycle, bridge structures have to withstand various uncertainties loads such as wind, typhoon, and accident loads which may pose serious threats to the integrity as well as the safety of the structure, especially when they induced significant damages to the structure. For many years, researchers have been trying to develop heath monitoring tools, which can identify accurately not only the location, but also the level of structural damage. In this paper, two novel avian-based optimization algorithms-Artificial Hummingbird Algorithm (AHA) and African Vulture Optimization Algorithm (AVOA) are reviewed for their feasibility in detecting structural damages in truss bridge. The accuracy of the proposed algorithms is compared against two other famous algorithms: particle swarm optimization (PSO) and cuckoo search (CS). The results of the feasibility review for damage detection capability are discussed.","['Engineering', 'Solid Mechanics', 'Structural Materials', 'Computational Science and Engineering']"
doi:10.1007/978-3-031-20141-7_10,en,Machine Learning and Web Integrated Chatting Forum Which Detected Mental Health of the User,OriginalPaper,"Nowadays in this 21st century, youth is mainly leaning on chatting forums instead of real-life conversations trying to convey their emotions to their close friends with the help of texts, emojis, etc. On the contrary, the receiver may find it difficult to understand the emotions due to mistyped texts, misunderstandings, or any other issues. Henceforth, this bafflement may lead to more depression, and anxiety and may lead to serious threats to life like suicides. Among all the reasons, almost one-half of the people attempt suicide due to depression, anxiety is the main reason as other people cannot understand them. To overcome this problem of the understanding mood of the people and motivating them, the proposed model can be one of the best applications which can help the depressed user to overcome his/her stress, anxiety, etc. with the help of motivational quotes. The proposed model is a chat-based forum that is designed to monitor the mental health of the user the model consists of two parts: (i) Web Development; (ii) Machine Learning. This application is built with a Machine Learning algorithm and integrated with web development. Web scraping and creation of datasets have been done with the help of ‘Tweet’ and ‘Pandas’. ML model is trained using ‘ScikitLearn’. Further, the Machine Learning model is integrated with the chat-based Forum web application with the help of ‘Flask’.","['Engineering', 'Computational Intelligence', 'Transportation Technology and Traffic Engineering', 'Manufacturing, Machines, Tools, Processes']"
doi:10.1007/978-981-19-5224-1_65,en,Operational Availability Optimization of Cooling Tower of Thermal Power Plants Using Swarm Intelligence-Based Metaheuristic Algorithms,OriginalPaper,"Cooling towers are mainly utilized to disperse the heat of thermal power plants (TPP). The availability of cooling tower is directly proportional to the maximum availability of TPP. To ensure the maximum availability of cooling towers, a mathematical model is developed followed by optimization using four swarm intelligence-based metaheuristic algorithms, viz. Grey Wolf Optimizer, Grasshopper Optimization Algorithm, Dragonfly Algorithm, and Whale Optimization Algorithm. The Markovian birth–death process and Chapman-Kolmogorov differential–difference equations are utilized to derive the objective function of availability associated with the proposed model. It is observed from the numerical investigation that the Whale Optimization Algorithm performs better than all other metaheuristic algorithms in providing the optimized values of various failure and repair rates and predicting the overall availability of the cooling tower.","['Engineering', 'Communications Engineering, Networks', 'Statistics, general', 'Cyber-physical systems, IoT', 'Sociology, general', 'Professional Computing']"
doi:10.1007/978-981-19-6004-8_41,en,Customer Analytics Research: Utilizing Unsupervised Machine Learning Techniques,OriginalPaper,"As the retail industry is growing, the challenges faced by small retail store owners have increased even more. While retail chain giants enjoy huge profits, small store owners struggle to survive. Hence, it becomes essential for small-scale vendors to incorporate advanced customer analytics into their businesses, serving the purpose of managing data to achieve an excellent customer experience. In our proposed work, some of the common customer analytics techniques like Customer Segmentation, and Market Basket Analysis were utilized. RFM analysis was used to categorize consumers based on their likelihood of churn and was further integrated by K-means, Hierarchical, DBSCAN, and Gaussian Mixture Model clustering, out of which K-means outperformed among clustering algorithms. Market Basket Analysis is accomplished with the courtesy of Association Rule Mining algorithms like Apriori, Eclat, and FP Growth. FP Growth, having taken 78.7892 ms, proved to be the best algorithm in terms of performance.","['Engineering', 'Computational Intelligence', 'Cognitive Psychology', 'Personality and Social Psychology', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-1645-8_37,en,Energy Optimization in Wireless Sensor Networks Based on Firefly Optimization Technique and Hybrid Eagle with Firefly Optimization Technique,OriginalPaper,"Wireless sensor networks (WSNs) consist of a number of sensor nodes working together for gathering and retransmitting data or information. WSNs have become increasingly popular due to their wide range of applications. They are typically used for remote environment monitoring in areas where supplying electrical power is difficult. The devices are powered by batteries and by alternative energy sources. Localization is used in WSNs to find the current location of the sensor nodes. Installation of GPS on each sensor node is expensive, further, manually configuring location details on each sensor node is not possible in dense WSNs. To make the deployment of WSNs economical, localization techniques are used. With the help of localization techniques, sensor nodes identify their location based on the information provided by an anchor node or beacon node. As the battery energy is limited for the sensor nodes, the different optimization techniques are required for energy optimization and localization. In this proposed work, the firefly optimization technique and the Hybrid Eagle with firefly Optimization technique for energy optimization with RSSI (Received Signal Strength Indication) positioning method is applied to complete the cluster and cluster head selection to optimize energy and power consumption and to increase network life cycle in WSN power consumption. The performance of both algorithms and parameters is executed in the MAT-LAB simulation platform.","['Engineering', 'Microwaves, RF and Optical Engineering', 'Wireless and Mobile Communication', 'Optics, Lasers, Photonics, Optical Devices']"
doi:10.1007/978-981-19-4990-6_40,en,Particle Swarm Optimization-Based Energy-Aware Task Scheduling Algorithm in Heterogeneous Cloud,OriginalPaper,"Task scheduling in a cloud computing environment is one of the important aspects in the field of information technology. An efficient schedule is required to enhance the performance of the whole system which results a good quality of services (QoS). It is an NP-complete problem and attracts many researchers to use various meta-heuristics algorithms to develop task scheduling methods in the cloud environment. In most of the evolutionary methods, search space is large and initialized randomly which is one of the key components. In this paper, using the working mechanism of particle swarm optimization (PSO) algorithm, a set of solutions or schedules is created. Solution with efficient QoS parameters like makespan, cloud utilization, and energy consumption is chosen for allocation of the task into the heterogeneous multi-cloud environment. The algorithm undergoes a simulation process and is tested upon benchmark datasets which shows a better result in comparison to some existing cloud scheduling algorithms like min-min, max–min, cloud min-min scheduling (CMMS), cloud max–min scheduling (CMAXMS), and cloud normalized min-min max–min (CNXM) algorithms, genetic algorithm, etc.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Wireless and Mobile Communication']"
doi:10.1007/978-981-19-3998-3_46,en,An Effective and Scalable Approach for Swarm-on-Swarm Air Combat Decision,OriginalPaper,"We present an approach simultaneously solving both swarm target assignment and optimal motion control for large-scale swarms to achieve autonomous air combat decision making. The swarm target assignment is solved by using a modified k-means clustering algorithm with balance degree, and our motion control adopts a particle swarm optimization framework. Our approach scale well with a large number of drones and is able to find policies in continuous action spaces. Our experiments test our algorithm on clustering and decision-making, respectively. We find that it is much simple to implement, scalable and outperforms other algorithms we compare against.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-3-030-79827-7_38,en,Grid Generation and Algebraic Solvers,OriginalPaper,"This work focuses on some of the most relevant numerical issues in the solution of the drift-diffusion model for semiconductor devices. The drift-diffusion model consists of an elliptic and two parabolic partial differential equations which are nonlinearly coupled. A reliable numerical approximation of this model unavoidably leads to choose a suitable tessellation of the computational domain as well as specific solvers for linear and nonlinear systems of equations. These are the two main issues tackled in this work, after introducing a classical discretization of the drift-diffusion model based on finite elements. Numerical experiments are also provided to investigate the performances both of up-to-date and of advanced numerical procedures.","['Engineering', 'Circuits and Systems', 'Electronic Circuits and Devices', 'Electronics and Microelectronics, Instrumentation']"
doi:10.1007/978-981-19-4960-9_69,en,Analysis of Cuckoo Search Technique for Solving Problems of Optimization,OriginalPaper,"“Cuckoo Search” was developed by Xin-She Yang and S. Deb in 2009. It is nature inspired approach relies on some species brood parasitism. Cuckoo Search in combined with Levy flights is firstly applied on several nonlinear constrained benchmark functions, and its results are outstanding comparing to other existing algorithms. Cuckoo Search parameters are initially maintained fixed for a specific amount of time, which reduces the algorithm’s efficiency. To address this problem, a mechanism for fine-tuning the parameters of Cuckoo Search has been developed. For tackling engineering optimization issues, CS is a very effective and reliable method.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Professional Computing']"
doi:10.1007/978-981-19-2840-6_49,en,A Fast Algorithm for Hunting State-Backed Twitter Trolls,OriginalPaper,"In recent years, state-backed troll accounts have been adopted extensively by many political parties, organizations, and governments to negatively influence political systems, persecute perceived opponents, and exacerbate divisiveness within societies. Thus, the need for an automatic state-backed troll classification system has increased. Various algorithms have been proposed in the literature to handle this problem, but a majority of them consider all types of trolls as one type which decreases the performance of classification algorithms. Our goal in this paper is to design a thorough method for detecting state-backed trolls on Twitter with the ability to work efficiently in any case regardless of the language, the location, and the purpose of the troll account. For accurate classification, a set of novel effective and powerful features from various categories are proposed. To train our algorithm, we gathered a large and relevant dataset from Twitter. The results show that the proposed algorithm achieves high classification accuracy (approximately 99%) and has the ability to classify state-backed troll accounts regardless of the language or the location of the account.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-4960-9_23,en,K-Means and BIRCH: A Comparative Analysis Study,OriginalPaper,"With the rise of the application of machine learning in academia and industrial sector, clustering has become an important field of study. Clustering has been extensively used in studies involving unlabeled data, image processing, and unsupervised learning. The purpose of this article is to discuss various applications of clustering, and take up two clustering algorithms of K means and balanced iterative reducing and clustering through hierarchy clustering (BIRCH), as these algorithms have been applied to a wide array of studies across different domains, and document a comparative study between these two. K -Means is a technique of partitioning-based clustering, whereas BIRCH clustering is a technique of hierarchical method of clustering. The methodology is based on comparing BIRCH and K -Means clustering algorithms, using a total of five datasets. The preprocessing of dataset is described in this article; encoding is performed on different attributes of these datasets and dimensionality reduction using principle component analysis is performed. In this article, validation of clustering performance using the internal validation is done, and here silhouette index is used. The silhouette index takes into account the mean distance between the clusters. The results are tested on 2–100 clusters, and deduction of optimal quantity of clusters is done as well. On every dataset, it is observed that K -Means outperforms BIRCH clustering method. Thus, we come to the conclusion that the K -Means clustering algorithm proves out to be better for clustering for our considered datasets.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Professional Computing']"
doi:10.1007/978-3-031-21062-4_9,en,Simulating a Gas Source Localization Algorithm with Gas Dispersion Produced by Recorded Outdoor Wind,OriginalPaper,"This paper reports the use of the first gas dispersion simulator capable of introducing large wind fluctuations into simulations. The proposed simulator enables testing of a modification made to a gas source localization algorithm in a realistic scenario in order to study how the change affects it. Gas source localization in an outdoor environment is a challenging task mainly due to the complexity of the gas spread caused by the unpredictable nature of constantly changing wind. Therefore, a novel use of outdoor wind in developing a gas source localization system by simulation is presented in this paper. To consider the characteristic of sudden but large and unpredictable changes in wind direction, we propose to use recorded outdoor wind to simulate a realistic outdoor gas dispersion which has been done for the first time to the best of our knowledge. With the use of this simulator, we have tested a modification to a mobile robot-based gas source localization algorithm. Multiple simulations of the modified and the original particle filter-based algorithm have been done to study the effect of the tested modification. The results showed that a small difference in the algorithm can greatly impact the results. From this study, we show that the use of simulation consisting of the necessary traits to evaluate outdoor gas source localization, has the potential to accelerate the development of a reliable localization system.","['Computer Science', 'Robotics', 'Robotics and Automation', 'Computational Intelligence']"
doi:10.1007/978-3-031-04090-0_3,en,Finite Element Model Updating Using a Shuffled Complex Evolution Markov Chain Algorithm,OriginalPaper,"In this paper, a probabilistic-based evolution Markov chain algorithm is used for updating finite element models. The Bayesian approaches are well-known algorithms used for quantifying uncertainties associated with structural systems and several other engineering domains. In this approach, the unknown parameters and their associated uncertainties are obtained by solving the posterior distribution function, which is difficult to attain analytically due to the complexity of the structural system as well as the size of the updating parameters. Alternatively, Markov chain Monte Carlo (MCMC) algorithms are very popular numerical algorithms used to solve the Bayesian updating problem. These algorithms can approximate the posterior distribution function and obtain the unknown parameters vector and its associated uncertainty. The Metropolis-Hastings (M-H) algorithm, which is the most common MCMC algorithms, is used to obtain a sequence of random samples from a posterior probability distribution. Different approaches are proposed to enhance the performance of the Metropolis-Hastings where M-H depends on a single-chain and random-walk step to propose new samples. The evolutionary-based algorithms are extensively used for complex optimization problems where these algorithms can evolve a population of solutions and keep the fittest solution to the last. In this paper, a population-based Markov chain algorithm is used to approximate the posterior distribution function by drawing new samples using a multi-chain procedure for the Bayesian finite element model updating (FEMU) problem. In this algorithm, the M-H method is combined with the Scuffled Complex Evolution (SCE) strategy to propose new samples where a proposed sample is established through a stochastic move, survival for the fittest procedure, and the complex shuffling process. The proposed SCE-MC algorithm is used for FEMU problems where a real structural system is investigated and the obtained results are compared with other MCMC samplers.","['Engineering', 'Mechanical Statics and Structures', 'Building Construction and Design', 'Operations Research/Decision Theory', 'Mathematical and Computational Engineering', 'Civil Engineering']"
doi:10.1007/978-981-19-2764-5_2,en,A Critical Analysis of Control Approach for DSTATCOM,OriginalPaper,"With the emergence of the smart grid, the need for a reliable and pure power supply to the customer arises. The problem of power quality of the power system has to be addressed at the distribution side itself, so that the remaining power grid remains clean. In this work, a critical analysis of the recent control algorithms proposed for extenuation of power quality problems at the distribution side will be analysed. The maximum Versoria criteria and affine projection sign-based control algorithms will be analysed thoroughly. The algorithm is adaptive and can work for reference current generation through estimation of reactive and active power of load current. The results of the algorithms will be compared in MATLAB/SIMULINK for various aspects.","['Energy', 'Energy Systems', 'Artificial Intelligence', 'Machine Learning', 'Cyber-physical systems, IoT', 'Professional Computing', 'Power Electronics, Electrical Machines and Networks']"
doi:10.1007/978-981-19-3250-2_11,en,Distributed Parallel FRW Algorithms for Capacitance Simulation,OriginalPaper,"Due to the advantages on scalability and reliability, the floating random walk (FRW) algorithm has been widely adopted for calculating the capacitances among three-dimensional (3-D) conductors. This is evidenced by the industrial practice of interconnect capacitance extraction during the design of high-performance very large-scale integrated (VLSI) circuits. In this chapter, the FRW algorithm is enhanced through the distributed parallel computing. With an efficient and adaptive task allocation scheme, the communication among different computer nodes is largely reduced. A distributed algorithm for accelerating the space management is also proposed. They have been implemented with message passing interface (MPI) and applied to the high-precision capacitance simulation for touchscreen design, along with the interconnect capacitance extraction of VLSI circuits. In addition, the techniques to enhance the reproducibility of the parallel FRW algorithm are presented, which ensure that same result is reproduced while rerunning the parallel FRW solver with same settings. Experiments on a computer cluster show that the proposed techniques achieve up to 114X speedup while using 120 cores, and build up the space management structure for a VLSI case including two million conductor blocks in just 22 s (37X parallel speedup on 60 cores). And, the proposed task allocation scheme is shown to be able to ensure the reproducibility while achieving better efficiency than other approach ensuring the reproducibility.","['Engineering', 'Electronics and Microelectronics, Instrumentation', 'Engineering Mathematics']"
doi:10.1007/978-3-031-16203-9_32,en,A Noise Resistant Credibilistic Fuzzy Clustering Algorithm on a Unit Hypersphere with Illustrations Using Expression Data,OriginalPaper,"This article presents a robust noise-resistant fuzzy-based algorithm for cancer class detection. High-throughput microarray technologies facilitate the generation of large-scale expression data; this data captures enough information to build classifiers to understand the molecular basis of a disease. The proposed approach built on the Credibilistic Fuzzy C-Means (CFCM) algorithm partitions data restricted to a p-dimensional unit hypersphere. CFCM was introduced to address the noise sensitiveness of fuzzy-based procedures, but it is unstable and fails to capture local non-linear interactions. The introduced approach addresses these shortcomings. The experimental findings in this article focus on cancer expression datasets. The performance of the proposed approach is assessed with both internal and external measures. The fuzzy-based learning algorithms Fuzzy C-Means (FCM) and Hyperspherical Fuzzy C-Means (HFCM) are used for comparative analysis. The experimental findings indicate that the proposed approach can be used as a plausible tool for clustering cancer expression data.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-09835-2_3,en,"Swarm Intelligence for Deep Learning: Concepts, Challenges and Recent Trends",OriginalPaper,"Machine learning and deep learning have undoubtedly contributed to tremendous achievements in Artificial Intelligence (AI) in recent years, and more are likely to follow. They have demonstrated extraordinary superiority in various real-world applications like computer vision, medical diagnostic systems, agriculture, robotics, and many more. It enables automating the computer-aided system and drastically reducing the human workload where correct prediction with accurate precision is needed. On the other side, as technology advances, a vast amount of data is generated, raising the problem complexity and computational challenges of real-world applications. Furthermore, machine learning, deep learning, and the majority of real-world applications have complex optimization problems within themselves that must be adequately addressed for better and more accurate analysis. Nonetheless, we believe that swarm intelligence-based approaches to deep learning have traditionally been understudied and may ultimately deliver similar advances in AI capabilities - either building on those provided by deep learning or offering whole new ones. Swarm intelligence approaches are frequently employed to solve a wide range of optimization issues. Nowadays, swarm intelligence-based methods are attracting a lot of attention from the research communities of different domains because previous research in complex optimization has shown that behavioral patterns and phenomena observed in nature have the ability to facilitate the foundation for many optimization algorithms and solve problems efficiently. Swarm intelligence, machine learning, and deep learning, on the other hand, each has its own set of advantages and disadvantages. Recently, research communities have discovered an interest in integrating these concepts in order to overcome the limitations of each domain and give rise to a new paradigm known as evolutionary machine learning or evolutionary deep learning. In the case of machine learning and deep learning, the “curse of dimensionality,” non-convex optimization, automatic parameter optimization, and optimal architecture are just a few of the issues that can be efficiently addressed with swarm intelligence, whereas in the case of swarm intelligence, slow convergence, local optima stagnation, and extensive computation cost can be addressed with the machine learning and deep learning community. Therefore, a robust and self-efficient model can be developed by integrating these concepts to solve the complex problem associated with real-world applications. This hybrid approach benefits the majority of research domains. Thus, this chapter will primarily present the ideas, challenges, and recent trends of an integrative approach of swarm intelligence with deep learning, which is currently in high demand for addressing industrial problems.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4250-1_4,en,Electro Hydraulic Hybrid Power Steering System,OriginalPaper,"Large commercial vehicles often need to travel for a long time and a long distance, so the steering system of commercial vehicles must have characteristics of low energy consumption and good steering feeling. However, the existing electronically controlled hydraulic power steering (ECHPS) system and electro-hydraulic power steering (EHPS) system and electric power steering (EPS) system are difficult to meet design requirements of steering system of large electric commercial vehicles in the future. The electro hydraulic hybrid power steer-by-wire system developed on the basis of the above steering system adopts dual actuator design.","['Engineering', 'Mechanical Engineering', 'Control and Systems Theory']"
doi:10.1007/978-981-19-7842-5_14,en,Truss Structure Optimization Design Based on FE-PSO-SQP Algorithm,OriginalPaper,"Compared with other structural optimization design algorithms, particle swarm optimization (PSO) gains many superiorities, like being easy to understand the principle and fewer parameters in the calculation model. When we use the PSO to deal with truss structure optimization problems, this algorithm usually has low computational accuracy, slow rates of convergence, and poor population varieties in the further model calculation. To overcome these shortcomings and better solve the truss structure optimization problem, FE-PSO-SQP algorithm, a new structure optimization method, is proposed herein by combining the PSO algorithm with the sequential quadratic programming (SQP) algorithm and finite element method (FE). In addition, a set of calculation program is developed by ANSYS software. When the self-made program is used to conduct simulation calculation on the truss structure optimization problem, the calculation results show that FE-PSO-SQP algorithm has faster convergence speed and higher calculation accuracy than FE-PSO algorithm, and can be used for structure optimization design.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-14537-7_6,en,Shape Recognition for Industrial Robot Manipulation with the Bees Algorithm,OriginalPaper,"Fitting primitive shapes to point cloud Point Cloud scenes is a challenging but necessary step for many robotic Robotic manipulation operations. State-of-the-art primitive fitting Primitive Fitting methods rely on geometric shape Geometric Shapes estimation or iterative procedures. They are often computationally complex and sensitive to algorithm parameterisation. This study tackles primitive fitting Primitive Fitting as a parameter Parameters optimisation problem, solving it using the Bees Algorithm Bees Algorithm, THE . The performance of the Bees Algorithm Bees Algorithm is evaluated on three sets of artificial scenes of varying degrees of blurriness and benchmarked against an evolutionary algorithm Evolutionary Algorithm . Experimental results proved the precision and consistency of the Bees Algorithm. Primitive fitting times were compatible with real-time Real-Time application.","['Engineering', 'Robotics and Automation', 'Artificial Intelligence', 'Industrial and Production Engineering', 'Professional Computing', 'Robotics', 'Machine Learning']"
doi:10.1007/978-3-031-15211-5_57,en,Analysis of the Multi-Objective Optimisation Techniques in Solving a Complex Vehicle Routing Problem,OriginalPaper,"The Vehicle Routing Problem (VRP) is a common logistics problem. The problem was first published in 1959 as the Truck Dispatching Problem. In the basic problem, vehicles deliver the products from a given depot and then return to the depot. The objective function is to minimise the distance travelled by the vehicles. Since the first published paper, a number of variants have been developed that adapt to real logistics demands. This article investigates the optimisation of a complex Vehicle Routing Problem. The following multi-objective optimisation techniques are investigated in the article: weighted-sum method, weighted-exponential sum method, weighted global criterion method, exponentially weighted criterion, weighted product method, bounded objective function method, pareto ranking, Non-dominated Sorting Genetic Algorithm II, Strength Pareto Evolutionary Algorithm, Niched Pareto Genetic Algorithm. The article provides a detailed analysis with the following heuristic algorithms: Ant Colony System, Genetic Algorithm, Tabu Search, Firefly Algorithm, Simulated Annealing.","['Engineering', 'Automotive Engineering']"
doi:10.1007/978-981-19-6780-1_22,en,Adaptive Memetic Algorithm on Novel CBLSP Algorithm for O-Tree Implementation,OriginalPaper,"In the floorplan representation of VLSI Design, B*-Tree and O-tree representations are recommended due to their vast advantages over other models. Out of this, B*-Tree representation is widely used due to its simplicity in implementation. But we may lack the significant benefits and flexibility that O-Tree representation offers in its execution. In this paper, a new method of O-tree implementation (Code-Based Location Search and position) is presented, which is relatively easy and flexible in use without any lag in performance. Also, this algorithm is implemented in the newly improved memetic algorithm. Experimental results are checked on standard MCNC benchmark circuits and compared with previous research. It has been found that the proposed algorithm is efficient in obtaining optimized floorplan area in lesser time. Performance metrics have improved to a great extent using this algorithm. Conclusion with results and discussions is drawn at the end.","['Engineering', 'Circuits and Systems', 'Energy Systems', 'Computer-Aided Engineering (CAD, CAE) and Design']"
doi:10.1007/978-3-031-19039-1_6,en,What Is on the Horizon?,OriginalPaper,"This chapter concludes the book by covering a set of issues that we believe will prove to be important for any industry or organization that is actively seeking to incorporate AI systems into their pipelines. We begin with the seemingly outlandish issue of AI copyright that has rapidly become important due to state-of-the-art AI’s success in generating “creative” art and writing. The central question is whether an AI should be allowed to own its own copyright. Related to the question of copyright is one of regulation. Currently, there is a vigorous debate on both regulation of algorithms, as well as regulation by algorithms, since the latter may yield more objective outcomes. Critics point, however, to the dehumanizing effects of such regulation, and to the fact that such algorithms may not be objective to begin with, since they have been trained on (potentially biased) human-generated data. We also cover the important and mainstream issue of legal regulation of Deepfakes and AI’s “explainability crisis” and conclude the chapter and the book with a note on the rapid convergence of AI with other emerging technologies, such as quantum computing.","['Business and Management', 'IT in Business', 'Industries', 'Artificial Intelligence', 'Business Strategy/Leadership']"
doi:10.1007/978-981-19-3679-1_63,en,Applying Machine Learning Algorithms on Urban Heat Island (UHI) Dataset,OriginalPaper,"Climate change worldwide is a huge challenge, and urban heat island (UHI) is being explored as one of the contributors to this challenge. UHI is an urban or rural area with a temperature variance than its neighbouring areas. Researchers can model the UHI data and predict the temperature change using various relative parameters of UHI. The land surface temperature (LST) data and its co-related parameter of the study area, i.e. Srinagar City, JK, India, has been extracted from satellite imageries. LST data of the study area is assessed to understand the evolution to help analyse the UHI effect and its variance. The LST data was extracted through MODIS Satellite, from 2001 to 2020, with an 8-day revisit time/peak month of the season. In having a voluminous dataset, i.e. 16 sampled LST data/each km 2 /year measured in Kelvin(k), various machine learning algorithms were applied on LST data to establish relations for UHI modelling. Unsupervised machine learning algorithms were used on continuous LST data to define clusters and further standardized/compared with existing scientific classifications of the study area. The number of clusters was tweaked to determine the best-case scenario. Additionally, correlation and regression were applied to determine if there is multicollinearity amongst the LST data. The outcome of two analyses was used to build a UHI framework on a structured UHI dataset. Performance of algorithms in predicting UHI parameters like urban, vegetation and wetlands zones varied considerably. Naive Bayes and support vector machine did considerably well in predicting wetlands but failed to perform impressive accuracy for urban and vegetation zones. Random forest, gradient boost tree and probabilistic neural networks failed in predicting wetlands. Neural networks have performed worst in predicting wetlands, having a prediction accuracy of around meagre 5%, while the decision tree algorithm has performed well in all three zones.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5184-8_3,en,"Personalizing the Patient Discharge Process and Follow-Up Using Machine Learning Algorithms, Assessment Questionnaires and Ontology Reasoning",OriginalPaper,"This chapter proposes an approach for personalizing the patient discharge and follow-up processes that combines machine learning algorithms with ontology-based reasoning. Machine learning algorithms are used for identifying the patients with high risk of readmission after their discharge, while ontology-based reasoning is used for generating personalized healthcare recommendations for patients in order to reduce the readmission risk. For predicting the patient’s readmission risk, different machine learning algorithms (i.e., logistic regression, decision tree, random forest, and gradient boosting tree) have been tested and comparatively analyzed. The tests have been performed on a data set containing information about the hospital admissions of patients with heart failure and as evaluation metrics precision, recall, and F1 have been used.","['Engineering', 'Computational Intelligence', 'Statistics, general', 'Artificial Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-3015-7_38,en,A Systematic Study About EEG Signal Data and Computer Aided Models for the Diagnosis of Alzheimer's Disease,OriginalPaper,"Dementia is brain disorder that can show impact on patient memory loss and impaired mental ability, such as speaking and thinking. Based on the several reasons, the dementia is occurred that considers Alzheimer’s disease, vascular dementia, Dementia with Lewy bodies, etc. Early medication may help dementia patients to overcome the memory loss and thinking skills. Various techniques are also used to manage this disease with behavioral issues. Sometimes, the medications also cannot change the brain that can cause dementia. 65% to 85% dementia patients have chances to convert Alzheimer’s disease. Electroencephalography (EEG) is the test that can calculates the electric activities that occur in brain. This test may help experts to estimate the status of the disease. EEG is also helps to diagnose the brain disorders such as dysfunction of brain (encephalopathy), dysfunction stroke, and sleep disorders. In this paper, the performance of various algorithms is analyzed by applying benchmark datasets and also real-time datasets for diagnosing and detection of Alzheimer's disease using EEG signals are reviewed. This helps researchers to select appropriate techniques according to their need.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Engineering', 'Data Mining and Knowledge Discovery', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-3-031-20241-4_8,en,Towards the Development of a Budget Categorisation Machine Learning Tool: A Review,OriginalPaper,"Engineering, procurement, and construction (EPC) contracts include time, budget, quality, and safety, among other issues. In budgeting, construction companies must assess each task's scope and map the client's expectations (expressed in the bill of quantities) to an internal database of tasks, resources, and costs. The results from this classification will determine the quality of the tenders issued by the company and are thus contractually binding. Construction companies must achieve their contractual targets in order to make a profit. In this paper, we review the literature and explore the latest advancements regarding the automatisation of these processes to find the methods that yield the best results in the classification of bills of quantities and works in the construction industry. Although full automation is not within our reach in the short term, especially due to the lack of standard construction specifications, machine learning can provide useful support tools. This communication is part of the authors’ study aiming to develop a framework and tool to automate the process of task classification in a construction contract.","['Engineering', 'Building Construction and Design', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence', 'Statistics, general']"
doi:10.1007/978-981-19-0095-2_47,en,Interpretation of Handwritten Documents Using ML Algorithms,OriginalPaper,"Handwritten character recognition is a continuing field of research which covers artificial intelligence, computer vision, neural networks, and pattern recognition. An algorithm that executes handwriting recognition can acquire and detect characteristics from given handwritten document/image as input and convert them to a machine-readable form. It is also known as the task to convert the input text to extracting the features with the help of symbol representation and icons of each letter. The main goal of this handwritten text recognition is to identify an input character and text on a scanned image which are written in cursive writing, and these features are extracted with each input character pixels. Each character dataset contains 26 alphabets. IAM datasets are used for training the characters and for classification and recognition. The output is generated in the form of human-readable text. In this paper,  the handwritten documents has been interpreted  using machine learning algorithms such as connectionist temporal classification (CTC), long short-term memory networks (LSTMs), and generative adversarial networks (GANs). The results show the comparison of feature extraction based on proposed approach with convolutional neural networks (CNN) and recurrent neural network (RNN) with real-time datasets gain in better performance when using these algorithms.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Systems and Data Security', 'Artificial Intelligence', 'Computational Intelligence']"
doi:10.1007/978-981-19-3590-9_13,en,Comparative Analysis of Diabetes Prediction Using Machine Learning,OriginalPaper,"Nowadays, one of the most common chronic diseases is diabetes mellitus, and sometimes, it may lead to death. If we predict diabetes in an early stage, then it will be helpful to take preventive measures, and it can helpful to prevent progression of the disease. In today's lifestyle, food containing large number of sugars, carbohydrates and fats which increases the high risk of diabetes. The computer-based detection helps the doctors to diagnose the disease in early stage. There are many machine learning algorithms were used for the prediction and classification of diabetes. In this paper, performance of different machine learning algorithms like support vector machine, artificial neural network, deep neural network, convolutional neural network has been compared against the parameters sensitivity, specificity and accuracy. The results were compared and tabulated to show which algorithm produces more efficient and accurate results.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security', 'Mobile and Network Security']"
doi:10.1007/978-981-19-3632-6_20,en,Online Education APP Information Supervision Based on Machine Learning Algorithms,OriginalPaper,"The mobile Internet era has brought a new way of online learning on the mobile terminal, and various online education applications are emerging one after another. The benefits of online education are obvious, such as learning anytime and anywhere, massive network resources, rich and excellent teaching resources, etc., but today’s online education apps still have uneven quality, scarce research literature, and narrow educational sections. Students’ learning willpower is weak and other issues. Therefore, it is necessary to study online education APP information supervision based on machine learning algorithms. This article first discusses the concept of online education APP and expounds the application of machine learning algorithms, and then designs and develops a system for online education APP information supervision, and tests the performance of the system. The final test result shows that the system response time is basically maintained at about 23/ms, indicating that the system response speed is relatively fast; the system delay time is basically maintained at about 12/ms, it can be said that the delay time is very low, and it also shows that the system response speed is fast. At the same time, the running time of the system is about 45/m, which can save the memory occupied by the system itself, and supervise the user learning situation of online education while saving loss.","['Engineering', 'Cyber-physical systems, IoT', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing']"
doi:10.1007/978-981-19-7130-3_7,en,Machine Learning-Enabled Biosensors in Clinical Decision Making,OriginalPaper,"Healthcare digitization offers a variety of chances for minimizing human error rates, enhancing clinical results, monitoring data over time, etc. Machine learning and deep learning AI techniques play a key role in enhancing new healthcare systems, patient information and records, and the treatment of various ailments, among other health-related topics. The utilization of conventional sensor systems to decipher the environment is changing as another time for “smart” sensor frameworks arises. To create refined “brilliant” models that are custom fitted explicitly for detecting applications and melding different detecting modalities to acquire a more comprehensive understanding of the framework being observed, savvy sensor frameworks enjoy taken benefit of conventional and state-of-the-art machine learning calculations as well as contemporary PC equipment. Here is a chapter of current developments in biosensors used in healthcare that are reinforced by machine learning. First, several biosensor types are classified and a summary of the physiological data they have collected is provided. The introduction of machine learning techniques used in subsequent data processing is followed by a discussion of their usefulness in biosensors. And last, the possibilities for machine learning-enhanced biosensors in real-time monitoring, outside-the-clinic diagnostics, and on-site food safety detection are suggested. These problems include data privacy and adaptive learning capabilities.","['Chemistry', 'Biotechnology', 'Materials Science, general', 'Biomedical Engineering and Bioengineering', 'Nanotechnology', 'Health Care Management']"
doi:10.1007/978-981-19-3035-5_13,en,Evaluation of Machine Learning Approaches for Prediction of Dengue Fever,OriginalPaper,"Dengue is a mosquito-borne, deadly viral disease that is a major threat to public health all over the world. Dengue and covid-19 symptoms are almost same, and sometimes, people are confused about which disease they are infected with. This year in Bangladesh dengue and covid-19 patients have been increasing at an alarming rate, and most of the time people didn’t properly recognize the disease. A developing country like Bangladesh has faced many difficulties to handle this situation. The target of this research work is to analyze the symptoms and predict the chances to get infected with dengue fever. Machine learning techniques are widely utilized in the health industry to detect fraud in treatment at lower cost, predictive analysis, cure the disease. Four machine learning algorithms are used which are support vector machine, decision tree, K -nearest neighbor, random forest to predict dengue fever based on symptoms. The results were compared for percentage split and K -fold cross-validation method for before and after applying principal component analysis. The experimental result shows that the support vector machine algorithm provides the highest performance compared to others algorithms.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Statistics, general']"
doi:10.1007/978-3-031-11170-9_1,en,Artificial Intelligence for the Future of Medicine,OriginalPaper,"Since its origins, medicine has been more linked to the cure of diseases than to their prevention. This is due to multiple factors, training of health professionals aimed at curing diseases, lack of quality data, processing capacity, poor multidisciplinary approach, etc. However, this paradigm is changing, focusing on maintaining the health of individuals to avoid diseases, improving social welfare. To achieve this, the new approach proposes that medicine must be Preventive, Participatory, Predictive, and Personalized (P4 Medicine). In this chapter, we will analyze how artificial intelligence can convincingly contribute to the construction of P4 Medicine, through the processing of key data such as DNA, electronic medical records and environmental variables to which people have been exposed. Here we can find complex data such as Computed Tomography images, electroencephalograms, free text in electronic medical records, pharmacological data, etc. These data have grown exponentially and efforts to improve their quality are already paying off. However, it is no longer possible for a health professional to analyze them to provide a better diagnosis or carry out preventive work on diseases, requiring the formation of multidisciplinary teams to find new solutions to ancient problems, such as healthcare, where data processing, knowledge extraction and its subsequent parameterization in support systems for medical decision-making are vital to save lives. In this sense, artificial intelligence, together with new methods for processing complex data and computational resources to process massive data, will be key to improving the humanity health.","['Computer Science', 'Health Informatics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2840-6_26,en,Sensor Data Fusion Methods for Driverless Vehicle System: A Review,OriginalPaper,"According to the research studies in recent years, it is predicted that level 5 autonomous vehicles will take the place of conventional vehicles. These driverless vehicles can make decisions according to the environmental data and accomplish the driving task accordingly. In order to accomplish this, autonomous vehicles use different types of sensors in order to detect and perceive their local environment. But sensors can still malfunction due to environmental conditions, manufacturing defects or noise; so the information obtained from one sensor would not be reliable for the tasks associated with driverless vehicles. A feasible solution for this issue is to collaborate multiple sensors and fuse their data to accomplish more accurate driving tasks in Autonomous Driving systems. The various methods used to improve the navigation system of driverless vehicles are being reviewed in this survey.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-08954-1_107,en,Gender Prediction Based on Arabic Names with Machine Learning Techniques,OriginalPaper,"The classification based on gender is a popular topic for many machine learning fields, much work has been done on gender classification throughout the years. The same goes when it comes to gender classification based on names, there are many papers for English and Chinese names; still, there has been almost no work done for Arabic so far. Moreover, this paper examines the outcomes of applying six machine learning algorithms (Support Vector Machine, Multinomial Naive Bayes, Bernoulli Naive Bayes, Decision Tree, Random Forrest, and Logistic Regression) and deep learning model (LSTM) for gender prediction on Arabic name. In addition, a dataset is created to investigate the results of these algorithms on Arabic names.","['Engineering', 'Mathematical and Computational Engineering', 'Business Mathematics', 'Data Engineering']"
doi:10.1007/978-981-19-3679-1_23,en,Type 2 Diabetes Prediction Using Machine Learning and Validation Using Weka Tool,OriginalPaper,"The purpose of this research is to figure out who is at risk for diabetes based on their lifestyle and family history. Accurate and timely predictions would be beneficial to people seeking ways to include a healthy lifestyle and therapy into their plans. To forecast the risk of type 2 diabetes, various machine learning algorithms are applied. These algorithms have undergone extensive testing to ensure the greatest levels of accuracy, which is now a must in the medical profession. After that, the WEKA tool is used to verify the algorithms that have been developed. Weka is a data mining toolkit that includes several machine learning algorithms. Data pre-processing, classification, regression, clustering, association rules and visualization are all available through Weka. Of all the approaches investigated in this study, we determined that logistic regression had the greatest accuracy. Individuals can self-evaluate their diabetes risk once the model has been trained to a high level of accuracy.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-3-031-19067-4_9,en,Beyond Distributed Training in the Cloud,OriginalPaper,"Let us summarize the concepts that we learned through this book, and discuss the future of distributed machine learning beyond cloud-based implementations that we studied in this book.","['Mathematics', 'Algorithms', 'Machine Learning', 'Algorithm Analysis and Problem Complexity', 'Artificial Intelligence', 'Probability Theory and Stochastic Processes', 'Computer Science, general']"
doi:10.1007/978-3-031-18344-7_38,en,SimLDA: A Tool for Topic Model Evaluation,OriginalPaper,"Topic model evaluation is a well studied field. Two classes of metrics are typically used to evaluate the quality of extracted topics, namely held-out perplexity and coherence measures. Although these metrics have been improved and refined, they still have drawbacks. In this paper we propose using simulated data generated from our flexible corpus generation tool, SimLDA, combined with an exact measure of dissimilarity, the average Kulback-Leibler divergence (KLD), to achieve a more fine-grained method for detecting differences in topic quality. In this work, we use our proposed approach to evaluate and compare topics extracted from synthetic data using two inference algorithms for latent Dirichlet allocation (LDA), namely, variational Bayes (VB) and collapsed Gibbs sampling. We then evaluate the extracted topics using a coherence measure (the $$C_{\text {v}}$$ C v score). Using the same two inference algorithms we then extract topics from the popular 20 Newsgroups data set and evaluate the extracted topics based on the $$C_{\text {v}}$$ C v score. Through these three steps, we show that although collapsed Gibbs sampling consistently outperforms VB, the use of simulated data (evaluated using both coherence measures and KLD) provides more insight into the quality of the extracted topics and allows us to examine performance differences of the inference algorithms.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3015-7_23,en,A Decision Support System for Understanding the Importance of Two-Dosage Vaccination,OriginalPaper,"Nowadays, vaccination plays the major role in controlling the death rates in COVID-19. However, certain people don’t have a trust on vaccines like Covaxin and Covishield. In order to make the decision on these vaccines like Covaxin and Covishield, decision support system (DSS) is necessary using machine learning approach. Many researchers find the supervised learning model gives best prediction among many machine learning models for COVID-19 situation. Supervised learning model has regression and classification models. Here, supervised machine learning models like logistic regression, decision tree and random forest are used to create a decision support system (DSS). With the use of this machine learning models, people can understand the uses of COVID-19 vaccines.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Engineering', 'Data Mining and Knowledge Discovery', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-981-19-2821-5_38,en,Supervised Automatic Text Summarization of Konkani Texts Using Linear Regression-Based Feature Weighing and Language-Independent Features,OriginalPaper,"Automatic summarization of text documents is a widely researched domain in natural language processing. A lot of research is carried out on the most commonly spoken languages in the world. Automatic text summarization needs to be explored to include some of the less popular languages in the world to help sustain such languages and promote their use. A language-independent summarization system that can be effortlessly extended to other such languages, which could have a limited number of resources to carry out such research is required. In this paper, we examine the efficiency of supervised linear regression models for the performing single document extractive automatic text summarization on Konkani language folktales dataset. We use 13 language-independent features and linear regression models to learn feature weights. These weights are then used to calculate a sentence’s score; top ranking sentences are then chosen for summary generation. We employ a k-fold evaluation strategy to evaluate the system-generated summary against a human-generated summary using ROUGE evaluation toolkit. Additionally, we also evaluate the use of L1 and L2 regularization on the summarization task. The work represents early attempts in automatic text summarization pertaining to Konkani language, and the dataset employed in these experiments is unique and devised particularly to facilitate research in this domain. The language-independent features used can be readily extended to other low-resource languages. The systems implemented in this work performed better as compared to an unsupervised system based on k-means approach and also beat the baseline systems.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5403-0_14,en,Classification of Swarm Collective Motion Using Machine Learning,OriginalPaper,"One of the subfields of artificial intelligence (AI) technology is machine learning. The basic goal is to develop robots that can learn in the same way that humans can. “Learning” here refers to seeing, comprehending, and denoting facts regarding a statistical phenomenon. Synonyms for “learning” include “observe,” “represent information,” and “understand some statistical phenomena.” Swarms of bio-inspired robots cover a wide range of dynamics and collective behaviors. The categorization of swarm behavior from given certain agent measurements of a swarm at a specific time instance is a significant challenge. In reality, only a few agents’ data are available, resulting in minimal agent samples for classification. We solve these issues in this study by applying machine learning to represent a swarm’s collective movements. We apply various machine learning algorithms to classify the swarm behavior in terms of flocking, aligned and grouped, or non-flocking, non-aligned, and non-grouped.","['Engineering', 'Computational Intelligence', 'User Interfaces and Human Computer Interaction', 'Data Structures and Information Theory', 'Artificial Intelligence', 'Data Mining and Knowledge Discovery']"
doi:10.1007/978-3-031-16078-3_42,en,Intrusion Detection Systems Using Support Vector Machines on the KDDCUP’99 and NSL-KDD Datasets: A Comprehensive Survey,OriginalPaper,"With the growing rates of cyber-attacks and cyber espionage, the need for better and more powerful intrusion detection systems (IDS) is even more warranted nowadays. The basic task of an IDS is to act as the first line of defense, in detecting attacks on the internet. As intrusion tactics from intruders become more sophisticated and difficult to detect, researchers have started to apply novel Machine Learning (ML) techniques to effectively detect intruders and hence preserve internet users’ information and overall trust in the entire internet network security. Over the last decade, there has been an explosion of research on intrusion detection techniques based on ML and Deep Learning (DL) architectures on various cyber security-based datasets such as the DARPA, KDDCUP’99, NSL-KDD, CAIDA, CTU-13, UNSW-NB15. In this research, we review contemporary literature and provide a comprehensive survey of different types of intrusion detection technique that applies Support Vector Machines (SVMs) algorithms as a classifier. We focus only on studies that have been evaluated on the two most widely used datasets in cybersecurity namely: the KDDCUP’99 and the NSL-KDD datasets. We provide a summary of each method, identifying the role of the SVMs classifier, and all other algorithms involved in the studies. Furthermore, we present a critical review of each method, in tabular form, highlighting the performances measures, strengths, and limitations, of each of the methods surveyed.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-3-031-21062-4_23,en,Intelligent Wheelchairs Rolling in Pairs Using Reinforcement Learning,OriginalPaper,"Intelligent wheelchairs aim to improve mobility limitations by providing ingenious mechanisms to control and move the chair. This paper aims to enhance the autonomy level of intelligent wheelchair navigation by applying reinforcement learning algorithms to move the chair to the desired location. Also, as a second objective, add one more chair and move both chairs in pairs to promote group social activities. The experimental setup is based on a simulated environment using gazebo and ROS where a leader chair moves towards a goal, and the follower chair should navigate near the leader chair. The collected metrics (time to complete the task and the trajectories of the chairs) demonstrated that Deep Q-Network (DQN) achieved better results than the Q-Learning algorithm by being the unique algorithm to accomplish the pair navigation behaviour between two chairs.","['Computer Science', 'Robotics', 'Robotics and Automation', 'Computational Intelligence']"
doi:10.1007/978-3-031-12807-3_6,en,Explainable AI and Its Applications in Healthcare,OriginalPaper,"Due to the lack of high-end graphics or tensor processing units, previously, deep neural networks could not be implemented as state-of-the-art Artificial Intelligence (AI) algorithms. Rather, linear models were preferred, and they were easy to understand and interpret. Things started changing with the advent of more advanced processing units, in the last decade, when the algorithms took on real-world problems. The models began getting bigger and better.","['Engineering', 'Computational Intelligence', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4052-1_39,en,An Overview of Efficient Regression Testing Prioritization Techniques Based on Genetic Algorithm,OriginalPaper,"Testing is crucial in delivering a bug-free application to the client. Retesting the application whether there is a modification in different functionalities of the application when there is a code change is called regression testing. It is discovered to be expensive as it should be introduced after every code change. Among the numerous strategies existing for regression testing, reordering the test cases through prioritization and just the low prioritized test cases are ignored without executing which saves cost and time. The fault detection rate is found to be more for search-based techniques that apply genetic algorithms. Multi-objective search-based prioritization was proved for its better performance when compared to the single objective genetic algorithms. Hence, this paper reviews and analyzes the multi-objective search algorithms, and it is subjected to improvements. The review proves that genetic algorithms when integrated along with an efficient approach yield a better result compared to other prioritization algorithms.","['Engineering', 'Computational Intelligence', 'Information Storage and Retrieval', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Data Structures and Information Theory', 'Artificial Intelligence']"
doi:10.1007/978-981-19-7083-2_2,en,Communication Efficient Federated Learning,OriginalPaper,"Federated learning, as a branch of distributed learning, suffers from the high cost and concurrency of communication. The situation gets even worse in training deep models on large-scale mobile devices. Hence, communication efficiency is an avoidable topic in multi-party federated learning systems. Focusing on this issue, this chapter first discusses the background, the main methodologies and potential directions for communication efficient federated learning. Then, we introduce two methods for reducing the communication cost of federated learning, which are layer-wise asynchronous update and model quantization. Extensive experiments are performed to show the efficiency of these two approaches.","['Computer Science', 'Machine Learning', 'Privacy', 'Cryptology']"
doi:10.1007/978-3-031-18461-1_11,en,"A Survey of Reinforcement Learning Toolkits for Gaming: Applications, Challenges and Trends",OriginalPaper,"The gaming industry has become one of the most exciting and creative industries. The annual revenue has crossed $200 billion in recent years and has created a lot of jobs globally. Many games are using Artificial Intelligence (AI) and techniques like Machine Learning (ML), Reinforcement Learning (RL) gained popularity among researchers and game development community to enable smart games involving AI-based agents at a faster rate. Although, many toolkits are available for use, a framework to evaluate, compare and advise on these toolkits is still missing. In this paper, we present a comprehensive overview of ML/RL toolkits for games with an emphasis on their applications, challenges, and trends. We propose a qualitative evaluation methodology, discuss the obtained analysis results, and conclude with future work and perspectives.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-6347-6_10,en,Meta-Heuristic LQI Bio-regulator Benchmark for a Permanent Magnet DC Motor on ARM Platform,OriginalPaper,"There are controllers such as the Linear Quadratic Controller plus Integral part (LQI) that have presented favorable results in critical and complex processes, however, one of the disadvantages of this controller is the parameterization of the Q and R matrices, since they are obtained based on the cost of the controller and a trial and error method. Therefore, the present study aims to optimize these parameters through meta-heuristic algorithms such as: Genetic Algorithms (GA), Bacterial Foraging Optimization (BFO) and Ant Colony Optimization (ACO). In the MATLAB/SIMULINK software, the control loop programming is performed, using the control blocks of the Waijung library and with the STM32F407 card with Advanced Risk Machine (ARM) processor, the capture, reading and processing of data from the plant containing the DC motor for control is obtained. To validate the efficiency of the controller, the Integral of the Absolute Value of the Time Weighted Error (ITAE) is used and together with the Wilcoxon statistical method, it compares the optimization methods or techniques performed in the LQI controller. Interesting and favorable results were obtained for the stability and viability of each bio-controller at the moment of applying them in the speed control of the DC motor.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Health Informatics', 'Statistics, general']"
doi:10.1007/978-3-031-18409-3_8,en,About the Fujisaki-Okamoto Transformation in the Code-Based Algorithms of the NIST Post-quantum Call,OriginalPaper,"Post-quantum encryption schemes use variants of the Fujisaki-Okamoto transformation in order to construct a highly secure key encapsulation mechanism from a weakly secure public key encryption scheme. In the third round of the NIST post-quantum cryptography standardization call, all the candidates for the key encapsulation mechanism category use some of these transformations. This work studies how the mentioned transformations are applied in the code-based candidates of the NIST third round. These are Classic McEliece (finalist), BIKE (alternative) and HQC (alternative). Studying the differences between the transformations gives a better understanding of these candidates.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Education, general']"
doi:10.1007/978-981-19-6379-7_6,en,Optimized Nature-Inspired Computing Algorithms for Lung Disorder Detection,OriginalPaper,"Using computational methods inspired by nature, new models for analyzing natural phenomena and behavior can be developed in order to address complex issues. Swarm intelligence and evolutionary computation are just two of the many cutting-edge research areas that fall under this authority. Medical image segmentation has been a major research topic and a major goal in computer vision for a long time. Emerging academic research in biomedical engineering is aided by nature-inspired intelligent methods in solving biomedical engineering problems. To keep up with the most recent developments in biomedical technology, this research includes extensive coverage of relevant topics like machine learning, clinical decision support systems, and swarm intelligence. Medical imaging relies heavily on lung tumor research nowadays because of the impact of COVID-19 and the wealth of morphological and physiological information it provides, which makes diagnosis and treatment planning much simpler. There are numerous detection and segmentation methods in use today, but they all fall short in terms of accuracy. The lung segmentation categorization is based on the usage of a learning algorithm in the selected technique, which is called a filter, a wrapper, or an embedded feature selection method. This research presents the analysis of different natural-inspired computational models in performing segmentation of lung images for the detection of COVID-19 and other health issues. The best performance exhibiting classifier is suggested in the detection process for accurate diagnosis.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Health Informatics', 'Cancer Research', 'Genetics and Genomics', 'Bioinformatics']"
doi:10.1007/978-3-031-08954-1_2,en,An Adaptive Oversampling Method for Imbalanced Datasets Based on Mean-Shift and SMOTE,OriginalPaper,"Class imbalance is a challenge in different actual datasets, where the majority class contains a large number of data points, and the minority class contains a small number of data points. Class imbalance affects the learning process negatively, resulting in classification algorithms’ ignorance of the minority class. To address this issue, various researchers developed different algorithms to tackle the problem; however, the majority of these algorithms are complex and generate noise. This paper provides a simple and effective oversampling technique based on the mean-shift clustering algorithm and using the synthetic minority oversampling technique (SMOTE) of selected clusters. We conducted several experiments to compare the performance of our technique with different algorithms mentioned in the literature on three common datasets. Experimental results indicate that our technique performs better in synthesizing new samples and improves support vector machine (SVM) classification performance on imbalanced datasets.","['Engineering', 'Mathematical and Computational Engineering', 'Business Mathematics', 'Data Engineering']"
doi:10.1007/978-3-031-18256-3_2,en,Breast Cancer Detection Algorithm Using Ensemble Learning,OriginalPaper,"There are certain parameters in the human body that may be indicators of the presence of breast cancer, these can be assessed with different algorithms such as the Support-Vector Machine (SVM), the Naïve Bayes Algorithm (BA) and Artificial Neural Networks (ANN) to determine whether the laboratory tests are positive or not. Machine Learning (ML) has gained more uses across fields as it proposes a cost-effective classifier with versatility to be developed for any type of application, such as early breast cancer detection. This paper shows an ensemble of the algorithms previously mentioned that, based on a database consisting of 8 characteristics, can provide a high accuracy result. The highest F1 Score obtained was 78.261% from the BA, followed by the ANN’s score of 77.273% and a 72.34% from the SVM, resulting in a compositive F1 Score of 80.851%. All the data used on this article was trained using supervised machine learning techniques and variables of interest for breast cancer proliferation.","['Engineering', 'Biomedical Engineering and Bioengineering', 'Regenerative Medicine/Tissue Engineering', 'Bioinformatics']"
doi:10.1007/978-981-19-6714-6_9,en,An Outlook for Future Mobile Network Data-Driven Urban Informatics,OriginalPaper,"This chapter provides an outlook for future directions of mobile network data-based urban informatics, particularly in travel behavior research. It discusses a dynamic characteristic of mobile network data that continues to change its properties and potential values with the technological advancement, which in turn poses new challenges and exciting research opportunities. This may include new paradigms for data collection as an alternative to the telecom provided data, which is rarely accessible due to data privacy regulations. There is still a need for rebalancing between the data’s utility and privacy for which data uncertainty and privacy algorithms are discussed. Future directions of mobile network data-based urban informatics will concern data mining techniques that help discover patterns and trends in trajectory data, including group movement pattern mining, trajectory clustering, and sequential pattern mining. Mining such patterns benefits travel behavior research with many applications, such as traffic detection, social gathering recognition, regional travel behavioral signature extraction, uncovering life/daily patterns, and unusual event detection.","['Computer Science', 'Data Structures and Information Theory', 'Artificial Intelligence', 'Data Mining and Knowledge Discovery', 'Statistics, general', 'Transportation Technology and Traffic Engineering', 'Computer Applications']"
doi:10.1007/978-3-031-16868-0_14,en,End-to-End Performance Predictors,OriginalPaper,"In fact, common optimization problems in ENAS are computationally expensive and are usually handled using surrogate-assisted EAs(SAEAs) [ 1 ], employing inexpensive approximation regression and classification models, such as the Gaussian process model [ 2 ], radial basis network (RBN), etc., to replace the costly fitness evaluation [ 3 ]. SAEAs have proven to be useful and efficient in a variety of practical optimization applications [ 1 ].","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4815-2_4,en,Delay-Sensitive and Availability-Aware Virtual Network Function Scheduling for NFV,OriginalPaper,"As noted before, the VNF placement and routing problem can be addressed with the goal of minimizing the maximum link load ratio and each user’s requested delay is satisfied. However, in addition to requested delay, resiliency is also an important Service Level Agreements (SLA) in a NFV service. In this chapter, we first investigate how to quantitatively model the traversing delay of a flow in both totally ordered and partially ordered SFCs. Subsequently, we study how to calculate the VNF placement availability mathematically for both unprotected and protected SFCs. After that, we study the delay-sensitive Virtual Network Function (VNF) placement and routing problem with and without resiliency concerns. We prove that this problem is NP-hard under two cases. We subsequently propose an exact Integer Nonlinear Programming (INLP) formulation and an efficient heuristic for this problem in each case. Finally, we evaluate the proposed algorithms in terms of acceptance ratio, average number of used nodes and total running time via extensive simulations.","['Engineering', 'Communications Engineering, Networks', 'Graph Theory', 'Operations Research, Management Science', 'Theory of Computation', 'Algorithm Analysis and Problem Complexity']"
doi:10.1007/978-3-031-19032-2_16,en,A Gender Genetic Algorithm and Its Comparison with Conventional Genetic Algorithm,OriginalPaper,"This study presents a new variety of gender genetic algorithm (GGA). Using the example of five test optimization problems, its superiority over conventional genetic algorithm (GA) with an elitism operator is shown. The analysis of the novel GGA on multi-extreme optimization functions confirms the effectiveness of the idea of gender separation of the population. Based on the results obtained from experimental data and on their analysis, a more advanced modification of GGA is proposed, using determination of the offspring's gender based on the combination of parental chromosomes in it.","['Engineering', 'Computational Intelligence', 'Machine Learning', 'Neurosciences']"
doi:10.1007/978-981-19-4162-7_46,en,Analysis of Disaster Tweets Using Natural Language Processing,OriginalPaper,"Now-a-days social media has become a crucial part of life. Twitter is a social networking site on which people post and interact with messages renowned as tweets. Users registered officially can tweet, like and re-tweet messages. During the emergence of a disaster or crisis social media has become a significant means of communication. The widespread use of mobile phones and other forms of communication allows individuals to express and alert others about real-life disasters. Such knowledge relating to disasters spread over the media could save thousands of individuals by warning others and allowing them to take the required actions. It is being worked on by many firms to analyze tweets and observe tweets relating to disasters and emergencies using programming. Such efforts may be useful to loads of people using the internet. However, this effort has other problems, such as detecting and distinguishing catastrophe tweets from non-disaster tweets. Often the data available in twitter is not structured so processing is to be done on the data to classify data as ‘disaster’ and ‘non-disaster’. This paper deals with developing a model that can tell if a user is sharing data about a disaster. The data set used includes 10,000 tweets along with classifiers. This Optimized SVM model pre-processes the data using Natural Language Processing (NLP) and then builds the classifier model that gives maximum accuracy.","['Engineering', 'Computational Intelligence', 'Data Mining and Knowledge Discovery', 'Systems and Data Security', 'Mobile and Network Security', 'Information Systems Applications (incl. Internet)']"
doi:10.1007/978-981-19-4975-3_40,en,The Correntropy Kalman Filter: A Robust Estimator for GPS Applications,OriginalPaper,"India suffers from low satellite visibility. If any GPS receiver is operated in urban canyons, the visibility further reduces. These system constraints lead to many challenges in providing precise GPS position accuracy over the Indian subcontinent. Among all these factors, the predominant factors that significantly influence the receiver position accuracy are selecting a user/receiver position estimation algorithm. In this article, a novel kinematic positioning algorithm is proposed designated as the Correntropy Kalman Filter (CKF) that adopts the robust correntropy criterion as the optimality criterion instead of using the well-known minimum mean square error (MMSE). A novel fixed-point algorithm is then used to update the posterior estimates. A sufficient condition that guarantees the convergence of the fixed-point algorithm is also given. The proposed algorithm results are then compared with the Least Square Estimator (LSE), traditional Kalman Filter (KF), and Extended Kalman Filter (EKF) algorithms. Results prove that the proposed CKF algorithm exhibits significant improvement in position estimation compared to the other three recursive algorithms (i.e., LSE, KF, and EKF). And Statistical position Accuracy Measures (SAM) like DRMS, CEP, SEP, etc. are additionally used for performance evaluation of the proposed algorithm.","['Engineering', 'Power Electronics, Electrical Machines and Networks', 'Energy Policy, Economics and Management', 'Energy Systems']"
doi:10.1007/978-981-19-0561-2_12,en,Machine Learning Techniques for Smart Manufacturing: A Comprehensive Review,OriginalPaper,"The smart manufacturing revolution is continuously enabling the manufacturers to achieve their prime goal of producing more and more products with higher quality at a minimum cost. The crucial technologies driving this new era of innovation are machine learning and artificial intelligence. Paving to the advancements in the digitalization of the production and manufacturing industry and with a lot of available data, various machine learning techniques are employed in manufacturing processes. The main aim of implementing the ML techniques being to save time, cost, resources and avoid possible waste generation. This paper presents a systematic review focusing on the application of various machine learning techniques to different manufacturing processes, mainly welding (arc welding, laser welding, gas welding, ultrasonic welding, and friction stir welding), molding (injection molding, liquid composite, and blow molding) machining (turning, milling, drilling, grinding, and finishing), and forming (rolling, extrusion, drawing, incremental forming, and powder forming). Moreover, the paper also reviews the aim, purpose, objectives, and results of various researchers who have applied AI/ML techniques to a wide range of manufacturing processes and applications.","['Engineering', 'Industrial and Production Engineering', 'Engineering Design', 'Machinery and Machine Elements']"
doi:10.1007/978-981-19-1412-6_52,en,A Comprehensive Solution for Handling Security Issues with Seaport IoT Systems,OriginalPaper,"In the current epoch, the Internet of Things (IoT) can be reflected as an important technological revolution related to evolution of smart cities, smart homes, IoT-controlled factories, and IoT for logistics in seaports implementations. With the existence of smart sensing systems in seaports becoming a reality today, different sectors in seaports are working toward a programmed mode. Some of the eye-opening projects related to smart seaports in the IoT era can be found all over the globe. In many of these new architecture implementations, even though the rapid development of IoT enables us to inspire new research works, the challenges in IoT also grow equally in terms of security. Encryption plays a key role in safeguarding IoT hardware and the data from various sensors. The proposed work focuses on reality study on various security issues emerging in the usage of IoT in seaports and suggestions for handling the security issues. Highly secure algorithms need developed in IoT encryption level standards are discussed here. Conclusions regarding the extension of future research prospects in the IoT systems and high-level security in seaports are guided in the final segment of the paper.","['Engineering', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security']"
doi:10.1007/978-981-19-5221-0_17,en,An Empirical Study of Multi-class Imbalance Learning Algorithms,OriginalPaper,"Real-life data are often imbalanced which represent the major hurdle in classification applications. Despite incremental improvements, gaining from this skew datasets remain a core interest of intense research. Deeper insight into the nature of imbalanced learning has been gained with the expansion of machine learning and data mining. This turned out to be more complicated with the arrival of the big data era and new emerging challenges of multi-class classification. Strategies for dealing with imbalanced dataset issues are continually being improved. Recent researches focus on analyzing not just the disparity between classes, yet in addition, different troubles implanted in the nature of data. These motivate to focus on computationally efficient, versatile, and real-time techniques for the imbalanced multi-class classification.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Sociology, general', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-4815-2_6,en,A-DDPG: Attention Mechanism-Based Deep Reinforcement Learning for NFV,OriginalPaper,"Chapters 3–5 transform the VNF placement and traffic routing proble into some well-known NP-hard problems, and then a heuristic or approximation method is proposed to solve it, at the expense of ignoring the network state dynamics. To bridge that gap, in this chapter, we formulate the VNF placement and traffic routing problem as a Markov Decision Process model to capture the dynamic network state transitions. In order to jointly minimize the delay and cost of NFV providers and maximize the revenue, we devise a customized Deep Reinforcement Learning (DRL) algorithm, called A-DDPG, for VNF placement and traffic routing in a real-time network. A-DDPG uses the attention mechanism to ascertain smooth network behavior within the general framework of network utility maximization (NUM). The simulation results show that A-DDPG outperforms the state-of-the-art in terms of network utility, delay, and cost.","['Engineering', 'Communications Engineering, Networks', 'Graph Theory', 'Operations Research, Management Science', 'Theory of Computation', 'Algorithm Analysis and Problem Complexity']"
doi:10.1007/978-981-19-5331-6_2,en,Exploring the Scheduling Techniques for the RTOS,OriginalPaper,"Real-time embedded systems have tight time constraints on the system response to external events. They are being used in many mission critical applications like avionics, industrial control systems, etc. Both hardware and software components might have an impact on the real-time system’s overall performance. For the most part, hardware components are designed with large-scale production in mind. Memory management and key kernel components like the scheduler are only two examples of software that interacts with an operating system. The problem of real-time scheduling extends range of algorithms from simple uniprocessor to highly complex multiprocessor scheduling algorithms. Over the last decade, in order to meet the demands of ever-increasing performance from the commercial market and faced with the fundamental performance limits which could not be achieved on a single-core processor due to clock speed ceiling, semiconductor manufacturers transitioned to multicore processor architectures to achieve better performance needed for real-time embedded systems. Further online (dynamic) scheduling algorithms are more flexible than offline (static) algorithms. It has been suggested in this research to survey a variety of dynamic scheduling techniques for real-time embedded systems. The characteristics and limitations of real-time activities are the subject of our research. The choice of scheduling algorithm depends on its ability to fulfill task time restrictions demanded by-product requirements.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-18461-1_43,en,Diagnosis of Hepatitis C Patients via Machine Learning Approach: XGBoost and Isolation Forest,OriginalPaper,"Although the transmission of Hepatitis C through blood transfusion is getting less and less prevalent with the use of anti-HCV tests for blood donors, availability and practice of screening remain low in developing countries. This results in Hepatitis C patients who are unaware of their condition until it worsens to become chronic liver diseases that are diagnosed through more costly or invasive methods–liver biopsy and radiology scans. Due to these limitations of the current methods of diagnosis, this study seeks to develop a machine learning model to diagnose patients with different stages of liver disease: hepatitis c, liver fibrosis, and cirrhosis. In this research, machine learning algorithms were applied to a dataset containing HCV patient information, and the algorithms were evaluated for their accuracy and performance in classifying the patients with the proper diagnosis. Findings from the study indicated that XGBoost can most accurately classify patients with an accuracy score of 95.48, but other algorithms used had high accuracy scores as well: the algorithm with the lowest accuracy score–Decision Tree–still had a score of 92.66. The second experiment also showed that the Isolation Forest algorithm could detect and isolate the suspect blood donors of the data with a relatively high accuracy of 93.22%. As both experiments of the study yielded a machine learning model of high accuracy, the algorithms used can be implemented into a diagnostic kit for liver disease to be used in developing countries where accessibility to current diagnosis tools is limited.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4052-1_70,en,Study on Optimizing Feature Selection in Hate Speech Using Evolutionary Algorithms,OriginalPaper,"Hate speech is an important problem while dealing with user-generated content on online social media platforms. The huge amount of data generated makes it nearly impossible to manually moderate hate speech content and take appropriate measures. In this paper, we utilize various optimization algorithms to enhance the feature extraction and vectorization, of various techniques like TF-IDF, Word2Vec, and Bag of Words and appertain on the machine learning models for two-fold classification. We gauge and visualize the conclusion of the propounded methodology of the hate speech problem about Twitter tweets. We examine our suggested technique on three datasets; out of which, two of the datasets were highly unbalanced, and SMOTE was used for class balance. Our experiments indicate the random behavior of particle swarm optimization and genetic algorithm and the decrease in accuracy when applied individually to the experiments. The results also indicate that the accuracy can be achieved back by applying particle swarm optimization and genetic algorithm parallels, countering their random behavior.","['Engineering', 'Computational Intelligence', 'Information Storage and Retrieval', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Data Structures and Information Theory', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4193-1_59,en,Route Optimization for Waste Collection,OriginalPaper,"The vehicle routing problem is a synonym used in the enclosure of transport, distribution, and outsourcing to optimize routes. Route planning techniques are one of VRP’s major errands: planning to seek an optimal way on a map from a starting point to a destination. We strive to achieve a GIS-based transport system that provides the easiest, fastest, and shortest route to reach the hub. In this paper, we discuss the description of the different route planning algorithms and then explain their efficiency comparison and analysis when Municipal Corporations implement them throughout the existing road network for use in the waste management framework. Along with Haversine formula, we choose Dijkstra, the most well-known shortest path algorithm and traveling salesman problem.","['Engineering', 'Computational Intelligence', 'Information Storage and Retrieval', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Data Structures and Information Theory', 'Artificial Intelligence']"
doi:10.1007/978-3-031-18461-1_29,en,Using Regression and Algorithms in Artificial Intelligence to Predict the Price of Bitcoin,OriginalPaper,"Cryptocurrency is a topic that is no longer strange in the investment world. Bitcoin is considered a very famous cryptocurrency and has a large amount of investment across the globe. Therefore, in recent years, the Bitcoin investment field has been attracting much research to help investors in this field maximize profits. In this study, using regression and algorithms in artificial intelligence such as K-Nearest Neighbors (K-NN), Neural Network (NN), Decision Tree (DT), Support Vector Machines (SVM), Random Forest (RF), and Linear Regression (LR) to predict the opening price of Bitcoin. We are using the hybrid model of the LR algorithm with K-NN, NN, DT, SVM, and RF algorithms to improve Bitcoin price prediction performance. The study results show that most algorithms predict well, and the hybrid model has better prediction results. This prediction result shows that the hybrid model has the potential to be applied in practice to improve the accuracy of Bitcoin opening price prediction.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-3-031-20105-9_5,en,IIR System Identification Using Several Optimization Techniques: A Review Analysis,OriginalPaper,"System identification is a difficult optimization problem, especially those that use the infinite impulse response (IIR) models which are preferred over their equivalent FIR (finite impulse response) models since they represent more accurate real-world applications. Nevertheless, IIR models tend to generate multimodal error surfaces which are significantly difficult to optimize.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2273-2_9,en,Optimizing Points of Intersection for Highway and Railway Alignment—Using Path Planner Method and Ant Algorithm-Based Approach,OriginalPaper,"The essential decision factors that govern the design of highway and railway alignment are the number of intermediate points ( $${\text{PIs}}$$ ), their locations, and the circular curve radius. The development of optimal alignment involves many challenges, such as evaluating an infinite number of potential solutions, complex terrain, environmental conditions, entwined complicated cost, and design constraints. The alignment development process is primarily manual, highly expensive, and time consuming and is also not practically feasible. So, many computer-aided optimization methods were developed to address the alignment optimization problem. However, most of these methods predefine the value of either one or more of these factors; thus, this approximation of values limits these models from obtaining an optimal solution. This paper proposes a heuristic-based path planner method (PPM) to address such issues. The model includes (a) exploration of non-convex high-dimensional space for obtaining a least-cost horizontal alignment, (b) sampling technique, along with PPM, is used to generate potential $${\text{PIs}}$$ and develop feasible alignments by finding a suitable number of intermediate $${\text{PIs}}$$ at feasible locations followed by curve fitting at each $${\text{PIs}}$$ , , and (c) geographical information system (GIS) database is integrated with the method for estimation of right-of-way cost and environmental impact. The alignment is developed as per the standard geometric design guidelines of highway and railway alignment. The effectiveness of the model is verified by using it for a real-world case study. The proposed method is capable of automatizing the development of a green field horizontal alignment and can aid engineers in the process of planning and development.","['Engineering', 'Transportation Technology and Traffic Engineering', 'Building Construction and Design', 'Mechanical Engineering']"
doi:10.1007/978-981-19-2145-2_79,en,Seismic Response of RC Elevated Liquid Storage Tanks Using Semi-active Magneto-rheological Dampers,OriginalPaper,"The paper presents the use of semi-active magneto-rheological (MR) dampers for the structural response reduction of the reinforced concrete (RC) elevated liquid storage tanks. The effectiveness of MR dampers is investigated based on the control strategies and the placement of the dampers in the staging. The RC elevated liquid storage tank is modeled as a multi-degree freedom system for the staging with a two-mass model for the container with liquid. Two control systems, viz., open-loop and closed-loop control systems are considered. The control algorithms employed are (1) Passive-OFF, (2) Passive-ON, (3) Clipped-Optimal Control (COC), and (4) Simple Semi-active Control (SSC). The study is also focused on the effect of change of voltage on the response quantities. For the COC algorithm, the feedback gain is obtained by considering velocity feedback. The present study proposes a SSC algorithm which is an effective way of controlling the response of RC elevated tank, which uses the ratio of the damper force and capacity of the damper. For numerical simulation, a code is developed in MATLAB. The coupled differential equations of motion for the system are solved using the state-space method. The response of the broad and slender tanks is studied by taking the ratio of the height of the liquid to the radius of the container ( S ) as 0.5 and 2.0, respectively. The controlled response of the tank under eight different ground motions comprising of near-field and far-field components of earthquakes is evaluated and compared with that of the uncontrolled response. Base shear, displacement, and damper force are obtained. The results showed that the structural response is effectively controlled using semi-active MR dampers with the proposed SSC strategy. The simple semi-active control algorithm proposed in this study could be considered as a proficient algorithm for the seismic response reduction of RC elevated liquid storage tanks using SAMRD.","['Engineering', 'Building Construction and Design', 'Construction Management', 'Transportation Technology and Traffic Engineering']"
doi:10.1007/978-3-031-08693-9_9,en,MIMO,OriginalPaper,"Most modern radios use multiple antennas. This opens up multiple possibilities to increase either or both the performance and throughput of the radio. All MIMO options, but specifically spatial multiplexing, require very complicated algorithms and unusual arithmetic, especially at the receiver. In this chapter, we consider multiple hardware-friendly options for decoding MIMO signals at the receiver.","['Engineering', 'Circuits and Systems', 'Microwaves, RF and Optical Engineering']"
doi:10.1007/978-3-031-21062-4_41,en,RL-Studio: A Tool for Reinforcement Learning Methods in Robotics,OriginalPaper,"This paper introduces RL-Studio, an open-source software that eases the implementation of reinforcement learning algorithms to solve a problem. This software enables the integration of any simulator to recreate the problem where a reinforcement learning algorithm can be applied. Some relevant advantages of this tool are the generalization of common software components and the unified architecture. RL-Studio permits to just focus on fine tuning the hyperparameters of the algorithm and redefine the goal and reward function of the previously integrated projects. In case a non-integrated scenario, algorithm or simulator is needed, RL-Studio also provides some already integrated libraries that can be reused to save time. It has been experimentally validated in research projects and some of the canonical problems such as Robot Mesh or Mountain Car.","['Computer Science', 'Robotics', 'Robotics and Automation', 'Computational Intelligence']"
doi:10.1007/978-981-19-5845-8_11,en,Comprehensive Assessment of Big Data in Recommendation Systems,OriginalPaper,"Developments in web-based e-commerce platforms cause recommendation systems to gain increasing importance. Recommendation systems are systems developed to provide valuable and personalized recommendations for users. In the age of big data, existing recommendation systems face scalability and efficiency problems in the face of increasing numbers of users and products. Within the scope of this study, a comprehensive and comparative review of big data and recommendation systems has been made. Studies in which big data are used in recommendation systems have been examined in the literature. The necessary pre-processes and methods for applying big data to recommendation system with high performance and success have been discussed in detail.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-11047-4_10,en,SPROUT - Smart Power ROUting Tool for board-level exploration and prototyping,OriginalPaper,"The board-level power network design process is governed by system-level parameters such as the number of layers and the ball grid array (BGA) pattern. These parameters influence the characteristics of the resulting system, such as power, speed, and cost. Evaluating the impact of these parameters is however challenging. To estimate the reduction in impedance if, for example, additional BGA balls are dedicated to the power delivery system, adjustments to the board layout and an additional impedance extraction process are required. These processes are poorly automated, requiring significant time and labor. Automating both power network exploration and prototyping can greatly enhance the board-level power delivery design process by increasing the number of possible design options. With power network exploration and prototyping, the effects of the system parameters on the electrical characteristics can be better understood, providing valuable insight into early stages of the design process. SPROUT – an automated algorithm for prototyping printed circuit board (PCB) power networks – is presented here. This tool includes the first fully automated algorithm for board-level power network layout synthesis. Two board-level industrial power networks are synthesized using SPROUT. The impedance of the resulting layouts exhibits good agreement with manual PCB layouts while significantly reducing the design time. The tool is used to explore area/impedance tradeoffs in a three rail system, providing useful data to enhance the PCB design process.","['Engineering', 'Circuits and Systems']"
doi:10.1007/978-981-16-9967-2_69,en,Artificial Bee Colony Optimization-Based Load Balancing in Distributed Computing Systems—A Survey,OriginalPaper,"Distributed computing allows the interoperability of components in distributed system in which software or hardware components located at networked computers coordinate and communicate their actions by message passing. The tasks in such a system are carried out independently. In distributed computing systems, load balancing is one of the issues, which is a means to distribute the tasks such that the computational nodes are neither overloaded nor underloaded, and the performance of the system is improved. Among the various solutions proposed for load balancing, metaheuristic-based algorithms are one of them. This paper discusses the variants and recent developments of artificial bee colony optimization algorithm for solving load balancing in distributed systems. As a result of load balancing, various performance metrics measured are throughput, response time, makespan, CPU utilization, memory utilization, and network utilization. The performance of the optimization algorithms is also measured with the time taken to converge in finding the optimal solution for load balancing.","['Computer Science', 'Computer Systems Organization and Communication Networks', 'Computational Intelligence', 'Artificial Intelligence', 'Wireless and Mobile Communication', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-4637-0_3,en,Optimal Control Problems and Common Solutions,OriginalPaper,"The fundamental problems for both trajectory planning and optimal guidance control are solutions to the optimal control problem. This section puts forward the optimal control problem, the methods for solving the extreme value problem, and introduces the methods for calculating the optimal control problem in detail, including indirect methods, direct methods and intelligent optimization algorithms. The nonlinear planning method and convex optimization method are introduced. The problems encountered in solution process are described and corresponding schemes are put forward.","['Engineering', 'Aerospace Technology and Astronautics', 'Engine Technology']"
doi:10.1007/978-981-19-2535-1_6,en,A Review on Virtual Machine Placement with ACO in Cloud Computing,OriginalPaper,"Cloud computing is an era idea wherein customers use far-off servers to keep statistics and applications. Cloud computing sources are demand-pushed and are used inside the shape of digital machines (VMs) to facilitate complicated tasks. Deploying a digital system is the method of mapping a digital system to a bodily system. This is an energetic study subject matter, and numerous techniques have been followed to cope with this difficulty inside the literature. Virtual system migration takes a sure quantity of time, consumes plenty of sources, influences the conduct of different digital machines at the server, and degrades machine performance. If you've got got a massive variety of digital system migrations on your cloud computing machine, you may now no longer be capable of meet your provider stage contracts. Therefore, the maximum trustworthy manner to lessen statistics middle electricity intake is to optimize the preliminary placement of digital machines. In the deployment method, many researchers use ant colony optimization (ACO) to save you immoderate electricity intake discounts. This is because of its effective comments mechanism and allotted retrieval method. This article information the contemporary techniques for digital system positioning and integration that let you use ACOs to enhance the electrical performance of your cloud statistics centers. The assessment among the techniques supplied here exhibits the value, limitations, and guidelines for improving different techniques alongside the manner.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3250-2_7,en,FRW Based Techniques for Handling Non-Manhattan Conductors,OriginalPaper,"The non-Manhattan conductor geometry existing in some capacitance extraction problems brings difficulty to the floating random walk (FRW) method using cubic transition domains. In this chapter, techniques are presented to enhance the FRW method for handling the structures with non-Manhattan conductors. Based on the aligned-box distances and corresponding calculating approaches, the techniques for generating the Gaussian surface and constructing axis-aligned transition cubes are presented. A practical strategy is then presented to judge the domination relationship of non-Manhattan conductor blocks for building the space management structure with candidate list. Finally, the strategy using rotated transition cube and related space management technique are presented to make further acceleration. Experiments on three-dimensional (3-D) interconnect structures including from eight to one thousand non-Manhattan blocks show that the developed method is from 2.9X to 96X faster than a simple extension of the original FRW method. The developed FRW solver is also up to 39X faster than a boundary element method based solver. Additional experiments are carried out to further validate the accuracy and efficiency of the presented techniques, and to demonstrate their suitability for large and multi-dielectric structures.","['Engineering', 'Electronics and Microelectronics, Instrumentation', 'Engineering Mathematics']"
doi:10.1007/978-981-19-3490-2_4,en,Battery Model,OriginalPaper,"Lithium ion batteries (LIBs) have become the favorite choice as the power sources for electric vehicles (EVs) due to the advantages such as long service life, high energy and power density and environmental friendliness, etc. The operating conditions of the LIBs in EVs vary with the environment, and the BMS is key to ensuring system safety, longevity and high efficiency.","['Engineering', 'Automotive Engineering', 'Transportation Technology and Traffic Engineering', 'Energy Systems', 'Energy Materials']"
doi:10.1007/978-3-031-16832-1_11,en,Multi-circle Detection Using Multimodal Optimization,OriginalPaper,"Object and shape detection in digital image were one of the hot topic over the last two decades. Especially automatic multi circle detection has received more attention over last years. Hough transform (HT) is a well-known and most popular method for lines and circles detection. However, HT has huge computational complexity expense. This paper proposed a new successful heuristic method to reduce computation time and improve the speed of HT for circle detection. In this proposed method the edges information of the image is obtained by means of Robert edge detection. Then, multimodal particle swarm optimization (PSO) and local search is employed to locate all exciting circle in the image. The experiments on benchmark images show that our scheme can perform multi circle detection successfully.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Engineering']"
doi:10.1007/978-3-030-99075-6_25,en,YOLOV4-Based Wind Turbine Blade Crack Defect Detection,OriginalPaper,"Wind turbine blade is an important component of wind turbine. Wind turbine blade crack damage will cause hidden danger to the operation of wind turbine. The current wind turbine blade defect detection mainly relies on manual inspection, and the image detection technology can improve the inspection efficiency and reduce the unit maintenance cost. In view of the existing wind turbine blade crack defect detection algorithm with low recognition rate and low accuracy, a YOLOv4-based wind turbine blade crack detection method is proposed. First establish the wind turbine blade crack image dataset, then the anchor box parameters in YOLOV4 are optimized by K-means++ algorithm to make the anchor box parameters match the crack defect size; BiFPN is used instead of PANet to achieve better feature fusion, and finally the Focal Loss function is introduced to balance the number of small size defect samples in the data. The comparison tests show that the AP of the improved YOLOv4 algorithm reaches 93.49, which is better than the original YOLOv4 and the other three comparison algorithms, and has better efficiency and practicability.","['Engineering', 'Industrial and Production Engineering', 'Mechanical Engineering', 'Machinery and Machine Elements']"
doi:10.1007/978-3-031-16832-1_1,en,Empirical Comparison of Heuristic Optimisation Methods for Automated Car Setup,OriginalPaper,"Tuning a race car to improve its performance by adopting an effective setup is crucial and an extremely challenging task. The Open Racing Car Simulator, referred to as TORCS, is a well-known simulator in which a race car requires a configuration of twenty two real-valued parameters for an optimal setup. In this study, various modern (meta)heuristic techniques, such as, evolutionary algorithms, swarm intelligence algorithm and selection hyper-heuristics, are evaluated using TORCS to solve the car setup optimisation problem across a range of tracks. An in-depth performance comparison and analysis of those techniques on the car setup optimisation problem are provided with a discussion on their strengths and weaknesses. The empirical results indicate the success of Covariance Matrix Adaptation Evolutionary Strategy for the car setup optimisation problem.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Engineering']"
doi:10.1007/978-981-19-1142-2_16,en,Implementation of Green Technology in Cloud Computing,OriginalPaper,"The increase in the use of modern technology worldwide in various sectors like business, software development, automation, etc., has made human life considerably easy, comfortable, and far from any danger. For this reason, there has been a rapid growth in technologies and upcoming trends. Cloud computing is one such paradigm which has rapidly developed in recent years. It has a range of applications in various domains due to the features it offers, like scalability, elasticity, and cost saving with low maintenance, security, and reliability. However, the production and consumption of these advanced technologies have a negative impact on the environment causing massive energy consumption and generating carbon footprints. Due to this, the concept of green technology has gained a lot of attention in order to make positive changes to the environment. Green computing is the implementation of environmentally friendly concepts in computing to increase power and energy and reduce carbon content. In this paper, we review that how adopting a cloud-based architecture has reduced the energy consumptions levels, and we further survey various methods and algorithms which can make clouds greener and more energy efficient.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Mobile and Network Security', 'Artificial Intelligence']"
doi:10.1007/978-3-031-19620-1_47,en,Optimal Design of Conventional and Freeform Optical Systems with Memetic Mind Evolutionary Computation Algorithm,OriginalPaper,"This paper studies distinct features between optimization of conventional and freeform optical systems. Freeform optical systems include lens or mirror surfaces with shapes that have no axis of revolution to reach better performance in off-axis designs. They have an increased number of design parameters compared to classical rotationally symmetrical optical systems which makes optimization more difficult. The authors applied several well-known optimization techniques both to a classic system and a freeform system, including commercial methods from Zemax OpticStudio software. In addition, a new parallel memetic algorithm was proposed that outperformed many methods under investigation. The algorithm incorporates local search techniques into an asynchronous parallel computing procedure thus helping to speed-up the convergence to a high-quality solution. The description of the proposed algorithm as well as the results a comparative study are presented in this paper. Computational experiments were conducted for two systems – the Cooke triplet and the freeform prism with two optical surfaces. Obtained results were estimated both from the optimization and optical perspectives.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1412-6_50,en,Hybrid Optimization Approach for Adaptive Beamforming in Smart Antenna System,OriginalPaper,"The paper presents novel the adaptive beamforming in linear antenna array through hybrid optimization algorithm. The hybrid optimization algorithm has been formulated by combining improved version of the whale optimization algorithm (IWOA) and improved version of sine–cosine algorithm. Application of hybrid algorithm in the beamforming is to estimate the excitation weights of the desire signal applied on array elements, different interferences received from different directions and update the position the receiver so as to receive better quality of service by adopting the weight of the input signal. The robustness of the algorithm is confirmed through the simulation in MATLAB, and result shows that performance has been improved by minimizing bit rate, power transmitted, beamforming through different number of array elements using hybrid optimization algorithm.","['Engineering', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security']"
doi:10.1007/978-981-19-2538-2_5,en,Meta-Analysis of Nature Inspired Hybrid Cuckoo Algorithm,OriginalPaper,"Diving deep into nature makes us understand it better. Nature inspires researchers world-wide to design technology based upon natural phenomenon. There are various birds such as migrating birds, cranes, and cuckoo which are used as inspiration to design algorithms. In this paper, the nature-inspired Cuckoo Algorithm, which is based on brood parasitism reproductive strategy, is discussed in detail. The Cuckoo Algorithm has various hybrids which are used in numerous applications; all these hybrids are reviewed and discussed in this paper. Meta-analysis is conducted using WoS and Scopus databases to study its variants and application domains, analyze the research trend for these hybrid algorithms and predict the future for these nature-inspired algorithms. Numerous experiments based upon correlation of related terms, year-wise analysis, article growth, etc. are conducted and described in this paper.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory', 'Mobile and Network Security']"
doi:10.1007/978-981-19-2879-6_3,en,Overview of Deep Learning,OriginalPaper,"As a machine learning model based on neural networks, deep learning is particularly advantageous in fields like computer vision, speech recognition and natural language processing. This chapter mainly introduces the basic knowledge related to deep learning, including the history, the components of neural networks, the types of deep learning neural networks, and the common problems researchers may encounter in the deep learning projects.","['Computer Science', 'Artificial Intelligence']"
doi:10.1007/978-981-19-7210-2_1,en,Introduction,OriginalPaper,"Physics-based simulation models from different disciplines are becoming indispensable in modern product design. In the preliminary design phase, these simulation models can help predict the performance of products to expedite the design space exploration and search for the optimal design.","['Engineering', 'Engineering Design', 'Optimization', 'Engineering Mathematics', 'Mathematical Modeling and Industrial Mathematics']"
doi:10.1007/978-981-19-3035-5_5,en,Enhancing the Performance of Heterogeneous Networks Using Optimized Cluster-Based Algorithm,OriginalPaper,"With an ever-increasing number of user equipment (UEs) and rising bandwidth demands of new applications, deployment dense heterogeneous cellular networks have been embraced in various network scenarios. The cells experience unloaded due to the random UEs mobility and cells deployment, which degrades the network performance such as handover success, throughput, and load distribution. We propose an enhanced cluster-based algorithm for small cell mobility load-balancing networks to address such a problem. The conventional mobility load-balancing (MLB) algorithms consider only the contiguous neighboring cells and do not expand enough performance of the network, while other MLB algorithms consider the neighboring cells of the total network experienced unneeded MLB actions. The proposed load-balancing algorithm studies overloaded cells and neighbors using the proposed efficiency parameter. To begin with and to identify the overloaded cells, we propose an efficiency factor B that compares a pre-defined threshold and the network threshold to control the algorithm triggering by modifying the CIO parameters of the cluster cells in both medium-loaded and overloaded cells triggering in both medium-loaded and overloaded cells. Then, to control the distribution, we propose a method to shift only a portion of the serving cells load, so the target cell load after handover always be equal to or less than B . In a low UE speed scenario, the simulation results showed a lower standard deviation (SD) by 19.99% and enhanced throughput by 7.355%.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Statistics, general']"
doi:10.1007/978-981-19-2635-8_3,en,Traffic Navigation for Urban Air Mobility with Reinforcement Learning,OriginalPaper,"Assuring stability of the guidance law for quadrotor-type Urban Air Mobility (UAM) is important since it is assumed to operate in urban areas. Model free reinforcement learning was intensively applied for this purpose in recent studies. In reinforcement learning, the environment is an important part of training. Usually, a Proximal Policy Optimization (PPO) algorithm is used widely for reinforcement learning of quadrotors. However, PPO algorithms for quadrotors tend to fail to guarantee the stability of the guidance law in the environment as the search space increases. In this work, we show the improvements of stability in a multi-agent quadrotor-type UAM environment by applying the Soft Actor-Critic (SAC) reinforcement learning algorithm. The simulations were performed in Unity. Our results achieved three times better reward in the Urban Air Mobility environment than when trained with the PPO algorithm and our approach also shows faster training time than the PPO algorithm.","['Engineering', 'Aerospace Technology and Astronautics', 'Engine Technology', 'Automotive Engineering', 'Mechanical Engineering']"
doi:10.1007/978-981-19-0105-8_52,en,Swift Sort: A New Divide and Conquer Approach-Based Sorting Algorithm,OriginalPaper,"Sorting implies the task of presenting a specific type of data in a specific order. These tasks are getting accomplished by different algorithms proposed by researchers. Researchers are trying to achieve this task in minimal space and time complexity with improved stability, correctness, finiteness and effectiveness. Sorting is used in wide range of fields namely, in Operating systems, Data Base Management systems, in searching and in various other data science related areas. In this paper, a divide and conquer approach-based algorithm is proposed to sort the data in a specific order using min–max searching. The time complexity of the proposed Swift Sort algorithm is O ( n log n ) and O ( n 2 ) in the average and worst cases, respectively. Moreover, time complexity of the proposed algorithm is comparable to Quick Sort, Merge Sort, Heap Sort and TimSort but at the same time Randomised Quick Sort, Merge Sort and Heap Sort produces a better Time Complexity in their worst cases than Swift Sort. The experimental results prove the correctness of the proposed algorithm.","['Engineering', 'Communications Engineering, Networks', 'Artificial Intelligence', 'Computational Intelligence', 'Bioinformatics']"
doi:10.1007/978-981-16-8274-2_15,en,Design of Quasi-Oppositional-Based CSA Optimized Cascade Pi-Fractional Order PID Controller for Interconnected Power System,OriginalPaper,"In this work, an adequate approach is depicted to endorse the superiority of cascade PI-fractional order PID (PI-FOPID) controller over PID and FOPID controllers and also to validate the quasi-oppositional-based crow search algorithm (QOCSA) to elect the peerless gains of the controllers over CSA algorithm. PI-FOPID controller is implemented in an interconnected reheat-thermal power system to amend system performances. The system is designed with nonlinearity such as generation rate constraint (GRC) and ITAE as fitness function. The fundamental intention of this system is to diminish the divergence of frequency and power. For this purpose, a hybrid QOCSA and CSA algorithms are implemented to determine the significant parameters of controllers by which the divergence reducing competence of controller can be improved. This analysis to substantiate the proposed PI-FOPID controller and QOCSA algorithm is accomplished with a step load of 0.01 p.u. injected in area-1. Finally, QOCSA is substantiated over CSA algorithm, and PI-FOPID controller is confirmed as an excel controller over FOPID and PID controllers.","['Energy', 'Energy Policy, Economics and Management', 'Engineering Thermodynamics, Heat and Mass Transfer', 'Engineering Fluid Dynamics', 'Environmental Policy', 'Sociology, general']"
doi:10.1007/978-981-19-2940-3_4,en,Kernel Learning Estimation: A Model-Free Approach to Tracking Randomly Moving Object,OriginalPaper,"Kernel learning estimation (KLE) is a kernel-based method, where the original spatial data is mapped into a high-dimensional Hilbert space by a nonlinear mapping, hiding the nonlinear mapping in a linear learning framework. The kernel function of the method can be used to replace the complex inner product operation in the high-dimensional space and avoid the Curse of Dimensionality caused by high-dimensional calculation effectively. The kernel-based method has advantages on learnability, computational complexity, precise linearization and generalization performances, providing a promising way to solve the problem of nonlinear target tracking. In traditional tracking methods, nonlinear tracking models are usually built as a priori to predict the current state of target motion, emphasizing on tracking accuracy and real-time performance. However, kernel-based method provides a general way of linearization processing, which can be independent of specific models to achieve highly efficient data-driven computation. Introducing the kernel learning mechanism into target tracking problem is expected to improve the environmental adaptability. In this paper, a review on kernel learning method with application to randomly moving target tracking is presented, including kernel-based algorithms for target detection, kernel-based algorithms for generative tracking and for discriminant tracking, and multi-kernel learning methods with multiple kernel functions. Further research is prospected in optimization of kernel function, long-term robust tracking, feature extraction, target occlusion and other potential aspects on moving target tracking using kernel learning theory.","['Computer Science', 'Artificial Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing', 'Sociology, general', 'Computational Intelligence', 'Machine Learning']"
doi:10.1007/978-981-19-4815-2_3,en,Delay-Aware Virtual Network Function Placement and Routing in Edge Clouds,OriginalPaper,"As noted before, resource allocation problem in NFV can be fomulated as an Integer Nonlinear Programming (INLP). And the most frequent approaches to deal with NFV resource allocation include combinatorial optimization theory (e.g., randomized/LP rounding, primal-dual approximation), Deep Reinforcement Learning, Game theory, etc. In this chapter, we study the problem of how to place VNFs on edge and public clouds and route the traffic among adjacent VNF pairs, such that the maximum link load ratio is minimized and each user’s requested delay is satisfied.","['Engineering', 'Communications Engineering, Networks', 'Graph Theory', 'Operations Research, Management Science', 'Theory of Computation', 'Algorithm Analysis and Problem Complexity']"
doi:10.1007/978-3-031-11128-0_4,en,Path Planning for Special Robotic Operations,OriginalPaper,"The problem of robotic path planning has been the focus of countless investigations since the early works of the ’70s and, despite the large number of results available in literature, is still a topic that draws a great interest. In virtually all robotic applications it is required to somehow define a feasible and safe path, and such a problem can be cast and solved in many ways, given the several possible combination of robots—industrial robots, Autonomous Guided Vehicles (AGVs), Unmanned Aerial Vehicles (UAVs), underwater vehicles—and scenarios—a production line, a warehouse, an hazardous mountain—and therefore a large number of approaches and solutions have been, and are being, investigated. The aim of this chapter is to provide an overview of such widespread literature, first by briefly recalling some classic and general-purpose methods used in path planning, then by focusing on some application-specific problems, related to AGVs in industry, medical robotics and robotic welding. This choice is motivated by the prominent relevance of the path planning problem in these three applications. Then, a single application of great industrial interest, such as robotic spray painting, is analysed. Its specific features are described, and several techniques for task modelling and path planning are considered. A detailed comparison among these techniques is carried out, so as to highlight pros and cons of each one, and to provide a methodology to choose the most suitable one for the specific robotic spray painting application.","['Engineering', 'Robotics and Automation', 'Engineering Design', 'Industrial and Production Engineering']"
doi:10.1007/978-3-031-16217-6_3,en,"Optimizing Multi-reservoir Systems with the Aid of Genetic Algorithm: Mahanadi Reservoir Project Complex, Chhattisgarh",OriginalPaper,"In a multi-reservoir system, a single reservoir’s activity might have an impact on the other reservoirs within the system. Therefore, the reservoir must be managed as a single entity to ensure long-term water conservation. However, the integrated operation of a multi-reservoir system becomes more difficult when there is less rainfall in a basin. For this reason, the existing operating policy must be evaluated to ensure integrated functioning. Metaheuristic-based algorithms such as genetic algorithms (GA) are employed in this study to find the optimal solution, and optimization efficiency can be improved by avoiding local optimal solutions. It aims to develop a steady-state optimum operating policy using a genetic algorithm that can satisfy long-term demand and measure the performance along with a deterministic simulation-optimization model (S-O Model) in terms of reliability, resilience, vulnerability, and sustainability indices of the existing multi-reservoir system, namely, Ravishankar Sagar reservoir, Dudhawa, and Murrum Silli in Chhattisgarh, India. In addition, the overall performance of the existing reservoir is improved based on reliability by 35.66%, resilience by 40.54%, sustainability by 36.70%, and vulnerability reduced by 54.09%, respectively, compared to actual water release. Apart from that, the GA model release satisfactorily meets the needs of demand, and no deficit conditions have occurred during the entire study period, excluding the years 1989–1990, 2001–2002, and 2002–2003, respectively.","['Computer Science', 'Computer Applications', 'Geography, general', 'Sustainable Development']"
doi:10.1007/978-981-19-2635-8_8,en,A Study on Path Planning Using Bi-Directional PQ-RRT* Algorithm and Trajectory Tracking Technique Using Incremental Backstepping Control,OriginalPaper,"An autonomous flight system is essential for effective mission performance of UAVs, which are increasingly being applied in civil and military missions. Thus, in this study, an effective approach for implementing guidance and flight control systems is proposed. Based on the rapidly-exploring random tree (RRT) algorithm, the bidirectional potential quick (PQ)-RRT* is proposed to implement the path planner of the guidance system. The proposed bidirectional PQ-RRT* algorithm has a combination of three different types of improvement methods based on RRT*: potential field guided sampling (P-RRT*), modified RRT*(Q-RRT*), and bi-directional searching tree methods (Bi-RRT*). The convergence path was efficiently optimized using the line-of-sight path optimization algorithm. Then, a flyable trajectory was generated by a 7 th order spline generator with waypoints from the path planner. Finally, incremental backstepping control was adopted to ensure trajectory-tracking performance within the overall operational flight envelope. To validate a series of processes, a simulation was performed to examine the practical realization. Based on the results, the bidirectional PQ-RRT* and line-of-sight path optimization algorithms were validated to provide an effective solution. In addition, the proposed flight control system exhibited excellent trajectory-tracking performance.","['Engineering', 'Aerospace Technology and Astronautics', 'Engine Technology', 'Automotive Engineering', 'Mechanical Engineering']"
doi:10.1007/978-981-19-5221-0_71,en,A Collaborative Filtering Recommendation Algorithm Based on Restricted Random Walk,OriginalPaper,"Traditional collaborative filtering disregards the granularity of users’ preference drifting and item popularity bias in modeling, thus diminished the accuracy of recommendation. This paper proposes a new collaborative filtering algorithm based on constrained random walk. Two new trust network: user-based and item-based are proposed, with Restricted Random Walk (RW) to adaptively track the change of users’ preference drifting and item popularity bias. Experimental results on social data sets show that the proposed method is superior to existing recommendation algorithms.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Sociology, general', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-20105-9_2,en,A Comparative Approach for Two-Dimensional Digital IIR Filter Design Applying Different Evolutionary Computational Techniques,OriginalPaper,"The two-dimensional Infinite Impulse Response (2D-IIR) filters design has attracted attention in many fields of engineering due to its wide range of applications. Incorporating a user-defined filter in the 2D-IIR structure can be represented as an optimization problem. Nevertheless, considering that 2D-IIR filters can easily generate unstable transfer functions, they produce multimodal error surfaces which are complex to optimize. On the other hand, Evolutionary Computation (EC) techniques methods with the ability to explore complex search spaces for suitable solutions.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4863-3_2,en,On the Studies and Analyzes of Facial Detection and Recognition Using Machine Learning Algorithms,OriginalPaper,"This paper compares practical machine learning-based algorithms of detection and recognition such as Haar cascade classifier and local binary pattern histogram (LBPH) method against GoogleNet, which uses convolutional neural network (CNN) architecture, using transfer learning. From the comparative analyzes and studies, it was elucidated that LBPH and Haar cascade are computationally efficient, but CNN has more accuracy despite its longer computational time.","['Engineering', 'Computational Intelligence', 'Engineering Design', 'Machine Learning', 'Communications Engineering, Networks']"
doi:10.1007/978-3-031-14537-7_15,en,A Parallel Multi-indicator-Assisted Dynamic Bees Algorithm for Cloud-Edge Collaborative Manufacturing Task Scheduling,OriginalPaper,"Industrial Internet-of-Things brings cloud Cloud and edge resources together to support customized manufacturing. With cloud-edge Cloud-edge collaboration, large-scale computational tasks of product and process simulation, force and torque analysis, real-time Real-Time process control Control , and so forth, are to be executed in cloud or edge resources, while related manufacturing tasks are to be executed in distributed end devices simultaneously. In this circumstance, hybrid task scheduling Task scheduling becomes a key to implement efficient and intelligent manufacturing. In this paper, a multi-indicator Multi-indicator -assisted dynamic Bees Algorithm (MIDBA) is presented to solve large-scale task scheduling problem for cloud-edge Cloud-edge collaborative manufacturing. The operators of the Bees Algorithm Bees Algorithm, THE are modified according to multiple indicators to find suitable cloud-edge Cloud-edge collaborative modes, cloud and edge resources. A parallel Parallel search scheme is also designed to accelerate the scheduling process for large-scale tasks. We implement numerical studies to examine the proposed algorithm on this problem. Compared to the state-of-the-art algorithms, the parallel MIDBA can find better solutions with lesser time.","['Engineering', 'Robotics and Automation', 'Artificial Intelligence', 'Industrial and Production Engineering', 'Professional Computing', 'Robotics', 'Machine Learning']"
doi:10.1007/978-3-031-17393-6_4,en,Training Interval Type-2 Fuzzy Systems Based on Error Backpropagation,OriginalPaper,"This chapter introduces various methods for optimizing an interval type-2 fuzzy system through different examples with real data to evaluate the performance of the training method, which will be the error backpropagation method, whereas the optimization methods will be gradient descent, Kalman filter, and genetic algorithm.","['Engineering', 'Computational Intelligence', 'Control and Systems Theory', 'Artificial Intelligence']"
doi:10.1007/978-3-031-14537-7_11,en,Memory-Based Bees Algorithm with Lévy Flights for Multilevel Image Thresholding,OriginalPaper,"The Memory-based Bees Algorithm (MBA) is a new optimisation algorithm based on the Bees Algorithm (BA). MBA includes private and social information of honey bees to copy the decision-making capability of the bees. Lévy flights are random processes that are based on a stable distribution called the Lévy distribution. The enhanced so-called Levy MBA (LMBA) is used to reduce the tunable Tunable parameters of the basic BA and MBA algorithms. It is tested for Otsu’s multilevel Multilevel image Image thresholding Thresholding method with the peak signal-to-noise Noise ratio (PSNR) as the thresholding Thresholding quality Quality measurement Measurement . The objective is to find optimal Optimal threshold values, particularly with the highest quality Quality . The results demonstrated several benchmark problems with the efficiency and robustness of the new algorithm.","['Engineering', 'Robotics and Automation', 'Artificial Intelligence', 'Industrial and Production Engineering', 'Professional Computing', 'Robotics', 'Machine Learning']"
doi:10.1007/978-3-031-14615-2_34,en,An Improved NSGA-II Algorithm for Solving Capacitated Lot-Sizing Problem,OriginalPaper,"In this paper, an improved Non-dominated Sorting Genetic Algorithm NSGA-II is proposed to solve the capacitated lot-sizing problem (CLSP) with backlogging, which is proved to be NP-hard problem. It consists to find the optimal production plan while minimizing simultaneously the total inventory level and the total cost, under capacity restriction. Based on the basic NSGA-II algorithm that is population-based metaheuristic, two main contributions are integrated. As first contribution, in order to solve the CLSP, effectively, an efficient chromosome representation is designed to determine the different decision variables related to the target problem. Moreover, to enhance the quality of the initial solutions, a new procedure that generates the initial population is developed and presented as second contribution of this work. The performance of the proposed improved NSGA-II algorithm is tested using different instances sizes (small, medium and large). Four metrics, which are commonly used in the literature, are considered to evaluate and compare the performance of the developed algorithm with the basic NSGA-II. These metrics are, namely, number of non-dominated solutions (NPS), maximum spread (MS), solutions quality (SQ) and execution time. Regarding the considered performance metrics, experimental results proved the effectiveness of the proposed improved NSGA-II algorithm compared to the basic one.","['Engineering', 'Vibration, Dynamical Systems, Control', 'Control, Robotics, Mechatronics', 'Materials Engineering', 'Classical and Continuum Physics']"
doi:10.1007/978-3-031-16868-0_7,en,Architecture Design for RBs and DBs Based CNNs,OriginalPaper,"As mentioned in Part III, the research of CNN architectural design algorithms is now in the early phases, particularly for entirely automatic ones with great performance and using limited CPU resources. In this chapter, a novel GA-based method to automatically design CNN architectures named AE-CNN will be introduced with the following highlights. Firstly, the use of AE-CNN has no pre-conditions on any prior knowledge of basic CNN design, examined datasets, GA, pre-processing, re-composition, and post-processing. Secondly, the variable-length encoding technique is used to estimate the best CNN depth. The new operators for crossover and mutation are invented and included in for exploring and exploiting the search space in discovering the ideal CNN architectures in order to achieve variable-length encoding. Thirdly, for accelerating the architecture design, an efficient encoding approach according to RBs and DBs are designed, and limited computational resources are used, while AE-CNN achieves promising results. It is worth noting that, while the RBs and DBs are employed in AE-CNN, users are no need to be familiar with these blocks in order to use it.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2412-5_4,en,Symbiotic Organisms Search Algorithm-Based Optimal Allocation and Sizing of Capacitor Bank in Radial Distribution Networks,OriginalPaper,"Increased line losses in distribution networks is a result of rapid growth in load demand. Aside from that, maintaining voltage stability of the grid in a healthy state becomes a problem for the utility sectors due to fluctuating loads. This paper investigates optimal capacitor placement (OCP) in radial distribution system (RDS) using optimization techniques to solve the above issues. The current work solves the OCP problem using a simple and efficient symbiotic organisms search algorithm. The most desirable buses for the installation of the capacitor are discovered first using a sensitivity index study, minimizing the searching space for the optimization phase. The optimum size and position of the capacitor banks are then determined, with the goal of minimizing system losses and optimizing net annual profit. To demonstrate its effectiveness, the studied approach is applied on 69-, 85-, and 118 bus standard RDSs. Switchable capacitor banks are considered to deal with variable loading condition. Furthermore, the suggested method's performance under maximum load and variable load situations is compared to that achieved using existing cutting-edge methods to determine its utility.","['Engineering', 'Power Electronics, Electrical Machines and Networks', 'Renewable and Green Energy', 'Energy Storage']"
doi:10.1007/978-3-031-16832-1_3,en,JAYA Algorithm Versus Differential Evolution: A Comparative Case Study on Optic Disc Localization in Eye Fundus Images,OriginalPaper,"In various retinal vascular disorders such as Cataract, glaucoma, diabetic macula and diabetic retinopathy, eye fundus images are extensively used for diagnosis. Optic disc in eye fundus image is very bright and clear-cut spherical or vertically marginal elliptical shape. The other structures in an eye fundus image like exudates and lesions may look like optic disc. Therefore, the Localization of optic disc in eye fundus image is viewed as a search problem. This chapter deals with the evolutionary algorithm such as Differential Evolution and Jaya Algorithm to search the optic disc in an eye fundus image. The outcomes are inspected through performance measures and hypothesis test.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Engineering']"
doi:10.1007/978-3-031-09835-2_22,en,Multi-Objective Artificial Hummingbird Algorithm,OriginalPaper,"This chapter introduces Multi-Objective Artificial Hummingbird Algorithm (MOAHA), a multi-objective variation of the newly established Artificial Hummingbird Algorithm (AHA). The AHA algorithm simulates the specific flight skills and intelligent search strategies of hummingbirds in the wild. Three types of flight skills are used in food search strategies, including axial, oblique, and all-round flights. Multi-objective AHA is tested through 5 real-world engineering case studies. Various performance indicators, such as Spacing (S), Inverted Generational Distance (IGD), and Maximum Spread (MS), are used to compare the MOAHA to the MOPSO, MOWOA, and MOHHO. The suggested algorithm may produce quality Pareto fronts with appropriate precision, uniformity, and very competitive outcomes, according to the qualitative and quantitative.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-7648-3_12,en,Priority-Aware Computational Resource Allocation,OriginalPaper,"Vehicular fog computing (VFC) has been expected as a promising scheme that can increase the computational capability of vehicles without relying on servers. Comparing with accessing the remote cloud, VFC is suitable for delay-sensitive tasks because of its low-latency vehicle-to-vehicle (V2V) transmission. However, due to the dynamic vehicular environment, how to motivate vehicles to share their idle computing resource while simultaneously evaluating the service availability of vehicles in terms of vehicle mobility and vehicular computational capability in heterogeneous vehicular networks is a main challenge. Meanwhile, tasks with different priorities of a vehicle should be processed with different efficiencies. In this work, we propose a task offloading scheme in the context of VFC, where vehicles are incentivized to share their idle computing resource by dynamic pricing, which comprehensively considers the mobility of vehicles, the task priority, and the service availability of vehicles. Given that the policy of task offloading depends on the state of the dynamic vehicular environment, we formulate the task offloading problem as a Markov decision process (MDP) aiming at maximizing the mean latency-aware utility of tasks in a period. To solve this problem, we develop a soft actor-critic (SAC) based deep reinforcement learning (DRL) algorithm for the sake of maximizing both the expected reward and the entropy of policy. Finally, extensive simulation results validate the effectiveness and superiority of our proposed scheme benchmarked with traditional algorithms.","['Computer Science', 'Computer Systems Organization and Communication Networks', 'Communications Engineering, Networks', 'Wireless and Mobile Communication']"
doi:10.1007/978-981-19-3951-8_38,en,Renewable Energy Integrated Economic Dispatch Using Intelligent Techniques: An Overview,OriginalPaper,"Nature-inspired and metaphor-less population-based computational techniques have gained tremendous importance for solving real-world constrained optimization complications during the last twenty years. This is due to their unconventional direct search mechanism, ease of application and non-dependence on the mathematical nature of objective function. Amongst the various engineering optimization problems, the economic dispatch (ED) is one of the most important problems which has been addressed using a large number of these techniques. In power system operation, ED has a special place and therefore this topic has received immense attention from researchers. With changing operational philosophies and technological advancements, the ED problem formulation has undergone many changes over the years. Beginning with simple and approximate models, various different practical constraints were integrated into the classical ED problem over time, the latest being integration and modelling of the renewable energy (RE) sources. The paper presents a review of different metaheuristic techniques proposed for various types of ED problems with renewable energy integration based on the last decade.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-981-19-0098-3_2,en,Hybrid Ant Particle Swarm Genetic Algorithm (APSGA) for Task Scheduling in Cloud Computing,OriginalPaper,"In cloud computing technology, task scheduling is one of the research challenges. For these various algorithms, works such as particle swarm optimization (PSO), firefly algorithm, ant colony optimization (ACO) and genetic algorithm (GA). PSO is inspired by the bird’s movement, and ACO is based on the behaviour of ants. GA works based on the natural evolution process. This paper presents the hybrid of PSO-ACO-GA for task scheduling on virtual machines of cloud computing known as ant particle swarm genetic algorithm (APSGA). Here, GA and PSO will perform iteration to get the task basis on fitness value and further ACO will distribute the task on specific virtual machines. This paper has achieved improved results for parameters such as CPU utilization, makespan and execution time. Our proposed algorithm has achieved makespan that is reduced by 27.1%, 19.45% and 21.24% with compare to PSO, ACO and GA, respectively. It has achieved maximum of CPU utilization and execution time.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Statistics, general', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-19958-5_87,en,Maximum Flow by Network Reconstruction Method,OriginalPaper,A maximum flow algorithm based on network reconstruction method is proposed in this paper. The principal idea of the method is to identify an outmost route in the network and remove it in such a way that the reduced network has the same maximum value as the original network. The complexity of the algorithm decreases as number of iterations increases. Numerical illustrations and computational comparisons are used to prove the validity and efficiency of the algorithm respectively. Computational comparisons have revealed that the proposed method requires less number of iterations as compared to other algorithms.,"['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-05347-4_6,en,Ant Colony Optimization Algorithm with Three Types of Pheromones for the Component Assignment Problem in Linear Consecutive-k-out-of-n:F Systems,OriginalPaper,"The ant colony optimization (ACO) algorithm is a meta-heuristic optimization method used to solve challenging optimization problems. Notably, the pheromone model of ACO impacts algorithmic performance. Hence, this paper presents an ACO algorithm with three types of pheromones for solving the component assignment problem of the linear consecutive- k -out-of- n :F system. This configuration can be used to represent a real system in which consecutive failed components cause system failures. Moreover, the component assignment problem seeks a component arrangement in which system reliability is maximized. The proposed algorithm is incorporated with either adjacence-, position-, or k -interval-wise pheromones that are compared using a numerical experiment. The results indicate that the ACO algorithm with the position-wise pheromone performs well within the scope of the experiment.","['Mathematics', 'Mathematical Modeling and Industrial Mathematics', 'Risk Management', 'Engineering Economics, Organization, Logistics, Marketing']"
doi:10.1007/978-981-19-5615-7_47,en,Autonomous Vehicle Path Planning Based on Improved Ant Colony Algorithm,OriginalPaper,"Path planning is one of the key technologies for autonomous vehicles. Ant Colony Algorithm can effectively achieve the goal of path planning for autonomous vehicles, but the algorithm has the problems of low search efficiency and local optimal solution in path planning. Therefore, this paper improves the classical ant colony algorithm, using adaptive initial pheromone distribution range build initial pheromone distribution, at the same time improve stimulating factor enhanced heuristic search efficiency, and introduces the rollback strategy self-locking and deadlock problem and adopt preferential set limit to update pheromone strategy, help reduce blind ant search path, and reduce the redundancy of map information. The simulation results show that the improved ant colony algorithm can greatly improve the global search ability and convergence speed, and can help the autonomous vehicle to find the optimal path quickly.","['Engineering', 'Transportation Technology and Traffic Engineering', 'Computational Intelligence', 'Automotive Engineering', 'Energy Policy, Economics and Management', 'Mechanical Engineering']"
doi:10.1007/978-981-19-3250-2_3,en,A Monte Carlo Algorithm for Solving the Telegrapher’s Equations,OriginalPaper,"A Monte Carlo (MC) algorithm for the numerical solution of the telegrapher’s equation is derived, based on the Kac’s stochastic model. The major ideas are to use random values under exponential distribution to facilitate the calculation of the random time, and to accelerate the simulation for multiple points through recycling random time simulation. Compared with the MC method recently proposed in Acebron and Ribeiro ( 2016 ), the Kac’s model based method is able to handle two-dimensional (2-D) and higher-dimensional problems with unbounded domain, and 2-D bounded-domain problems with the homogeneous boundary condition. Moreover, it has an easy and efficient algorithmic implementation. With numerical experiments, we have validated the accuracy and efficiency of the proposed algorithms, and their applicability to some 2-D telegrapher’s equations.","['Engineering', 'Electronics and Microelectronics, Instrumentation', 'Engineering Mathematics']"
doi:10.1007/978-981-19-5574-7_3,en,Intelligent Segmentation of Furnace Flame Image,OriginalPaper,"In the edge detection process, it is Furnace  necessary to convert the color flame image into gray image, which will inevitably lead to the loss of some information of the flame image. For the actual furnace Furnace  safety monitoring system, only obtaining the edge position information of flame can not meet the production needs, nor can it realize the intelligent monitoring and diagnosis of combustion in the furnace Furnace . In order to realize the intellectualization of coal-fired power plants Coal-fired power plant , it is also necessary to mine the information of flame image in the furnace Furnace , such as color brightness information, color distribution, color difference between frames, and so on.","['Engineering', 'Control, Robotics, Mechatronics', 'Energy Systems', 'Computational Intelligence']"
doi:10.1007/978-981-19-4971-5_45,en,Performance Assessment and Improvement of Classifiers Using Error Correcting Output Code for Islanding Detection in Microgrid,OriginalPaper,"Islanding detection has become an important issue for interconnected power distribution systems. The main objective of the paper is to develop a new error correcting method which is reliant on the results of the pre-established classifiers. The measurements from different locations of the laboratory-based distribution system are collected, and the dimensionality is reduced using any one of the dimension reduction algorithms, i.e. principal component analysis, probabilistic principal component analysis, kernel principal component analysis and Andrews method. After dimension reduction, comparative analysis of classifiers for islanding detection in a laboratory-based microgrid has been established. The algorithms show unique characteristics when tested on the basis of decision surface, probability of classification and confusion matrix. The dimension reduction times and the classification training times are compared. Eventually, a novel error correcting output code has been implemented. The dimension reduction process used in this error correcting codes is a combination of kernel principal component and Andrews method. This error correcting method has been proved to be much beneficial for improving the accuracy of any type of classifiers for islanding detection.","['Engineering', 'Power Electronics, Electrical Machines and Networks', 'Energy Policy, Economics and Management', 'Energy Systems']"
doi:10.1007/978-3-031-21203-1_21,en,Weaponizing Actions in Multi-Agent Reinforcement Learning: Theoretical and Empirical Study on Security and Robustness,OriginalPaper,"Cooperative Multi-Agent Reinforcement Learning (c-MARL) enables a team of agents to determine the global optimal policy that maximizes the sum of their accumulated rewards. This paper investigates the robustness of c-MARL to a novel adversarial threat, where we target and weaponize one agent, termed the compromised agent , to create natural observations that are adversarial for its team. The goal is to lure the compromised agent to follow an adversarial policy that pushes activations of its cooperative agents’ policy networks off distribution. This paper shows mathematically the exploitation steps of such an adversarial policy in the centralized-learning and decentralized-execution paradigm of c-MARL. We also empirically demonstrate the susceptibility of the state-of-the-art c-MARL algorithms, namely MADDPG and QMIX, to the compromised agent threat by deploying four attack strategies in three environments in white and black box settings. By targeting a single agent, our attacks yield highly negative impact on the overall team reward in all environments, reducing it by at least 33% and at most 89.6%. Finally, we provide recommendations on improving the robustness of c-MARL.","['Computer Science', 'Artificial Intelligence']"
doi:10.1007/978-981-19-6068-0_23,en,Sequence Rule Mining for Insulin Dose Prediction Using Temporal Dataset,OriginalPaper,"The objective of pattern mining is to mine sensitive and non-critical information hidden from databases. Sequential rule mining is a pattern mining technique that retrieves rules in order. It has number of applications in different area including healthcare. Healthcare is the prime concern for human’s life. Insulin dependent diabetes mellitus (IDDM), which is also known as type-1 diabetes is a kind of chronic disease and patients of these disease needs to get insulin as a supplement or medicine. Technologies that predict the right amount of insulin dose for a patient is needed for correct prognosis of patients. It facilitates to better health in patients to maintain the glucose level in a specific range which produces the right energy for human cells. Our objective is to find insulin therapy plan for diabetes patients. In this work, we applied some sequential mining algorithms to predict the dosage values of regular, NPH and ultraLente insulin at three different time frames, i.e., at prebreakfast, prelunch, and presupper. Sequential rules are generated to predict the dosage ranges for different time frames with support and confidence metrics. These rules are used to recommend particular type of insulin with dosage amounts. This work also compares different sequential rule mining algorithms such as ERMiner, CMRules, CMDeo, and RuleGrowth with their memory taken and execution speeds. We concluded that by making sequences of blood glucose ranges with insulin dose ranges we can generate rules for insulin prediction as well as diabetes predictions. We can also conclude that after applying different sequential rule mining algorithms, ERMiner is faster among the algorithms but it takes more memory to execute.","['Computer Science', 'Artificial Intelligence', 'Computational Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-5403-0_31,en,Graded Classification of Liver Cirrhosis Using Machine Learning Algorithms on a Highly Unbalanced Dataset,OriginalPaper,"Liver cirrhosis is the fibrosis of liver caused by a long-term damage of the organ. This study classifies the disease in four classes based on a highly unbalanced dataset having 18 features and a data count of 6800 with labeled data of 465, 1507, 1322, and 3506 for the four classes using machine learning (ML) algorithms. Twelve ML algorithms have been deployed for the classification purpose which reflected the highest accuracy of 68.21% for the Histogram Gradient Boost Classifier. For further improvement of the accuracy, hyper-parameter tuning was done on all the ML algorithms which fetched the highest accuracy of 77.97% for the Gradient Boost Classifier (GBC). Further improvement of accuracy was observed with stacking model which furnished an accuracy of 84.24%. The stacked model comprised of the GBC as the meta-learner, and K -Nearest Neighbor (KNN), Xtreme Gradient Boost algorithm (XGB), Support Vector Machine (SVM), and the Light Gradient Boost Machine (LGBM) as the base-learners. To the best of our knowledge, this is the first attempt for graded classification of liver using all the ML algorithms, including hyper-parameter tuned and stacked models.","['Engineering', 'Computational Intelligence', 'User Interfaces and Human Computer Interaction', 'Data Structures and Information Theory', 'Artificial Intelligence', 'Data Mining and Knowledge Discovery']"
doi:10.1007/978-981-19-3391-2_7,en,A Comparison of Algorithms for Bayesian Network Learning for Triple Word Form Theory,OriginalPaper,"The triple word form (TWF) theory provides a formal framework for understanding the cognitive processes involved in reading and spelling. On the basis of this theory, spelling errors can be classified into different types, and by understanding the relationships between these error types, one can draw inferences about the difficulties students face while spelling. This paper examines data from 210 second-grade, bilingual students in Kerala, South India. These students participated in a spelling test, and their spelling errors on the test were classified according to the TWF theory. Bayesian networks were used to understand the relationships between the error types. This paper compares three algorithms that were used to study the structure of the Bayesian networks: a score-based algorithm, a constraint-based algorithm, and a hybrid algorithm. Using tenfold cross-validation, it was found that among these three algorithms, the score-based algorithm performed best in terms of expected loss.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Statistics, general', 'Cyber-physical systems, IoT', 'Professional Computing', 'Communications Engineering, Networks']"
doi:10.1007/978-3-031-20601-6_34,en,A Robust Privacy Preserving Approach for Sanitizing Transaction Databases from Sensitive High Utility Patterns,OriginalPaper,"Utility-Based Mining (UBM) is one of the fundamental problems in data mining technologies that has attracted the research community for many years. UBM algorithms are often applied to transaction databases, where they target the detection of patterns that have the potential to build critical decisions. Unfortunately, these algorithms can be misused, and even lead to major privacy issues for data holders. To cope with these issues, Privacy-Preserving Utility Mining (PPUM) algorithms have been recently employed as a defensive mechanism against the unauthorized use of utility mining techniques. However, the current performance of the existing PPUM algorithms is still limited and can drastically decrease the quality of the database, making it useless and unreliable source of information. In this research, we present a privacy-preserving solution based on the concept of utility. In particular, a heuristic approach; named Selecting the Best two Victim items First (SB2VF), is developed to hide the sensitive patterns that can be extracted from transactional databases after applying a UBM algorithm. Our main goal is to promote data sharing and publishing by providing data owners with an effective way to sanitize their data from the confidential knowledge that might prevent them from releasing their data. The proposed SB2VF adopts an effective technique to identify the appropriate victim items in each sensitive itemset. Also, a novel sorting technique is suggested to identify the appropriate victim transactions for each sensitive itemset. The experimental results show that the proposed SB2VF has very promising and encouraging overall performance and can result in minor side effects than other heuristic approaches.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-6068-0_39,en,Diabetes Prediction Using Ensemble Methods,OriginalPaper,"Diabetes is considered to be one of the most common, severe and deadliest disease as it can lead to various complications and diseases such as renal disease, kidney problems, heart diseases, blindness and many more. The early detection is extremely important for its timely treatment. Hence, there is a need to design and develop a model that can easily predict diabetes in patients. For the purpose of our study, we have used the Indian PIMA dataset that is available in the UCI machine learning repository. It consists of nine attributes and the records of about 768 female patients. We have used various machine learning algorithms along with some ensemble techniques.","['Computer Science', 'Artificial Intelligence', 'Computational Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-5184-8_9,en,Analyzing the Impact of COVID-19 and Vaccination Using Machine Learning and ANN,OriginalPaper,"The proposed method examines newly developed predicting models in-depth and forecasts the numerous cases of confirmed, recovered, and fatality caused through coronavirus in India. To improve the COVID-19 impact analysis, machine learning techniques such as decision tree, multiple linear model (MLR), random forest, Support Vector Machine algorithm (SVM), and Artificial neural network model were utilized for enhancing precision. With an 0.9992 R 2 score, the projected number of cases matches the actual numbers quite well. A follow-up on the vaccination and its effects is required for research and the development of new ways to protect us from the disease. Also, using XGBoost, the accuracy has been improvised. Importing the matplotlib package is used to visualize the COVID-19 data. Finally, before and after the vaccine, a performance analysis was implemented.","['Engineering', 'Computational Intelligence', 'Statistics, general', 'Artificial Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-3391-2_17,en,A Comprehensive Survey of Datasets Used for Spam and Genuineness Views Detection in Twitter,OriginalPaper,"Social media is one of the evolving platforms to share the views. The social media such as Twitter, Instagram, Facebook, and other microblogging sites floats lot of information from one corner of the world to another corner. This information can be used for the various purposes. Social media plays major role in collection of wide variety of information. This wide variety of information can be used to extract sentiments, opinions, spam, and genuineness of views shared by the users. To perform the experimentation, proper datasets should be available. In this survey paper, we have throws light on the recent datasets used for experimentations. We have analyzed the results obtained by using various datasets and its performance. By comparing the results and performance, we try to analyze the suitable domain datasets which will give the better results after applying various methods, techniques, and algorithms.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Statistics, general', 'Cyber-physical systems, IoT', 'Professional Computing', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-6004-8_56,en,Review and Comparative Analysis of Unsupervised Machine Learning Application in Health Care,OriginalPaper,"Artificial intelligence had the most significant leap in the last two decades. In health care, artificial intelligence can be applied to many different task solutions. One of the machine learning types is unsupervised learning, and the most known type of this is clustering. Scientific researches show that clustering algorithms can be applied to identify different diseases. However, although there are many new clustering algorithms, k-means, hierarchal agglomerative clustering, and k-modes methods are still the most widely used algorithms, as these are fast-acting and work well with specific datasets. This work aims to give a brief overview of machine learning and pay more attention to unsupervised machine learning and clustering. Briefly introduce the current clustering methods in the medical field and apply the clustering methods to different medical and non-medical datasets. Results showed that different methods work best for the different datasets, and there are no universal clustering methods for all datasets. Results showed that for the E. coli dataset, the best method tested was BIRCH, but for the cancer clustering, the dataset's best model was Gaussian mixture model.","['Engineering', 'Computational Intelligence', 'Cognitive Psychology', 'Personality and Social Psychology', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-5077-3_34,en,Energy Assessment of a Hybrid Multiple Stage Evaporator Using Metaheuristic Algorithms,OriginalPaper,"This paper encases the energy optimization of an energy integrated heptad-based Multiple Stage Evaporator (MSE) used to escalate the solid concentration of the aqueous black liquor obtained from the pulp and paper mill. A standalone MSE is designated as the most energy-intensive unit, hence, various Energy Reduction Schemes (ERSs) are integrated to enhance the energy efficiency of this unit. Steam Consumption (SC) and Steam Economy (SE) are the two major energy efficiency parameters to judge the energy performance of the MSE. Hence, a single objective optimization problem is developed by considering the interrelation of SE and SC as the objective function for the hybrid MSE. The dependency of the problem variables is stated by the constraint functions developed by employing thermo-dynamical laws that create a couple of nonlinear equations for each stage of MSE. The solution to this optimization problem is obtained using two metaheuristic approaches named Differential Evolution Algorithm and Archimedes Optimization Algorithm. Employment of these algorithms provides excellent performance in searching for optimized unknown process parameters with enhanced energy efficiency for this complex optimization problem.","['Environment', 'Environment, general', 'Geoengineering, Foundations, Hydraulics', 'Sustainable Development', 'Environmental Engineering/Biotechnology']"
doi:10.1007/978-981-19-2879-6_1,en,A General Introduction to Artificial Intelligence,OriginalPaper,"The emergence and rise of artificial intelligence undoubtedly played an important role during the development of the Internet. Over the past decade, with extensive applications in the society, artificial intelligence has become more relevant to people’s daily life. This chapter introduces the concept of artificial intelligence, the related technologies, and the existing controversies over the topic.","['Computer Science', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1610-6_22,en,Real-Time and Zero-Footprint Bag of Synthetic Syllables Algorithm for E-mail Spam Detection Using Subject Line and Short Text Fields,OriginalPaper,"Contemporary e-mail services have high availability expectations from the customers and are resource-strained because of the high-volume throughput and spam attacks. Deep machine learning architectures, which are resource hungry and require offline processing due to the long processing times, are not accepted at the front-line filters. On the other hand, the bulk of the incoming spam is not sophisticated enough to bypass even the simplest algorithms. While the small fraction of the intelligent, highly mutable spam can be detected only by the deep architectures, the stress on them can be unloaded by the simple near real-time and near zero-footprint algorithms such as the bag of synthetic syllables algorithm applied to the short texts of the e-mail subject lines and other short text fields. The proposed algorithm creates a circa 200 sparse dimensional hash or vector for each e-mail subject line that can be compared for the cosine or Euclidean proximity distance to find similarities to the known spammy subjects. The algorithm does not require any persistent storage, dictionaries, additional hardware upgrades or software packages. The performance of the algorithm is presented on the one day of the real SMTP traffic.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-18256-3_5,en,Design and Comparison of Artificial Intelligent Algorithms for Breast Cancer Classification,OriginalPaper,"Breast cancer early detection is a critical factor associated to patient survival and treatment cost reduction. Nevertheless, it is difficult to obtain a diagnose at earliest stages since it does not cause any symptoms. Recently, artificial intelligence field has demonstrated to be a suitable alternative to improve classification and early detection for this affection. Therefore, this paper proposes the design and comparison of three artificial intelligent algorithms for breast cancer classification. The algorithms used for classification were a naive Bayesian network (NBN), a support vector machine (SVM), and an artificial neural network (ANN). These algorithms were trained and validated in the Breast Cancer Prediction Database, located on the Kaggle platform. This database contains ten real-valued features computed from benign and malignant tumors. The evaluation results in F1 score shown 94%, 92% and 91% for the NBN, ANN and SVM respectively. These scores were compared with state-of-the-art algorithms to demonstrate the robustness of the proposed algorithms. The comparison was made considering feature-based and image-based models. Findings shown that our feature-based algorithms obtained competitive results requiring less computational resources than image-based models. Therefore, algorithms here proposed are a good option for the development of a high-fidelity system to classify the mentioned database into the cancer and non-cancer categories.","['Engineering', 'Biomedical Engineering and Bioengineering', 'Regenerative Medicine/Tissue Engineering', 'Bioinformatics']"
doi:10.1007/978-981-19-4960-9_35,en,Heart Disease Diagnosis Using Machine Learning Classification Techniques,OriginalPaper,"Heart disease is one of the leading causes of mortality around the globe, including third world nations such as Bangladesh. While accurately predicting cardiac illness is a difficult and time-consuming task, it is possible using modern machine learning (ML) approaches to achieve a tolerable degree of accuracy. This study explains our suggested approach for predicting heart illness, which aims to achieve the objective of identifying relevant variables by using machine learning algorithms, hence increasing the accuracy of the predicted heart disease. Our data set consists of 14 characteristics, which may be found on the UCI repository. We developed our model by employing classification methods such as maximum entropy, random forest, and support vector machine to learn about the world (SVM). Despite the fact that accuracy for various algorithms varies depending on the number of instances in the data set, SVM provided the greatest performance in our proposed system, with an accuracy level of 92.67% for the threshold instances of the data set in our suggested system. The proposed working approach has achieved 20% more accurate results as compared to existing results.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Professional Computing']"
doi:10.1007/978-3-031-16865-9_58,en,"Analysis of Data Mining Algorithms for Predicting Rainfall, Crop and Pesticide Types on Agricultural Datasets",OriginalPaper,"Data mining is a classification technique that can be used to handle large volumes of data. Hence, data mining has evolved as an excellent solution for large agricultural datasets. This is partly because it can predict categorical class labels, classify data based on training set and class labels, and it can also evaluate new data. In agricultural production, farmers and agribusiness representatives need to make daily decisions. However, accurate yield estimate of the various crops related to the planning is a critical issue for agricultural plannings. Data mining technique is therefore required for achieving realistic and effective outcomes. The aim of this study is to classify different data features and implement various algorithms as it relates to agricultural big data. Additionally, a given dataset is preprocessed to ensure that relevant data is present in all datasets. Algorithms such as Rule JRIP, Tree LMT, and Naive Bayes are implemented. Then, the Mean Absolute Error (MAE) and Relative Absolute Error (RAE) were compared, and the performance error of the resulting classification algorithm is performed on each dataset. The overall results indicates that JRIP has the highest efficiency with a value of 96%. This is followed by Naive Bayes which has 84% efficiency, whereas tree LMT has 78% efficiency. The result of this study can help to advance current research, as well as benefit future research in the agricultural sector.","['Engineering', 'Computational Intelligence', 'Data Engineering']"
doi:10.1007/978-981-19-5403-0_29,en,SMS Spam Detection Using Deep Learning Approach,OriginalPaper,"The popularity of mobile phones has increased drastically in the recent years which is making users vulnerable to various threats like SMS spam, where the user is deceived into revealing private information that could result in a security breach. The motivation of this research is to curb the attackers, hackers, etc., from using SMS spam to exploit mobile device users. Several researchers proposed various machine learning models to automatically detect spam, but they could not achieve a commendable accuracy rate. In this research, several machine learning and deep learning models are utilized to detect SMS spam. A dataset from UCI is used and deep learning models are developed to detect and classify SMS spam using LSTM and BERT. The results are compared with the previous models in SMS spam detection. The proposed deep learning approach obtained the highest accuracy of 99.28% using BERT and 98.84% using LSTM. We utilized Python for all implementations.","['Engineering', 'Computational Intelligence', 'User Interfaces and Human Computer Interaction', 'Data Structures and Information Theory', 'Artificial Intelligence', 'Data Mining and Knowledge Discovery']"
doi:10.1007/978-3-030-89123-7_233-2,en,Situation Awareness of Field Robots,ReviewPaper,,"['Life Sciences', 'Agriculture', 'Data Engineering', 'Signal, Image and Speech Processing', 'Control, Robotics, Mechatronics']"
doi:10.1007/978-3-031-17576-3_9,en,"A Novel Big Data Classification Technique for Healthcare Application Using Support Vector Machine, Random Forest and J48",OriginalPaper,"In this study, the possibility of using and applying the capabilities of artificial intelligence (AI) and machine learning (ML) to increase the effectiveness of Internet of Things (IoT) and big data in developing a system that supports decision makers in the medical fields was studied. This was done by studying the performance of three well-known classification algorithms Random Forest Classifier (RFC), Support Vector Machine (SVM), and Decision Tree-J48 (J48), to predict the probability of heart attack. The performance of the algorithms for accuracy was evaluated using the Healthcare (heart attack possibility) dataset, freely available on kagle. The data was divided into three categories consisting of (303, 909, 1808) instances which were analyzed on the WEKA platform. The results showed that the RFC was the best performer.","['Engineering', 'Computational Intelligence', 'Machine Learning', 'Big Data']"
doi:10.1007/978-3-031-18409-3_11,en,"State of the Art of Cybersecurity in Cooperative, Connected and Automated Mobility",OriginalPaper,"In recent years, mobility systems have been steadily improving their performance in terms of connectivity, allowing road users to communicate among them and with the road infrastructure either directly or through internet cloud-based services. The aim of this contribution is to provide an overview of inter-vehicle communications cybersecurity challenges in the cooperative, connected and automated mobility sector and make possible a further analysis of the cryptographic methods and tools that can leverage their security in a world where quantum computers will be a practical menace at some point in the future.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Education, general']"
doi:10.1007/978-3-031-09835-2_20,en,Applying the Population-Based Ant Colony Optimization to the Dynamic Vehicle Routing Problem,OriginalPaper,"The population-based ant colony optimization (P-ACO) algorithm is a variant of the ant colony optimization metaheuristic specifically designed to address dynamic optimization problems. Whenever a change in the environment occurs, P-ACO repairs the pheromone trails affected by the change using previous solutions maintained in a population-list. Typically, change-related information are utilized for repairing these solutions. The change-related information for this dynamic vehicle routing problem (DVRP) case are the nodes removed and inserted when a change in the environment occurs. In this chapter, the operators of the unstringing and stringing (US) heuristic are utilized for repairing the solutions. Experimental results demonstrate that P-ACO embedded with the US heuristic outperforms other peer methods in a series of DVRP test cases.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3015-7_4,en,A Performance Study of Prediction Models for Diabetes Prediction Using Machine Learning,OriginalPaper,"During the past couple of decades, the geriatric community is commonly affected by a well-known disease, namely diabetes. Recently, many researchers are focusing on developing a prediction model which can accurately predict if the patient is affected by diabetes at an early stage so that they can prevent further complications in health. The proposed research work focuses on analyzing the performance of various machine learning algorithms such as logistic regression, support vector machine, KNN, random forest, naïve Bayes, and gradient boosting classifier which could be used as a prediction model for predicting the common disease diabetes. The performance of these machine learning algorithms is compared, evaluated, and validated using the accuracy score. The results show that random forest classifier outperforms all the other classification algorithms considered for the study.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Engineering', 'Data Mining and Knowledge Discovery', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-3-031-19945-5_1,en,Question Classification for Albanian Language: An Annotated Corpus and Classification Models,OriginalPaper,"Question classification has an important role in Question Answering systems by determining the expectation for the correct answer to the question. The question classification system aims to determine the question type and based on it can be given the correct answer for the question. This paper presents the first questions annotated corpus in Albanian language using a six-classes tag-set. The annotated corpus is used to train and test three machine learning algorithms for question classification task using a variety of metrics. Furthermore, we conclude our work by analyzing and comparing the performance of the implemented models and giving direction for future improvement of the models. In terms of accuracy, the best performant algorithm is SVM.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Computer Applications']"
doi:10.1007/978-981-19-7842-5_2,en,Video Tracing of Moving Objects by Fusing Three-Term Decompositions,OriginalPaper,"In this work, low-rank representation of video with the aim of background modelling and subtraction in order to trace moving objects is investigated based on three-term decompositions. The input video is modelled as a 3-way tensor and over it are applied separately 3-Way-Decomposition (3WD), Motion-Assisted Matrix Restoration (MAMR), Robust Motion-Assisted Matrix Restoration (RMAMR) and the Alternating Direction Method of Multipliers (ADMM). The results from detecting moving objects from the 2 most accurate algorithms (3WD and MAMR) are then combined on a frame basis in order to get more precise results. Two fusing techniques are applied using the logical OR and AND operations. The results are promising and render the proposed algorithms applicable in fields such as video surveillance, vehicle traffic control, crowd monitoring and others.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4017-0_3,en,Machine-Learning Basics,OriginalPaper,"In Chap.  1 , we discussed how machine-learning algorithms differ from traditional algorithms. This chapter will introduce some machine-learning terminologies as well as some details about the working of ML algorithms.","['Engineering', 'Circuits and Systems', 'Artificial Intelligence', 'Mathematics, general', 'Special Purpose and Application-Based Systems', 'Computer Science, general']"
doi:10.1007/978-981-19-2821-5_40,en,"A Review on Machine Learning-Based Patient Scanning, Visualization, and Monitoring",OriginalPaper,"One of the most important topics for society is human health care; to find the appropriate diagnose or correct diseases, detection is the primary key to get appropriate care; traditional technique is facing many challenges from delay or unnecessary treatment to incorrect diagnoses which lead to a diagnostic error that can effect on the treatment progress, increasing the bill, and give more time to the disease to spread or affect and harm the patient body. Those such errors could be avoided and minimized by using machine learning algorithms. In recent years, many significant efforts have indeed been developed to increase computer-aided diagnosis detection applications, which is a rapidly increasing area of research, and machine learning algorithms are particularly significant in CAD, which is used to detect patterns from medical data sources and making nontrivial predictions could assist the doctor and clinical in making decisions on time. This paper will discuss different ML algorithms that are used in diagnosing different diseases. Therefore, in this paper two major diseases have been chosen like cancer and heart disease, and the use of several ML algorithms applied their performance and accuracy.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-3-031-19067-4_1,en,Distributed Optimization in Machine Learning,OriginalPaper,"Machine learning is revolutionizing data-driven decision-making in a myriad applications including search and recommendations, self-driving cars, robotics, and medical diagnosis.","['Mathematics', 'Algorithms', 'Machine Learning', 'Algorithm Analysis and Problem Complexity', 'Artificial Intelligence', 'Probability Theory and Stochastic Processes', 'Computer Science, general']"
doi:10.1007/978-3-031-07422-6_16,en,Hungary,OriginalPaper,"The emergence of data-driven business models, data analytics and algorithms provide unprecedented opportunities to gain and maintain a competitive advantage on the part of big tech service providers whose main income is from the analysis, processing and selling of data. However, this also triggers high exposure by individuals through technology because there seems to be a significant imbalance between providers and users. The use of digital services and the utilisation of algorithms and artificial intelligence (AI) is now essential in the enforcement activities of various regulatory agencies prosecuting consumer protection, competition and data protection infringements, and it seems that it is necessary to provide a coordinated answer to the issues raised by new business models, considering the interplay between privacy law, competition law and consumer protection law issues.","['Law', 'Private International Law, International & Foreign Law, Comparative Law', 'IT Law, Media Law, Intellectual Property', 'Artificial Intelligence', 'Online Marketing/Social Media', 'Big Data', 'International Economic Law, Trade Law']"
doi:10.1007/978-3-031-07242-0_7,en,Cloud Computing and Information Security,OriginalPaper,"Computer security issues exacerbate with growth of the Internet as more people and computers join the web, opening new ways to compromise an ever-increasing amount of information and potential for damages. However, an even bigger challenge to information security has been created with the implementation of Cloud Computing. This chapter gives a description of information security issues and solutions. Some information security challenges that are specific to Cloud Computing are described. Security solutions must make a trade-off between the amount of security and the level of performance cost. The key thesis of this chapter is that security solutions applied to Cloud Computing must span multiple levels and across functions. A few key challenges related to Cloud Computing and virtualization are presented. Our goal is to spur further discussion on the evolving usage models for Cloud Computing and security. Any such discussion needs to address both the real and perceived security issues. Then we present security using encryption keys, challenges in using the standard security algorithms, and Cloud Computing security practices. We wrap up this chapter with a discussion of side channel security attacks and an introduction to block chain technology.","['Engineering', 'Circuits and Systems', 'Communications Engineering, Networks', 'Computer Communication Networks']"
doi:10.1007/978-3-031-21595-7_4,en,Benchmarking Concept Drift Detectors for Online Machine Learning,OriginalPaper,"Concept drift detection is an essential step to maintain the accuracy of online machine learning. The main task is to detect changes in data distribution that might cause changes in the decision boundaries for a classification algorithm. Upon drift detection, the classification algorithm may reset its model or concurrently grow a new learning model. Over the past fifteen years, several drift detection methods have been proposed. Most of these methods have been implemented within the Massive Online Analysis (MOA). Moreover, a couple of studies have compared the drift detectors. However, such studies have merely focused on comparing the detection accuracy. Moreover, most of these studies are focused on synthetic data sets only. Additionally, these studies do not consider drift detectors not integrated into MOA. Furthermore, None of the studies have considered other metrics like resource consumption and runtime characteristics. These metrics are of utmost importance from an operational point of view. In this paper, we fill this gap. Namely, this paper evaluates the performance of sixteen different drift detection methods using three different metrics: accuracy, runtime, and memory usage. To guarantee a fair comparison, MOA is used. Fourteen algorithms are implemented in MOA. We integrate two new algorithms (ADWIN++ and SDDM) into MOA.","['Computer Science', 'Software Engineering/Programming and Operating Systems', 'Computer Communication Networks', 'Database Management', 'Data Mining and Knowledge Discovery', 'Information Systems Applications (incl. Internet)', 'Machine Learning']"
doi:10.1007/978-981-19-2764-5_21,en,Power Enhancement of Total-Cross-Tied Configured PV Array During Dynamic Irradiance Change Using Metaheuristic Algorithm-Based MPPT Controllers,OriginalPaper,"Partial shading condition (PSC) is the major threat to the building-integrated PV systems as they are sorely affected in terms of drastic reduction in PV output power and efficacy. To enhance the maximum power production capability and efficacy, the PV system needs a robust maximum power point tracking (MPPT) controller capable of tracking global maximum power peak (GMP) under PSCs. Many conventional algorithms, i.e., incremental conductance (Inc) , perturb and observe (P&O), etc., are reported in literature, but they are failed to track GMP and also create significant power oscillations in steady state during PSCs. Hence, this paper proposes metaheuristic algorithms-based TCT-configured PV MPPT system. In this, metaheuristic algorithms such as artificial bee colony (ABC), grey wolf optimization (GWO), and particle swarm optimization (PSO) techniques are applied to TCT-configured PV array to operate at GMP under four dynamic PSCs. All the metaheuristic algorithm-based MPPT methods are simulated in MATLAB/Simulink platform and their performances are compared with each other and also with conventional P&O and Inc techniques with respect to achieved GMP, tracking speed/convergence time, efficiency, and oscillations at GMP. The presented simulation results confirm that PSO algorithm outperforms other methods by achieving the highest GMP, efficiency, less convergence time, and reduced oscillations around GMP.","['Energy', 'Energy Systems', 'Artificial Intelligence', 'Machine Learning', 'Cyber-physical systems, IoT', 'Professional Computing', 'Power Electronics, Electrical Machines and Networks']"
doi:10.1007/978-3-031-08395-2_5,en,Artificial Intelligence Empowered Models for UAV Communications,OriginalPaper,"UAVs and AI are used for a variety of tasks, including object detection, segmentation, tracking, facial recognition, fire and smoke detection, and so on. Drones can collect data from sensors thanks to AI, resulting in a smart, agile model for businesses and consumers. AI technology aids UAVs in identifying things while in flight, resulting in data collection and analysis on the ground. UAVs can recognize and track objects using a neural network, which is considered the foundation model of AI. Drones also help in conducting risky work in construction sites and monitoring agricultural activities. UAVs use a variety of methods from machine learning, which is a subset of artificial intelligence. Deep learning, a subset of machine learning, is also included, which aids with object detection and image recognition. This chapter discusses the usage of artificial intelligence techniques in real-world scenarios. It also discusses usage of UAV in various fields. Better connectivity, a good prediction system, and increased UAV network performance are all made possible by combining AI, ML, and DL. Because they capture photographs via drones and large data is smoothly linked with multiple commercial applications, AI-based platforms offer a lot of potentials.","['Engineering', 'Cyber-physical systems, IoT', 'Transportation Technology and Traffic Engineering', 'Communications Engineering, Networks', 'Robotics']"
doi:10.1007/978-3-031-20631-3_1,en,A Unified Approach to the Synthesis of Hypercomplex-Valued CORDIC-Like Algorithms,OriginalPaper,"A systematized analysis of such hardware-oriented computational algorithms as CORDIC-like algorithms for fast solving linear algebra problems in signal, image and speech processing is given. The aim of this survey is a formulation of unified approach to the methodology of factorizing complex and hypercomplex numbers (HNs) and their matrix representations for the implementation of the linear transformations with the dimension of space m  = 2, 3, 4, 8. These iterative algorithms are called discrete linear transforms (DLTs). They involve iterative factorization of HNs with fixed factors of simple form and determining the required factorization operators in each iteration. This approach significantly saves time and physical resources when implementing DLTs. The analysis includes well-known CORDIC-like algorithms and those previously proposed by the author. An example is provided to illustrate the methodology. As a result, the research formulates the steps of the methodology. The article can help researchers to get a general view of the ways to solve an identified problem.","['Engineering', 'Electronics and Microelectronics, Instrumentation', 'Electrical Engineering']"
doi:10.1007/978-3-031-12011-4_77,en,Size Optimization of Truss Structures Using Real-Coded Genetic Algorithm with a Novel Constraint Handling Method,OriginalPaper,"Minimum weight design has been increasingly important in the twenty-first century due to rising concerns about reducing the carbon footprint of structures. Further, it also reduces the cost by better utilization of the materials. The advances of metaheuristic algorithms have resulted in the ability to attain global optimum even for highly non-linear, non-convex problems such as structural size optimization of complex structures. However, the computational time for the optimization process could increase drastically with the complexity of the problem. Therefore, the requirement for reducing the computational time of the process is essential. This research aims to do weight minimization for truss structures by size optimization using a real-coded genetic algorithm. A new constraint handling technique called the ‘corner bounding fly-back mechanism’ is proposed in this work. The proposed method enables a feasible set of solutions during each iteration and produces a higher convergence rate than other traditional methods. A series of well-known benchmark examples in the literature are optimized using the proposed method, coded in MATLAB. The numerical results obtained indicate that the convergence rate for the proposed method is about four to ten times when compared to other conventional constraint handling methods in the literature.","['Engineering', 'Construction Management', 'Building Construction and Design', 'Geotechnical Engineering & Applied Earth Sciences']"
doi:10.1007/978-3-031-16072-1_36,en,Trustworthy Artificial Intelligence for Cyber Threat Analysis,OriginalPaper,"Artificial Intelligence brings innovations into the society. However, bias and unethical exist in many algorithms that make the applications less trustworthy. Threats hunting algorithms based on machine learning have shown great advantage over classical methods. Reinforcement learning models are getting more accurate for identifying not only signature-based but also behavior-based threats. Quantum mechanics brings a new dimension in improving classification speed with exponential advantage. In this research, we developed a machine learning-based cyber threat detection and assessment tool. It uses two-stage (unsupervised and supervised learning) analyzing method on 822,226 log data recorded from a web server on AWS cloud. The results show the algorithm has the ability to identify the threats with high confidence.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16075-2_10,en,Detecting Complex Intrusion Attempts Using Hybrid Machine Learning Techniques,OriginalPaper,"Organizations are in a constant race to secure their services and infrastructure from ever-evolving information security threats. The primary security control of the arsenal is the Intrusion Detection System (IDS), which can automatically detect attacks and intrusion attempts. For the IDS to be effective, it needs to detect all kinds of attacks while not disturbing legitimate traffic by erroneously classifying them as attacks and affecting normal operations. Additionally, IDS needs to detect previously unknown attacks that do not exist in its knowledge base. This capability is traditionally achieved by anomaly detection based on trends and baselines; an approach that is prone to high false-positive rates. This paper will explore the most appropriate machine learning algorithms and techniques, specifically hybrid machine learning. This hybrid approach will combine unsupervised and supervised machine learning to detect previously unknown attacks while minimizing false positives by analyzing events generated by different connected systems and devices.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3571-8_73,en,An Analysis on Predicting Social Media Ads Using Kernel SVM Function,OriginalPaper,"This paper predicts the social media users who will buy a car based on the previously observed dataset. The dataset is extracted from user who has undergone the search of cars and advertised by it in the Internet. The particular dataset has attributes such as User ID, Gender, Age, Estimated Salary, and Purchased car. Using certain data mining methods, we predict the customer who’s most likely to buy a car and our focused gets on entirely on respective users. Ignoring those are not really ready to purchase a car at that time. This helps marketing department where to relay on hence, saving of money and time on par with having an analysis of going whether to car or not. This gives an idea to monitor on certain users to look up for. Push on the ads to these users who are most likely to purchase. Concentrating less on those are unlikely to buy based on dataset, we have extracted. Based on the analysis of the data extracted, we used different kernel SVM techniques and already existing data mining models, according to this data we say which algorithm gave an effective result, and conclude the best algorithm. The approach we going to possess is via confusion matrix and get concluded on accuracy, precision, specificity, etc.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-5221-0_70,en,Performance Evaluation of Heart Disease Disorder Diagnosis Using Intelligent Supervised Machine Learning Classifiers,OriginalPaper,"The heart plays an important character in living things. Diagnosis and prognosis of heart disease needs greater completeness and accuracy because a small mistake can lead to extreme problems or loss of the person, there are many heart-related deaths and the number is expanding rapidly everyday. To solve this problem, a disease awareness prediction system is a key requirement. Machine learning is a type of artificial intelligence (AI). It provides outstanding support for the prediction of all types of events caused by natural disasters. In this article, we calculate the correctness of machine learning algorithms for heart disease prediction, as these algorithms are k-proximal neighbors, decision tree, linear regression, and support vector machine (SVM) in using UCI benchmark data sets for training and testing. The best tool to implement Python programming is the Anaconda (Jupyter) notebook, which contains many kinds of libraries and header files that make the task crisp and efficient.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Sociology, general', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-3035-5_60,en,Machine Learning-Based Depression Detection,OriginalPaper,"Depression is an extremely serious illness of humans which causes constant mood swings and feelings of sadness. Nowadays, it is considered to be a deadly disorder in the world. At present, everyone from young to old is suffering from depression but most of them do not have the right idea about their mental state. Everyone needs to have a proper idea about their mental state. We will detect depression through a machine learning-based detection approach. Talking with psychologists and depressed people, we find some factors that are related to becoming depressed, and depending on those factors, information is collected from both depressed and non-depressed people. After applying preprocessing techniques, a processed dataset was created finally. Then, feature selection techniques were used. We applied eight machine learning algorithms and two feature selection methods to our dataset. We used k-nearest neighbor ( k -NN), decision tree (DT), linear discriminant analysis (LDA), adaptive boosting (AB), support vector machine (SVM), naive Bayes (NB), random forest (RF), and logistic regression (LR) classifier. In our work, the RF classifier gave the best performance based on accuracy and the accuracy of the RF classifier was 96.00%.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Statistics, general']"
doi:10.1007/978-981-19-6737-5_19,en,Machine Learning-Based Investigation of Employee Attrition Prediction and Analysis,OriginalPaper,"Employees are a company’s most valuable assets. However, if they left their jobs suddenly, it might cost a company a lot of money. Consequently, companies nowadays are actively seeking tools and technologies that can help in accurate and early employee attrition prediction. The main focus here shall be on the visualization of the available employee data in order to gain intuitive insights on the correlation among attributes and top causes behind the attrition. In this paper, we present the comparison of four algorithms used to predict whether an employee will leave or not, based on various attributes like age, salary, experience, etc., along with intuitive visualizations and its importance. The models used for prediction are random forest, logistic regression, K-nearest neighbor, and Naïve Bayes classifier. Thus, the visual analysis of employee attrition problem and accurate prediction can allow HR managers to take precautionary actions to retain the employee within the company.","['Computer Science', 'Computer Communication Networks', 'Computer Applications', 'Computer System Implementation', 'Artificial Intelligence', 'Image Processing and Computer Vision']"
doi:10.1007/978-981-19-1976-3_34,en,Privacy Preserving Datamining Techniques with Data Security in Data Transformation,OriginalPaper,"Data mining is the process of pattern recovery in multiple database fields. Big data is the great volume of data that is being processed in the environment of data mining. It is therefore impossible to use hand-held database management tools or typical data processing programme to collect data sets, so that data mining techniques have been deployed. An effective data transformation is a vital prerequisite for facilitating an efficient process for discovering information on a wider scale. I would want to mention that in present PPDM research, certain fundamental problems are not addressed. First of all, Privacy Preserving Data Mining (PPDM) does not have a standard terminology. Second, for the centralised database, most algorithms are developed. However, data are commonly stored in several sites in today’s global digital world. Third, many algorithms are focused on safeguarding the privacy of personal information, but do not focus on data mining results. There is no single approach to obtain data and to hide limitations. Fourth, each algorithm is specialised on data mining tasks primarily. No single strategy can work for any type of data clustering algorithm. Part of data privacy also is a crucial role in transforming data after data storage. These can be used as a guide to future PPDM research. Present research explores the privacy of data mining with various ways to approach the scope of new development approach.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-1-0716-2819-5_16,en,Phased Genome Assemblies,OriginalPaper,"The ultimate goal of de novo assembly of reads sequenced from a diploid individual is the separate reconstruction of the sequences corresponding to the two copies of each chromosome. Unfortunately, the allele linkage information needed to perform phased genome assemblies has been difficult to generate. Hence, most current genome assemblies are a haploid mixture of the two underlying chromosome copies present in the sequenced individual. Sequencing technologies providing long (20 kb) and accurate reads are the basis to generate phased genome assemblies. This chapter provides a brief overview of the main milestones in traditional genome assembly, focusing on the bioinformatic techniques developed to generate haplotype information from different specialized protocols. Using these techniques as a knowledge background, the chapter reviews the current algorithms to generate phased assemblies from long reads with low error rates. Current techniques perform haplotype-aware error correction steps to increase the quality of the raw reads. In addition, variations on the traditional overlap-layout-consensus (OLC) graph have been developed in an effort to eliminate edges between reads sequenced from different chromosome copies. This allows for large presence–absence variants between the chromosome copies to be taken into account. The development of these algorithms, along with the improved sequencing technologies has been crucial to finish chromosome-level assemblies of complex genomes.","['Life Sciences', 'Genetics and Genomics']"
doi:10.1007/978-981-19-3575-6_26,en,Detecting Deceptive News in Social Media Using Supervised Machine Learning Techniques,OriginalPaper,"Our society has witnessed numerous incidents concerning fake news. Social media has always played a significant role in its contribution. People with notorious mindsets often are the generators and spreaders of such incidents. These mischievous people spread the fake news without even realizing the effect it has on naive people. People believe on the fake news and start behaving accordingly. Fake news appeals to our emotions. It plays with our feelings, and it can make us angry, happy, or scared. Also, fake news can lead to hatred or anger toward a specific person. Nowadays, people easily befool each other using social media as a tool to spread the fake news. In this paper, we proposed a machine learning-based model for detection of such deceptive news which creates disturbances in our society. This model is implemented in Python. We used machine learning algorithms, viz. logistic regression, multinomial Naive Bayes, passive-aggressive classifier, and multinomial classifier with hyperparameter. Different vectorization techniques have been used for evaluation of models. Results show that the passive-aggressive classifier using Tf-idf vectorization outperforms others in terms of accuracy to detect the fake news.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-08927-5_11,en,"Artificial Intelligence, Deep Learning, and Machine Learning Applications in Total Hip Arthroplasty",OriginalPaper,"Artificial intelligence (AI) recently gained popularity in total hip arthroplasty (THA) applications due to several reasons including technological improvements such as availability of data storage, processor capabilities, AI technique developments, and surgery-related improvements including presurgical Pre-surgical analysis techniques developed and data collected for input to algorithms (Mont, et al. J Arthroplast. 34(10):2199–200, 2019). In this work the focus will be on the research literature covering AI, deep learning (DL), and machine learning Machine learning (ML) (ML) techniques that relate to only THA. This coverage excludes the combined results for total knee Total knee arthroplasty (TKA) arthroplasty Arthroplasty (TKA) and THA unless THA is analyzed independently from TKA. Applications determined include THA-related economic analysis Economic analysis and payment models Payment model , patients’ well-being, risk of blood Blood transfusion, hip fracture Hip fracture detection Detection (Kim and MacKinnon. Clin Radiol. 73:439–45, 2018). Biomechanical considerations, optimal implant design Implant design , post-THA implant brand detection Implant brand detection , hip disability upon THA, inpatient and outpatient THA surgery detection, automating and improving angle of acetabular component, text-based database Database search for THA-related factors, mechanical Mechanical loosening detection loosening Loosening detection of the transplant, patient comfort after THA, and implant failure detection Implant failure detection . Many more applications are possible using AI, DL, and ML with few of them suggested in the conclusion section.","['Engineering', 'Biomedical Engineering and Bioengineering', 'Biomechanics', 'Surgical Orthopedics', 'Robotics']"
doi:10.1007/978-981-19-0968-9_43,en,Parallelization Strategies for Hierarchical Density-Based Clustering Algorithm Using OpenMP for Scan-To-BIM Applications,OriginalPaper,"Clustering is an unsupervised learning method that provides insights by investigating unknown structures in a dataset without exploiting any ground truth target information. For constructing an as-built Building Information Models (BIM) from captured laser-scanned datasets, the segmentation process precedes modeling, which provides a baseline to be traced for obtaining 3D models from point clouds. For the segmentation process, a clustering algorithm can be effectively applied so that it can group the points having similar features without predefined criteria which, in turn, segments can be easily separated from the entire scene. Amongst various types of clustering algorithms, Hierarchical Density-Based Spatial Clustering of Applications with Noise (HDBSCAN) was developed as a density-based and hierarchical clustering algorithm which provides a simplified tree of significant clusters. This algorithm has several distinct advantages over other clustering algorithms: (1) avoids “flat” (i.e. non-hierarchical) labeling of data objects, (2) automatically simplifies the hierarchy into the most significant clusters, and (3) requires a single input parameter (i.e. minimum number of points) for density threshold. However, this algorithm has an overall computation time complexity represented as a quadratic form (i.e., $${\text{O}}\left( {dn^2 } \right)$$ O d n 2 ) which suffers from the computational efficiency issue especially for massive amounts of data such as those found in 3D point clouds. To ease the applicability of HDBSCAN to Scan-to-BIM applications, this research aims to parallelize major time-consuming components of HDBSCAN algorithm. OpenMP interface was adopted for thread parallelization and parallel efficiency was measured by calculating speedup and efficiency from strong and weak scaling results.","['Engineering', 'Building Materials', 'Geoengineering, Foundations, Hydraulics', 'Transportation Technology and Traffic Engineering', 'Environment, general']"
doi:10.1007/978-3-031-15509-3_3,en,A Fuzzy Survival Tree (FST),OriginalPaper,A fuzzy survival tree (FST) is introduced as an alternative proposal for survival tree learning. Fuzzy logic theory and Harrell’s index (c-index) are combined as a new rule in node splitting. The introduction of fuzzy sets in tree learning improves FST performance and provides robustness to the algorithm when data are missing. FST performance improves significantly over other tree-based machine learning algorithms as demonstrated in public clinical datasets.,"['Engineering', 'Data Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/s10473-023-0108-5,en,Optimal Birkhoff Interpolation and Birkhoff Numbers in Some Function Spaces,OriginalPaper,"This paper investigates the optimal Birkhoff interpolation and Birkhoff numbers of some function spaces in space L ∞ [−1, 1] and weighted spaces L p,ω [−1,1], 1 ≤ p < ∞, with ω being a continuous integrable weight function in (−1,1). We proved that the Lagrange interpolation algorithms based on the zeros of some polynomials are optimal. We also show that the Lagrange interpolation algorithms based on the zeros of some polynomials are optimal when the function values of the two endpoints are included in the interpolation systems.","['Mathematics', 'Mathematics, general', 'Analysis']"
doi:10.1007/978-981-19-3632-6_57,en,Data Security Detection and Location Technology Based on DLP Network,OriginalPaper,"Faced with a complex network environment, network security issues are getting more and more serious. Cyber attacks will not only leak user privacy, but also cause huge economic losses. In the face of massive network data, decision trees have become an effective method for detecting abnormal network data. The decision tree method trains a model on a large amount of data, classifies normal data and abnormal data, and detects network attacks more efficiently and accurately. This article aims to study DLP network data security detection and positioning technology. Based on the analysis of DLP trends, the development direction of intrusion detection, abnormal data classification algorithms and positioning technology, the KDD CUP1999 data set is selected as the experimental data set. These three methods, namely, decision tree, support vector machine, are used to detect the data set. The detection results show that the data detection rate and false alarm rate of the decision tree algorithm perform better among the three algorithms, and are suitable for network data security detection.","['Engineering', 'Cyber-physical systems, IoT', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing']"
doi:10.1007/978-3-031-16865-9_4,en,"Comparing Accuracy Between SVM, Random Forest, K-NN Text Classifier Algorithms for Detecting Syntactic Ambiguity in Software Requirements",OriginalPaper,"Software requirements are ambiguous due to the ambiguity of natural language in general. The ambiguity of the requirements leads to software development errors. As a result, a multitude of approaches and techniques for detecting ambiguity in software requirements have emerged. This study used three supervised ML algorithms that used Bag-of-Words features to detect grammatical ambiguity in software requirements: support vector machine (SVM), random forest (RF), and k-nearest neighbours (KNN). RF had the highest accuracy of 86.66%, followed by SVM (80%) and KNN (70%).","['Engineering', 'Computational Intelligence', 'Data Engineering']"
doi:10.1007/978-981-19-3632-6_58,en,Construction of Network Data Security Detection System Based on Data Mining Algorithm,OriginalPaper,"With the rapid popularization and development of the mobile Internet, the issue of network data security has received more and more attention. In order to effectively guarantee Internet data security, an advanced, efficient and reliable intrusion monitoring and detection system is bound to be indispensable. This article mainly focuses on the research of the Internet data security detection management system based on data mining algorithms. Based on the collection of relevant literature materials, it summarizes the actual needs of the Internet data security detection management system, and then analyzes the Internet data mining in the Internet data security detection application research in the management system. Based on these technologies, the Internet data security detection management system of the Internet data mining algorithm is designed, and the designed system is tested. The detection results are obtained. The system after the algorithm is improved. It is lower than the traditional system, and as the amount of data increases, the system saves more time. The detection rate of the improved system is 4.44% higher than the traditional detection rate.","['Engineering', 'Cyber-physical systems, IoT', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing']"
doi:10.1007/978-981-19-2004-2_35,en,Machine Learning Approaches on Intrusion Detection System: A Holistic Review,OriginalPaper,"With the remarkable development of the Internet over the last few decades, network security is one of the major issues in this century. With the increasing development of malicious software or malware as well as extensive use of the Internet, the destruction and unauthorized access of the network security are increasingly vital. An intrusion detection system is basically implemented to detect the intrusion in the system and identify the different types of unauthorized access of data and information over the networks. However, to understand the research work on IDS, the survey is made on 40 papers from 2010 to 2021. The survey paper includes a basic idea of machine learning, datasets and the different algorithm used in IDS. After studying different existing approaches of IDS techniques, limitations and complexities are mentioned here.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Artificial Intelligence', 'Materials Science, general']"
doi:10.1007/978-3-031-13714-3_6,en,Decomposition Methods,OriginalPaper,"The chapter first recalls few properties of recursive algorithms. Next, it introduces a general recursive constructive method. Finally, it presents the large neighborhood search and the POPMUSIC metaheuristics.","['Business and Management', 'Operations Research/Decision Theory', 'Optimization', 'Computational Mathematics and Numerical Analysis', 'Algorithms', 'Computational Science and Engineering', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3575-6_54,en,Detecting Zeus Malware Network Traffic Using the Random Forest Algorithm with Both a Manual and Automated Feature Selection Process,OriginalPaper,Zeus is the most widespread banking malware variant ever discovered. This paper proposes a methodology for detecting the Zeus malware network traffic flows by using a random forest machine learning algorithm. The research in this paper explores a manual feature selection process and compares this with an automated feature selection algorithm to determine whether a manual feature selection process is suitable for detecting Zeus. This will help researchers to comprehend which network flow features could be used for detecting Zeus and whether these features will work across multiple variants of Zeus. This research also reports on whether the methodology can predict both older and newer variants of the Zeus malware.,"['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-2188-9_18,en,Optimal Location of PZT Sensors and Actuators for the Metallic and Composite Structures: A Review,OriginalPaper,"Vibration is the major problem caused by parametric uncertainties and environmental disturbances in the structures like aircraft, automobiles, railway compartments and machine parts, etc. Many researchers have been interested in the problem of vibration control of structures by using a piezoelectric sensor and actuator. Lightweight structures are the best solution to control the vibration due to low damping. In this regard, it is of value to study the optimal location of PZT sensors for different structures. This review aims to provide an overview of the different methods to select the optimal location of the piezoelectric sensor and actuator on different structures such as beam and plate with different boundary conditions.","['Engineering', 'Industrial and Production Engineering', 'Mechatronics', 'Engineering Thermodynamics, Heat and Mass Transfer', 'Energy Storage', 'Materials Engineering']"
doi:10.1007/978-981-19-0095-2_48,en,Survey of Streaming Clustering Algorithms in Machine Learning on Big Data Architecture,OriginalPaper,"Machine learning is becoming increasingly popular in a range of fields. Big data helps machine learning algorithms better timely and accurate recommendations than ever before. Machine learning big data phases and subsystems point the way to comparable issues and threats, as well as to associated research in various of previously new of unexplored areas. In latest days, data stream mining has become a popular research topic. The biggest challenge in streaming data mining is extracting important information directly from a vast, persistent, and changeable data stream in just one scan. Clustering is a powerful method for resolving this issue. Financial transactions, electronic communications, and other fields can benefit from data stream clustering. This research examines approaches for synthesizing enormous data streams, including projection clusters for high-dimensional data, scalability, and spreading computing, as well as the issues of big data and machine learning. The data abstraction and regular features of learning streams, such as abstraction wander, data flow system, and outlier observation, are discussed in this study. AutoCloud, which seems supported by previous inform prospect of typicality with eccentricity data science, will be used to discover deviations but instead resolve them using the support clustering approach, which is the process of computing difficulty and clustering exactness, will be detailed in this article. We present the MLAutoCloud algorithm, which will be used in machine learning PySpark frameworks. Implement the MLAutoCloud algorithm in the future to tackle the AutoCloud algorithm’s problems.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Systems and Data Security', 'Artificial Intelligence', 'Computational Intelligence']"
doi:10.1007/978-3-031-17544-2_4,en,Multi-Objective Optimization Algorithms in Medical Image Analysis,OriginalPaper,"Color correction is important part for medical image preprocessing. The proposed method provides color correction with minimum error for the human visual perception. The principal feature of proposed method: the color error is calculated according to perceptual metric CIEDE2000. Using the loss function based on CIEDE2000 metric leads to necessity transfer from least square method using for transformation function parameters identification to multi-objective optimization. Each color of palette is represented as separate target function. As algorithm for palette matching, the 3rd order polynomial with 11 coefficients for each color channel was used. Algorithm of transformation function coefficients estimation based on multi-objective optimization includes three steps: evaluation of starting point by least square method, line search by BFGS (Broyden–Fletcher–Goldfarb–Shanno) algorithm and solution refinement by Nelder—Mead Algorithm. Our experiments show that for all colors from palette error according CIEDE2000 is less than 1. If error of CIEDE2000 for colors after matching is more than 1 the difference between color will be visible for observer.","['Engineering', 'Computational Intelligence', 'Biomedical Engineering and Bioengineering', 'Health Informatics']"
doi:10.1007/978-981-19-1412-6_35,en,Modified ElGamal Algorithm Using Three Paring Functions,OriginalPaper,"Cryptography defines different methods and technologies used in ensuring that communication between two parties over any communication medium is secure, especially in presence of a third part. This is achieved through the use of several methods, such as encryption, decryption, signing, generating of pseudo-random numbers, among many others. Cryptography uses a key or some sort of a password to either encrypt or decrypt a message that needs to be kept secret. This is made possible using two classes of key-based encryption and decryption algorithms, namely symmetric and asymmetric algorithms. The best known and the most widely used public key system is ElGamal. This algorithm comprises of three phases, which are the key generation phase, encryption phase, and the decryption phase. Owing to the advancement in computing technology, ElGamal is prone to some security risks, which makes it less secure. The following paper previews combination of three paring function used to enhance the ElGamal algorithm and increase its security. The results showed that the modified algorithm gives 93% accuracy.","['Engineering', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security']"
doi:10.1007/978-3-031-18516-8_13,en,Auto-Diversified Ameliorated MultiPopulation-Based Ensemble Differential Evolution,OriginalPaper,"Stagnation and premature convergence are considered the most known problems of differential evolution (DE). To address this issue, we propose a multipopulation differential evolution with an automatic re-diversification mechanism that consists of combining our previously proposed approach (AMPEDE) with a detection/re-diversification process. In the proposed AD-AMPEDE, the objective function values’ mean and the coefficient of variance are used to detect whether the population has been stagnant or has converged to probably a local optimum. After confirming the existence of stagnation and premature convergence, a re-diversification mechanism, with the strategy proposed for AEPD [ 4 ], is applied on the population. A set of 24 Black-Box Optimization Benchmarking (BBOB2009) functions is used to evaluate the AD-AMPEDE efficiency. Results display that AD-AMPEDE is very competitive and provides an excellent performance in dealing with some categories of optimization problems.","['Engineering', 'Complexity', 'Computational Intelligence', 'Control and Systems Theory']"
doi:10.1007/978-981-19-5331-6_60,en,Implementation of Anomaly Detection Using Unsupervised Machine Learning,OriginalPaper,"Anomaly detection is a strenuous and complex task to achieve. With the increase in the generation of live-streamed big data, detecting anomalous data and alerting the concerned party are crucial. Although many algorithms have been developed by researchers to detect anomalies from a data set, choosing the right fit is significant. Anomaly detection is a key issue when dealing with the enormous amount of continuous data. This paper presents different unsupervised learning algorithms and how well they fare when applied to huge multidimensional data for anomaly detection. As a sample data set, we have selected Weather Records of Goa, India from 1st July 2016 to 31st July 2019 from Kaggle. We have applied three algorithms to this data set, viz. Isolation Forest, K-Means and Density-Based Spatial Clustering Application with Noise (DBSCAN) and have compiled their respective observations for comparison. As this data set was obtained from Kaggle, there it was no need of data pre-processing.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-4960-9_6,en,HIDSC2: Host-Based Intrusion Detection System in Cloud Computing,OriginalPaper,"In today’s world, protecting a website or any online document from a web-based attack is a major challenge due to malicious users’ bad intentions on the Internet. Researchers are attempting to determine the best solution for preventing these web-based attacks. Cloud computing is a technique that is widely used and popular among users. The majority of organizations and companies are using cloud computing. Therefore, many important, private, and confidential data are available on the cloud. And cloud computing is facing two major issues, first is security and the other is efficiency. Cloud is a virtual pool between resource and user. So, it has a major risk. Many security issues, including intrusion detection, arise as a result of the shift to this computing paradigm. Traditional intrusion detection systems have been defeated by large amounts of network traffic data and dynamic behavior, as intrusion and attack tools have become more sophisticated. IDS technique is becoming very popular, where subscribers or clients pay for the resources per use basis; in this scenario, securities become the main aspects, and at that time, an intrusion detection system detects computers attacks by different methods. The main intention is to protect the cloud, using an intrusion detection system. Here, two different IDS are merged, and with this combination, the cloud can be protected and alerts can be generated.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Professional Computing']"
doi:10.1007/978-981-19-3998-3_103,en,Distributed Optimization Problem of Second-Order Multi-agent Systems via Event-Triggered Proportion-Integration-Differentiation Algorithm,OriginalPaper,"This paper studies the event-triggered distributed optimization problem of second-order multi-agent systems. In order to obtain the optimal solution with low communication costs, a distributed event-triggered proportion-integration-differentiation algorithm is presented, where the event-triggered time sequence is dependent on the states of the agents. By using matrix transform and differential inequality technique, the global exponential convergence is obtained. Furthermore, the event-triggered time sequence is proved to be free of Zeno behavior. Finally, a numerical example illustrates the effectiveness of theoretical results.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-3-031-18292-1_3,en,"Explainable Artificial Intelligence (XAI): Conception, Visualization and Assessment Approaches Towards Amenable XAI",OriginalPaper,"For last decade, due to the accessibility of huge databases and recent advancements in deep learning methodology, machine learning systems have arrived at or transcended tremendous performance in a spacious variety of tasks. One can see this speedy development in speech analysis, image recognition, sentiment analysis, strategic game planning and many more, for e.g. in medical field, it’s used for diagnosing different diseases, like breast cancer etc., based on their symptoms. But many state-of- the-art models is facing lack of transparency and interpretability which is a major hindrance in many applications, e.g. finance and healthcare where visualization, interpretation and explanation for model's decision is an obligation for trust. This is an implicit problem of the current techniques carried by sub-symbolism (e.g. Deep Neural Networks) that were not shown in the last hype of AI (specifically, rule based models and expert systems). Models underlying this problem come within the so-called Explainable AI (XAI) field, which is extensively acknowledged as a racial feature for the practical deployment of AI models. As a result, explainable artificial intelligence (XAI) has turned into scientific interest in last recent years. So, this chapter epitomizes contemporary developments in Explainable AI that describes explainability in Machine Learning, constituting a fiction definition of explainable Machine Learning that envelopes such prior conceptual propositions with a considerable focus on the audience for which the explainability is needed. Except of this definition, this chapter starts a confabulation on its various techniques that are essentials for analysing interpretability and explainability of Artificial Intelligence, and also gives a comparison between two medical experiments, that are based on predicting heart disease using disparate Explainable Artificial Intelligence techniques, which can give a lead for researchers as well as practitioners or newcomers in the field of Artificial Intelligence for selecting suitable methods with Explainable AI to grasp the advances of AI in their action sectors, without any previous bias for its dearth of interpretability.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-21203-1_39,en,AN Using Local Search in Multi-issue Bilateral and Repeated Negotiation,OriginalPaper,"Designing an automated agent for Human-Agent Negotiation is a challenging task. Especially in the domain that combines multi-issue bilateral negotiations and repeated negotiations. In this domain, the agents negotiate with humans over more than one item, and there are several rounds of negotiation in each game. Designing this kind of agent can be very challenging. Our agent needs to estimate the preferences of the human opponent in real-time, proposing fair offers that will be excepted by the human opponent but taking into account, not proposing offers that don’t increase the agent’s score. On the other hand, local search algorithms have proven to be effective in a variety of fields in artificial intelligence. In this paper, we present a novel approach for an automated agent for this type of negotiation by using local search algorithms, in particular: Simulated Annealing and Hill Climbing. As we analyze the results from our experiments and compare the local search algorithms, we show that local search algorithms can be more efficient in Human-Agent negotiation than traditional methods. Moreover, our agent is capable of negotiating efficiently and outperforming the human opponent.","['Computer Science', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16078-3_15,en,Object Tracking with a Fusion of Event-Based Camera and Frame-Based Camera,OriginalPaper,"The framed-based camera is commonly used for object tracking tasks. However, under poor light conditions, the frame camera cannot work properly and provide stable detection for the tracking system. Also, it has motion blur when the object is moving fast. Compared to the frame-based camera, the event camera has a higher temporal resolution and dynamic range. The event data is transmitted immediately when the brightness of each pixel changes. The higher temporal resolution helps the event camera avoid the motion blur and provide more precise temporal information. Moreover, the higher dynamic range allows the event camera to work in extreme light conditions, such as evening, raining, and strong sunshine environments. In all, those advantages make the event cameras an applicable complementary sensor to the frame cameras. In this paper, several optical flow algorithms for the event data are tested. Then, a clustering algorithm is proposed to generate the detection and hybrid it with the detection from frame images. At last, the PMBM filter is used to realize object tracking and test it on our self-recorded dataset with the DAVIS346 and several publicly available datasets.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5845-8_56,en,Modeling and Control of Induction Machine and Drive in the Combined Domain with New Chaotic Gorilla Troop Optimizer,OriginalPaper,"In this work, a new chaotic version of gorilla troop optimizer is developed. The position equation of the algorithm is modified with the help chaotic maps. Around ten widely cited chaos maps, one-dimensional in nature, are considered to develop new chaotic algorithms. Two unimodal and three multi-modal test functions are employed to validate the efficacy of the proposed technique. A 50 hp induction motor model is also reduced and further its controller is designed utilizing the benefit of delta operator with the help of this proposed algorithm. Finally, a practical test system of induction motor drive is taken up for modeling and control action as well. The controller realization in both cases is carried out using approximate model matching framework. The convergence speed and accuracy of the proposed techniques are better as compared to the standard and latest methods. Thus, the results in all experimentations performed show great promise.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-17024-9_7,en,Towards Improving Bio-Image Segmentation Quality Through Ensemble Post-processing of Deep Learning and Classical 3D Segmentation Pipelines,OriginalPaper,"In biological image analysis, 3D instance segmentation is a crucial step towards extracting information on objects of interest from microscopy datasets. Existing instance segmentation pipelines are frequently affected by errors such as missing boundary layer cells or poorly segmented regions. In this study, we propose several ensembles as post-processing methods for improving the quality of outputs obtained from deep learning and classical 3D segmentation pipelines. These methods take as input the results from two independent 3D segmentation pipelines and combine them using different fusion algorithms. The first algorithm uses label set intersection, the second one involves adjacency graph composition and the third one works through segmented object boundary fusion followed by 3D watershed. These 3 algorithms are tested on a dataset of 3D confocal microscopy images of floral tissues. The third fusion algorithm is found to perform best and has better global and local accuracies compared to its input segmentations. The specialty of the proposed ensemble methods is that these are model agnostic, i.e., they can be used to combine segmentation results from deep learning as well as non-deep learning or classical pipelines. These methods could be highly beneficial in correcting segmentation errors arising from missing cells in the boundary layer or under segmentation in the inner tissue layers and ultimately provide us robust segmentation results in presence of variable image qualities in biological datasets.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Bioinformatics']"
doi:10.1007/978-981-19-2394-4_26,en,Fault-Tolerant Distributed Mutual Exclusion over Elastic Logical Ring Topology,OriginalPaper,"Under mutual exclusion is understood preventing of any opportunity more than one active object (process, thread, task) to access a shared resource at a time. The distributed ring-based (aka token-ring ) mutual exclusion algorithm is executed over logical circular topology. Due the chosen topology the ring-based algorithm is the simplest of this kind. Its pros are simplicity and minimalistic preliminary information required to be known a priori from each system process. The main drawback of this attractive algorithm in its basic definition is the strong presumption of absolute system reliability which makes it impractical. After all, the failure model of distributed systems itself assumes that failures should not be treated as exceptions but as a norm. Three working recovery schemes are considered through the overall project “Class of Fault-Tolerant Distributed Algorithms for Mutual Exclusion over Elastic Logical Ring Topology”. They evolve consistently and complement each other: Failure recovery without reconfiguration ( Scheme 1 ); Failure recovery with one-way reconfiguration/resiliency ( Scheme 2 ); Failure recovery with two-way reconfiguration/resiliency ( Scheme 3 ). The first two recovery schemes are described in previous works. Here is presented the third one. It supposes both exclusion of the faulty processes and inclusion (injection) of faultless spare processes as replacement of faulty ones. Combining both Scheme 2 and Scheme 3 the communication ring acquires the property of elasticity or two-way resiliency. So, we eliminate the impractical assumption of “absolute” reliability. The full code of the algorithm test bed is placed in the GitHub under MIT license.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-13714-3_4,en,Constructive Methods,OriginalPaper,"This chapter presents methods for constructing solutions. It starts with the branch and bound methods, widely used for the design of exact algorithms. Then two basic methods are presented, random and greedy constructions. The latter sequentially selects the elements to include to a partial solution, never changing the choices that have been made. This method can be improved by a deeper evaluation of the consequences of a choice. Beam search and the pilot method are part of it.","['Business and Management', 'Operations Research/Decision Theory', 'Optimization', 'Computational Mathematics and Numerical Analysis', 'Algorithms', 'Computational Science and Engineering', 'Artificial Intelligence']"
doi:10.1007/978-3-031-11748-0_13,en,Lyapunov Robust Constrained-MDPs for Sim2Real Transfer Learning,OriginalPaper,"Safety and robustness are two desired properties for any reinforcement learning algorithm. Constrained Markov Decision Processes (CMDPs) can handle additional safety constraints and Robust Markov Decision Processes (RMDPs) can perform well under model uncertainties. In this chapter, we propose to unify these two frameworks resulting in Robust Constrained MDPs (RCMDPs). The motivation is to develop a framework that can satisfy safety constraints while also simultaneously offer robustness to model uncertainties. We develop the RCMDP objective, derive gradient update formula to optimize this objective and then propose policy gradient based algorithms. We also independently propose Lyapunov-based reward shaping for RCMDPs, yielding better stability and convergence properties.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Machine Learning']"
doi:10.1007/978-3-031-16868-0_5,en,Architecture Design for Variational Auto-Encoders,OriginalPaper,"Most VAEs were developed with symmetrical architecture in mind, which means that the encoder and decoder must have the same number of layers. However, when completing the step of unsupervised pre-training step, the decoder portion is deprecated and will never be employed when fine-tuning image classification problems. As a result, maintaining a symmetrical architecture is not nearly necessary [ 1 ]. However, new complications develop when the asymmetrical architecture is used, despite the fact that it is a quite appealing decision. This shows that if the asymmetrical architectures of CVAEs are planned to improve, one needs to evaluate the architectures of each partition on its own before making any changes to the architectures as a whole. In addition, for the correct forwarding of the asymmetrical CVAEs, it is essential to make certain that the decoder appropriately fits the resolution of the raw input data in the appropriate manner. This also adds another layer of complication to the manual design process for VAE designs.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4971-5_33,en,Absolute Point Positioning Algorithm for Navigation Applications,OriginalPaper,"In this paper, one static positioning algorithm (i.e. lease square estimator) is implemented and one kinematic positioning algorithm designated as correntropy extended Kalman filter (CEKF) is proposed for precise GNSS/GPS applications and GAGAN-based aircraft landings. The proposed algorithm uses correntropy criterion (CC) as an optimal criterion, a local similarity measure, unlike minimum mean square error (MMSE). Also, it uses an iterative approach called fixed point for renovating the rearward estimates. The simulation results show that the proposed algorithm outperforms the static positioning algorithm in two-dimensional and three-dimensional surface.","['Engineering', 'Power Electronics, Electrical Machines and Networks', 'Energy Policy, Economics and Management', 'Energy Systems']"
doi:10.1007/978-3-031-19945-5_8,en,Simulated Annealing and Tabu Search for Solving the Single Machine Scheduling Problem,OriginalPaper,"This paper presents a comparative study of two metaheuristic optimization algorithms for solving the Total Weighted Tardiness problem in its single-machine mode, which represents the most frequent scheduling and sorting problems occurring in the industrial environment. The metaheuristics evaluated in this study were Tabu Search, and Simulated Annealing, because they have shown satisfactory results in this kind of problems. The performance of each algorithm was evaluated by means of the total tardiness and the execution time using instances of 40, 50, and 100 jobs extracted from the OR-Library. The Simulated Annealing algorithm was found to be the most efficient method, being the one that found the best solutions in comparison to Tabu Search, nonetheless, Tabu Search found the results in the shortest time. A difference approximated of twenty-four units between Simulated Annealing and Tabu search was found in the total tardiness value when a set of 125 instances were executed. On the other hand, Tabu Search required only the 13% of the time execution required by Simulated Annealing.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Computer Applications']"
doi:10.1007/978-3-031-13702-0_3,en,Explainable AI and Slime Mould Algorithm for Classification of Pistachio Species,OriginalPaper,"The safety and quality of the food are considered an essential issue in the entire world. This is due to food being the basis of human health. Nowadays, machine learning algorithms have embodied the recent technology in all stages of food processing such as food grading, food quality determination, and food classification. Pistachio nuts have an important role in the agricultural economy. To increase the efficiency of post-harvest industrial processes, there is a need to introduce technologies for classifying different species of pistachio. This study considers an automated model to separate pistachio species. The proposed pistachio species classification consists of three main phases; features selection based on slime mould algorithm phase, feature interpretation based on explainable artificial intelligence phase, and finally classification of pistachio species using logistic regression phase. The proposed pistachio species classification model obtained overall 90% classification accuracy, 90% precision, and 91% f1-score.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Artificial Intelligence', 'Food Science']"
doi:10.1007/978-3-031-22200-9_57,en,Enhancing Total Transfer Capability via Optimal Location of Energy Storage Systems Using a Hybrid Improved Min-Cut Algorithm and Genetic Algorithm,OriginalPaper,"This paper proposes a new optimal approach to determine the location and size of the Energy Storage System (ESS) in transmission expansion planning (TEP). The proposed method combines two steps in sequence: the improved MinCut algorithm (IMCA) and the Genetic Algorithm (GA) algorithm to reduce the search space and time for finding the optimal solution satisfying many constraints. This algorithm reduces the computational volume significantly compared to previous algorithms and thereby shortens the calculation time leading to investors making timely and competitive ESS system investment decisions. The research results are applied in determining the position of the ESS in the IEEE 24-bus system, which shows the possibility of a solution to the TEP problem.","['Engineering', 'Mathematical and Computational Engineering', 'Mechanical Engineering', 'Electrical Engineering']"
doi:10.1007/978-3-031-04536-3_12,en,Haptic Software Design,OriginalPaper,"This chapter reviews design concepts of haptic modeling and rendering software. The main focus lies in realistic kinesthetic and tactile haptic models for virtual and augmented reality based on the data collected from physical objects. We consider both data-driven algorithms providing a black-box action-response mapping and measurement-based approaches identifying parameters of physics-based models. To show the research landscape and highlight ongoing research challenges, we introduce a series of state-of-the-art methods including data-driven models with deterministic and stochastic responses, physics-based simulation using optimization-based FEM solver, and hybrid approaches of combining the concepts of both data-driven and physics-based methods. These examples also cover a wide range of haptic properties, i.e., modeling and rendering of elasticity and plasticity, tool deformation, and haptic textures.","['Computer Science', 'User Interfaces and Human Computer Interaction', 'Control, Robotics, Mechatronics', 'Special Purpose and Application-Based Systems']"
doi:10.1007/978-3-031-06829-4_7,en,Detecting Distresses in Buildings and Highway Pavements-Based Deep Learning Technology,OriginalPaper,"The massive number of pavements and buildings coupled with the limited inspection resources, both monetary and human, to detect distresses and recommend maintenance actions lead to rapid deterioration, decreased service life, lower level of service and increased community disruption. Therefore, this chapter aims at providing (1) a state-of-the-art review of the literature concerning deep learning techniques for detecting distress in both pavements and buildings; (2) research advancements per asset/structure type; and (3) future recommendations in deep learning applications for distress detection. A critical analysis was conducted on 181 deep learning-based crack detection papers. A structured analysis was adopted to analyse major articles according to their focus of study, employed methods, findings, and limitations. The utilisation of deep learning to detect pavement cracks is advanced compared to assessing and evaluating buildings’ structural health. There is a need for studies that compare different CNN models to foster the development of an integrated solution that considers the data collection method. Further research is required to examine the setup, implementation, running costs, capturing data frequency, and deep learning tool. In conclusion, the future of applying deep learning algorithms instead of manual inspection for detecting distresses has shown promising results. The availability of previous research and the required improvements in the proposed computational tools and models (e.g., artificial intelligence, deep learning, etc.) are triggering researchers and practitioners to enhance the distresses’ inspection process and make better use of their limited resources. A critical and structured analysis of deep learning-based crack detection for pavement and buildings is conducted for the first time to enable novice researchers to highlight the knowledge gap in each article, as well as, building a knowledge base from the findings of other research to support developing future workable solutions.","['Engineering', 'Building Construction and Design', 'Cyber-physical systems, IoT', 'Professional Computing', 'Construction Management']"
doi:10.1007/978-3-031-09382-1_25,en,Solving Manufacturing Orders Scheduling Problem Using Annealing Simulation,OriginalPaper,"For many years, the decision-making process has been based on a human factor and the foreman’s know-how, what was error prone. Nowadays production processes are more and more complex. The company that wants to be competitive in the market must take under consideration many factors and basing on human factor only is not efficient at all. The paper presents the production scheduling optimization problem in the furniture company. Until now, company engineers used to schedule production based on customers’ orders and their know-how. The problem was that customers make orders at various times with fixed deadlines, and for the company, it is profitable to group customers’ orders together. Wise order scheduling makes a significant difference in total production time and cost. In the paper, the use of a greedy algorithm, Simulated Annealing, and Tabu Search algorithms to verify the current method of production process scheduling and improve the process has been proposed.","['Engineering', 'Engineering Design', 'Manufacturing, Machines, Tools, Processes', 'Complexity']"
doi:10.1007/978-981-19-6004-8_59,en,Sine Cosine Algorithm with Tangent Search for Neural Networks Dropout Regularization,OriginalPaper,"Convolutional neural networks belong to the group of deep learning methods, largely influenced by the structure and functioning of the human brain. Their primary usage is to perform image classifying tasks. All neural networks, including convolutional neural networks, are susceptible to the overfitting issue, which can occur when the network exhibits good performance on the train data while failing to accurately predict the new data when it is fed to the inputs. Few regularization approaches exist that may help in avoiding the overfit. This paper proposes a novel swarm intelligence optimization method to address the overfitting problem by choosing the adequate dropout parameter value. Swarm algorithms have previously been used to optimize the structure of neural networks; however, the full potential of these algorithms has yet not been thoroughly investigated. Scientists must invest a lot of time to choose the appropriate dropout value if they execute this task manually. In this research, an automated framework, that uses improved sine cosine metaheuristics to perform this task, is proposed. The proposed framework was tested on four standard benchmark datasets, namely MNIST, CIFAR10, Semeion, and UPS. The simulation results have been validated against the results generated by several other state-of-the-art swarm intelligence algorithms. The comparison shows that the proposed method outperforms other cutting-edge algorithms in terms of classification error, therefore achieving higher accuracy percentage.","['Engineering', 'Computational Intelligence', 'Cognitive Psychology', 'Personality and Social Psychology', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-2126-1_34,en,Parallel Computation of Probabilistic Rough Set Approximations,OriginalPaper,"Probabilistic rough sets (PRS), a generalization of Pawlak rough sets, have become increasingly successful in dealing with inconsistent information systems. Over the last few decades, rough sets with a probabilistic approach have been applied extensively for data pre-processing, analysis, and decision rule generation in the areas such as data mining and knowledge discovery, pattern recognition, and machine learning. Finding the approximations, both lower and upper are the fundamental steps in PRS or in any generalization derived from rough set theory. With the massive and rapid increase in data generation, computing approximations effectively using the existing traditional probabilistic approaches is turning out to be a challenging task. Recent advances in parallel processing techniques and tools like MapReduce, Apache Hadoop, and Apache Spark have ushered in the development of computationally efficient methods for the analysis of massively large datasets. This paper presents an algorithm by name parallel algorithm for computing probabilistic rough set approximations (PACPRSA), for computing regions and approximations using PRS in parallel. The results of extensive experimentation suggest that the proposed parallel algorithm evidently performs well in standard scalability metrics and therefore is well suited for application on contemporary large datasets.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Machine Learning', 'Big Data', 'Computer Systems Organization and Communication Networks']"
doi:10.1007/978-3-031-16684-6_1,en,"Automatic System Based on Riesz MV-algebras, for Predictive Maintenance of Bearings of Industrial Equipment Using Temperature Sensors",OriginalPaper,"Predictive maintenance systems take a more and more important place in increasing the reliability of industrial equipment, of productivity and reducing production costs. There’s a constant focus to develop new system architectures and in using the latest numerical methods and algorithms in developing more and more reliable predictive maintenance systems. Based on recent results in using Shepard local approximation operators defined in Riesz MV-Algebras for IoT devices signals processing, in this article we propose a new architecture for a predictive maintenance system by adding an extra layer (denoted Data Validation Layer). This new layer is processing the acquired signals by sensors such that to provide to the predictive algorithms a complete and validated data set. The proposed architecture was validated by implementing and testing a predictive maintenance system that is monitoring the bearings of industrial equipment using temperature sensors.","['Engineering', 'Control and Systems Theory', 'Computational Intelligence']"
doi:10.1007/978-3-031-20601-6_68,en,A New Framework for Multi-objective Route Planning in Smart Cities,OriginalPaper,"Route planning is a crucial map navigation feature. Nevertheless, standard commercial map programs only offer optimum routes based on a particular objective, such as time, distance, or other metrics, and disregard the safety objective. Therefore, there is a need for a multi-objective criterion to avoid accidents and to be able to locate not only a short route but also a safe route. This paper proposes a new framework for multi-objective route planning in smart cities. The framework is evaluated by multiple symmetric travelling salesman problem (TSP) instances with varying scale sizes. Several assessment measures are employed to evaluate the proposed framework. The experimental findings demonstrate that the proposed multi-objective framework outperforms and achieves the safety goals compared with other alternatives that considered only the shortest path objective. These findings reveal the robustness of the proposed framework that could be used as a reliable tool for improving the safety and management of road traffic.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16159-9_27,en,Neural Modelling of Dynamic Systems with Time Delays Based on an Adjusted NEAT Algorithm,OriginalPaper,A problem related to the development of an algorithm designed to find an architecture of artificial neural network used for black-box modelling of dynamic systems with time delays has been addressed in this paper. The proposed algorithm is based on a well-known NeuroEvolution of Augmenting Topologies (NEAT) algorithm. The NEAT algorithm has been adjusted by allowing additional connections within an artificial neural network and developing original specialised evolutionary operators. This resulted in a compromise between the size of neural network and its accuracy in capturing the response of the mathematical model under which it has been learnt. The research involved an extended validation study based on data generated from a mathematical model of an exemplary system as well as the fast processes occurring in a pressurised water nuclear reactor. The obtaining simulation results demonstrate the high effectiveness of the devised neural (black-box) models of dynamic systems with time delays.,"['Engineering', 'Control and Systems Theory', 'Computational Intelligence']"
doi:10.1007/978-981-19-3387-5_96,en,Encoding and Decoding Algorithm of LDPC for Low Orbit Satellite Communication Based on Artificial Intelligence,OriginalPaper,"As the most promising satellite mobile communication system at present, the low-orbit satellite communication system has the advantages of small delay, low path loss, and wide coverage. Low-density parity-check (LDPC) code, as an emerging channel coding, can provide high coding gain while maintaining high coding efficiency, which is very suitable for low-orbit satellite communications. The purpose of this paper is to study the encoding and decoding algorithms of LDPCs for low-orbit satellite communications based on artificial intelligence. This article introduces the basic coding method of LDPC and the original model LDPC in detail, and explains its advantages over LDPCs. Based on LDPCs, the coding algorithm is improved. This paper proposes an early stopping iterative algorithm and further simplifies the LLR decoding algorithm. In the low-orbit satellite communication environment, the LDPC encoding and decoding algorithm proposed in this paper is simulated, and the influence of interference factors in the actual environment on the performance of the LDPC is tested. The simulation results show that under the Rice channel condition, when the Rice coefficient is greater than 8, when the bit error rate, the bit error rate coding gain of LDPC decreases by about 2.8 dB, which proves that the algorithm proposed in this paper can be used in the low-orbit satellite communication environment.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Aerospace Technology and Astronautics']"
doi:10.1007/978-981-19-5438-2_22,en,Adaptive In-Flight Alignment of INS/GPS Systems for Aerial Mapping,OriginalPaper,"The integrated INS/GPS measurement system can be used to provide attitude information and then the exterior orientation parameters can be derived for the purpose of direct georeference of the airborne imagery. In-flight alignment (IFA) plays an important role in achieving high accuracy of attitude estimation in the integrated INS/GPS measurement system. However, the statistics of INS noise is usually time-varying and it often degrades seriously the estimation accuracy in practice. In order to solve this problem, this chapter is devoted to IFA of the integrated INS/GPS system for aerial mapping applications. Firstly, an adaptive algorithm is developed to adjust the window size of data processing in IFA. Then the covariances of INS noise can be estimated and updated online, so that the resulted estimation performance can be improved. Moreover, a strong tracking filter (STF) is applied to guarantee the convergence of the IFA algorithm as well as its robustness against the parameter perturbation and trajectory maneuvers. A real aerial mapping experiment demonstrates the effectiveness of the methods.","['Engineering', 'Control and Systems Theory', 'Mathematical and Computational Engineering', 'Systems Theory, Control']"
doi:10.1007/978-981-19-2225-1_38,en,Frequent Pattern Mining in Big Data Using Integrated Frequent Pattern (IFP) Growth Algorithm,OriginalPaper,"Day-by-day, a huge volume of data are generated through electronic gadgets via recent technologies. The data are generated in different forms and thereby its complex in nature. Therefore, big data analytics techniques are introduced to analyse the complex dataset efficiently in different perspectives. Among the different perspectives, the finding of frequent pattern matching in the given dataset is addressed in this work. However, researchers introduced various algorithms for finding frequent pattern matching. But, the existing algorithms have less accuracy for predicting frequent pattern matching and take more retrieval time. In addition to that, the existing algorithms do not preprocess the dataset. Therefore, the main objective of the proposed work is to increase the accuracy by preprocessing the dataset and minimize the response time by parallel processing the dataset. In order to achieve the above objectives, this work introduces an integrated frequent pattern (IFP) growth algorithm to find the distributed frequent pattern effectively from the large dataset. Therefore, IFP growth algorithm deploys in a Hadoop platform. In Hadoop, the Hadoop distributed file system (HDFS) processes the dataset using a multiprocessor. Henceforth, the IFP growth algorithm improves the accuracy and also minimizes the prediction time. Thus, the proposed work chooses a supermarket dataset as a case study.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Statistics, general', 'Mobile and Network Security']"
doi:10.1007/978-981-19-1412-6_53,en,Dynamic Load Balancing in Cloud Network Through Sunflower Optimization Algorithm and Sine–Cosine Algorithm,OriginalPaper,"The objective of the paper is to scheduling of independent task dynamically among the virtual machines (VMs) in the cloud network on the share resources. Scheduling of task and allocating of the resources from the data center have been performed through the several meta-heuristic algorithms and achieved encouraging results. However, their performance evaluation is far based on the ideal state and needs more improvement. Load balancing in necessary when some VMs are executing more number of task and task need to wait in queue for processing at the same time other VMs are free and not allocated any task or less number of tasks for execution. The problem under consideration is proposed sunflower optimization algorithm with sine–cosine algorithm (SFOA-SCA) for improving the performance of load balancing in cloud network. The experimental result illustrates that the projected procedure is outstripping its opponent in the manner of throughput time, waiting time, response time, execution time, and utilization energy during load balance of task in cloud network.","['Engineering', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security']"
doi:10.1007/978-981-19-4193-1_43,en,Hybrid Security for Data in Cloud Computing: A Review,OriginalPaper,"Cloud computing is the most current technology to emerge in the last several decades. It is a great platform for the users to share data or applications on remote server that can be processed and accessed through Internet. Users are always concerned with security issues which are really challenging in cloud computing because many customers were sharing the same cloud. The cloud service provider must ensure that the sensitive information in the cloud is secured using the latest security techniques to protect the data, applications, and infrastructure associated with the cloud. This study aims in discussing, various cloud security hazards and different hybrid cryptosystem used for security. A new method is proposed for high security which includes Blowfish symmetric algorithm and RSA asymmetric algorithm for data privacy along with Password-Based Key Derivation Function 2 (PBKDF2) algorithm for strong password security.","['Engineering', 'Computational Intelligence', 'Information Storage and Retrieval', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Data Structures and Information Theory', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4975-3_50,en,Lncosh-Based Adaptive Control Algorithm for Single-Stage SPV Grid-Interfaced System,OriginalPaper,"This work proposes the use of a logarithmic hyperbolic cosine (Lncosh)-based adaptive algorithm for a single-stage solar photovoltaic (SPV) grid-interfaced system. The design incorporates a VSC coupled SPV array to provide active power along with reactive power compensation. It also serves to offer load balancing, reduction of harmonics, and power factor correction. A maximum power point (MPP) extraction method based on the incremental conductance (InC) technique, integrated with the VSC control algorithm, is employed to ensure that the SPV array operates at the MPP under varying levels of irradiation. The Lncosh-based algorithm simultaneously offers benefits of both the least mean squares (LMS) and sign-error LMS algorithms, providing faster convergence without sacrificing the mean-square-error (MSE) performance. The proposed configuration is implemented for simulation in MATLAB with the Simulink environment; the steady-state and the dynamic behavior is observed and verified to be well within recommended limits.","['Engineering', 'Power Electronics, Electrical Machines and Networks', 'Energy Policy, Economics and Management', 'Energy Systems']"
doi:10.1007/978-3-030-99075-6_10,en,Improvement and Application of YOLOv3 for Smartphone Glass Cover Defect Detection,OriginalPaper,"Smartphone glass covers defects detected by human, which is inefficiency, high costs, low detection accuracy and labour intensive, while the automatic detection methods based on traditional machine vision is poor flexibility, low yield and poor generalisation capability. Therefore, this paper introduces YOLO (You Only Look Once) v3 to smartphone glass cover defects for the first time. The YOLOv3 algorithm was improved for the actual characteristics and specific requirements of defect detection. First of all, the channel attention mechanism SENet (Squeeze and Excitation Networks) was added to the feature extraction network to detect inconspicuous defect features. Moreover, a 104 × 104 scale detection layer was added to the YOLOv3 detection network to solve the problem of multi-scale defects. Finally, the scaling factor coefficient of the BN (Batch Normalization) layer in the convolutional network is used as the important factor for model pruning to improve the defect detection speed. The improved YOLOv3 algorithm is applied to smartphone glass cover defect detection, and a high accuracy and high detection speed method for smartphone glass cover defects is proposed. 15,914 production site images covering four types of defects, including chipped edges, pits point, soiling and scratches, were obtained from smartphone glass cover manufacturers, 14,321 were annotated as the training set and 1593 were used as the test set to compare and analyse the proposed method and the original YOLOv3 algorithm in this paper. These experiments showed that the mAP (mean average precision) of the detection was 81.0% and the detection speed was 43.1 sheets/s. Compared to the original YOLOv3 algorithm, the mAP of the detection increased by 3% and the detection speed increased by 6.7 frames/s, which meets the need for high precision and efficient detection of defects in the industrial production of smartphone glass covers.","['Engineering', 'Industrial and Production Engineering', 'Mechanical Engineering', 'Machinery and Machine Elements']"
doi:10.1007/978-3-031-18461-1_45,en,Using Genetic Algorithm to Create an Ensemble Machine Learning Models to Predict Tennis,OriginalPaper,"In this paper, we illustrate our study of using genetic algorithms and machine learning to create an ensemble technique, which is used to predict tennis games using limited amounts of data. The genetic algorithm was used to improve the game representations, derived from the players’ statistics differences, to be utilized by the machine learning algorithms. The use of genetic algorithms also reduced the dependence on human expertise in creating the game representations. The majority of the ensemble models we generated were either as good or performed higher than the predictions based on just the player’ official rankings.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-3-031-13714-3_7,en,Randomized Methods,OriginalPaper,"This chapter is devoted to random and memory-free methods that repeatedly construct solutions or modify them. Among the most popular techniques, there are simulated annealing, threshold accepting, great deluge and demon algorithms, noising methods, late acceptance hill climbing, variable neighborhood search, and GRASP.","['Business and Management', 'Operations Research/Decision Theory', 'Optimization', 'Computational Mathematics and Numerical Analysis', 'Algorithms', 'Computational Science and Engineering', 'Artificial Intelligence']"
doi:10.1007/978-3-031-14537-7_17,en,Supply Chain Design and Multi-objective Optimisation with the Bees Algorithm,OriginalPaper,"Supply chain Supply chain management network design is a complex multi-objective optimisation Multi-objective optimisation problem consisting of identifying the best combination of suppliers, manufacturing and transport options inter alia , with the aim of optimising the overall performance of the network. In this chapter, the Bees Algorithm Bees Algorithm, THE is presented as a powerful tool for designing optimal Optimal supply chains by minimising the total cost Cost and the total lead time simultaneously when the number of possible configurations is high, which is classified as a NP-hard problem. The Bees Algorithm Bees Algorithm shows better performance compared to other well-known approaches and it is effective in solving multi-objective supply chain optimisation problems.","['Engineering', 'Robotics and Automation', 'Artificial Intelligence', 'Industrial and Production Engineering', 'Professional Computing', 'Robotics', 'Machine Learning']"
doi:10.1007/978-981-19-5403-0_8,en,Packet Delivery Comparison Using Artificial Bee Colony Algorithm with Dynamic Technique,OriginalPaper,"Clustering is an excellent strategy to create a better path that does not cause any difficulties while sending data and the artificial bee colony algorithm may be an efficient optimisation method for the acquisition model of bees. In this paper, the dynamic technique has been used with an artificial bee colony. This technology makes packet delivery faster. The packet delivery is fast as compared to TORA LEACH and INSENS. Packet delivery comparison has been done using an artificial bee colony algorithm with a dynamic technique. It has been seen that due to the use of this technology, packet distribution has happened at a very fast speed. Whereas the packet delivery speeds of other technology are very less.","['Engineering', 'Computational Intelligence', 'User Interfaces and Human Computer Interaction', 'Data Structures and Information Theory', 'Artificial Intelligence', 'Data Mining and Knowledge Discovery']"
doi:10.1007/978-3-031-12127-2_11,en,A Phonetics and Semantics-Based Chinese Short Text Fusion Algorithm,OriginalPaper,"With the rapid development of the Internet, short text has become more and more popular on the Internet and many short texts with a length of a few words to dozens of words have exploded, such as chats, text messages and comments. Among them, the extraction and analysis of such short texts relies on accurately text similarity calculations. Due to the ambiguity and data sparsity of short text, improving the accuracy of calculations for the similarity of short text remains an important and challenging task. To solve this problem, this paper conducts an in-depth study on the unsupervised Chinese short text similarity algorithm and proposes a fusion algorithm based on phonetics and semantics. The algorithm takes the sound, character, and word-meaning of the short text as the features, through these features to construct the feature vectors and calculate its own similarity for each vector, and then calculate the comprehensive semantic similarity of the text through the fusion algorithm and finally complete the similarity calculation method that integrates the three features of phonetic, character and semantics. In this paper, our algorithm was experimentally verified by LCQMC, a Large-scale Chinese Question Matching Corpus and the accuracy was improved by up to 29.2% compared with the traditional text similarity algorithm.","['Engineering', 'Computational Intelligence', 'Information Systems and Communication Service', 'Management of Computing and Information Systems']"
doi:10.1007/978-3-031-14537-7_12,en,Α New Method to Generate the Initial Population of the Bees Algorithm for Robot Path Planning in a Static Environment,OriginalPaper,This research work presents a modified form of the Bees Algorithm for mobile robot Mobile robot path planning Path planning . This modification is based on an alternative method to generate the initial population of the Bees Algorithm. The proposed method is adopted with the Bees Algorithm Bees Algorithm to find the shortest collision-free path Collision-free path for a mobile robot Mobile robot in static environments Static environment . The environment is represented using a 2D configuration space method that includes the robot and stationary obstacles Stationary obstacles —this representation guarantees dealing with a continuous map Maps as a reality. The new approach of initialising the population of the Bees Bees Algorithm ensures finding the initial paths even though the complexity of the given environment. The local search Local Search and global search Global Search are also implemented to enhance the initial solutions. Several benchmark maps Maps were simulated to compute the fitness of the generated paths. The results obtained using the Bees Algorithm Bees Algorithm for path planning Path planning were compared with those of other algorithms. The simulation proved the significant performance of the Bees Algorithm. The comparison results show the efficiency and superiority of the proposed method in finding the shortest path Shortest path .,"['Engineering', 'Robotics and Automation', 'Artificial Intelligence', 'Industrial and Production Engineering', 'Professional Computing', 'Robotics', 'Machine Learning']"
doi:10.1007/978-981-19-3998-3_162,en,Research on Real-Time Target Assignment of UAV Swarm Based on DA-PSO Algorithm,OriginalPaper,"Aiming at the real-time task allocation of unmanned aerial vehicle (UAV) clusters, a particle swarm optimization algorithm (DA-PSO) based on distributed auction mechanism is proposed. The simulation results show that the solution obtained by the application not only fully meets the requirements of the UAV swarm against real-time target allocation, but also has better convergence and better allocation effect than the traditional particle swarm optimization algorithm and other swarm intelligence algorithms. In addition, we also explored the Pareto optimal solution of the algorithm in this paper when solving multi-objective constrained optimization problems, and verified the optimality and efficiency of the algorithm by analyzing the distribution of the solution set points on the Pareto frontier.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-3-031-09835-2_4,en,Advances on Particle Swarm Optimization in Solving Discrete Optimization Problems,OriginalPaper,"Particle Swarm Optimization (PSO) is a well-known optimization method which optimizes a problem by having a population of candidate solutions, here dubbed particles, and moving these particles around in the search-space according to simple mathematical formulae over the particle's position and velocity. PSO initially proposed for continuous optimization and, to till, different discrete optimizations methods are developed adapting PSO in different time periods. The major concerns to solve discrete optimization task with PSO are the adaptation of particle encoding, velocity measurement and position update. The aim of this study is to demonstrate the evolution of PSO in solving discrete optimizations conceiving different adaptations in its operations. This study explains adaptation of PSO for four different discrete optimization problems: knapsack problem (KP), traveling salesman problem (TSP), vehicle routing problem (VRP), and university course scheduling problem (UCSP). The selected problems are well diverse having different constraints and objectives; KP seems a simplest one and UCSP is the most complex optimization task. The rhythmic presentation of PSO adaptation in solving KP, TSP, VRP and UCSP in this chapter may be a proper demonstration of PSO transformation from its original continuous domain to different discrete domains. The study will be made easy to understand other PSO-based discrete optimization methods as well as will be helpful to solve any new discrete optimization task adopting PSO.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-14537-7_7,en,Bees Algorithm Models for the Identification and Measurement of Tool Wear,OriginalPaper,"Bio-inspired computing algorithms are emerging approaches that are based on the principles and vision of the biological evolution of nature to implement new and robust competing techniques. Recently, bio-inspired algorithms Bio-inspired algorithms have been identified in machine learning to find the optimal Optimal solutions of problems in production processes. In this framework, swarm intelligence Swarm intelligence , which is a subfield of artificial intelligence concerning the intelligent actions of biological swarms by the relationship of individuals in such environments, is used to solve problems in the world by simulating such biological behaviours. Swarm intelligence Swarm intelligence is defined as the development of intelligent algorithms that mimick the behaviour of different animal societies. In particular, the Bees Algorithm Bees Algorithm, THE displays the foraging Foraging point behaviour of honeybees to solve optimisation and search problems. The algorithm performs a sort-of exploitative neighbourhood search combined with random explorative search. This chapter describes the use of the Bees Algorithm Bees Algorithm in its basic formulation for tool wear Tool wear identification and measurement Measurement during turning Turning operations.","['Engineering', 'Robotics and Automation', 'Artificial Intelligence', 'Industrial and Production Engineering', 'Professional Computing', 'Robotics', 'Machine Learning']"
doi:10.1007/978-981-19-6737-5_25,en,Community Detection Using Label Propagation Algorithm with Random Walk Approach,OriginalPaper,"Community detection is widely used research topic. Community detection refers to detect same type of community structure in given graph or network. Nowadays, community detection is used for many applications like fraud detection, recommendation system, segmentation, etc. In this paper, our objective is to find the label for the unlabelled node using random walk and then label propagation algorithm. In this method, labelled and unlabelled data is provided as input and then, we take random walk until we find the unlabelled node, after that label for unlabelled node is provided based on labelled node using label propagation algorithm. The output of this method will be label for unlabelled node by using this we can divide the network into community. Comparison of different algorithm for community detection is discussed in this paper.","['Computer Science', 'Computer Communication Networks', 'Computer Applications', 'Computer System Implementation', 'Artificial Intelligence', 'Image Processing and Computer Vision']"
doi:10.1007/978-3-031-15211-5_56,en,Fitness Landscape Analysis of Population-Based Heuristics in Solving a Complex Vehicle Routing Problem,OriginalPaper,"In this paper, a fitness landscape analysis of a complex Vehicle Routing Problem (VRP) is presented, and the effectiveness of population-based heuristic techniques is analyzed on this complex problem. The Vehicle Routing Problem is a common optimization task where vehicles deliver products to customers. The task is NP difficult; several heuristic algorithms have been involved in solving the problem. The objective is to select the right algorithm for the task, where the search space analysis provides an analytical answer. In this paper, the analysis of the population-based heuristics is presented. The paper presents an analysis of the following population algorithms: Ant System, Elitist Strategy of Ant System, Firefly Algorithm, Genetic Algorithm. In this paper, the results of the iterations of each population algorithm are analyzed in terms of the followings: fitness values, fitness distances, basic swap sequence distances, Hamming distances, the best solution, and filtered optima. Based on the test results, it can be concluded that the Ant System algorithm proved to be the most effective and the Firefly algorithm is not recommended to solve the presented complicated VRP.","['Engineering', 'Automotive Engineering']"
doi:10.1007/978-981-19-3842-9_61,en,Application of SecOC Based on SM4 Algorithm for Communication Security of Bus in Vehicle,OriginalPaper,"In order to promote the healthy and sustainable development of China’s Internet of Vehicles industry, the symmetric encryption algorithm generated by MAC is studied in this paper, according to the principle of SECOC secure communication mechanism in AUTOSAR specification. In this paper, based on the security framework of SECOC, the SM4 algorithm of the State Security is used to generate MAC, and MAC is added to the onboard communication in CAN to ensure the information security of the onboard CAN bus communication. Considering the high real-time requirement of vehicle network communication, the application scheme was verified by experiments.","['Engineering', 'Mechanical Engineering', 'Automotive Engineering', 'Transportation Technology and Traffic Engineering']"
doi:10.1007/978-3-031-20545-3_5,en,Task Allocation in Multi-robot Systems—Resource Welfare,OriginalPaper,"This chapter presents the application of a social welfare Social welfare function into an algorithm Algorithm that supports task allocation Allocation decisions in multi-robot systems. The algorithm Algorithm uses a resource welfare Resource welfare metric to make decisions in real-time Real-time allowing to pursue simultaneously resource consumption Resource consumption minimization and task completion Task completion maximization. The implementation of the algorithm Algorithm is explained in detail using numerical examples, and its flexibility and advantages over other market-based algorithms are discussed.","['Engineering', 'Computational Intelligence', 'Social Choice/Welfare Economics/Public Choice/Political Economy', 'Robotics and Automation', 'Artificial Intelligence']"
doi:10.1007/978-981-19-6149-6_5,en,Design of WAAM System Based on Industrial Robot,OriginalPaper,"With the development of material technology and craft, wire arc additive manufacturing (WAAM) is widely used due to its low cost, short cycle and strong structure. This article mainly studies WAAM system design and realization, path planning algorithm, and software development. The WAAM system is suitable for practical applications based on the improved SOM algorithm for 3D model simplification, the subdivision algorithm for increasing the accuracy of the 3D model, and the hybrid filling algorithm for filling the 3D model. In addition,the printing path and printing sequenceis also optimized. Based on the actual operation verification, it can be seen that the system has a certain practicability, and desired printing effect an be obtained.","['Engineering', 'Control, Robotics, Mechatronics', 'Artificial Intelligence', 'Industrial and Production Engineering', 'Control and Systems Theory']"
doi:10.1007/978-981-19-3387-5_128,en,A Research on an Unknown Radar Signal Sorting with DBSCAN-BP Algorithm,OriginalPaper,"For the unknown radar signal, this paper proposes a radar signal sorting algorithm DBSCAN-BP algorithm which combines unsupervised learning with supervised learning. DBSCAN algorithm is used to pre-sort and de-noise the unknown radar signal pulse data, and then BP neural network is used to finally sort the pre-sorting results of DBSCAN algorithm to realize the radar signal classification. In addition, this paper also proposes a method of radar data set division based on frame number, which can guide the simulation of real scene and make the radar sorting process more scientific.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Aerospace Technology and Astronautics']"
doi:10.1007/978-981-19-3998-3_164,en,Optimal Attack Against Coverage Path Planning in Multi-robot System,OriginalPaper,"Optimal path planning is a universal problem, but in the field of multi-robot system (MRS), most of the cases are NP. How to get the optimal solution of the problem is important and well worth studying. In this paper, we consider the confrontational scenario of MRS which performs a full coverage path planning (CPP) to execute missions. To prevent competitive MRS from completing missions, we develop an optimal attack path planning method to attack competitive MRS. We design an efficient breadth-first search (BFS) algorithm, through sacrificing part of the space complexity, realized in the obstacle environment for multi-robot system. The environment considered in this paper is represented by node connected graph and decomposed by univariate method. Finally, a series of simulation experiments are carried out, and the results are compared with another typical greedy algorithm. The comparison between the optimal and the worst case is obtained, which shows the superiority of the proposed algorithm.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-3-031-10650-7_14,en,Artificial Intelligence (AI) and Machine Learning (ML),OriginalPaper,This chapter presents “von Neumann Architecture” and analyzes the types of human intelligence and how machines can simulate human thinking; the logic used by Artificial Intelligence (AI); and techniques used by Machine Learning (ML) to “learn.”,"['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Computer Communication Networks']"
doi:10.1007/978-981-19-5077-3_15,en,Implementing Machine Learning Models for Drought Prediction Based on Metrological Drought Indices with Varying Time Scales: A Case of Latur Region,OriginalPaper,"Droughts have a huge socioeconomic impact, thus globally affecting the people, the environment, and the economy on a massive scale. Proper monitoring and accurate predictions can help mitigate the ill effects of such natural calamities to a considerable level. Providing warning signals and proper preplanning can provide further solutions. Drought occurrences highly depend on the environmental characteristics of the region. To identify drought and analyze its severity level, metrological drought indices like Standard Precipitation Index (SPI), Standardized Precipitation and Evapotranspiration Index (SPEI), and Reconnaissance Drought Index (RDI) are popularly used. The present work focuses on drought prediction using three drought indices SPI, SPEI, RDI. The case of Latur region of Maharashtra, India, has been taken for the research work. The prediction model is developed using support vector regression (SVR) and long short-term memory (LSTM) for varying timescales 1, 3, 6, 9 and 12 months, and the performance of the model is evaluated across measures like mean absolute error (MAE) and root mean squared error (RMSE).","['Environment', 'Environment, general', 'Geoengineering, Foundations, Hydraulics', 'Sustainable Development', 'Environmental Engineering/Biotechnology']"
doi:10.1007/978-981-19-2397-5_66,en,A Systematic Literature Review on Quadratic Programming,OriginalPaper,The aim of this paper is to present a review on the state-of-the-art related to quadratic programming (QP) according to the methodology of Kitchenham and Charter. Our review was motivated from four questions: Q1: In what areas are quadratic programming models used? Q2: What optimization methods are used to solve quadratic programming problems? Q3: What optimization methods or algorithms have been used for portfolio selection? Q4: What optimization methods or algorithms solve quasiconvex quadratic problems? We obtain very interesting results on QP and discovered a new line of research for future investigations.,"['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4863-3_27,en,Bidirectional LSTM-Based Sentiment Analysis of Context-Sensitive Lexicon for Imbalanced Text,OriginalPaper,"The authors plan to use a context-based lexicon as a source of energy to investigate totally unbalanced text sentimental analysis in this article. This strategy addresses two important issues in text sentiment classification: scenario interdependence and data corpus imbalance. To begin, it identifies subjective words in different contexts and computes weight rankings for vague generalisations and full review. As a result, RNNs have recently been used to solve real-world problems, specifically natural language processing tasks. The authors employ a context-based lexicon as well as a bidirectional LSTM to interact with text sentiment classification. Second, it interacts with unbalanced data by generating modern and unconventional text test results using a text-based post-processing technique. The experimental results show that using a sentiment lexicon similar to the framework and combining bidirectional LSTM with text-based sampling is beneficial in unbalanced text sentiment classification and yields state-of-the-art results when compared to deep neural learning model benchmarks.","['Engineering', 'Computational Intelligence', 'Engineering Design', 'Machine Learning', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-1844-5_33,en,Spice Yield Prediction for Sustainable Food Production Using Neural Networks,OriginalPaper,"The world population is increasing rapidly, and the consumption pattern of mankind has made a drastic drift over the recent years. Sustainable food production is important for our existence. The main focus of the study is to build a model that can predict the crop yield for spices such as black pepper, dry ginger, and turmeric based on given factors such as the district of cultivation, year of cultivation, area of production, production per year, temperature, and rainfall. The dataset was obtained from the Spice Board of India and Meteorological Database of India. The region primarily focused on is the districts of Kerala. Neural networks were used for the prediction, and a comparative study was done on different models such as deep neural network (DNN), recurrent neural network (RNN), gradient recurrent unit (GRU), long short-term memory (LSTM), bi directional long short-term memory (BiLSTM), backpropagation neural network (BPNN). The validation techniques taken into consideration include normalized mean absolute error (MAE), normalized root mean square error (RMSE), and mean absolute percentage error (MAPE). For dry ginger, GRU performed better compared to other algorithms followed by SRN. For black pepper, DNN performed better compared to other algorithms followed by simple recurrent network (SRN). For turmeric, GRU performed better compared to other algorithms followed by BPNN.","['Engineering', 'Communications Engineering, Networks', 'Mobile and Network Security', 'Artificial Intelligence', 'Big Data']"
doi:10.1007/978-3-031-16078-3_53,en,Modular Enumeration Algorithms: Analytical Study and Experimental Verification of Effectiveness,OriginalPaper,"Analyzed is a new approach to the use of enumeration procedures for finding solutions to a number of the following computational problems: search for globally optimal solutions to discrete optimization problems with Boolean variables, calculation of definite integrals with a given accuracy, solution of a multi-step antagonistic game of two persons with complete information. The purpose of this work, is in searching for the parameters of algorithms that implement modular enumeration, allowing them to be adapted in relation to the problem being solved and the computer used. The purpose of adaptation is to minimize the search time. It is shown that the effectiveness of this approach depends on three factors: on requirements for the accuracy of calculations, on the number of variables of the problem to be solved and on the amount of RAM of the computer used. Presented are the conditions that allow us to adapt the modular enumeration algorithms in relation to the numerical parameters, characterizing above factors. Experimental verification of the analytical results is based on the statistics obtained by solving the knapsack problem with different implementations of modular enumeration and on the statistical data obtained by calculating definite integrals with different requirements for the accuracy of calculations. The experimental data confirmed the correctness of the analytical forecasts and made it possible to determine the conditions for the most efficient applications of the modular enumeration technology.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5845-8_22,en,Pedestrian Detection Using MobileNetV2 Based Mask R-CNN,OriginalPaper,"Pedestrian detection system is one of the recent technological innovations to save human lives on the roadways. According to WHO, road accidents highly contribute to the increasing mortality. These traffic accidents can be avoided by utilizing an autonomous vehicle equipped with AI algorithms to identify the pedestrians efficiently. Advances in computer vision and deep learning techniques open up new research possibilities. This research study has introduced novel algorithms to combine two of the most efficient deep learning models. It is well-known that the Mask R-CNN is the most efficient deep learning model used for performing object detection in two stages. This process leverages high accuracy but it also include limitations such as low detection speed and high computational cost. To resolve this problem a lighter version of Mask R-CNN with MobileNetV2 architecture has been developed. In order to make Mask R-CNN light, some modifications have been done in Region Proposal Network (RPN) like a Convolution Operation is replaced by the Depthwise Separable Convolution Operation. To further speed up the process, MobileNetV2 architecture is used in the place of ResNet-101. MobileNetV2 uses inverted residual block and linear bottleneck to generate less number of parameters and reduced network computation to save time and speed up the process. The main goal of the proposed model is to detect the pedestrian with high accuracy and at high speed by consuming less computational cost without compromising robustness of the system. Further, the experimentation has been carried out with INRIA dataset and recorded a 98.9% detection rate, 0.87 mAP and 0.85 mIoU, which is far better than the standard Mask R-CNN with ResNet-101 architecture. The proposed model's weight is also 65% lighter than the conventional model, allowing it to operate faster and spend less time in interpretation. The performance of ResNet-101 based Mask R-CNN and MobileNetV2 based Mask R-CNN were compared in this study. This model can be expanded in future to yield more accurate findings and improve the ability to deal with emerging challenges in smart vehicles.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-16-3059-0_21-2,en,Emerging Futures and Technology Ethics,ReviewPaper,"Ethical standards in social work as they relate to technology have given much focus to issues of boundaries, confidentiality, and practicing within one’s area of expertise. This offers a temptation for social workers to claim that technology is not in their expertise, and thus avoid technology-mediated practice tools. Yet, as technology becomes more prominent in the lives of people served by social workers, it becomes more vital that social workers are conversant in ethical issues beyond online boundaries between social worker and client, as social workers may possess important roles related to helping clients navigate their technology-mediated lives. The global Covid-19 pandemic brought to light the ways that technology served as a first-line service for many clients, whether or not the social workers were ready for technology-mediated practice. This experience is likely to change our future practice. Ideally, it helps us move toward deeper discussions about the impact of technology on social service delivery, including present and near-future ethical issues related to the use of data, machine learning, and other emerging practices.","['Education', 'Education, general', 'Social Work', 'Social Work and Community Development', 'Ethics']"
doi:10.1007/978-981-16-9967-2_23,en,A Model to Generate Benchmark Network with Community Structure,OriginalPaper,"Meena, Shyam Sundar Tokekar, Vrinda The studies of social networks focus on the structure and components of networks at different levels. To identify the component in a network, researchers have developed various community detection algorithms. To test the quality of community detection results, networks with well-known community structures are used. But, a very few networks are available for this purpose. Researchers have suggested some models that generate artificial networks with the community. However, most of the proposed models are unable to produce benchmark networks similar to the real-world network. We propose a model that generates benchmark networks for the evaluation of community detection algorithms. The proposed model has been compared with well-known LFR Lancichinetti et al. (Phys Rev 78(4):046110, 2008 [ 14 ]) and GLFR Le et al. (2017 26th international conference on computer communication and networks (ICCCN). IEEE, pp 1–9, 2017[ 15 ]) models. For performance testing, various structural properties have been analyzed, which are followed by real-world networks. The NMI scores achieved by well-known community detection algorithms were also compared. In experimental analysis, we found that networks generated by our model follow essential properties of real-world networks.","['Computer Science', 'Computer Systems Organization and Communication Networks', 'Computational Intelligence', 'Artificial Intelligence', 'Wireless and Mobile Communication', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-4182-5_16,en,A Survey of Learning Methods in Deep Neural Networks (DDN),OriginalPaper,"Machine learning algorithm hyperparameters for a specific dataset are mathematically expensive and it is challenging to find the best values. Machine Learning predictive modelling algorithms are governed by hyperparameters. Artificial intelligence has become a new-age solution to most of the global challenges, hitherto unravelled and resolved. Within artificial intelligence, Machine Learning and its subset Deep Learning (DL) have brought a paradigm shift with their computation power. Currently, DL is a widely used computational approach in machine learning. The uniqueness of deep learning is its capability to learn a large amount of data. This paper discusses mathematical algorithms that are associated with each of these performance-enhancing measures and demonstrates tuning results and efficiency gains for each process and analysis, and it attempts to review different types of deep learning training and learning methods, viz., supervised, unsupervised, semi-supervised, and reinforcement learning together with challenges each face. Deep Learning algorithms are evaluated by applying different machine learning techniques.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Computer Systems Organization and Communication Networks', 'Statistics, general']"
doi:10.1007/978-981-19-3148-2_67,en,Recognition of Handwritten Digits Using Neural Networks: A Review,OriginalPaper,"Handwritten digit recognition is an ongoing and challenging research topic. In today’s world, the method for identifying handwritten digits is quite important, as there are plenty of methods to choose from. Handwritten digit recognition is an extremely common task and therefore requires techniques that are not only efficient but also that is extremely accurate. Currently, determining the correct meaning of handwritten characters is extremely difficult. The characters vary in their shapes and sizes depending on the writing style. There are numerous postal addresses for applications, as well as, bank checks that require handwritten digit recognition. Handwritten recognition techniques can help solve a variety of problems and make people’s jobs easier. The focus of this review article will be on several strategies for recognizing handwritten digits. The limitations and advantages of several neural network algorithms used for recognizing handwritten digits will be outlined in this review document. As a result, this paper provides an overview of various neural network algorithms for digit recognition as well as their limitations and precision rates.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory']"
doi:10.1007/978-3-031-21062-4_3,en,Artificial Stupidity in Robotics: Something Unwanted or Somehow Useful?,OriginalPaper,"Artificial stupidity has been reported in multiple computer science applications. This phenomenon can appear in two ways: artificial stupidity by accident is the result of artificial intelligence failures, whereas artificial stupidity by design is an intended development with a purpose. However, these concepts have not been studied in the context of robotics. This paper analyzes artificial stupidity in robotics, searching to answer the question: “Is artificial stupidity something that we must avoid or, on the contrary, something that can be useful for us?” It addresses the definition of the artificial stupidity problem and analyzes some potential methods to solve it.","['Computer Science', 'Robotics', 'Robotics and Automation', 'Computational Intelligence']"
doi:10.1007/978-3-031-18050-7_6,en,CPU Computation Influence on Energy Consumption Forecasting Activities of a Building,OriginalPaper,"Scheduling forecasting activities and improving the forecasting accuracy is important to deliver energy efficiency to the customers. However, it is also important to reduce the computational effort dedicated to these forecasting activities to ensure more effective environment sustainability. This paper proposes two forecasting algorithms known as artificial neural networks and k-nearest neighbors to anticipate energy patterns of a building monitoring data from five-to-five minutes. Using a case study with an annual historic and one week test, different scenarios are defined to test the forecasting activities with both higher and lower computational effort. It is achieved to ensure energy predictions with above reasonable accuracies evaluations while decreasing the computational effort, and the respective energy consumption, dedicated to forecasting activities.","['Engineering', 'Computational Intelligence', 'Industrial and Production Engineering']"
doi:10.1007/978-981-19-3148-2_69,en,An Effective Approach for Heart Diseases Prognosis Using Machine Learning Techniques,OriginalPaper,"Heart disease, often called as cardiovascular illness, is a term that refers to a group of illnesses that damage the heart, most commonly manifesting as myocardial infarctions or heart failure. When the heart is unable to pump sufficient blood to satisfy the body’s needs, this is referred to as heart failure. It connects a bevy of heart disease risk variables to a critical need for accurate, reliable, and pragmatic techniques for diagnosing and controlling the condition early on. Data mining is a common technique for evaluating vast volumes of data in the healthcare sector. Researchers analyze enormous volumes of complex medical data using a range of machine learning and data mining technologies, supporting doctors in the prediction of cardiac illness. This research study discusses numerous heart disease features, as well as ensemble and boosting models based on supervised learning algorithms like CatBoost, XGBoost, LGBM, etc. The goal of this study is to forecast whether such a patient will acquire heart disease. CatBoost classifier achieves the highest accuracy and F1 score, according to the results.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory']"
doi:10.1007/978-981-19-5221-0_30,en,Credit Card Fraud Detection using Machine Learning Algorithms,OriginalPaper,"Credit Card (CC) fraud has been an essential target to be addressed nowadays. E-commerce and many other online sites have increased the number of payment options available online, raising the risk of online fraud. Due to the rise in fraud rates, researchers began employing various Machine Learning (ML) approaches to detect and analyze online transaction fraud. The paper’s major goal is to build and create a novel fraud detection approach for Transaction data streams, with the goal of analyzing customer’s historical transaction details and extracting behavioral patterns. The effects of algorithms are manifested in agreement with established patterns, followed by correctness, accuracy, recall, and F1-score. The F1-score resides as many highly good ideas, particularly ancient ones, and the Naive Bayes, Bernoulli, and Random Forest are displayed with precision, accuracy, and recall.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Sociology, general', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-13150-9_42,en,Cyber Security Intruder Detection Using Deep Learning Approach,OriginalPaper,"Intrusion detection systems (IDS) are among the most promising approaches for securing data and networks; through the years, numerous categorization algorithms have been utilized in IDS. In recent years, as the alarming increase in computer connectivity and the substantial number of applications associated with computer technology have increased, the challenge of cyber security is constantly rising. A proper system of protection for numerous cyber-attacks is also required. This is how incoherence and attacks in a computer network are detected and IDS developed, which could play a possible role in cyber security. The authors used the CICIDS2017 dataset to meet this objective. It is the 2017 set of the Canadian Cyber Security Institute. The authors propose an IDS based on the deep learning technique to increase safety. The purpose was to use a neural network classifier to predict the network and web attacks.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Management']"
doi:10.1007/978-3-031-07242-0_12,en,Analytics in the Cloud,OriginalPaper,"The sheer volume of information available on Cloud, and the rate at which new data is being generated, is overwhelming the capacity of enterprises to manage it and people to use it in a meaningful manner. We examine a typical day in the life of the Internet. Such a data deluge has surpassed the capacity of existing data centers to store and process it in a timely manner. This gave rise to a new class of algorithms, such as MapReduce, which we shall study in a later section. In this chapter, we will introduce MapReduce and Hadoop and give examples of Amazon’s MapReduce (AMR). A class project of Twitter sentimental analysis using cloud is presented, which was able to predict the outcome of 2016 US presidential elections a full year in advance. Then we look at IoT-driven analytics in Cloud with a healthcare application, real-time decision-making support systems, and machine learning in a Public Cloud.","['Engineering', 'Circuits and Systems', 'Communications Engineering, Networks', 'Computer Communication Networks']"
doi:10.1007/978-3-031-13433-3_6,en,Intelligent Engineering Construction,OriginalPaper,"This chapter starts with the essential characteristics of intelligent construction “perception, analysis, decision-making, execution.” It firstly analyzes the feasibility of intelligent technology application in the design stage and the critical problems to be solved. It then focuses on the intelligent problems in the construction stage. Including the intelligentization of the service guarantee system and the intelligentization of each link in the construction process, the main tasks of intelligent maintenance are analyzed, the feasibility of intelligent construction management technology is analyzed, and the basic concept of virtual construction is introduced in this basis. It also provides some main contents of virtual simulation of road engineering. Finally, it introduces the application case of intelligent construction—the implementation process of intelligent compaction and related machine learning algorithms. In addition, the risks of intelligent construction are also discussed.","['Engineering', 'Transportation Technology and Traffic Engineering', 'Data Engineering', 'Building Construction and Design', 'Sustainable Development', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-18458-1_10,en,Implementation of Lightweight Cryptographic Algorithms in IoT Devices and Sensor Networks,OriginalPaper,"The Internet of Things (IoT) is a paradigm for normal entities capable of sensing and interacting with Internet-connected smart gadgets. The information can be combined from several devices which is applied as statistics to share the databases with this information. The Internet of Things modernizes the chips, cellular network, and sensor network, by connecting everything to the Internet. It has a wide range of uses in our life and industry. One area that requires attention is ensuring the confidentiality, validity of information, and data integrity that arises as a consequence of security and privacy. We have examined in this paper the use of various design principles via the development of KLEIN lightweight block cipher design. This study has indicated that the suggested loop unrolled design technique is useful in terms of energy efficiency. This implementation leads to a more efficient design with a lower energy consumption per bit. The implementation of the unrolled architecture permits the unrolling of additional rounds, up to the entire number of rounds needed by the cipher.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-0098-3_3,en,Anonymization of Multi-relations Datasets Using Single Table Algorithms,OriginalPaper,"Nowadays, immense educational data is available for analysis. To extract useful information from huge data, data analysis is required. For analysis, data has to be shared with a third party called data analyst. Sharing data with data analyst introduces the risk of privacy for individuals whose sensitive information is present in the shared data. Privacy is the right of an individual, so it needs to be maintained while sharing the data with a third party. There are many privacy-preserving algorithms available. k-anonymization is one of the most popular and traditional privacy-preserving methods. It modifies data to protect an individual's sensitive information by disconnecting the link between an individual and its sensitive information. k-anonymization uses generalization and suppression tools to anonymize the data. Generalization replaces specific values of attributes with general values, and suppression deletes unmatched values of attributes. There are many existing single table anonymization algorithms. The proposed work presents how a single table anonymization algorithm can be applied on multi-relation dataset. It also discusses the problems encountered when single table anonymization algorithms are used for the multi-relation dataset. Present work also discusses the limitations of k-anonymization and gives future research directions.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Statistics, general', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-18292-1_6,en,Explainable Artificial Intelligence in Health Care: How XAI Improves User Trust in High-Risk Decisions,OriginalPaper,"Explainable AI (XAI) is a set of methodologies, design concepts, and procedures that assist developers and organizations in adding a layer of transparency to AI algorithms so that their predictions can be justified. AI models, their predicted impact, and any biases may all be described using XAI. Human specialists can grasp the forecasts generated by this technology and have trust in the results. Medical AI applications must be transparent in order for doctors to trust them. Explainable artificial intelligence (XAI) research has lately gotten a lot of attention. XAI is critical for medical AI solutions to be accepted and adopted into practice. Health care workers utilize AI to speed up and enhance a variety of functions, including decision-making, forecasting, risk management, and even diagnosis, by analyzing medical pictures for abnormalities and patterns that are undetected to the naked eye. Many health care practitioners already use AI, but it is frequently difficult to understand, causing irritation among clinicians and patients, especially when making high-stakes decisions. That’s why the health-care business requires explainable AI (XAI). Significant AI recommendations, such as surgical treatments or hospitalizations, require explanation from providers and patients. XAI delivers interpretable explanations in natural language or other simple-to-understand formats, allowing physicians, patients, and other stakeholders to better comprehend the logic behind a suggestion—and, if required, to dispute its validity.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1412-6_6,en,Evaluating Various Classifiers for Iraqi Dialectic Sentiment Analysis,OriginalPaper,"Nowadays, social media outlets involve peoples’ opinions, reactions, and emotions. Sentiment analysis classifies the text from those sites into negative or positive polarity. Over the years, a multitude of researchers studied Arabic sentiment analysis but most of them focused on standard Arabic language. However, the Arabic dialects should have much concentration by researchers. Therefore, the main focus of this research is the sentiment analysis of the Iraqi Arabic dialect. The data sourced from Facebook platform (Posts and Comments), the most popular social media site in Iraq. Then, the data passed through several preprocessing steps and weighting methods. The processed data then passed into comparative experiments with six machine learning algorithms including Naïve Bays, Support Vector Machine (SVM), Logistic Regression (LR), Decision Tree (DT), Random Forest, and K-Nearest Neighbor (KNN). The results indicated the highest accuracy achieved by Naïve Bays with 81.2%, followed by SVM and LR with 74%, while DT and Random Forest achieved accuracy 64% and 63%, respectively. The worst result was achieved by KNN algorithm of 57%.","['Engineering', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security']"
doi:10.1007/978-3-031-07242-0_14,en,Healthcare in the Cloud: Case Studies,OriginalPaper,"In this chapter, we focus on health care in the Cloud, starting with an example of moving brain flow data using Transcranial Doppler (TCD) to a Public Cloud and accessing it via mobile devices. We deep dive into the architecture and deployment of a sample application that enables authorized doctors anytime, anywhere to access their patient’s records. Then we look at the examples of heart’s blood flow analysis and an antibiogram using unclassifiable data, both implemented using Cloud. Lastly, we look at evolution of multi-Clouds, federated learning to enable multi-party based computations in the Cloud.","['Engineering', 'Circuits and Systems', 'Communications Engineering, Networks', 'Computer Communication Networks']"
doi:10.1007/978-981-19-2535-1_54,en,Analysis of COVID-19 Vaccination Sentiments Using a Voting Hybrid Machine Learning Approach,OriginalPaper,"The coronavirus was declared a pandemic by the World Health Organization, and a vaccine for it was developed and is currently being used to vaccinate people all over the world. From the beginning of the COVID-19 vaccination program, many people have refused to accept the vaccine due to widespread misconceptions and propaganda concerning the COVID-19 virus itself, whether it is real or not, and the vaccination program as well. All these misconceptions and propaganda have been spreading through word of mouth (verbal) discussion among citizens. In this study, a hybrid machine learning approach was proposed with the help of natural language processing to build a sentiment classification and prediction system using the data collected from the public regarding their opinions on the COVID-19 vaccination program. The data was collected through the Google Form. The evaluation metrics used to measure the effectiveness of the proposed work were accuracy, precision, recall, and f-measure. Various machine learning algorithms were used for the implementation. Two algorithms, namely Support Vector Machine and Bagging Classifier, outperformed the remaining algorithms with the same accuracy and precision scores of 75%, respectively. The two algorithms were considered for the voting, which served as the final hybrid machine learning model for the sentiment classification and prediction tasks. The voting classifier works by predicting an output voting class based on the highest likelihood of the combined models, which were Bagging Classifier and SVM. Using the voting classifier, accuracy, and precision scores of 75% and 75% were also obtained.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3035-5_15,en,Android Malware Detection Using Machine Learning Classifiers,OriginalPaper,"The Android operating system has changed what mobile can do. The population of Android mobile users has been increasing, and the number continues to grow as the number of mobile users increases. Primarily, the applications used in Android devices are distributed via the Google Play Store. These applications are required to meet several criteria in order to be distributed via the Play Store. However, attackers sometimes find their way to compromise the Android operating system devices and steal users’ sensitive information. Malicious software or malware is designed to extract data from users by compromising their devices for financial gain or other reasons. This study uses machine learning algorithms to detect Android malware in the Android malware dataset. Using CICAndMal2017 dataset, random sampling was done to extract a balanced dataset. Feature engineering was performed to obtain the most significant features. Machine learning algorithms were trained using the balanced dataset with selected features. Initially, all the models were trained using ‘Label’ as the target variable and then ‘Family’ as the target variable. Maximum accuracy of approximately 99% was obtained using random forest in both cases.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Statistics, general']"
doi:10.1007/978-981-19-3951-8_3,en,Using Convolutional Neural Networks to Detect Compression Algorithms,OriginalPaper,"Machine learning is penetrating various domains virtually, thereby proliferating excellent results. It has also found an outlet in digital forensics, wherein it is becoming the prime driver of computational efficiency. A prominent feature that exhibits the effectiveness of ML algorithms is feature extraction that can be instrumental in the applications for digital forensics. Convolutional neural networks are further used to identify parts of the file. To this end, we observed that the literature does not include sufficient information about the identification of the algorithms used to compress file fragments. With this research, we attempt to address this gap as compression algorithms are beneficial in generating higher entropy comparatively as they make the data more compact. We used a base dataset, compressed every file with various algorithms and designed a model based on that. The used model was accurately able to identify files compressed using compress, lzip and bzip2.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-3-031-18409-3_1,en,Analysis of Long-Range Forecast Strategies for IoT on Urban Water Consumption Prediction Task,OriginalPaper,"With the rapid development of technology, researchers worldwide have applied the Internet of Things to effectively transmit and monitor water levels and detect anomalies in real time. The data obtained enables numerical methods to predict water consumption as well. In the presented paper, an attempt has been made to predict water consumption for various problems forward using dedicated models and a system using an iterative approach. For this purpose, neural network algorithms such as Random Forest, XGBoost, Decision Tree, and Support Vector Regression were tested and used to train the prediction models. The results presented allowed to indicate the difference between the examined methods through the Mean Absolute Percentage Error of prediction. The used set of algorithms allowed to show the problem of estimating water prediction from different points of view. Thus, determining the tested systems’ seasonality and short-term and long-term trends. This allowed to choose the two best algorithms, one that needs less computational power to work; this seems to be a better solution.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Education, general']"
doi:10.1007/978-981-19-5224-1_72,en,Machine Learning Prediction if the Patient is at Risk of Undergoing Surgery Based on Preoperative Medical Reports,OriginalPaper,"The ultimate aim of preoperative medical assessment is to minimize the patient’s surgical and anesthetic preoperative morbidity or death, and to return him to normal functioning as soon as feasible. Any preoperative evaluation must begin with a thorough history and physical examination, with an emphasis on risk factors for cardiac and pulmonary problems as well as determining the patient’s functional ability. We analyzed a real-world dataset of patients’ blood tests by using machine learning techniques and data science. We had raw data in CSV format; we had to normalize the data and then analyzed the data and then visualized the data. After that we used different machine learning models on the data. We have used different libraries such as sklearn, pandas, scipy, numpy, and matplotlib. Among a large variety of algorithms, we have used by the included study; the highest accuracy we have obtained is 83.34% from logistic regression technique using random state. We have obtained close to similar result using decision tree with 81.81% accuracy. As far as our other algorithms used, we have obtained 73% accuracy and 80% by using gradient boosting classifier and support vector machine algorithms, respectively. The remaining algorithms that were not fruitful enough giving us −13.3% and −9% for gradient boosting regressor and linear regression, respectively.","['Engineering', 'Communications Engineering, Networks', 'Statistics, general', 'Cyber-physical systems, IoT', 'Sociology, general', 'Professional Computing']"
doi:10.1007/978-981-19-3590-9_8,en,Prediction of Students Programming Performance Using Naïve Bayesian and Decision Tree,OriginalPaper,"Machine learning strategies are faster than ever in the field of education. Machine learning aims to discover hidden information and students’ performance in programming. From this paper, we suggest a model for predicting the performance of students in programming using two classification algorithms: Naïve Bayes and decision tree. Information was collected from Bachelor of Computer Application students at affiliated colleges at the University of Madras. The main purpose of such classification strategies may be to help students identify their weak points and improve their programming skills. Teachers can also take corrective measures to improve the students learning in programming. Test results show that Naïve Bayes is better than the decision tree with a high accuracy of 91.02%.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security', 'Mobile and Network Security']"
doi:10.1007/978-981-19-2225-1_9,en,A Survey on Applications of Machine Learning Algorithms in Health care,OriginalPaper,"As one of the main early adopters of innovative advances, the medical care industry has delighted in much accomplishment accordingly. In various wellbeing-related fields like new operations, patient information the executives, and ongoing infection treatment, artificial insight subset machine learning is assuming a key part. Inside the medical services industry, machine learning is gradually acquiring a foothold. An assortment of medical services circumstances is now being affected by machine learning (ML). With machine learning (ML) applied to the medical services industry, a great many different datasets can be investigated to make expectations about results, just as given opportune danger scores and exact asset designation. This exploration prompted the making of a more effective choice organization for clinical applications.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Statistics, general', 'Mobile and Network Security']"
doi:10.1007/978-981-19-3951-8_49,en,Intelligent Behavioral Health Analysis in Youth Using Real-Time Smartphone and Wearable Data,OriginalPaper,"Wearable devices have sensors that can be used for collecting motion data and provide objective measures of sleep and physical activity. Smartphones are being used increasingly contributing to users’ screen viewing time and hence be capable of providing accurate objective measures for the same. Disruption in the key lifestyle patterns like sleep, physical activity, and screen viewing may result in behavioral health impairments as these correspond to the utmost engaged times during the day. This work uses real-time features of physical activity, sleeping habits, and screen viewing to assess the behavioral health of 24 youths. Data is acquired from participants’ smartphones and smartwatches and behavioral health scores are evaluated based on the extracted features. Three statistical feature filtering methods have been used for feature selection, viz. correlation attribute evaluator, information gain, and gain ratio. The features selected by these attribute evaluators have been used to train supervised learning algorithms including four baseline machine learning algorithms and two deep learning algorithms. The best performance is reported by random forest and convolutional neural network with the performance accuracy of 93.06% and 96.77%, respectively, for the prediction of behavioral health.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2821-5_62,en,Automatic Detection of Online Hate Speech Against Women Using Voting Classifier,OriginalPaper,"Freedom of expression found on social media has various pros and cons. Gender-Based Violence (GBV) is also a major issue in social media. As a part of GBV, hate speech against women is on the rise on all social media. There are some lapses available in the stand-alone classifiers in detecting such speech, and the performance of ensemble classifiers is much better. Also, many research works have focused on common hate speech datasets. Hate speech against women has been used in very few research activities. But such hate speech is very dangerous. As a result, this research employs, Decision Tree (DT), Logistic Regression (LR), Random Forest (RF), and Long Short-Term Memory (LSTM) to compute metrics and performances and then use those algorithms to create a voting classifier to develop a more accurate model for detecting hate speech against at women. Two phases were used in this study. RF, LR, DT, and LSTM were used as foundation stand-alone classifiers in the first phase of the ensemble procedure. In Phase Two, the weights of the second-level classifier were estimated using first-level classifiers. Hate speech against women was detected using an open-source #MeToo dataset that was utilized for training and testing by the researchers. The dataset is publicly available on GitHub which was uploaded by Nazmus Sakib. This dataset consists of 278,765 #MeToo movement posts on social media. It clearly shows that the proposed voting classifier model has the highest values in all metrics including accuracy (89%). When we check the strongly positive classification, the proposed model has performed well in precision (0.90), recall (0.91), and F-measures (0.90) and it can calculate strong positive hate speech more efficiently than other stand-alone classifiers. This voting model takes more time to train since it has multiple models inside. By training it for more epochs, we can further increase accuracy.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-3-031-18461-1_6,en,Feature Extraction and Nuclei Classification in Tissue Samples of Colorectal Cancer,OriginalPaper,"Cancer is considered to be a major health risk and ranked third most important cause of death in the USA. The American Cancer Society (ACS) predicted that by the end of 2020, there will be close to 2 millions new cases and over half million deaths in the USA. In particular, colorectal, breast, lung, and prostate cancers are the most dangerous cancers. This paper aims at providing new solutions for Computer-Aided Diagnosis (CAD) of colorectal cancer, using feature extraction and machine learning algorithms. in this paper, four well-known machine learning techniques have been compared to classify tissue categories. That is, Random Forest, Naive Bayes, Multi-layer Perceptron and Support Vector Machine. In order to measure the performances of these algorithms, we have used Precision, recall and F1-Score. In particular, we have focused on the colors and morphological characteristics in the images and, how they can be useful to improve the classification and diagnosis of colorectal cancer. We believe that such an improvement represents a significant contribution to the state-of-the-art, in both quantitative and qualitative ways.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2635-8_17,en,Control Allocation Switching Scheme for Fault Tolerant Control of Hexacopter,OriginalPaper,"A control allocation switching method is proposed for hexacopter control considering actuator faults. The proposed method is a two-stage switching scheme, consisting of a projection-based adaptive control allocation and a constrained optimisation-based control allocation. The proposed method switches control allocation algorithms from the adaptive control allocation to the optimisation-based control allocation when the actuator of the hexacopter is saturated. The switching criterion decides the switching timing so that the control allocation is robust for the delay of fault detection and isolation module. Numerical simulation demonstrates that the proposed method can effectively perform actuator-fault tolerant position control of the hexacopter without actuator saturation and consume less control effort compared with existing one-stage control allocation algorithms.","['Engineering', 'Aerospace Technology and Astronautics', 'Engine Technology', 'Automotive Engineering', 'Mechanical Engineering']"
doi:10.1007/978-3-031-11051-1_122,en,Models of Recognition Algorithms Based on Construction of Two-Dimensional Logical Classifiers,OriginalPaper,"The paper considers issues related to the construction of a model of recognition algorithms (MRA) designed to solve the problem of object classification in conditions of interconnectedness of features. A new approach to the construction of the MRA is proposed on the basis of the construction of two-dimensional threshold classifiers (TDTC). The main idea of the proposed MRAs is to form a set of preferred two-dimensional classifiers. A distinctive feature of the proposed model is to determine a suitable set of TDTCs when constructing an extreme recognition algorithm (RA). The purpose of this paper is to develop MRAs based on the construction of a TDTC in the subspace of representative features. In scientific terms, the results of this work together represent a new solution to a scientific problem related to the issues of increasing the reliability of RA based on the construction of two-dimensional threshold classifiers. The practical significance of the results lies in the fact that the developed MRAs can expand the area of their application in the context of the interconnectedness of characteristics.","['Engineering', 'Control and Systems Theory', 'Control, Robotics, Mechatronics', 'Communications Engineering, Networks']"
doi:10.1007/978-3-662-65625-9_13,en,Time Management and Scheduling,OriginalPaper,"Planning & control in organizational logistics aims to deliver products and orders reliably by the specified due date. Time management and scheduling are first and foremost a matter of medium-term and short-term planning (during order release), although there are some long-term elements. Figure 13.0.0.1 shows the reference model for business processes and the tasks of planning & control introduced in Figure 5.1.4.2, highlighting the tasks and processes in time management and scheduling on a darker background.","['Engineering', 'Engineering Economics, Organization, Logistics, Marketing', 'Operations Management', 'IT in Business', 'Industrial Organization', 'Organization']"
doi:10.1007/978-981-16-7487-7_12,en,Error-Tolerant Mapping for Quantum Computing,OriginalPaper,"Quantum computers are built with fragile and noise/error-prone qubits. Some prominent errors include, decoherence/dephasing, gate error, readout error, leakage, and crosstalk. Furthermore, the qubits vary in terms of their quality. Some qubits are healthy whereas others prone to errors. This presents an opportunity to exploit good quality qubits to improve the computation outcome. This chapter reviews the state-of-the-art mapping techniques for error tolerance. We take quantum benchmarks as well as approximate algorithms for applications covering MaxCut, object detection and factorization to illustrate various optimization challenges and opportunities.","['Engineering', 'Circuits and Systems', 'Electronic Circuits and Devices', 'Processor Architectures', 'Nanotechnology', 'Electronics and Microelectronics, Instrumentation']"
doi:10.1007/978-3-031-22200-9_58,en,Evaluation of Model Order Reduction Algorithms for Unstable High-Order System Applied to Large Power System,OriginalPaper,"This paper presents and evaluates the method of order of large-scale unstable power systems using Modal truncation (MT), Balanced truncation (BT), Positive-real balanced truncation (PRBT), Balanced stochastic truncation (BST) and Linear-quadratic Gaussian balanced truncation (LQGBT). The results show that the LQGBT and BT algorithm has the smallest order reduction error. The MT method has the largest order of decreasing error. The BST algorithm gives the best time domain response. The PRBT method preserves the passivity of the original system. The simulation results show the advantages and disadvantages and the application range of step reduction methods.","['Engineering', 'Mathematical and Computational Engineering', 'Mechanical Engineering', 'Electrical Engineering']"
doi:10.1007/978-3-031-06780-8_11,en,Self-learning Decision and Control for Highly Automated Vehicles,OriginalPaper,"The decision and control module plays a key role for autonomous driving, which is responsible for generating appropriate control commands that navigate the autonomous vehicles safely and efficiently. Existing decision and control modules for automated vehicles are mainly using a rule-based hand-engineered approach. Although working well in a number of specialized scenarios, such method shows its limitation when dealing with highly automated driving tasks such as dense urban scenarios. Recent advances in artificial intelligence have inspired a line of works about self-learning based decision and control, which enable self-reinforcement of the control policy to potentially super-human performance. In this chapter, we will introduce how to appropriately apply such techniques to automated vehicles. The chapter will begin with the motivations and basics, followed by the key challenges and recent achievements of self-learning decision and control for automated vehicles, focusing on the following key aspects: scalability, performance, interpretability, mixed-model, and emergency handling.","['Engineering', 'Automotive Engineering', 'Computational Intelligence', 'Transportation Technology and Traffic Engineering', 'Signal, Image and Speech Processing']"
doi:10.1007/978-3-030-95764-3_3,en,AI in Logistics and Supply Chain Management,OriginalPaper,"Artificial intelligence (AI) applications are pervading logistics and supply chain management. The widespread availability of data, combined with sustained improvements in computing power, provides new opportunities to improve supply chain decision making. Data may originate from digital logistics applications or the connectivity of assets through Internet of things technologies. AI can also facilitate the automation of well-defined workflows. Yet, while AI may appropriate certain tasks, we believe it will not make the job of the logistics planner obsolete. AI empowers and augments human capabilities. This chapter explores and demystifies the opportunities of AI for logistics and supply chain management.","['Business and Management', 'Operations Management', 'Operations Research, Management Science', 'Industrial and Production Engineering']"
doi:10.1007/978-981-19-1484-3_3,en,An End-to-End GUI-Based Real-Time Attendance System by Training Annotated Facial Data on YOLO v3 Algorithm,OriginalPaper,"Attendance plays a major role in every student’s life; parents and school/college administrators are really concerned about their student’s attendance. Lower attendance can also lead to bad grades in schools and colleges, and at the same time, taking attendance manually alleviates the allocated time of a particular subject. In counteraction to the issues which we are dealing, this paper initiates the “An End-to-End GUI-based Real-Time Attendance System by Training Annotated Facial Data on YOLO v3 Algorithm” which keeps traces the student/ward attending a certain class with the help of photos captured from a visual recording device like surveillance camera by means of utilizing CNN, max pooling, and YOLO algorithms. Identifying a student’s image was popularized through the media. Facial recognition system has a wide variety of uses in recent times on mobile platforms like unlocking the mobile phone with the help of face recognition and in other forms of technology, such as robotics. It is mostly used as authorization in monitoring systems and can be compared to other biometrics such as retina recognition, voice authentication, and fingerprint recognition systems. This designed system will be absolutely systematized and authentic as Siamese network which has proven to proffer high authenticity in the face recognition system. The core intention of this paperwork is to develop a GUI page using Python programming, which will display the number of students who are present and amount of students who are absent along with the amount of students when section details are entered manually. In addition to this, pictures of the students who are present are displayed on the framework. It is called the real-time face detection which is very beneficial lately.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Machine Learning', 'Data Structures and Information Theory', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-981-19-3679-1_3,en,Comparative Analysis of Object Detection Models for the Detection of Multiple Face Masks,OriginalPaper,"Deep learning has immense prospective in many real-life practices, one of them being object detection. Object detection based on deep learning has shown encouraging results. Since December 2019, deadly virus named CORONA or COVID-19 started to engulf the whole planet with its impact. One of the easiest and simplest ways to protect oneself from this virus is by wearing a mask. In order to detect whether a person is wearing mask or not, we propose a model to detect various face masks that include cloth masks, N-95 masks, medical masks, and no mask. The proposed model consists of two major components—annotating, labeling images and detection of face masks. A new dataset has been created by combining images from Medical Masks Dataset and Google Images, and then these images were annotated according to the mentioned categories. A comparative study has been presented among different object detection algorithms along with a proposed detection algorithm. Results show that YOLOv5 performs best in the detection of face masks when compared to other detection models. It achieved a mAP of 0.51 in just 0.24 h on our dataset. On comparing YOLOv5 to the proposed model, we found that our model achieved a precision of 0.9 as compared to 0.88 of YOLOv5. Among existing approaches YOLOv5 performed the best with precision of 0.88. The model proposed in the work results in precision of 0.90 outperforming all existing models.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1577-2_52,en,Applicability of Peak Detection Methods for Composite Fatigue FBG Wavelength,OriginalPaper,"This study compares the accuracy and effectiveness of existing peak detection methods on the FBG spectrum in sensing the fatigue strain in a composite. It aims to give a solution to measure the FBG spectrum and further processing it, including selecting the FBG peak wavelength. The FBG sensor was bonded to the fatigue test specimen and the spectrums were acquired during the fatigue test were progressing. Three different peak detection algorithms were utilised, which include maximum, polynomial and centroid algorithms. Results showed that the centroid has the lowest precision compared to the polynomial and maximum algorithms. For fatigue wavelength data, it was found out that the maximum algorithm and third-order polynomial fitting are applicable as the peak seeking method for fatigue strain data from FBG sensor.","['Engineering', 'Electronics and Microelectronics, Instrumentation', 'Computational Intelligence', 'Biomedical Engineering and Bioengineering', 'Measurement Science and Instrumentation']"
doi:10.1007/978-3-031-18409-3_18,en,Obfuscating LLVM Intermediate Representation Source Code with NSGA-II,OriginalPaper,"With the generalisation of distributed computing paradigms to sustain the surging demands for massive processing and data-analytic capabilities, the protection of the intellectual property tied to the executed programs transferred onto these remote shared platforms becomes critical. A more and more popular solution to this problem consists in applying obfuscating techniques, in particular at the source code level. Informally, the goal of obfuscation is to conceal the purpose of a program or its logic without altering its functionality, thus preventing reverse-engineering on the program even with the help of computing resources. This allows to protect software against plagiarism, tampering, or finding vulnerabilities that could be used for different kinds of attacks. The many advantages of code obfuscation, together with its low cost, makes it a popular technique. This paper proposes a novel methodology for source code obfuscation relying on the reference LLVM compiler infrastructure that can be used together with other traditional obfuscation techniques, making the code more robust against reverse engineering attacks. The problem is defined as a Multi-Objective Combinatorial Optimization (MOCO) problem, where the goal is to find sequences of LLVM optimizations that lead to highly obfuscated versions of the original code. These transformations are applied to the back-end pseudo-assembly code ( i.e. , LLVM Intermediate Representation), thus avoiding any further optimizations by the compiler. Three different problem flavours are defined and solved with popular NSGA-II genetic algorithm. The promising results show the potential of the proposed technique.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Education, general']"
doi:10.1007/978-3-031-16078-3_54,en,Fatigue-Aware Event-Participant Arrangement in Event-Based Social Networks: An Upper Confidence Bound Method,OriginalPaper,"As the mobile Internet and social computing developed, online e vent- b ased s ocial n etworks (EBSNs) were derived, which mainly assign events to users according to the scores a linear combination of some features (i.e., location, similarity, friendship). Most of existing research work only takes offline scenarios into consideration, where users’ full information is known in advance. However, on real-world EBSN platforms, online scenarios have practical application value. Besides, existing works did not consider online learning users’ feedbacks (i.e., accept or reject arrangement), and did not consider users’ fatigue from seeing less interest events. In this paper, we investigate the online users’ feedback and fatigue control, where users can give a feedback by accepting a set of events arranged or reject events arranged due to less interesting events. In particular, we first model the problem as a stochastic bandit, and then applying Upper Confidence Bound based method (UCB-based) with expected regret, which is the polynomial in the events quantity in combinatorial settings. Finally, we evaluate the performance of our proposed algorithms with real data sets and synthetic data sets. And we find that in most setting, UCB-based algorithm has much lower regret compared to current state-of-the-art technology.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-0095-2_55,en,Email Spam Detection Using Multilayer Perceptron Algorithm in Deep Learning Model,OriginalPaper,"Email spam detection is a filtering process which identifies either it is spam or not. It also removes the unsolicited data present in the user’s email inbox. Certain type of spam mails contains malware which misuse the users’ data. Hence, we need to identify spam mails and take necessary actions. Many machine learning algorithms have proposed for differentiate spam mails from normal mails. Tokenization of emails between length and frequency is one of the techniques. It helps to split the raw emails into tokens known as small words. After tokenization, tokenized count has taken into consideration for process the emails. Based on that spam emails to be identified which are present in the dataset of spam and ham emails. To extracting these features, term frequency—inverse document frequency (TF-IDF) has used to train the model. In this method, multilayer perceptron deep learning algorithm is applied to compute the model. It has two layers. When input is given to the perceptron, the input is multiplied by the hidden layers, and it holds the activation function such as sigmoid activation with regularization function. For the better optimization, the model uses the Adam optimizer with gradient descent for fastest optimization. The network learns the model. The learning rate is set to true. While computing the model, it goes in the forward direction to train the model and comeback again (backpropagation). This process will be repeated. Going to the forward direction and comes back, then again, maintaining forward approach is called one epoch. The epoch rate has computed in the model. In the comparison between multilayer perceptron algorithm and machine learning algorithms such as support vector machine (SVM), random forest, and XGBoost, the deep learning algorithm produces 99% of accuracy on precision, recall, and F-measure and holds less computation time. Hence, the results prove that deep learning algorithm performs better than machine learning algorithms.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Systems and Data Security', 'Artificial Intelligence', 'Computational Intelligence']"
doi:10.1007/978-3-031-11170-9_10,en,Barriers of Artificial Intelligence in the Health Sector,OriginalPaper,"Demographic change, shortage of qualified employees and increasing cost pressure—the healthcare sector has to deal with various challenges. Coping with the current COVID-19 pandemic is an additional issue. All these barriers contribute to the fact that digitalization in the healthcare sector is moving forward more and more. Without the application of advanced technologies, healthcare organizations would reach their limits. In this context, the use of AI is becoming increasingly important. The potentials are wide-ranging and include applications in diagnostics and therapy, as well as the development of pharmaceuticals. But what challenges are associated with the use of AI in healthcare? Within the framework of a qualitative empirical study according to Mayring, this question has been investigated. Based on a systematic literature review, the following barriers of AI in healthcare have been identified and examined: Disagreement in data protection, lack of compatibility with ethical aspects, quality of training data, knowledge, and trust of physicians in AI-supported systems. The next step in the research design have been expert interviews among medical staff as well as AI developers with focus on AI in the healthcare sector mainly in Germany. According to these interviews, the data are analyzed and evaluated. Based on the results of the study, potential activities have been derived in order to be able to successfully overcome the barriers of AI in the healthcare sector in the future. Finally, the opinions of physicians and developers on the identified barriers are compared and discussed.","['Computer Science', 'Health Informatics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1142-2_18,en,House Pricing Prediction Based on Composite Facility Score Using Machine Learning Algorithms,OriginalPaper,"Various features of a house play some role to determine its price. Out of these, location is the dominant feature to determine the price. Besides location, there are some other features which affect the price of a house like area, sports facility, hospital, 24 × 7 security, etc. In this paper, 40 features, available in dataset of houses, are taken from Kaggle platform and have been considered for prediction of house prices. The data of six different cities of India has been included, and these are Delhi, Bangalore, Hyderabad, Kolkata, Mumbai, and Chennai. Here, we endeavored to develop a predictive model for anticipating the price dependent on a specific number of highlights that influence the price. Six machine learning algorithms are used to develop models and compared based on their accuracy of prediction, and the most accurate model is used to determine the price of houses.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Mobile and Network Security', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16072-1_21,en,"Framework for Modelling of Learning, Acting and Interacting in Systems",OriginalPaper,This work outlines unified formal approach to modelling and analysis of different ML problems in single-user and multi-user setting. This is done by extending formal framework of game theory and enriching standard definition of the game by introducing state (or memory) and algorithm for the players. This together creates formal tool allowing expression of the subtle properties of the models and algorithms. Additionally proposed definitions try to capture stochastic aspects of both algorithms and environment algorithms operate hence make stochasticity internal to the model.,"['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2225-1_35,en,K-Means Clustering in Image Compression,OriginalPaper,"Two techniques of machine learning are supervised learning and unsupervised learning. In Supervised learning, data is labelled whereas in a non-supervised learning algorithm input data is unlabelled. Supervised learning is further divided into classification and regression and unsupervised into clustering. This paper discusses the idea of clustering and its classification into hierarchical and partitional clustering, further discussing the types of partitional clustering, mainly K-means, and its difference over partition around medoids (PAM) and clustering large applications (CLARA) is also explained. This paper talks about the application of K-means clustering in image compression, and a practical case of compressing an image is also discussed.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Statistics, general', 'Mobile and Network Security']"
doi:10.1007/978-3-031-14623-7_27,en,Planning Field Development Using Optimization Algorithms,OriginalPaper,"The ultimate oil recovery rate is affected by both the geological properties of strata and the technological parameters of field development. The key indicators when choosing a development system are well grid density, the ratio of production and injection wells, technological modes of operation. Under the conditions of complex geological structure of fields, this problem cannot be solved without the use of tools of geological and hydrodynamic modeling. This work considers three options of planned well count arrangement with the distances between the wellbores of 150, 250, and 350 m within the limits of the external contour of the object oil bearing. The inverse five-point system has been chosen as an arrangement scheme. Calculations have been made using the hydrodynamic model. The results obtained showed that different options for the development of the object can be implemented (with different withdrawal rates, strategy performance, oil recovery rates), depending on the company's development strategy and allocated investments. Another important factor in choosing the option of object development is the operation modes of wells. For this purpose, we propose to use optimization algorithms built into the simulator. These algorithms make it possible to find the best solutions, observing the given conditions. The following algorithms were used in iterative calculations to find the optimal operation modes: differential evolution, particle swarm method, simplex method. The calculation results show that the optimization algorithms can be used to select a wide range of solutions for field development.","['Engineering', 'Construction Management', 'Building Construction and Design', 'Regional/Spatial Science']"
doi:10.1007/978-3-031-15191-0_14,en,Classification of Hate Speech Language Detection on Social Media: Preliminary Study for Improvement,OriginalPaper,"This study aims to improve performance in the detection of hate speech on social media in Indonesia, particularly Twitter. Until now, the machine learning approach is still very suitable for overcoming problems in text classification and improving accuracy for hate speech detection. However, the quality of the varying datasets caused the identification and classification process to remain a problem. Classification is one solution for hate speech detection, divided into three labels: Hate Speech (HS), Non-HS, and Abusive. The dataset was obtained by crawling Twitter to collect data from communities and public figures in Indonesia. The optimization process of the classification algorithm is carried out by comparing the SVM algorithm, eXtreme Gradient Boosting (XGBoost), and RandomSearchCV. The experiment was carried out through two stages of activity: the classification algorithm using SMOTE and without SMOTE with Stratified K-Fold CV algorithm. The highest performance accuracy with SMOTE is obtained at 90.7% with the SVM model. Whereas without SMOTE, the highest performance accuracy uses the SVM with a value of 87.8%. Furthermore, with the addition of the Stratified K-Fold CV algorithm for non-SMOTE, the train_score is 97.4%, and the test_score is 95.2%. The results show that SMOTE oversampling can increase the accuracy value in detecting hate speech.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Mobile and Network Security']"
doi:10.1007/978-3-031-17091-1_49,en,Adaptive Weighted Sum Bi-objective Bat for Regression Testing Optimization,OriginalPaper,"Regression testing is a type of testing carried out during the software maintenance phase, to confirm the validity of a software system after any modifications. However, regression testing is expensive, and sometimes it cannot be carried out within the testing budget, due to the large size of a test suite. In order to reduce regression testing cost, the test suite should be reduced without losing its efficiency in terms of pre-defined criteria such as its capability of fault detection; this problem is known as test suite reduction problem (TSR). In this paper, the TSR problem was formulated as a bi-objective optimization problem using an adaptive-weighted (AW) sum method. Then an adapted binary Bat algorithm (AW-ABBA) was utilized to search for a Pareto-optimal set of solutions; allowing the decision-maker under various circumstances to choose the best solution from the proposed set. The efficacy of the AW-ABBA was assessed using three metrics, Cardinality ratio, $${IGD}^{+}$$ IGD + and Diversity, over five test suites of different sizes. Experimental results showed that the AW-ABBA was able to efficiently approximate a reference Pareto-front.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Cyber-physical systems, IoT', 'Industrial and Production Engineering']"
doi:10.1007/978-981-19-2821-5_24,en,Designing Intelligent Intrusion Detection System for Industry 4.0 Using Feature Learning Techniques,OriginalPaper,"Increase in connectivity and cost pressure has pushed Industry 4.0 to rely on the systems built over Internet of Things (IoT). These IoT devices are susceptible to cyber-attacks. Intrusion detection system (IDS) protects such IoT devices from such attacks. However, the IoT devices are wreaked with the high-computational costs and curse of dimensionality. Current study presents an intelligent IDS system which is able to reduce the unwanted features. Proposed IDS system shows an accuracy of 99.26% with a precision over 99% to identify the attacks from the CICIDS2018 dataset.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-6068-0_15,en,Link Performance in Community Detection Using Social Network,OriginalPaper,"The structures of social network provide the regularities in the patterning of relationship among social entities. The relationship can be determined by frequency of interactions, propagation, and cultural activities and strong/week ties in social network. The structure of social network characterizes in terms of nodes (individual actors, people, or a thing within the network), ties, edges and links. The node is to be optimized to improve the link availability, clique through rate, effectiveness of link usage. The node optimization could be achieved by optimization of links. There are many predicting techniques are used to predict the nodes decision to improve the ‘influence propagation’ and ‘retrieve information’ from the requested users. The existing link prediction algorithms are based by the performance of the community’s with multiple parameters in the social network environment, and each parameter has to be quantified for best trade among the links. Hence, a node proximity clustering (NPC) algorithm has considered multi-dimensional parameters along with node weight value to quantify the importance value of the link prediction. The performance of the designed algorithm has been experimented in the various scenarios. The node proximity clustering algorithm (NPC) has been experimented in the defined environment with the fast greedy (FG), binomial (B), and socio rank (SR) of prediction algorithms. The results had been compared and analyzed. The proved algorithm has yielded 97.66% accuracy. It has validated with improvised label propagation algorithm and found that the proved algorithm accelerated the accuracy up to 15%.","['Computer Science', 'Artificial Intelligence', 'Computational Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-3571-8_36,en,A Survey on Diagnosis of Hypoglycemia and Hyperglycemia Using Backpropagation Algorithm in Deep Learning,OriginalPaper,"Diabetes is a metabolic issue. It has a great impact on uncountable individuals from one side of the planet to the other. Its annual occurrence rates are startling. Diabetes-related disorders in several important organs of the body can be lethal if left untreated. Diabetes must be detected early in order to receive adequate treatment and prevent the condition from escalating to severe consequences. A smart analytics model using deep learning should predict the risk factor about the patient and rigorous of diabetics using an unknown dataset. Deep neural network approach helps to find the optimal results using predictive analytics. Already available predictive models are used to predict whether the disease is normal or not based on the data processed. At first in this paper, the survey tells us that the ML algorithm is utilized for identifying the disease. Secondly, the deep neural network uses the backpropagation neural network as the base unit for breaking down the information by relegating loads to each part of the neural network. The main focus of the survey is to analyze and discuss about the machine learning and deep learning algorithms for the prediction of diabetics and investigate the solutions for getting best results in diabetic prediction with forecasting.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-18326-3_35,en,A Framework for Manufacturing System Reconfiguration Based on Artificial Intelligence and Digital Twin,OriginalPaper,"The application of digital twins and artificial intelligence to manufacturing has shown potential in improving system resilience, responsiveness, and productivity. Traditional digital twin approaches are generally applied to single, static systems to enhance a specific process. This paper proposes a framework that applies digital twins and artificial intelligence to manufacturing system reconfiguration, i.e., the layout, process parameters, and operation time of multiple assets, to enable system decision making based on varying demands from the customer or market. A digital twin environment has been developed to simulate the manufacturing process with multiple industrial robots performing various tasks. A data pipeline is built in the digital twin with an API (application programming interface) to enable the integration of artificial intelligence. Artificial intelligence methods are used to optimise the digital twin environment and improve system decision-making. Finally, a multi-agent program approach shows the communication and negotiation status between different agents to determine the optimal configuration for a manufacturing system to solve varying problems. Compared with previous research, this framework combines distributed intelligence, artificial intelligence for decision making, and production line optimisation that can be widely applied in modern reactive manufacturing applications.","['Engineering', 'Robotics and Automation', 'Industrial Chemistry/Chemical Engineering', 'Computer-Aided Engineering (CAD, CAE) and Design']"
doi:10.1007/978-3-031-10507-4_11,en,Post-Quantum Digital Signatures for Bitcoin,OriginalPaper,"The security guarantees of Bitcoin rely on public key cryptography and hash primitives. However, once that large-scale quantum computers become available, these cryptographic primitives will be vulnerable to quantum attacks. This chapter presents a study of the main challenges associated with the design of a quantum-resistant version of Bitcoin that is based on any of the post-quantum digital signatures selected as finalists and alternates of NIST third-round Post-Quantum Cryptography Standardization Process. Our analysis takes into account on the one hand Bitcoin’s security requirements and, on the other hand, NIST finalists and alternates reported public key and signature sizes, as well as their corresponding signature/verification timing performances. We conclude that most of the finalist and alternate candidates are unsuitable for being used by Bitcoin. The most promising post-quantum candidates are lattice-based Falcon and Dilithium-2 schemes. However, it still represents a formidable challenge to deal with the extra burden that the public key and signature sizes produced by these post-quantum candidates would impose in Bitcoin’s block size.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Systems and Data Security']"
doi:10.1007/978-981-19-4676-9_27,en,Study of Document Clustering Algorithms Applied on Covid Data,OriginalPaper,"Suresh, Sweety Krishna, Gopika Thushara, M. G. The advancement in the technology rises online unstructured data. As the data grow rapidly, tackling the information is becoming hard. There is a demand to maintain these unstructured data to gather important insights. Clustering of the text documents has become leading edge over Internet. Document clustering is mainly described as grouping of the similar documents. It plays vital role for establishing massive information. The paper shows an overview of study done on different clustering algorithms on covid data. The study of the semantic links between words and concepts in texts aids in the classification of documents based on their meaning and conception. The clusters were visualized using the k-means clustering technique, which was then evaluated using t-distributed stochastic neighbor embedding (t-SNE) and principal component analysis (PCA).","['Engineering', 'Computational Intelligence', 'Systems and Data Security', 'Artificial Intelligence', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-981-19-3330-1_12,en,Guidelines for Minimization of Uncertainties and Estimation of a Reliable Shear Wave Velocity Profile Using MASW Testing: A State-of-the-Art Review,OriginalPaper,"Resilience against earthquakes has become important in the current scenario, when numerous events of seismic shaking keep on occurring, especially in regions of high population. For that, reliable seismic site characterization is extremely important. The seismic surface wave methods are the commonly adopted methods for seismic site characterization and subsequent applications. After many evolvements, the multichannel analysis of surface waves (MASW) has grown to be the widely chosen surface wave method across the globe. However, the method has numerous peculiar specifications regarding its procedures of data acquisition, analysis, and interpretations. Each step in the MASW can induce notable uncertainties in the results. Even a single mistake in any of the procedures can lead to erroneous results, which are difficult to be identified even by any third party. Many such cases have been reported earlier by researchers. Such practices may foster substantial losses because ultimately the MASW results are useful for the generation of the design response spectra. Due to all these reasons, there is an alarming need for the dissemination of knowledge about the guidelines for the reliable practice of MASW testing. This paper provides a comprehensive account of the fundamentals of the MASW method, the ways to implement its three steps of data acquisition, processing, and inversion, and the ways to improve confidence in the results. It presents a detailed and comprehensive literature review on the topic, including the historical developments and theoretical basis, subsequent evolvements, current practices, and recommendations for reliable testing. The amount of references has been kept very high to facilitate a thorough understanding of the topic and draw sufficient inferences. An elaborate description of the uncertainties in the test and how to deal with them has been presented. The parameters to be set while carrying out those three steps have been discussed, and suggestions are presented. The suggestions are based on the field experiences and literature review of the research works by many prominent researchers.","['Engineering', 'Geoengineering, Foundations, Hydraulics', 'Geotechnical Engineering & Applied Earth Sciences', 'Natural Hazards', 'Agriculture', 'Solid Mechanics']"
doi:10.1007/978-981-19-5845-8_45,en,Virtual Machine and Container Live Migration Algorithms for Energy Optimization of Data Centre in Cloud Environment: A Research Review,OriginalPaper,"The growing pace of cloud computing technology needs to optimize the energy consumption of the data centres. Virtualization is one such technology that helps in live migration of Virtual Machines and Containers and thus help reduction in energy consumed. An effort is made in this paper to explore different approaches for energy optimized live migration using Virtual Machine and Container. Majority of the work has been carried out by researchers considering CPU utilization as the parameter to optimize the energy consumption and some works have used other parameters like memory, disk space, application execution time for active server along with CPU utilization. The survey also depicts majority of the work are implemented using CloudSim and also there is more scope for developing solutions for optimal migration in Virtual Machine and Containers.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2535-1_63,en,Performance Stagnation of Meteorological Data of Kashmir,OriginalPaper,"Rainfall prediction is the highest research priority in flood-prone areas across the world. This work assesses the abilities of the Decision Tree (DT), Distributed Decision Tree (DDT), Naïve Bayes (NB), Random Forest (RF), Support Vector Machine (SVM), K Nearest Neighbour (KNN), and Fuzzy Logic Decision Tree (FDTs) machine learning algorithms for the rainfall prediction across the Kashmir province of the Union Territory of Jammu & Kashmir. On application of Machine learning algorithms on geographical datasets gave performance accuracy varying from (78.61–81.53)%. Further again machine learning algorithms were reapplied on the dataset without season variable yet again performance ranged in between (77.5–81)%. Vigorous analysis has established that these machine learning models are robust and our study has established that the dataset reaches performance stagnation and thus resulting in performance capping. The stagnation is irrespective of the choice of algorithm and the performance shall not improvise beyond a specific value irrespective of the choice of the machine learning algorithm.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4990-6_31,en,Vedic Multiplier for High-Speed Applications,OriginalPaper,"We live in a technologically advanced society. The use of diverse electronic gadgets is interwoven with even the most fundamental aspects of our daily lives. They increase and smoothen the pace of our life. The multiplier component controls the speed of most electronic systems. The multiplier module is a significant component of high-speed applications that employ the IEEE 754–2008 standard for single precision FPUs. Several existing methods have been included to enhance the multiplier's speed of operation. They have, however, not demonstrated a substantial difference in speed, raising it by a maximum of 1.182 times. As a result, we presented “Vedic Design,” a novel algorithm with a distinctive architecture. When this was simulated in Vivado, it improved the multiplier's speed by 3.4478 times, resulting in a multiplier that is nearly 3.5 times more efficient. The gadget is better equipped to function as a result of the reduced computational path latency.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Wireless and Mobile Communication']"
doi:10.1007/978-981-19-3035-5_41,en,The Application of Cyclostationary Malware Detection Using Boruta and PCA,OriginalPaper,"An analysis of cyclostationary malware is introduced. The most important cyclostationary features used for network intrusion detection systems (NIDS) are then detected with a feature extractor algorithm, such as Boruta and principal component analysis (PCA). These feature patterns are classified to determine the most cyclostationary ones. In particular, this article shows the relevance of detecting cyclostationary malware for a NIDS by using legacy datasets, such as the KDD99 and NSL-KDD. This research has also used the UGRansome cyclostationary dataset intended to support research on anomaly detection. This dataset is subdivided into normal and abnormal classes of network threats. A comparative analysis based on random forest and support vector machine algorithms is undertaken, and the performance of Boruta and PCA was also evaluated. The research suggests the utilization of PCA in terms of extracting cyclostationary network feature patterns as a viable proposition compared to Boruta. The Internet Protocol (IP), malware financial damages, class C of IP addresses, and signature malware were also found to be the most cyclostationary feature pattern. The UGRansome dataset outperformed the KDD99 and NSL-KDD in terms of detecting signature malware with an accuracy of 99% using the random forest algorithm, while the support vector machine achieved 68%. This research proposes the UGRansome as a suitable choice to reduce the computational time of cyclostationary malware classification. Lastly, the research suggests the utilization of random forest to stratify and detect cyclostationary malware.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Statistics, general']"
doi:10.1007/978-981-19-6004-8_17,en,Forecasting Prediction of Covid-19 Outbreak Using Linear Regression,OriginalPaper,"Coronavirus these days becomes an alarming topic as the loss of lives is increasing every day. Coronavirus was born in China (Wuhan) and has spread globally within no time. Machine learning is used to forecast the future outcomes almost in all areas like computers, medical, business, security, and many more. In this study, various machine learning techniques such as Linear Regression, SVM, Random Forest, Logistic Regression, and KNN are used to forecast the future tendency of SARS-CoV-2. The polynomial feature with degree 3 is used to enhance the accuracy of the model. Dataset is collected from Johns Hopkins University dashboard. It contains 3 separate files of Covid-19 such as confirmed case, recovered case, and death case dataset. This article has four phases, i.e., data preprocessing, data classification, training, testing, and parametric evaluation such as RMSE, MSE, MAE, and R 2 -score. In this study, Linear Regression (LR) shows excellent outcome in contrast to other approaches. LR has a minimum mean squared error value and an obtained accuracy of 99.92% for Covid-19 confirmed cases, 99.73% for recovered cases, and 99.60% for death cases. Results show that if humans become unsocial and the administration imposes strict lockdown, there is a great chance to overcome this disease within a small period.","['Engineering', 'Computational Intelligence', 'Cognitive Psychology', 'Personality and Social Psychology', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-19958-5_64,en,8–10-Gene Expression-Based Atom Search for Aquaponic Lettuce Evapotranspiration Optimization Based on Photosynthetic Light Properties,OriginalPaper,"Sustainability in controlled-environment agriculture (CEA) can be achieved through improved productivity and optimized use of resources. Water evaporation and plant transpiration causes loss of water from vegetation and known as evapotranspiration (ET). ET is a crop attribute that can be controlled by light intensity and radiation to improve plant growth. In this study, minimum evapotranspiration rate for aquaponic lettuce is achieved by optimizing artificial light properties through hybrid multi-gene symbolic regression genetic programming and bio-inspired algorithms including Genetic Algorithm (GA), Lichtenberg Algorithm (LA), and Atom Search Optimization (ASO). The optimized global solution was achieved using 8–10 gene expression-based atom search optimization model. Results of this study can be used to improved aquaponic lettuce yield and growth in controlled environment.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2412-5_3,en,An Overview of Quantum Computing Approach in the Present-Day Energy Systems,OriginalPaper,"With the increase in global population and global heating, energy demand is also constantly increasing. The uprising demand to be fulfilled by taking care of environmental conditions’ protection to keep global warming in check. Significant efforts have been put into designing, controlling, handling, planning, and managing energy systems. In this regard, bio-inspired or nature-inspired evolutionary optimization schemes in the existing energy systems and innovative energy sources are inducted into the available resources. On the other hand, quantum computing has changed the classical computational approach with speed and efficiency. The assurance of quantum computing in the optimization of energy systems also gained a research attraction. The optimization techniques employed with the quantum advantage by quantum computers supersede classical approaches. This study explores the viability of quantum computing in energy system optimization and various challenges to tackle. This work will help the readers to plan for applying this approach in sustainability energy harvesting, intelligent power and energy systems, distribution network, and renewable energy. Security of the smart grid, intelligent energy systems, evaluation of the energy production process, and other similar or related applications may also be explored.","['Engineering', 'Power Electronics, Electrical Machines and Networks', 'Renewable and Green Energy', 'Energy Storage']"
doi:10.1007/978-981-19-3575-6_23,en,Combining Variable Neighborhood Search and Constraint Programming for Solving the Dial-A-Ride Problem,OriginalPaper,"Dial-a-ride problems (DARPs) have become a popular topic in logistics in recent years. They are frequently used in transportation, goods distribution, and fast delivery. The DARP is an NP-hard optimization problem in which the objective is to organize transmutations from pickup to delivery locations of geographically dispersed customers. Multiple exact and heuristic approaches have been proposed in the literature to solve the DARP. In this paper, we propose a novel algorithm that combines a variable neighborhood search with constraint propagation to solve this problem. Variable neighborhood search is a metaheuristic that iteratively modifies routes to improve the quality of an incumbent solution. Constraint propagation makes use of techniques like backtracking, forward filtering, consistency enforcement to iteratively restrict the possible routes in the problem. Combining the two approaches, one obtains an algorithm that has good properties in terms of runtime and solution quality. In simulations, the algorithm is shown to be more efficient than the basic variable neighborhood search when runtimes are small.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-11047-4_4,en,Synchronization in VLSI,OriginalPaper,"Virtually all modern high performance integrated systems are sequential in nature, requiring a precise order of data flow. A temporal reference, i.e., the clock signal, is therefore distributed within the network to temporally control the flow of data. The clock distribution network is a seminal part of any synchronous integrated circuit. The high frequency nature of the clock signal combined with the long distance to each clocked element significantly complicates the distribution of the clock signal. In this chapter, the clock distribution network design process is considered from a graph theoretic perspective. Graph-based techniques used during clock tree synthesis are described, including cycle basis, spanning tree, Steiner minimal tree, and graph optimization. With clock skew scheduling, the arrival time of the clock signal at each synchronous element is determined while maximizing the speed and/or robustness of a system. An abstract topology of a clock tree is determined during clock tree synthesis. A physical layout is produced during clock tree embedding. The position of the synchronous elements and wire lengths are adjusted to satisfy the target arrival times of the clock signal.","['Engineering', 'Circuits and Systems']"
doi:10.1007/978-3-031-18154-2_4,en,Second Trimester and Artificial Intelligence,OriginalPaper,"In this chapter we are going to explore the more complex anatomy of the second trimester fetus. Once again, Artificial Intelligence systems can aid the sonographer by signaling possible anomalies. Congenital heart diseases can also be spotted using the sonographer + Artificial Intelligence merger. Other screening tests are also depicted.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Gynecology', 'Obstetrics/Perinatology/Midwifery', 'Machine Learning']"
doi:10.1007/978-3-031-16203-9_22,en,Expert Decision Support System Modeling in Lifecycle Management of Specialized Software,OriginalPaper,"The paper describes the complexity of the short-term planning process in lifecycle management of specialized software. The critical stages of sprint scope planning in projects, which works by Agile models were explored. Network planning methods have been adapted to determine the critical indicators in lifecycle management of specialized software. An algorithm for automated construction of a network model and its representation in PC memory is proposed, as a data structure. Based on it, algorithms for constructing and traversing graphs of the network model, determining early and late execution time, and determining the critical execution path and time reserves are proposed. Developed algorithms for constructing and traversing graphs of the network model to automate the calculation of its parameters will be embedded in the work of the expert decision support system in lifecycle management of specialized software. The developed expert system will allow making operative decisions on re-planning of duration and the maintenance of project works in real-time. The system was developed using the Java programming language. The results of the system are presented in the development environment IntelliJ IDEA.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2468-2_28,en,FIR Filter Design Using Grasshopper Optimization Algorithm,OriginalPaper,"In this paper, digital finite impulse response (FIR) low-pass filter (LPF) and high-pass filter (HPF) are designed using a novel meta-heuristic algorithm named grasshopper optimization algorithm (GOA). The GOA is meta-heuristic population-based optimization algorithm, which mimics the food searching behaviour of the grasshopper. The filter design aims to evaluate the optimal filter parameters and find the minimum objective function value so that the output of the designed filter matches with the output response of the ideal filter. Mean square error (MSE) is taken as the error objective function. The results obtained using GOA are compared with the other two algorithms, namely particle swarm optimization (PSO) algorithm and grey wolf optimization (GWO) algorithm. The simulated results reveal that GOA is best suited algorithm for FIR filter design problem.","['Engineering', 'Electronics and Microelectronics, Instrumentation', 'Quantum Physics', 'Measurement Science and Instrumentation']"
doi:10.1007/978-981-19-4960-9_21,en,Bengali Review Analysis for Predicting Popular Cosmetic Brand Using Machine Learning Classifiers,OriginalPaper,"Nowadays, online platform has become one of the most popular media to express people’s thought of all ages. That made the online platform a precious source for getting almost every kinds of information. As online shopping is rising in no time in recent years, as a result millions of comments are generating every single day. These users generated opinions on social media and different websites has made it easier for the people choosing the right product for them. Hence, sentimental analysis is a sought-after research topic nowadays. Our research paper has portrayed an experimental study on different cosmetics products review. To do so, we have selected ten popular cosmetic brands for analyzing their product review and chosen to analyze Bengali comments or sentences. The main focus of our work was to get out the most popular cosmetic brands among ten chosen brands. We have applied four classification algorithm such as naive Bayes, random forest, decision tree, and support vector machine for analyzing the final outcome and found vaseline and clear are the most popular brands.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Professional Computing']"
doi:10.1007/978-3-031-16598-6_22,en,Digital Transformation for Intelligent Road Condition Assessment,OriginalPaper,"Recently, governments have been resorting to cutting-edge artificial intelligence technologies to facilitate the digital transformation of smart cities. Remarkable progress has been made to strengthen smart city governance and sustainability, especially in road condition assessment. Road data acquisition and defect detection, two major processes of intelligent road condition assessment, play an important role in ensuring road maintainability while providing maximum traffic security and driving comfort. Traditional manual visual inspection is inefficient and lacks objectivity. Therefore, intelligent road condition assessment systems developed based on data-driven techniques have received increasing attention. This chapter presents the state-of-the-art intelligent road condition assessment systems, the existing challenges, and future development trends.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-18458-1_18,en,S-Image (Situation Image): A New Technique for Data Aggregation in Cloud Server for IoT Based Smart City,OriginalPaper,"The diversity and sheer expanding in the number of Internet of Things (IoT) devices in a smart city context has raised substantial problems about storage and processing. Different sensors use different data formats. A situation is formed by combining data obtained from different sensors. This combination process needs a unified representation of sensor data. However, processing this massive amount of data and combining it to represent appropriate situations is a difficult task. To overcome this challenge, a data aggregation mechanism that is both efficient and light-weight is required. In this research, we developed a new data aggregation technique in cloud servers, where the processed data is transformed into a two-dimensional image-like spatial representation called Situation Image (S-image). We also developed a prototype that realizes the aforementioned aggregation model. In our experiment, multiple data mining techniques were chosen for processing various datasets in order to meet a variety of application goals. The experimental findings proved the viability of our data aggregation method.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-0448-6_10,en,Energy-Efficient Base Station Association and Beamforming for Multi-Cell Multiuser Systems,OriginalPaper,"This chapter investigates the energy-efficient base station (BS) association and beamforming for multi-cell multiuser systems. Section  10.1 introduces the motivation of investigating energy-efficient BS association and beamforming. Section  10.2 presents the system model and formulates the problem. Section  10.3 develops the centralized BS association and beamforming algorithm, and Sect.  10.4 develops the decentralized beamforming algorithm. Section  10.5 presents the numerical results, and Sect.  10.6 concludes this chapter.","['Engineering', 'Wireless and Mobile Communication', 'Energy Systems']"
doi:10.1007/978-981-19-1976-3_4,en,K-Weighted Cluster Head Selection in Wireless Sensor Networks,OriginalPaper,"Wireless Sensor Networks (WSNs) are emerging technologies with a huge range of potential applications. They are different from other wireless technologies due to a set of specific requirements and feature such as node density, power requirements, and computer capabilities. To increase the lifetime of WSN, clustering is one of the most important ways which includes the collection of sensor nodes into groups and the selection of Cluster Heads (CHs) for each clusters. This paper focuses on hierarchical cluster head selection that aims to reduce the number of dead nodes in WSN. To attain this, K-Weighted Cluster Head Selection (K-WCH) algorithm is proposed with a weight factor to reduce the computational overhead. The proposed algorithm prolongs the network lifetime by reducing the computational energy and minimizing the number of dead nodes. From the simulation results, it is inferred that the proposed K-WCH algorithm outperforms K-means and LEACH protocol in terms of energy consumption and dead nodes.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-20105-9_7,en,Comparison of Optimization Techniques for Solar Cells Parameter Identification,OriginalPaper,"The management of renewable energies has increased over the years due to the environmental effects that fossil fuels cause. Several energies alternatives have been adopted for their exploitation recently, one of the most accepted is the solar cells due to their unlimited source of power. Solar cells parameter determination has become an important task for several fields in science. The performance of solar cells operation is associated with the parameters of their design, which becomes a complex task due to the multimodality and non-linearity of their error surfaces, increasing the difficulty of their optimization. EC’s techniques are employed for determining optimal solutions to complex problems.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-6072-7_5,en,Application of AI in Rail Transit Operation and Maintenance,OriginalPaper,"Compared with traditional methods, artificial intelligence has produced unprecedented good results in improving driving efficiency and safety.","['Engineering', 'Automotive Engineering', 'Artificial Intelligence', 'Transportation Technology and Traffic Engineering']"
doi:10.1007/978-981-19-6004-8_49,en,Advanced Approach for Heart Disease Diagnosis with Grey Wolf Optimization and Deep Learning Techniques,OriginalPaper,"Electrocardiography (ECG) has gained popularity in recognizing abnormally quick and slow heart rates. Previously, clinical data was used for heart disease diagnosis. Advance technology led to improvement in deep learning (DL) and optimization algorithms that use image data to classify and predict heart diseases. DL eliminates data pre-processing as in machine learning (ML), to scan and search features that correlate and combine them to enable faster learning. DL requires huge data to perform accurately. DL is expensive concerning hardware requirements and training which increases the overall cost. Hence, grey wolf optimization (GWO) can provide competitive results of improved local optima. This paper presents an advanced approach of index matching to perform analysis in two categories by merging clinical data with ECG for classifying and diagnosing heart diseases. Best features are selected by GWO on merging 12-lead Physikalisch-Technische Bundesanstalt (PTB-XL) ECG data and clinical data. Evaluations using deep neural networks on the merged data set are performed. In comparison, the results show that convolutional neural networks (CNNs) using Visual Geometry Group (VGG-16) outperform all other algorithms. Performance is evaluated with various parameters like accuracy, recall, precision, and area under the receiver operator characteristic curve (AUC). Deep learning-based algorithms have a promising future in ECG analysis regarding quantitative exactness and quality.","['Engineering', 'Computational Intelligence', 'Cognitive Psychology', 'Personality and Social Psychology', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-0105-8_23,en,Skeletonization and Its Application to Quantitative Structural Imaging,OriginalPaper,"Skeletonization provides a compact yet effective representation of an object using its medial loci defined by Blum’s grassfire transform process. It has been popularly used in many low- as well as high-level imaging applications. Quantitative characterization of object structures is a popular application of skeletonization, where a skeleton serves two purposes—generations of a compact representation of an object and location of representative points for defining local structure morphology. This paper reviews the roles of skeletonization and digital topological analysis in characterizing individual trabecular bone plate-rod microstructure assessing overall bone quality and fracture risk at in vivo imaging.","['Engineering', 'Communications Engineering, Networks', 'Artificial Intelligence', 'Computational Intelligence', 'Bioinformatics']"
doi:10.1007/978-3-031-04524-0_19,en,"Intelligence and Cognitive Computing at the Edge for IoT: Architecture, Challenges, and Applications",OriginalPaper,"Cognitive computing is the development of computerized models to mimic human behavior. The best examples are virtual assistants such as Siri, Alexa, Cortana, etc. Cognitive computing and AI play a big role in solving problems and building applications to support several domains in Internet of Things (IoT). The downside to AI and cognitive computing is the complexity of the architecture involved in building models that supports IoT. Toward the late 1960s, researchers came up with a technology called cloud computing that allowed individuals and organizations to make use of services provided by the cloud to solve problems. This meant that one no longer needed to worry about the software and hardware components required to develop intelligent models. Although cloud computing has been able to solve most complexity issues, it has several drawbacks of its own – latency, privacy, security, reliability, etc. Domains like healthcare rely on intelligent models to make important time-sensitive decisions and cannot wait for data to be shipped all the way to the cloud to get results. The need for quick and real-time results is what probed researchers to develop Edge Intelligence or Cognitive Computing at the Edge with IoT application services. Edge Intelligence is the deployment of intelligent computerized models close to the data source – on the edge node of an IoT network or very near to the network edge. This chapter highlights and examines the principles, architecture, challenges, applications, and existing industrial implementations of Edge Intelligence.","['Engineering', 'Cyber-physical systems, IoT', 'Communications Engineering, Networks', 'Computer Communication Networks']"
doi:10.1007/978-3-031-07707-4_11,en,Experiments with the Discrete Bacterial Memetic Evolutionary Algorithm for Solving the Cumulative Capacitated Vehicle Routing Problem,OriginalPaper,"In this paper we present our initial experiments with the Discrete Bacterial Memetic Evolutionary Algorithm for solving the Cumulative Capacitated Vehicle Routing Problem. The algorithm was tested on instances proposed in the literature. However our method was able to find the optimal solution for small (around 50 nodes) instances, but its convergence speed is low. In the last section some of our ideas to improve the performance of the algorithm were presented.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Computational Mathematics and Numerical Analysis']"
doi:10.1007/978-3-031-17544-2_7,en,Hybridization of Fuzzy Theory and Nature-Inspired Optimization for Medical Report Summarization,OriginalPaper,"It is becoming increasingly challenging to construct a smart medical system because of the large amount of accumulating information in the scientific literature of the biomedical sector. The current scenario reflects progress in a variety of less known regions as a means of extraction for the understanding of prevention and treatment for significant medical diseases such as COVID-19. Recently, many good scientific research publications in the biomedical arena was released using the MEDLINE/PubMed dataset. In the fields of biomedical research and healthcare, assessing these enormous data sets and extracting valuable information is a critical but difficult endeavour. Here, we attempt to retrieve relevant data from openly accessible text materials, like medical reports, journals, articles, papers, and some other research works, in the medical area. hese types of text data undergo first preprocessing in this chapter using sentence tokenization, then stopword removal, stemming operations, and ultimately vectorization using the BioBERT model. Consequently, a structured data is generated to process each report in feature extraction process and then clustered the similar sentences by Fuzzy C-means clustering. Then, using multiple similarity clustering measures and a bi-objective strength measure, defuzzify the clusters and construct the base summaries. To construct the report summary, en ensemble summarising approach has been employed by using Pareto evolutionary algorithm. The method contains two optimization methods(or functions): one dependent on the produced summary size, which is constant, and the other dependent on the IG (i.e., information gain) of the considering base summaries, which is variable. When the process of evolution converges, the strongest chromosomal solution of the ultimate population offers a desired summary report. This approach is used to generate an efficient summary from biomedical reports publically available in the MEDLINE/PubMed dataset, and finally, its performance comparing with a few similar cutting-edge techniques.","['Engineering', 'Computational Intelligence', 'Biomedical Engineering and Bioengineering', 'Health Informatics']"
doi:10.1007/978-981-19-2065-3_47,en,A Review on Congestion Control Using Routing Technique and Machine Learning,OriginalPaper,"Congestion is the biggest problem for all kind of communication network. When multiple users send the data or packets to each other in a network then traffic of data/packets increases in a network then congestion problem occur. To solve the congestion problem, use routing protocols and machine learning techniques. Mobile Ad hoc Network (MANET) associate with real time applications. MANET is use to improve the real time structure for optimization of energy efficiency, fundamental objectives that deploy in resource limited environment. To the congestion problem implement decision tree approach from machine learning. Implement multipath algorithm to save the energy of data transmission. In this comprehensive literature to identify the critical problems and discuss the contribution.","['Engineering', 'Communications Engineering, Networks', 'Artificial Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Machine Learning']"
doi:10.1007/978-3-030-96154-1_7,en,Configuring Blockchain Architectures and Consensus Mechanisms: The Healthcare Supply Chain as a Use Case,OriginalPaper,"The literature on blockchain technology in operations and supply chain management falls short in elaborating salient blockchain architectural features. Most often, it attempts to capture the difference between the public, private and consortium blockchain systems. To advance our knowledge of this distributed technology and help in a better understanding of its various applications, we focus on the consensus algorithms deployed within blockchain systems. We introduce the Proof of Work (PoW), Proof of Stake (PoS), Delegated Proof of Stake (DPoS), Proof of Authority (PoA) and Practical Byzantine Fault Tolerance (PBFT). Our paper demonstrates that many blockchain architectures and new supply chain configurations can emerge with the change in the blockchain consensus mechanism. We focus on the healthcare supply chain, one of the most appealing use cases for blockchain, to outline the architecture of state-of-the-art blockchain systems. This research is a step forwards illustrating the significant change in the concepts and practices towards fully decentralised supply chains.","['Engineering', 'Engineering Economics, Organization, Logistics, Marketing', 'Supply Chain Management', 'Professional Computing', 'Industrial and Production Engineering', 'Logistics']"
doi:10.1007/978-3-031-18458-1_58,en,A Hybrid Learning-Driven Computer Vision Framework for Reverse Engineering via Enhanced 3D Shape Reconstruction,OriginalPaper,"Reverse engineering (RE) has played a key role in producing low demands parts, especially with the recent advent of robust additive manufacturing (AM) techniques. The synergetic interaction of both cutting-edge RE and AM techniques significantly enhance part re-producing and minimize the product development cycle time, even if there is no blueprint for the desired product. Recently, computer vision algorithms have enhanced the RE process and strengthen its capabilities to reconstruct challenging shapes. Nevertheless, the large body of the reported literature is restricted to estimate the 3D shape of the scanned part from a single/multiple 2D/3D image based on predefined classes using supervised learning. The ability to reconstruct intricate geometrical features of real mechanical parts and complex shapes has not been fully realized yet. In this context, this paper reports on a hybrid learning technique-based conceptual computer vision framework to enhance RE process for reproducing of low demand products. The hybrid learning proposed herein is a supervised and unsupervised learning technique using a dual deep learning models to enrich the computer vision technique with the ability to reconstruct 3D complex features using a single 3D depth image.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3250-2_6,en,FRW Based Techniques for Handling Cylindrical Inter-Tier-Vias,OriginalPaper,"Three-dimensional integrated circuits (3-D ICs) make use of the vertical dimension for smaller footprint, higher speed, lower power consumption, and better timing performance. In 3-D ICs, the inter-tier-via (ITV) is a critical enabling technique because it forms vertical signal and power paths. Accordingly, it is imperative to accurately and efficiently extract the electrostatic capacitances of ITVs using field solvers. Unfortunately, the cylindrical via shape presents major challenges to most of the existing methods. To address this issue, we develop a novel floating random walk (FRW) method by rotating the transition cube to suit the cylindrical surface, devising a special space management technique, and proposing accelerating techniques for structures with large-sized through-silicon-vias (TSVs). Experiments on typical ITV structures suggest that the FRW algorithm enhanced with the presented techniques is up to hundreds times faster than a simple FRW approach and the boundary element method (BEM) based algorithms, without loss of accuracy. In addition, compared with extracting the square-approximation structures, the presented techniques can reduce the error by 10X. Large and multi-dielectric structures have also been tested to demonstrate the versatility of the presented techniques.","['Engineering', 'Electronics and Microelectronics, Instrumentation', 'Engineering Mathematics']"
doi:10.1007/978-3-031-18344-7_18,en,A Quantum Algorithm to Locate Unknown Hashgrams,OriginalPaper,"Quantum computing has evolved quickly in recent years and is showing significant benefits in a variety of fields, especially in the realm of cybersecurity. The combination of software used to locate the most frequent hashes and n -grams that identify malicious software could greatly benefit from a quantum algorithm. By loading the table of hashes and n -grams into a quantum computer we can speed up the process of mapping n -grams to their hashes. The first phase will be to use KiloGram to find the top- k hashes and n -grams for a large malware corpus. From here, the resulting hash table is then loaded into a quantum simulator. A quantum search algorithm is then used search among every permutation of the entangled key and value pairs to find the desired hash value. This prevents one from having to re-compute hashes for a set of n -grams, which can take on average O ( MN ) time, whereas the quantum algorithm could take $$O(\sqrt{N})$$ O ( N ) in the number of table lookups to find the desired hash values.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2821-5_16,en,Heart Disease Prediction Using Modified Machine Learning Algorithm,OriginalPaper,"Heart patient number is escalating day by day, and numerous individuals lost their precious lives each year due to sudden heart attack in all over the world. Because of this, before time diagnosis of cardiovascular disease is necessary to prevent death. Some technology-based software is required to help in medical field to recognize heart patients with more accuracy and lesser time. Huge amount of heart patients are present in different hospitals in all over the world, which can be used efficiently to diagnose the heart disease by applying data mining techniques. In the process of data mining, knowledge or useful information is extracted among the large sets of raw data. In the prediction analysis, machine learning techniques are applied to discover valuable patterns and forecast future events or trends. This research work will predict the likelihood of coronary heart disorder in patients by implementing a modified machine learning algorithm. The input data are passed through various procedures comprising preprocessing, clustering, and selection of effective attributes before classification. To determine the heart illness, four algorithms which include random forest, K-means, genetic algorithm, and logistic regression are assimilated. In this technique, the irrelevant attributes of heart dataset are discarded to improve the performance and to decrease the training period time. This process is completed by random forest technique. K-means clusters are optimized by genetic algorithm in order to group all the outlier data points. At last, logistic regression is applied to classify the patients based on the heart disease. Performance comparison among various existing techniques has analyzed on the basis of some performance measures. The calculated accuracy increased up to 95%.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-3-031-05491-4_13,en,A LWE-Based Receiver-Deniable Encryption Scheme,OriginalPaper,"In this era, user privacy is a very important issue and encryption is a general solution. However, the encryption technique cannot keep user privacy while the key is leaked under outside coercion. To solve this problem, the deniable encryption technique is a useful tool since it makes the user be able to answer the outside coercer with fake data and proofs. In this paper, we propose a deniable encryption scheme based on the LWE problem (Learning with Errors). We enhance the Regev LWE encryption scheme proposed in 2009 by increasing the probability of decryption failure. So the user can cheat the outsider with the fake message. We also apply the multi-distributional concept proposed by O’Neill et al. scheme to construct our deniable encryption scheme.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Engineering', 'Big Data', 'Mathematical and Computational Engineering']"
doi:10.1007/978-981-19-3877-1_3,en,Classification of Diabetic Retinopathy,OriginalPaper,,"['Engineering', 'Biomedical Engineering and Bioengineering', 'Ophthalmology', 'Signal, Image and Speech Processing', 'Computational Intelligence']"
doi:10.1007/978-3-031-18461-1_4,en,Alternate Approach to GAN Model for Colorization of Grayscale Images: Deeper U-Net + GAN,OriginalPaper,"Image colorization refers to applying appropriate colors in a given grayscale image, such that the viewer can accept the results as close to reality. By analyzing existing colorization algorithms based on AutoEncoder and VGG-16, this paper showed that they are not able to provide an accurate result in most cases, and are inefficient in terms of computation time. In contrast to these models, we suggested a new model developed from an established GAN model. By reforming the generator part and adding 1x1 convolutional layers based on VGG-11, we were able to create a deeper model where we could also apply nonlinear functions such as ReLU, and Leaky-ReLU. Comparing the results printed by our new model and the conventional model, we proved that our model produced better results in terms of the accuracy and clarity of colors and computation time. However, there is still room for further research in which one can investigate the optimal number of convolution layers and depth that maximizes accuracy and minimizes computation time. Still, this research holds value in that it successfully provides an alternate algorithm with better performance, and opens a path toward further development for colorization algorithms.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-3-031-13588-0_56,en,A Pre-processing Tool for Particle-Based Fluid Dynamics Simulations,OriginalPaper,"A pre-processing tool for fully-Lagrangian particle-based computational fluid dynamics methods is presented in this work. It adopts relatively simple strategies to generate particle models of the elements of the computational domain from boundaries represented by triangular meshes. Essentially, it is based on identification of the relative positions between cubic lattice nodes and the meshes to create particles that represent the geometry of the elements and assign the material type of the particles that are required for the simulations. Focusing on the recognition of the lattice nodes inside closed surfaces, variants of ray-casting and rasterization algorithms were proposed and evaluated. As a result, the rasterization considering three different orthogonal reference planes is the most accurate one with relatively low computational cost. Examples of the successful applications of the pre-processing tool are also provided.","['Engineering', 'Engineering Mathematics', 'Computational Intelligence']"
doi:10.1007/978-981-19-3632-6_60,en,Intelligent Algorithm of Semantic Analysis Based on BP Neural Network,OriginalPaper,"With the growth of scientific and technological information technology and the rapid popularization of the Internet, network big data and information technology are also growing rapidly. Information technology provides people with more information, and it also significantly increases the operating and management costs of my country’s Internet companies. In order to solve this problem thoroughly, people propose a new type of it development, research and business model, namely BP neural network technology. At present, BP neural network technology has been widely used in various application fields such as network storage, search engines, distributed computers, e-commerce, social networks, and has achieved rapid growth. This article mainly adopts the method of organically combining theoretical exploration and empirical research, and systematically analyzes the data collected through research based on the views and research contents of some scholars in recent years. Combining with the analysis of the data of intelligent semantic analysis algorithm, some relevant characteristics of BP neural network are summarized. This article mainly focuses on the research of an intelligent algorithm for image semantic analysis for image processing. The semantic analysis intelligent algorithm can well change the situation of target detection difficulties. This article uses an intelligent algorithm based on BP neural network to automatically analyze and distinguish differences. The final results of the research show that this paper uses the attention model and proposes a semantic analysis algorithm combined with graphic target detection through a multi-scale segmentation network. The experiment shows that the three performances of attention are 71.6, 56.5 and 49.3, which can be learned this algorithm is better than the same comparison algorithm in terms of three performance evaluation indexes.","['Engineering', 'Cyber-physical systems, IoT', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing']"
doi:10.1007/978-3-031-19032-2_33,en,Modeling of a Neural Network Algorithm for Suppressing Non-stationary Interference in an Adaptive Antenna Array,OriginalPaper,"The existing adaptation algorithms do not provide quite deep suppression of non-stationary interference in time in some situations. Recurrent neural networks can improve the efficiency of suppressing such interference by predicting time series. This paper investigates the characteristics of the suppression of non-stationary blinking jamming in an adaptive antenna array (AAA) on a neural network amplitude-phase control. We used the example of a simulation model developed in the Matlab/Simulink software environment. The results of comparing the efficiency of the adaptation algorithms based on a recurrent neural network (LSTM network) and based on a direct matrix inversion method, which provide the minimum power of noise and interference at the AAA output, are presented. The proposed algorithm is able to increase SNIR, which is important for many radar, radio navigation and communication systems.","['Engineering', 'Computational Intelligence', 'Machine Learning', 'Neurosciences']"
doi:10.1007/978-981-19-2764-5_33,en,Modeling and Tracking of Underground Cable Fault Using Genetic Algorithm,OriginalPaper,"In this paper, the genetic algorithm has been implemented to track the fault signals generated in an underground cable. In addition, GA has also been implemented for estimating the parameters such as amplitude, phase, and frequency of the fault signals. Several faults have been simulated to study the consistency of genetic algorithm for tracking the signals. The robustness of the algorithm has been validated by tracking a fault signal with additive white Gaussian noise. It reveals that GA performs better and can reliably estimate the fault signal in a noisy environment.","['Energy', 'Energy Systems', 'Artificial Intelligence', 'Machine Learning', 'Cyber-physical systems, IoT', 'Professional Computing', 'Power Electronics, Electrical Machines and Networks']"
doi:10.1007/978-3-031-20601-6_32,en,Real Time Adaptive GPS Trajectory Compression,OriginalPaper,"The tremendous increase in the amount of GPS (GPS) data transferred by Internet of Things (IoT) devices emphasized the importance of GPS compression techniques. The compression techniques target decreasing the size of data representing the trajectory to minimize the cost of transferring and processing these data. Key aspects of compression techniques is to achieve highest possible accuracy with maximum compression ratio as possible in a reasonable time. This paper targets compression in IoT domain, prioritizing the complexity of the algorithm (performance) key aspect. An implementation for the batched Sliding Window (SW) technique is introduced in this paper, in addition to two novel approaches. A real time Fuzzy Sampler (FS) approach using fuzzy compression that resulted in a significant improvement in the running time compared to the offline and batched SW techniques, while resulting in a smaller compression ratio. Another approach Fuzzy Sampling Window Segmentation (FSW) is to add the FS as a filter to the batched SW technique which resulted in a significant improvement in performance compared to traditional techniques and small decrease in compression ratio. The FS technique is more suitable for low complexity hardware, where small computational power are available, while the FSW requires higher computational power compared to FS and results in higher compression ratios, thus lower transfer cost.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-15345-7_6,en,Lifetime Reliability Optimization Algorithms of Integrated Circuits Using Dual-Threshold Voltage Assignment,OriginalPaper,"In nanoscale complementary metal-oxide-semiconductor (CMOS) technology, circuit reliability is a growing concern for complicated digital circuits due to manufacturing process variation and aging effects. In this chapter, a statistical circuit optimization framework is presented to analyze and improve the lifetime reliability of digital circuits in the presence of process variation and aging degradation. The proposed framework takes advantage of a process variation- and aging-aware gate-level delay degradation model to characterize and evaluate the lifetime reliability of combinational circuits. A metric called Guardband-Aware Reliability (GAR) is proposed for a fair evaluation of the lifetime reliability of combinational circuits using a guardband and timing yield specified by the designer. Using a criticality metric, a set of statistically critical gates is selected to be optimized in the optimization framework. For the improvement procedure, the dual-threshold voltage assignment technique is applied to the identified critical gates to enable the manufactured chip to improve lifetime reliability in terms of low timing yield loss.","['Engineering', 'Circuits and Systems']"
doi:10.1007/978-3-031-11295-9_10,en,Electrical Consumption Optimization Based on Clustering of Consumers’ Data Applying K-Means Algorithm,OriginalPaper,"This new era demands the use of electricity in an efficient way. The growth of population and the increasing percentage of urban zones shows several needs for preparing the actual electrical infrastructure to reach higher demands. In this paper, the optimization of consumer’s data is performed through metaheuristic methods. The first step was to determine the higher electricity consumers from K-means algorithm. After identifying the data to be optimized, the Particle Swarm Optimization (PSO) minimized the cost function related to the energy consumption. Finally, conclusions were analyzed from the results of the experiment.","['Social Sciences', 'Sociology, general', 'Urban Studies/Sociology']"
doi:10.1007/978-981-19-3998-3_57,en,Fully Distributed Nash Equilibrium Seeking Algorithm with Quantization Effects in a Directed Graph,OriginalPaper,"This paper considers a distributed Nash equilibrium (NE) seeking problem with limited communication capacity. A fully distributed NE seeking algorithm is proposed with quantized information, including projected pseudo-gradient dynamics, distributed decision estimation and adaptive quantization. Based on a proposed encoder-decoder scheme, the algorithm is able to converge to the theoretical NE without any errors caused by quantization. Finally, a numerical simulation is provided to validate the effectiveness of our algorithm.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/s10473-023-0101-z,en,A Superlinearly Convergent Splitting Feasible Sequential Quadratic Optimization Method for Two-Block Large-Scale Smooth Optimization,OriginalPaper,"This paper discusses the two-block large-scale nonconvex optimization problem with general linear constraints. Based on the ideas of splitting and sequential quadratic optimization (SQO), a new feasible descent method for the discussed problem is proposed. First, we consider the problem of quadratic optimal (QO) approximation associated with the current feasible iteration point, and we split the QO into two small-scale QOs which can be solved in parallel. Second, a feasible descent direction for the problem is obtained and a new SQO-type method is proposed, namely, splitting feasible SQO (SF-SQO) method. Moreover, under suitable conditions, we analyse the global convergence, strong convergence and rate of superlinear convergence of the SF-SQO method. Finally, preliminary numerical experiments regarding the economic dispatch of a power system are carried out, and these show that the SF-SQO method is promising.","['Mathematics', 'Mathematics, general', 'Analysis']"
doi:10.1007/978-981-19-1939-8_1,en,Turbulent Flow Estimation by Wavelet Transform,OriginalPaper,"Turbulent flow estimation from an image sequence is challenging due to the lack of dedicated flow measurement techniques. Existing techniques estimate flowrate with high uncertainty. In this paper, a new technique based on discrete wavelet transform (DWT) is proposed. Wavelets have the advantage of decomposing flow signals into numerous levels and remove input signal noise. The flow signals are first decomposed using DWT into multiple levels, then, the wavelet coefficients are correlated by the Fast Fourier Transform (FFT) based algorithm to determine the velocity field. This wavelet-based algorithm is named as DWT-FFT. DWT-FFT was evaluated first using synthetic signals and then applied for turbulent flow estimation. The accuracy of DWT-FFT was compared to classical algorithms including direct cross correlation (DCC) and direct implementation of FFT. DWT-FFT estimated the flow with an error of 0.7%, outperforming both DCC and FFT which estimated with an error of 7.14% and 12.2% respectively.","['Engineering', 'Industrial and Production Engineering', 'Power Electronics, Electrical Machines and Networks', 'Energy Storage']"
doi:10.1007/978-3-031-14537-7_13,en,Method for the Production Planning and Scheduling of a Flexible Manufacturing Plant Based on the Bees Algorithm,OriginalPaper,"Production planning Production planning and scheduling of flexible manufacturing plants Scheduling of flexible manufacturing plant are still highly manual labor-intensive tasks. The production efficiency is constrained due to the large number of combinations of feasible machine selection Machine selection and operation sequence Operation sequence arrangement. In this study, a mathematic model approximating the real working environment and two different Bees Algorithms Bees Algorithm were compared. In the improved Bees Algorithm with site abandonment technology Bees Algorithm with site abandonment technology , different strategies were used for the abandonment of initial sites and elite sites. The simulation results based on actual factory data from Trumpf (China) show that the mathematical model and the Bees Algorithm Bees Algorithm, THE could help to improve production effectiveness. Moreover, the improved Bees Algorithm with site abandonment technology Bees Algorithm with site abandonment technology shows its excellent ability to solve problems such as production planning issues in flexible manufacturing plants.","['Engineering', 'Robotics and Automation', 'Artificial Intelligence', 'Industrial and Production Engineering', 'Professional Computing', 'Robotics', 'Machine Learning']"
doi:10.1007/978-981-19-5574-7_5,en,Furnace Temperature Prediction Based on Optimized Kernel Extreme Learning Machine,OriginalPaper,"In power plants, the Furnace  furnace temperature directly affects the combustion efficiency and safe operation of the boiler combustion system, which is of great significance for the boiler combustion control system [ 1 ]. However, furnace Furnace  combustion is an extremely complex process, and its temperature is affected by many related factors.","['Engineering', 'Control, Robotics, Mechatronics', 'Energy Systems', 'Computational Intelligence']"
doi:10.1007/978-981-19-3035-5_56,en,Training Logistic Regression Model by Enhanced Moth Flame Optimizer for Spam Email Classification,OriginalPaper,"Spam email is a massive issue that bothers and consumes receivers’ time and effort. Because of its effectiveness in identifying mail as wanted or unwanted, machine learning approaches have become a popular technique in spam detection. Current spam detection methods, on the other side, typically have low detection performance and are incapable of handling high-dimensional information easily. As a result, a unique spam detection approach that combines an improved moth flame optimization algorithm and a logistic regression classification model was proposed in this paper. The research evidence on two accessible datasets (CSDMC2010, Enron) indicates that the suggested methodology can tackle high-dimensional data due to its very powerful local and global search skills. The suggested technique was evaluated for spam detection accuracy to that of logistic regression, naive Bayes classifiers, and support vector machine, as well as the performance of earlier research’ that includes state-of-the-art approaches. In terms of classification performance, the suggested methodology outperforms the other spam detection algorithms examined in this work.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Statistics, general']"
doi:10.1007/978-3-031-19604-1_15,en,NSGA-II-AMO: A Faster Genetic Algorithm for QWSCP,OriginalPaper,"The task of the QoS-driven web service composition problem (QWSCP) is to find the optimal combination of atomic web services to meet the high demand for QoS parameters. However, different scenarios have various sensitivities to each parameter, researchers prefer algorithms that solve the problem to output non-dominated solution sets. NSGA-II, a genetic algorithm, has become one of the most contacted algorithms for solving the QWSCP problem due to its ability to search for non-dominated solution sets. However, NSGA-II algorithm still suffers from the challenge of slow convergence and the tendency to fall into local optimum solutions. In adjusting the NSGA-II mutation probabilities, it was found that the setting of the mutation probabilities affects the effectiveness of the algorithm, and that the optimal mutation probabilities for different loci are related to the distribution of data for that locus. Therefore, this paper proposes an improved NSGA-II-AMO algorithm, which uses an adaptive mutation operator to complete the mutation process when generating children in the NSGA-II algorithm, so that the mutation probability adaptively changes with different distributions of data, effectively improving the search speed at the beginning of population iteration; at the same time, in order to avoid the problem of oscillatory search at a later stage, AMO reduces the mutation probability as the population converges, preventing the re-introduction of inferior genes into the population. We compare the NSGA-II-AMO algorithm cross-sectionally with the PSO algorithm, the NSGA-II algorithm and the ABC algorithm, and the adaptive mutation operator achieves improved convergence with guaranteed distributivity.","['Engineering', 'Computational Intelligence', 'Software Engineering/Programming and Operating Systems', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3632-6_82,en,Mobile English Learning Platform Based on Collaborative Filtering Algorithm,OriginalPaper,"With a large number of digital resources as the carrier, mobile learning breaks through the shortage of resources and the limitation of time and space under the current learning mode. However, its rich resources also bring information overload, which greatly affects the learning efficiency. The mobile English learning platform based on collaborative filtering algorithm not only makes full use of the advantages of mobile learning, but also recommends learning resources according to the learning needs of different learners to meet the learning needs of different learners, saving learners’ time and effort to a certain extent all. It has certain practical significance.","['Engineering', 'Cyber-physical systems, IoT', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing']"
doi:10.1007/978-981-19-3571-8_40,en,Cluster-Based Energy-Efficient Routing in Internet of Things,OriginalPaper,"Lot of improvements are taking place in the communication technology. The networks are becoming ubiquitous and pervasive. Devices connecting to the internet are increasing tremendously due to the inception of Internet of things (IoT) in the current technology domain, and this count is going to become very huge in the upcoming future. Majority of these devices are low power battery operated. These devices need to handle their energy efficiently while doing the communication with the rest of the neighboring devices. The adopted approach in this paper deals with such devices and their energy usage. This approach has used dragonfly algorithm for the selection of cluster heads. It changes the selection of cluster heads over the period of time regularly so that the usage of energy will be balanced across the network efficiently. The selection of cluster heads is done based on the specially designed fitness function. At the end, the experimental outcomes prove the outperformance of the proposed model over the conventional approaches.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-0588-9_7,en,Comparative Study of Shortest Distance Calculation Techniques in IoT-Based Wireless Sensor Networks,OriginalPaper,"The Internet of Things (IoT) includes the network of physical things installed with sensors, software application, and various other modern technologies to attaching and exchanging information with various other tools and systems over the Internet (Lee et al., in Int J Appl Sci MDPI 7:1072–1097, 2017). With the introduction of the IoT, communication capacity will certainly not be restricted to only smartphones. Instead, it will increase to all points which exist side-by-side. In this paper, a wireless sensor network (WSN) is designed using IoT nodes. A comparative study of two techniques is carried out to calculate the shortest distance between the source and destination node. The techniques are simulated using CupCarbon IoT 5.0 simulator.","['Energy', 'Energy Systems', 'Transportation Technology and Traffic Engineering', 'Electronics and Microelectronics, Instrumentation']"
doi:10.1007/978-981-19-3148-2_13,en,Formal Specification of Dynamic Load-Based Coordinator Selection Algorithm with Recovery in Distributed Systems,OriginalPaper,"Distributed systems consist of a group of computer nodes connected over a communication network which do not have a common clock or shared memory. These nodes communicate with each other through message passing. High availability and reliability are essential for fault tolerance in a distributed system. Database replication helps in achieving high availability. Reliability can be achieved through consistency among the replicas. A node is designated as a coordinator among the group of nodes in order to bring consistency among the replicas through consensus algorithms. The coordinator plays an important role in reducing overhead in maintaining consistency among the replicas. Optimization and formal analysis of a leader election algorithm known as bully algorithm are demonstrated in this paper. In this algorithm, a process with the highest vote value is chosen as the coordinator. The algorithm is optimized by improving its message complexity and increasing fault tolerance by adding the provision of modifying the vote value of a node dynamically as per the quantum of load at the node. This reduces the chances of failure of coordinator due to overloading. Recovery and consequent vote allotment of the failed coordinator is also demonstrated. The paper also presents the formal specification of the optimized bully algorithm using Event-B and Rodin platform.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory']"
doi:10.1007/978-3-031-09835-2_7,en,Bee Colony Optimization with Applications in Transportation Engineering,OriginalPaper,"Metaheuristics turned out to be a dominant tool for solving difficult combinatorial optimization problems. Between them, a group of biologically motivated algorithms can be identified. The Bee Colony Optimization (BCO) method, which uses collective intelligence applied by honey bees, during the nectar gathering process, is one of them. The basic idea at the back of the BCO is to create a multi-agent system (a colony of artificial bees) competent to effectively discover solutions to difficult combinatorial optimization problems. The artificial bee colony performs to a certain degree alike, and in other parts differently, from bees in nature. The analysts specify the possible agents’ behavior and simulate the relations between them (how artificial bees interact with each other). The model and related software imitate how artificial bees execute their actions. The BCO is a stochastic, random-search population-based method. The BCO uses likeness among how bees in nature search for nectar, and how optimization algorithms look for an optimum in combinatorial optimization problems under study. Two variations of the BCO algorithm can be differentiated easily: constructive BCO and the alternative based on the solutions improvement idea. This chapter offers a taxonomy and analysis of the research results accomplished using both variants of BCO to model transportation engineering processes. Thus far, BCO has effectively been used to various real-life traffic control and transportation planning problems: the vehicle routing problem, the ride-matching problem, the traffic sensor location problem on highways, inspection station location problem, the p -center problem, disruption mitigation on public transit, pre-timed control for isolated intersections, area-wide urban traffic control, etc. The main goal of this text is to notify colleagues with the key principles of Bee Colony Optimization, as well as to denote new possible BCO uses in traffic control and transportation planning.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4975-3_41,en,A Novel Arithmetic Optimization Algorithm-Based 2DOF Tilted-Integral-Derivative Controller for Restructured LFC,OriginalPaper,"During the last decade, the electrical power system has experienced several changes raised by increasing privatization and the newly deregulation policy. Further, the load–frequency control (LFC) job becomes more challenging due to the integration of non-conventional energy resources such as nuclear, wind, solar, and fuel into the power system. If the demand of consumers varies, then the voltage along with the frequency of the multiple area interconnected power system also changes. Therefore, these changes must be kept within a certain range to supply better quality of electricity to the consumers. The study in this article is focused upon the Load–Frequency Control (LFC) of a double area deregulated power system along with multiple generation sources using Tilted-Integral-Derivative Controller (TIDC) with 2DOF. LFC is the mechanism by which the power system tries to restore its nominal frequency after it has been subjected to load fluctuations. The control areas considered for this paper comprise a reheat turbine and gas unit in addition to the thermal generating unit. Considering the practical scenario of operation, an appropriate generation rate constraint (GRC) has been included for each unit. The gain parameters of the 2DOF Tilted-Integral-Derivative Controller have been optimized by Arithmetic Optimization Algorithm (AOA). Later, the supremacy of the suggested algorithm is verified among the other well-known meta-heuristic approaches such as particle swarm optimization (PSO), Teaching learning-based optimization (TLBO), and Artificial bee colony (ABC) by evaluating under the same test conditions. The dynamic response of the proposed controller to load disturbances has been compared with prevalent controller schemes to bring about the efficacy of the prospective work.","['Engineering', 'Power Electronics, Electrical Machines and Networks', 'Energy Policy, Economics and Management', 'Energy Systems']"
doi:10.1007/978-3-031-06780-8_7,en,Robust AI Driving Strategy for Autonomous Vehicles,OriginalPaper,"There has been significant progress in sensing, perception, and localization for automated driving, However, due to the wide spectrum of traffic/road structure scenarios and the long tail distribution of human driver behavior, it has remained an open challenge for an intelligent vehicle to always know how to make and execute the best decision on road given available sensing/perception/localization information. In this chapter, we talk about how artificial intelligence and more specifically, reinforcement learning, can take advantage of operational knowledge and safety reflex to make strategical and tactical decisions. We discuss some challenging problems related to the robustness of reinforcement learning solutions and their implications to the practical design of driving strategies for autonomous vehicles. We focus on automated driving on highway and the integration of reinforcement learning, vehicle motion control, and control barrier function, leading to a robust AI driving strategy that can learn and adapt safely.","['Engineering', 'Automotive Engineering', 'Computational Intelligence', 'Transportation Technology and Traffic Engineering', 'Signal, Image and Speech Processing']"
doi:10.1007/978-981-19-4990-6_13,en,FPGA Design of Area Efficient and Superfast Motion Estimation Using JAYA Optimization-Based Block Matching Algorithm,OriginalPaper,"We are in modern world and preferred to use modern services such as high-definition television, video-on-demand, video email, and video conferencing. The modern communication system exchanges information via audio, image, video, and graphics formats for long distance. The different video coding formats are MPEG-1, MPEG-2, MPEG-4, H.261, H.263, H.264, Theora, Real video RV40, VP9, and AVI, used for those services. Due to the temporal and spatial redundant problem, codes required a motion estimation algorithm. This paper proposes an area efficient motion estimator using JAYA optimization-based block matching (JAYA-BM), without compromising searching speed. The JAYA-BM algorithm strives to search the motion vector by superfast manner. The field programmable gate array (FPGA) design of proposed motion estimator performed using Verilog language and synthesized with different FPGA device families in Xilinx tool. The simulation result shows that our motion estimator is able to enhance the hardware usage and searching speed with better quality.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Wireless and Mobile Communication']"
doi:10.1007/978-981-19-4162-7_10,en,Bio-Inspired Firefly Algorithm for Polygonal Approximation on Various Shapes,OriginalPaper,"Polygonal approximation (PA) is a challenging problem in representation of images in computer vision, pattern recognition and image analysis. This paper proposes a stochastic technique-based firefly algorithm (FA) for PA. This technique customizes a kind of randomization by searching a set of solutions. In contrast, PA requires more combination of approximation to find an optimal solution. The algorithm involves several steps to produce better results. The attractiveness and brightness of the firefly have been used efficiently to solve the approximation problem. While compared to other similar algorithms, FA is independent of velocities which are considered as an advantage for this algorithm. Subsequently, the multi-swarm nature of FA allows finding multiple optimal solutions concurrently. This technique achieves the main goal of PA that is minimum error value with less number of dominant points. The experimental results show that proposed algorithm generates better solutions compared to other algorithms.","['Engineering', 'Computational Intelligence', 'Data Mining and Knowledge Discovery', 'Systems and Data Security', 'Mobile and Network Security', 'Information Systems Applications (incl. Internet)']"
doi:10.1007/978-981-19-1844-5_1,en,Implementation of Machine and Deep Learning Algorithms for Intrusion Detection System,OriginalPaper,"The intrusion detection system (IDS) is an important aspect of network security. This research article presents an analysis of machine and deep learning algorithms for intrusion detection systems. The study utilizes the CICIDS2017 dataset that consists of 79 features. Multilayer perceptrons (MLPs) and random forests (RFs) algorithms are implemented. Four features extraction techniques (information gain, extra tree, random forest, and correlation) are considered for experimentation. Two models have been presented, the first one using the machine learning random forest (RF) algorithm and the second using deep learning multilayer perceptron (MLP) algorithm. The increased accuracy has been observed when using the random forest algorithm. The RF algorithm gives the best results for the four feature selection techniques, thus proving that RF is better than MLP. The RF algorithm gives 99.90% accuracy, and 0.068% false positive rate (FPR) with 36 features. Furthermore, the dimensionality of the features has been reduced from 79 to 18 features with an accuracy of 99.70% and FRP of 0.19%.","['Engineering', 'Communications Engineering, Networks', 'Mobile and Network Security', 'Artificial Intelligence', 'Big Data']"
doi:10.1007/978-981-19-4606-6_71,en,Firefly Algorithm Established Economic Load Dispatch with Loss Coefficients,OriginalPaper,"Economic load dispatch (ELD) is an significant optimization assignment in power system. With this allotment of generation for each unit has been achieved effectively to minimize the generation. Generally, power system problems like ELD have difficulties during solving with general maths. Conventional methods are necessary to minimize the cost of generation, with proper allotment and the reduction of losses. It can be solved by using Newton approach, nonlinear programming, quadratic programming and so on. These techniques may be struct at local optimum. Therefore, to avoid that, in this paper, newly developed firefly algorithm has been applied on six-unit generator system. With the firefly algorithm, the obtained results are superior to other methods, and it confirms the best generator output and optimal fuel cost of the system.","['Engineering', 'Industrial and Production Engineering', 'Machinery and Machine Elements', 'Materials Engineering']"
doi:10.1007/978-981-19-3998-3_3,en,Overview on Task Allocation Methods for Cooperative Multi-target Attack,OriginalPaper,"The cooperative multi-target attack is a challenging mission for the military action in modern complex combat environment, and task allocation system will play a key role. Both modeling and solving are important for the task allocation problem, and they have been studied by more and more experts . This paper summarizes the task allocation methods for cooperative multi-target attack. Firstly, it introduces the development status of typical task allocation projects at home and abroad, and combs the development context of the system. The mission planning is divided into task allocation and path planning, and the task allocation modeling and solving algorithm of multi-UAV cooperative attack on multi-target are analyzed respectively, and the advantages and disadvantages of various task allocation methods are compared and summarized. Finally, the challenges in the field of task allocation are described. A comprehensive grasp of task allocation will help us to engage in innovative research in related fields.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-981-19-3387-5_129,en,An Industrial Internet Delay Optimization Scheme Based on Time Sensitive Network,OriginalPaper,"In order to improve the real-time performance of Industrial Internet, this paper proposes a network communication delay optimization scheme that based on the IEEE 802.1Qbv protocol of time sensitive network (TSN). The scheme distinguishes the network data types with different time delay requirements, and proposes a TAS-EWRR scheduling algorithm in the data link layer of OSI model. The algorithm combines with time aware shaper (TAS), stream reservation protocol (SRP), frame preemption mechanism and enhanced weighted round robin (EWRR) algorithm. At the same time, a shortest path algorithm based on delay is combined at the network layer to realize the optimization of the delay of the entire network.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Aerospace Technology and Astronautics']"
doi:10.1007/978-981-19-3998-3_81,en,Privacy-Preserving Nash Equilibrium Seeking Algorithm over Directed Graph,OriginalPaper,"This paper considers a private-preserving issue of distributed Nash equilibrium seeking algorithms over directed graph, assuming the objective function is sensitive. In order to ensure the privacy of individuals, agents’s information is interfered by independent random noises that obey Laplace distribution, and then sent to their neighbors. By resorting to Perron-Frobenius (PF) theorem, a fully distributed algorithm is established with perturbed local information, where the weights of the PF eigenvector are adopted. Since the mappings are strongly monotone and Lipschitz continuous, the algorithm we proposed guarantees the asymptotic convergence of NE and keeps the information privacy of each agent. Furthermore, the proposed algorithm is proved to be $$\epsilon $$ ϵ -differentially private and the value of $$\epsilon $$ ϵ can be obtained. Finally, the above conclusion is verified by numerical simulation.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-3-031-05516-4_7,en,Smart Transport as an Enhancement of the Urban Infrastructure,OriginalPaper,"The concept of a Smart City is to use the existing resources in an optimal way to provide the greatest convenience to its residents. This requires close integration of all components, for example, street video surveillance, public services, intelligent transport systems and others, on the scale of a megalopolis. Every year, the world's megacities are becoming more comfortable for residents due to the introduction of newest technologies. First, such technologies include intelligent control systems in the transportation field. The main goals of Smart Transportation are the efficient and coordinated movement of people, monitoring the location of objects, fast and reliable interaction of vehicles with each other, as well as guaranteeing road safety. This paper represents examples of artificial intelligence technologies and optimization methods applications to create such smart systems.","['Engineering', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Cities, Countries, Regions', 'Artificial Intelligence', 'Statistics, general']"
doi:10.1007/978-3-031-13786-0_1,en,"A Comprehensive Study on 5G: RAN Architecture, Enabling Technologies, Challenges, and Deployment",OriginalPaper,"The fifth-generation (5G) technology promises to provide agile, scalable, and programmable network services in order to respond to the myriad of applications and connected devices of vertical industries. It aims to boost the network capacity, throughput, energy, and spectral efficiencies while reducing latency for sub-milliseconds. In order to fulfill the diverse requirements of industrial Internet of Things (IIoT) applications, drastic changes have been proposed by several telecommunication bodies for the radio access network (RAN) and core. In this chapter, we aim to study comprehensively the 5G architectural frameworks proposed by telecommunication bodies and standards for public and private 5G networks. Furthermore, this chapter provides an in-depth study on the key 5G enabling technologies such as software-defined network (SDN), network functions virtualization (NFV), network slicing, artificial intelligence/machine learning (AI/ML), and multi-access edge computing (MEC). Moreover, 5G simulators and projects are explored and compared considering features, advantages, and limitations.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Computer Communication Networks']"
doi:10.1007/978-981-19-3842-9_57,en,Continuous-Curvature Path Planner Based on RS Algorithm,OriginalPaper,"Path planning algorithms directly affect the performance of the automatic parking assist system (APA). RS algorithm is very suitable for embedded code transplantation and can quickly generate the shortest parking path due to its low computational complexity, so it is widely used in the parking path planning algorithms. However, because the RS algorithm does not consider the constraint of curvature mutation, the phenomenon of turning the wheel on the spot often occurs during the actual parking process, which will not only accelerate tire wear, but also affect the driver’s driving experience. In order to solve the curvature instantaneous problem of the RS algorithm, this paper proposes a continuous curvature parking path planning algorithm, that is, to optimize and upgrade the RS algorithm with clothoid and straight line, and change the connection of arcs and straight lines used by the RS algorithm to clothoid arcs and straight lines, and so on the basis of retaining the advantages of RS algorithm, it can effectively solve the problem of curvature mutation problem during parking process. Finally, the effectiveness of the proposed algorithm is tested and verified by simulation and real vehicle experiments in two common parking scenarios. The experimental results show that the proposed algorithm is not only simple for embedded transplantation, but also can effectively solve the curvature mutation problem during parking process.","['Engineering', 'Mechanical Engineering', 'Automotive Engineering', 'Transportation Technology and Traffic Engineering']"
doi:10.1007/978-981-19-1412-6_31,en,Multi-robot Cooperation and Path Planning Using Modified Cuckoo Search,OriginalPaper,"The paper proposes an innovative approach to solve the cooperation and path planning problem of multiple mobile robots in clutter environment. The main emphasis of the work lies in designing a multi-objective fitness function for stick-carrying robot pairs to compute a collision-free optimal path. The present context of the paper address the multi-robot cooperation and path planning of two pairs of stick-carrying robots that move from a predefined initial location to a pre-assumed goal position by carrying a stick at either end. The basic cuckoo search (CS) algorithm is modified concerning the step size and the scaling parameter at each step of movement of the robot pairs. The modified cuckoo search (MCS) algorithm is implemented with the robot pair to mimic the egg laying behavior of the cuckoo for producing the next generation solution. The proposed algorithm is validated using computer simulation and has been compared with other existing approaches such as ICFA, CS, SDA, and ABCO. Due to its simplicity and efficacy in terms of path optimality, the proposed algorithm produces an optimal solution both in the static and dynamic environment irrespective of the number of obstacles.","['Engineering', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security']"
doi:10.1007/978-3-031-02063-6_15,en,On Improving the Reliability of Power Grids for Multiple Power Line Outages and Anomaly Detection,OriginalPaper,"Improving the reliability of smart grids is critical to not only cost-effectiveness of electricity delivery but also repair cost reduction. To efficiently improve the reliability, the real-time anomaly behavior detection and efficient location identification of multiple line outages play a major role in wide area monitoring of smart grids. However, capturing the features of anomalous interruption and then detecting them at real time is difficult for large-scale smart grids, because the measurement data volume and complexity increase drastically with the exponential growth of data from the immense intelligent monitoring devices to be rolled out. This is especially true for multiple line outage detection, as the methods of identifying the locations of multiple line outages face two major challenges: a limited number of Phasor Measurement Units (PMUs) and the high computational complexity. This chapter proposes an efficient real-time anomaly detection (ReTAD) algorithm to address these challenges, inspired in part by the ambiguity group theory. To characterize the performance of line outage identification, this chapter also introduces a statistical model to describe the average identification capability of multiple line outages. Under this model, we develop a global optimal PMUs placement strategy to maximize the average identification capability for a fixed budget of PMUs. Using 14-, 30-, 57-, 118- and 2383-bus systems, our experimental study demonstrates that our proposed ReTAD algorithm successfully detects the anomalous events in real-time and identifies the most likely multiple line outages with a $$500\times $$ 500 × speedup when compared to the method of exhaustive search. For the IEEE 14- and 57-bus systems, our experimental study also demonstrates that the proposed techniques can select optimal PMU locations while improving the average identification capability by about $$10\%$$ 10 % compared to random PMUs placement method.","['Engineering', 'Engineering Economics, Organization, Logistics, Marketing', 'Mathematical Modeling and Industrial Mathematics', 'Risk Management', 'Industrial Organization']"
doi:10.1007/978-981-19-3842-9_40,en,Application of Composite PSO Algorithm in Hybrid Electric Vehicle Control Optimization,OriginalPaper,"The optimization of hybrid electric vehicle control strategy parameters has always been the concern subject of researchers. At present, matching and optimization methods for the control strategy parameters are still being explored. The optimization of HEV control strategy parameters is a multivariate multi-objective nonlinear programming problem. Most of the methods adopted by OEMs are still based on large numbers of calibration tests and data analysis, through a large number of repeated modification of control parameters to obtain a relatively good data as the best result. As a result, the work efficiency is low, the research and the development cycle times are long. According to the characteristics of the PSO algorithm and its composite algorithm, it is not easy to fall into the local optimal solution, and the convergence speed is fast and the work efficiency is significantly improved. This paper provides a composite PSO algorithm for multi-variable nonlinear programming problems. The algorithm is easy to obtain better global optimization results. Combined with practical application requirements, it has been used to guide the development of actual vehicle control systems.","['Engineering', 'Mechanical Engineering', 'Automotive Engineering', 'Transportation Technology and Traffic Engineering']"
doi:10.1007/978-3-031-20545-3_3,en,Ambulance Dispatching—Preparedness Welfare,OriginalPaper,"This chapter presents in detail an ambulance Ambulance dispatching Dispatching algorithm Algorithm that uses the concept of preparedness Preparedness , which allows to improve the readiness Readiness of an emergency system to serve future calls within a service area. Different ways of aggregating area preparedness Preparedness are proposed based on social welfare Social welfare functions. Simulated experiments show that the preparedness-based algorithm Algorithm significantly reduces response time Response time in comparison with the conventional method of dispatching Dispatching the closest available ambulance Ambulance to an emergency call. However, performance Performance of the algorithm Algorithm depends on the specific operating characteristics of the environment and the aggregation method used to calculate area preparedness Preparedness . All required calculations and steps of the algorithm Algorithm are thoroughly explained with numerical examples.","['Engineering', 'Computational Intelligence', 'Social Choice/Welfare Economics/Public Choice/Political Economy', 'Robotics and Automation', 'Artificial Intelligence']"
doi:10.1007/978-3-031-12409-9_6,en,"Bayesian Methods, Regularization and Expectation-Maximization",OriginalPaper,"This chapter summarizes some techniques that use Bayes’ theorem. These are classical Bayesian statistical models using, e.g., the Markov chain Monte Carlo (MCMC) method for model fitting. We discuss regularization of regression models such as ridge and LASSO regularization, which has a Bayesian interpretation, and we consider the Expectation-Maximization (EM) algorithm. The EM algorithm is a general purpose tool that can handle incomplete data settings. We illustrate this for different examples coming from mixture distributions, censored and truncated claims data.","['Mathematics', 'Applications of Mathematics', 'Statistics for Business, Management, Economics, Finance, Insurance', 'Machine Learning', 'Data Structures and Information Theory', 'Artificial Intelligence']"
doi:10.1007/978-3-658-38316-9_3,en,Intelligent Retail,OriginalPaper,"In smart retail, there are five central issues that will shape the retail of the future. First and foremost, the basic prerequisites must be created that enable data-based working. This in turn allows the use of artificial intelligence (AI) and thus customer data-based one-to-one marketing. In order to be able to work with this at all, intelligent employee qualification and recruitment is required. Qualified employees are also needed for a digital supply chain as well as future-proof business modeling including the development of smart stores. Digital-based stores also enable digitalized shopping centers. In the end, it’s all about “channel no matter” as the highest evolutionary stage of stationary retail.","['Business and Management', 'Trade']"
doi:10.1007/978-3-031-14630-5_15,en,Law-Technology Lag or Law as Technology in the Big Data Age,OriginalPaper,"In an data-driven world, people increasingly value the protection and security of their personal data. Many states have adopted or are in the process of adopting data protection laws based on principles similar to those of the General Data Protection Regulation (GDPR) of the European Union, resulting in a global convergence of data protection rules. Yet doubts may arise regarding the ability of the GDPR to effectively safeguard data protection principles and rights in the age of big data and related algorithmic decision-making. Against this background, the choice of the risk-based approach as the key law enforcement mode under the GDPR might be interpreted to be a result of the recognition of a law/technology lag in this instance, in the sense of an intrinsic difficulty of the law in dealing with the pervasiveness and automation involved in present-day collection, circulation and use of the data. The risk-based approach leaves data protection decisions mainly to the data controllers. A better explanation for the GDPR’s novel enforcement mode may be found in the “law as technology” proposition, meaning a law intended to liberate the use of digital technologies. In the context of its strategy for a data-driven economy, the EU had shown its concern with European lateness in embracing the data revolution. Accordingly, EU data protection reform has been meant to reduce the administrative burden on the data controllers and processors so as to further the competitiveness of the digital single market. As a consequence, data protection will ultimately depend on how the data controllers will meet their greater responsibilities.","['Philosophy', 'Philosophy of Technology', 'Science and Technology Studies', 'History of Technology']"
doi:10.1007/978-3-031-16159-9_1,en,Trustworthy Applications of ML Algorithms in Medicine - Discussion and Preliminary Results for a Problem of Small Vessels Disease Diagnosis,OriginalPaper,"ML algorithms are very effective tools for medical data analyzing, especially at image recognition. Although they cannot be considered as a stand-alone diagnostic tool, because it is a black-box, it can certainly be a medical support that minimize negative effect of human-factors. In high-risk domains, not only the correct diagnosis is important, but also the reasoning behind it. Therefore, it is important to focus on trustworthiness which is a concept that includes fairness, data security, ethics, privacy, and the ability to explain model decisions, either post-hoc or during the development. One of the interesting examples of a medical applications is automatic SVD diagnostics. A complete diagnosis of this disease requires a fusion of results for different lesions. This paper presents preliminary results related to the automatic recognition of SVD, more specifically the detection of CMB and WMH. The results achieved are presented in the context of trustworthy AI-based systems.","['Engineering', 'Control and Systems Theory', 'Computational Intelligence']"
doi:10.1007/978-981-19-4193-1_8,en,A Comparative Analysis of Performances of Different Ensemble Approaches for Classification of Android Malwares,OriginalPaper,"All Android applications require the accumulation of permissions during installation, and these are considered features that can be used in permission-based malware detection. Different ensemble strategies for categorisation of Android malware have recently gotten a lot more attention in comparison with traditional methodologies. In this work, comparative analysis of performances of different ensemble approaches (boosting, bagging and stacking) in R libraries for classification of Android malwares is projected. Both the desirable qualities of an ensemble technique, accuracy and diversity are preserved by the presented methods. In terms of categorisation accuracy, the proposed techniques have produced significantly superior results.","['Engineering', 'Computational Intelligence', 'Information Storage and Retrieval', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Data Structures and Information Theory', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3148-2_33,en,Prefix Method of Parallel Pattern Search and Homogeneous Computing Matrix,OriginalPaper,"This article focused on the development of matrix methods of pattern search with hardware implementation based on associative memory. The objective is to reduce the search time by forming a set of prefixes and their parallel processing with a set of associative computational matrices. The method uses dynamic reconfiguration of text character relationships so that the text as a char is alternately represented by matrix-string data structures. The method is based on parallel comparisons of a pattern and specially prepared prefixes with a matrix representation of the test. The comparison matrices obtained in the search steps allow us to calculate the amount of text shift by more than 1 character, which leads to a reduction in the search time. As a result, the original pattern is represented by a triangular matrix consisting of prefixes shifted to the right. The extreme prefix has a length of one character. The text for this method has a two-dimensional representation with the number of columns being equal to the length of a pattern. The representation of a pattern as a set of prefixes makes it possible to reduce the total number of steps by analyzing a variety of options for the initial search positions. The constructed computing matrix is based on combining the results of a parallel search and highlighting the priority position of a partial occurrence, excluding unproductive (blank) steps.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory']"
doi:10.1007/978-3-031-15928-2_60,en,Generative Design in Bicycle Frames: A Review,OriginalPaper,"This paper addresses the analysis of the projects related to generative design (GD) applied to bicycle frames. GD constitutes an innovative working methodology by providing designers with computer algorithms capable of generating potentially efficient designs and, in turn, responding to established design objectives and constraints. Its application to the design of different types of mechanical components is growing and a clear example of this is bicycle frames. The main reason why GD stands out among other work procedures is the resolution and generation of complex digital geometric models. Furthermore, the case studies analyzed reflect a clear convergence towards the achievement of two common goals thanks to the use of GD, which are: the efficient use of materials and, consequently, the reduction of costs associated with the production process. However, there are not many scientific communications about GD applied to bicycle frames and just a few projects dealing with this subject. In short, the GD can contribute, thanks to additive manufacturing (AM), as a turning point in the process of design and construction of components with high performance and reduced costs compared to traditional methods.","['Engineering', 'Engineering Design', 'Industrial and Production Engineering', 'Computer-Aided Engineering (CAD, CAE) and Design']"
doi:10.1007/978-3-031-16078-3_40,en,Adversarial Attack and Defense Based Hydrangea Classification via Deep Learning: Autoencoder and MobileNet,OriginalPaper,"Hydrangea, a pervasive flower that grew throughout the world, has proven to be harmful in ways as an invasive species. To tackle this widespread issue, our experiment aimed to prevent adversarial attacks, which can result in real-life effects. One minor but vital step of our process was preprocessing, including normalization and train-test splitting. Furthermore, an autoencoder (AE) was implemented to help distinguish noise. A total of 7 algorithms were then applied to test how successful our program was. As demonstrated in the paper, images with noise returned a significantly lower accuracy. Two algorithms, the normal model and MobileNet, were tested once more with the addition of an AE. The established hypothesis was that it would result in higher accuracies compared to those with noise since that would verify the benefit of implementing AEs. For reference, the accuracy of MobileNet was 67.4% with noise, 88.5% without noise, and 100% with both noise and an autoencoder. In both scenarios, the autoencoder notably boosted the accuracy in the presence of noise. Though hydrangea was the specialized field of study in this research, our methodologies can be implemented elsewhere, as long as the required data is available.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2764-5_28,en,Comparative Analysis of Different Signal Processing Schemes for Islanding Detection in Microgrid,OriginalPaper,"In this paper, islanding detection in a microgrid scenario is analyzed by using the signal processing techniques such as the S-transform method (ST), Sparse S-transform (SST), variational mode decomposition method (VMD) and total variation filtering method (TVF). To get a clear picture of the comparison, all the detection schemes are evaluated in the standard 13-bus distribution system. In this paper, the PCC voltage of a three-phase system is utilized for further signal processing and subsequent feature selection procedure. The extracted voltage is also called as modal voltage. Various monitoring parameters have been considered to check the effectiveness of the selected threshold and subsequent islanding detection. Further, the detailed overview of above-mentioned methods has been thoroughly discussed.","['Energy', 'Energy Systems', 'Artificial Intelligence', 'Machine Learning', 'Cyber-physical systems, IoT', 'Professional Computing', 'Power Electronics, Electrical Machines and Networks']"
doi:10.1007/978-981-19-1610-6_11,en,Preliminary Results on Constraint Programming and Branch & Bound Algorithms for the Cyclic Bandwidth Sum Problem,OriginalPaper,"The cyclic bandwidth sum problem (CBSP) consists in embedding a host graph into a cycle graph while minimizing the sum of cyclic distances between guest adjacent vertices embedded in the host. While the problem has been addressed by heuristic and metaheuristic methods, to the best of our knowledge, this is the first effort to apply exact methods. This work presents preliminary results on the use of constraint programming (CP) and a branch & bound (B &B) algorithm to solve the cyclic bandwidth sum problem in small graphs from commonly employed topologies. We created a CP model of the CBSP and devised two further refined versions by adding new constraints based in problem-specific knowledge. For our proposed B &B algorithm, we designed a custom criterion for search priority employing estimations of potential cost. The results provided an assessment of the pros and cons of both methodologies, with the CP approach offering a more reliable alternative in terms of solved instances, execution time, and implementation effort.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-19067-4_8,en,Decentralized SGD and Its Variants,OriginalPaper,"In all the distributed SGD implementations that we studied so far, namely, synchronous SGD.","['Mathematics', 'Algorithms', 'Machine Learning', 'Algorithm Analysis and Problem Complexity', 'Artificial Intelligence', 'Probability Theory and Stochastic Processes', 'Computer Science, general']"
doi:10.1007/978-3-031-06780-8_19,en,Big Data in Road Transport and Mobility Research,OriginalPaper,"This chapter covers topics related to big data sources, methods and applications in transportation and mobility research. Big data sources covered include data from vehicle-based and infrastructure-based sensors. Methods from traditional regression to machine-learning and AI are discussed in terms of prediction and inference goals. Finally, example use cases of Big Data and AI are discussed in the context of safety, travel and micromobility.","['Engineering', 'Automotive Engineering', 'Computational Intelligence', 'Transportation Technology and Traffic Engineering', 'Signal, Image and Speech Processing']"
doi:10.1007/978-981-19-1844-5_3,en,Classification of Breast Cancer Using CNN and Its Variant,OriginalPaper,"Deep learning comes under machine learning. It includes statistics and predictive modeling, which plays vital role in data science. It helps in acquiring and analyzing vast amount of data quick and easier. This technique is employed in image recognition tools and natural language processing. Carcinoma is one other frequently occurring cancer in women. Carcinoma can be identified in two variants: One is benign, and another one is malignant. Automatic detection in medical imaging has become the vital field in many medical diagnostic applications. Automated detection of breast cancer in magnetic resonance imaging (MRI), and mammography is very crucial as it provides information about breast lesions. Human inspection is the conventional method for defect detection in magnetic resonance images. This method is impractical for large amount of data. So, cancer detection methods are developed as it would save radiologist time and also the risk faced by woman. Various machine learning algorithms are used to identify breast cancer. Deep learning models have been widely used in the classification of medical images. To improvise the accuracy in the model various, deep learning approaches are to be used to detect the breast cancer. The proposed approach classifies the breast cancer not just as benign or malignant, but it will classify the subclasses of breast cancer. They are Benign, Lobular Carcinoma, Mucinous Carcinoma, Ductal Carcinoma, and Papillary Carcinoma. To classify the subclasses of tumor, we use DenseNet Architecture. Image preprocessing is done using histogram equalization method.","['Engineering', 'Communications Engineering, Networks', 'Mobile and Network Security', 'Artificial Intelligence', 'Big Data']"
doi:10.1007/978-3-031-21333-5_75,en,Overcoming the Lack of Data to Improve Prediction and Treatment of Individuals with Autistic Spectrum Disorder and Attention Deficit Hyperactivity Disorder,OriginalPaper,"The problem of lack of data remains a major drawback regardless of the continuous evolution of machine learning and deep learning models. This paper presents a modular and scalable architecture for the prediction and treatment of autism spectrum disorder (ASD) and attention deficit hyperactivity disorder (ADHD). With this architecture, therapists will be able to collect data from individuals from anywhere and at anytime, thanks to mobile devices, which will enable personalised monitoring. One of the main objectives of this ongoing project, which has a very widespread international projection within the framework of social inclusion, is the creation of a new collection of data due to the lack of data in this area. As a result, we will be able to place it in important repositories and specialised journals and thereby make it available to the scientific community. This architecture has been evaluated with several supervised and unsupervised machine learning algorithms in order to identify possible candidates for ASD/ADHD diagnosis. The initial results are very encouraging despite the small volume of data because they allow the possibility of developing personalised dashboards, which specialists can adapt to the personalised treatment of each individual according to the indicators obtained.","['Engineering', 'Data Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2821-5_58,en,Context-Based Vulnerability Risk Scoring and Prioritization,OriginalPaper,"Protecting an organization’s intellectual property, financial secrets, and performance is crucial because it is sensitive data that if compromised could be catastrophic to the organization in question. As a result of the growing economy, organizations of scale have a significant portion of their infrastructure over technology which makes the organization vulnerable. The security teams of such organizations work to patch such vulnerabilities as they come across them but may spend a significant amount of organization resources fixing vulnerabilities that may not be exploited. After conducting our own research on the existing methods to prioritize vulnerabilities that have a higher probability of being exploited, we found that machine learning can be used to make the process of vulnerability prioritization efficient. This paper discusses our research on using machine learning for vulnerability prioritization and the different machine learning algorithms that can be of use for the same. This paper also discusses our approach on creating a system for vulnerability prioritization in an organization.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3679-1_47,en,An Ensemble BERT CHEM DDI for Prediction of Side Effects in Drug–Drug Interactions,OriginalPaper,"Adult primary health care is highly dependent on the management of medications prescribed for them. Ineffective administration of drugs can cause serious side effects and lead to death. Early identification of drug interactions helps to effectively manage drugs. We propose a method called Ensemble BIO BERT CHEM DDI a Framework, which aims to identify potential patterns in the molecular structure of drugs. The 2013 DDI interaction dataset is considered for analysis at the molecular level. Historical analysis of similar studies proven that it is time-consuming and high-complexity problem to solve. A solution that can predict accurate drug–drug interactions can save millions of lives years. A total of 730 drug library documents were processed to understand the relationship between drug interactions. The Ensemble BERT CHEM DDI model framework is designed to predict five different categories (negative, effect, query, severe effect, and metabolism). The performance of the model is better than the previous literature. The f1 score is increased by 3%, and the model accuracy is improved by 6%. ROC AUC area increased to 4% compared to previously published work.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2004-2_43,en,Comparative Assessment of Performances of Various Machine Learning Algorithms in Detection of Liver Ailments,OriginalPaper,"Liver is a crucial interior organ of the human body whose primary tasks are to eliminate waste which is produced by the organs. In human body, most of the difficult tasks are being performed by the liver, and any abnormal activities happening due to malfunctioning of the liver will result into life-taking reason. Disease prediction in the human being has always been a long tenure procedure in early days. As the days have passed, computer-based diagnosis has become an important role in the medical world for prognosis, analyzing, and storing medical information with their related images. The liver disorder can cause various fatal and life-taking diseases, which also includes liver cancer. Early diagnosis and treating the patients beforehand can be helpful to reduce the risk of those lethal and fatal diseases. As the diagnosis of liver disease is quite expensive and sophisticated, numerous research have been performed using machine learning (ML) methods for classifying liver disorder cases. In this present work, we have categorized the liver patients on the basis of liver patient dataset using various machine learning techniques and approaches. In our work, we have classified our dataset with different classifiers such as k-nearest neighbor, random forest, support vector machine, and Extra Trees. After analysis, we concluded that after comparing all the accuracies, we found that Extra Trees classifiers gave the highest accuracy compared to other classifiers. We got the highest accuracy of 91.67%.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Artificial Intelligence', 'Materials Science, general']"
doi:10.1007/978-981-19-3590-9_12,en,A Review to Enhance Operations in an Airport with a Deep Learning and Computer Vision Approach,OriginalPaper,"Over a decade, the airline activities have seen a gradual increase all over the world. One of the reasons we can claim is the enhancing economy. According to International Civil Aviation Organization (ICAO), Civil Aviation Statistics and ICAO staff estimates that the number of airline travelers has increased from 2.25 billion in 2009 to 4.39 billion in 2019 globally. This increasing number of travelers calls for smart airport operations, and since there is an upsurge in utilization of deep learning and computer vision in recent years, a review has been done on how it can be utilized as for smart operations in airport.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security', 'Mobile and Network Security']"
doi:10.1007/978-3-031-16072-1_1,en,Anomaly-Based Risk Detection Using Digital News Articles,OriginalPaper,"Enterprise risk management is a well established methodology used in industry. This area relies heavily on risk owners and their expert opinion. In this work, we present an approach to a semi-automated risk detection for companies using anomaly detection. We present various anomaly detection algorithms and present an approach on how to apply them on multidimensional data sources like news articles and stock data to automatically extract possible risks. To do so, NLP methods, including sentiment analysis, are used to extract numeric values from news articles, which are needed for anomaly analysis. The approach is evaluated by conducting interview questionnaires with domain experts. The results show that the presented approach is a useful tooling that helps risk owners and domain expert to find and detect potential risks for their companies.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-3-031-18292-1_1,en,Explainable Artificial Intelligence: Concepts and Current Progression,OriginalPaper,"AI is a broad term used in computer science to mimic the human mind. Machine Learning is also a part of AI and is used in various fields of decision-making by using different algorithms. In the last few decades, AI has gained more popularity in the field of Industry, Medicine, Education, Defense, etc. Based on the algorithm AI is categorized into: Interpretable AI and Explainable AI (XAI). In interpretable AI, experts have problems in understanding the working of the model. They have no idea of working behind the algorithm so from here the term explainable AI came into existence. The term Explainable AI is coined by DARPA. This is also known as Explainable Machine Learning. The term came into existence to provide transparency in the process of decision-making by different Machine learning algorithms. In the current scenario, XAI is gaining popularity because of its transparent working. XAI is used in every field where AI can be used but with some modification or by adding some techniques of XAI as “SHAP (Shaply Additive exPlanations), DeepSHAP, DeepLIFT, CXplain, and LIME”. The main goal of this chapter is to provide a brief overview of XAI by covering almost every aspect of XAI. The chapter is divided into sections, in the first section brief introduction is discussed. Related work concerning medicine is stated in Sect. 2 . Later other sections will cover principles, techniques, current state of art, benefits, and, applications. This chapter infers that XAI is a great development in AI due to its transparent nature. The chapter also addressed the challenges in XAI, as well as the field’s future potential.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-0108-9_36,en,A Critical Analysis of Machine Learning’s Function in Changing the Social and Business Ecosystem,OriginalPaper,"Machine learning is an automization based technique that learns automatically about something without specific programming of the task. It is used in a variety of fields. The capabilities of Data-driven modeling (DDM) have recently been expanded by advances in machine learning, allowing artificial intelligence to infer system behavior by correlating computing and exploiting between variables that were observed within them. The use of auto-generated high volume business data can be enabled by machine learning algorithms and aided by applying models of ecosystem services across scales, allowing the flow of these services to be analyzed and predicted to disaggregated beneficiaries. Machine learning is a very advanced field with numerous applications in a wide range of business environments. Currently, in the field of information science, data processing techniques such as machine learning have been developed and applied in a variety of areas for practical applications.","['Engineering', 'Manufacturing, Machines, Tools, Processes', 'Renewable and Green Energy', 'Materials Science, general', 'Nanotechnology']"
doi:10.1007/978-981-19-2126-1_25,en,IoT and Deep Learning-Based Weather Monitoring and Disaster Warning System,OriginalPaper,"Evolution of Internet of Things (IoT) and wireless sensor network (WSN) have lead to vast changes in day-to-day life. IoT and WSN have done very well in many fields.Agriculture, defence, automation, automobile, weather monitoring and disaster control are largely been transformed by IoT and WSN. In this paper, we will utilise IoT and deep learning in weather monitoring and disaster control systems. There is a strong need to build a cheap, robust and affordable system that sends early disaster warnings and monitors the situation .With the increase in computation power, various deep learning algorithms have been developed. In this paper, we have implemented various deep learning algorithms and model to predict the various climatic conditions.The bagging, boosting, trees and regression algorithm are being used in this paper to predict the weather condition efficiently. Systems are developed that accurate and precise to predict the weather conditions.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Machine Learning', 'Big Data', 'Computer Systems Organization and Communication Networks']"
doi:10.1007/978-981-19-2065-3_38,en,Impact of COVID-19 Vaccination: A Machine Learning Approach,OriginalPaper,"The speed with which the COVID-19 pandemic has spread is astounding, but the global response is based on lessons learned from earlier sickness outbreaks in the recent years. In an ordinary immunization study, one gathering of volunteers in danger for an infection is given an exploratory antibody, and another gathering is not; scientists screen the two gatherings after some time and contrast results with check whether the antibody is protected and viable. In a human test immunization study, solid volunteers are given a test antibody, and afterward intentionally presented to the life form making the sickness check whether the antibody works. Nonetheless, there are significant moral contemplations that should be tended to—especially for another infection like COVID-19, which we do not yet completely comprehend are as yet figuring out how to treat; it could be hard for the clinical local area and expected volunteers to appropriately appraise the possible dangers of taking an interest in a COVID-19 human test study. The speed with which this immunization has been created is wonderful. The examination here will investigate certain components related with the up-and-comer and will anticipate whether it is good for him to get immunized. The investigation is completed utilizing managed AI calculations. In this examination, we attempt to foresee the yield with greatest exactness.","['Engineering', 'Communications Engineering, Networks', 'Artificial Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Machine Learning']"
doi:10.1007/978-981-19-4990-6_57,en,Breast Cancer Detection Using Machine Learning,OriginalPaper,"Through studies and statistics, it has been found that these days, breast cancer is the most common cancer leading to frequent deaths among women. Early screening and subsequent treatment can raise the chances of survival. Through this paper, we aim to demonstrate the ability to detect breast cancer cases using MRI scan data by analyzing the given data with machine learning algorithms. Using machine learning, we hope to ease the process of cancer detection in the hospitals so the patient can be afforded the right treatment as soon as possible before the situation can become critical. It also opens the door toward new possibilities in cancer detection for other different types of cancers as well as other diseases by use of machine learning in medical science, where detection using conventional means is usually laborious and time-taking.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Wireless and Mobile Communication']"
doi:10.1007/978-981-19-4863-3_1,en,A Framework for Early Recognition of Alzheimer’s Using Machine Learning Approaches,OriginalPaper,"Alzheimer’s disease is a neurological disorder of the brain that primarily affects the blood nuclear cells in our brain. Early detection of Alzheimer’s disease is extremely crucial for disease prevention. Recently, the developers proposed a pre-selection technique for measuring image similarity. However, this method has a high computation time and a lengthy process. As a result, propose a novel machine learning framework for classifying Alzheimer’s disease. In this paper, several machine learning algorithms are used to classify Alzheimer’s disease in order to predict it at an early stage. Some of these include random forest, SVM, decision tree, and XGB classifier. Based on these algorithms propose a CatBoost classifier for the highest accuracy. These algorithms are applied on the OASIS dataset. In these algorithms, the CatBoost classifier achieves 85.7% accuracy on the OASIS dataset. The findings show that this framework can be used to identify and treat Alzheimer’s disease in healthcare at an early stage.","['Engineering', 'Computational Intelligence', 'Engineering Design', 'Machine Learning', 'Communications Engineering, Networks']"
doi:10.1007/978-3-031-15928-2_133,en,A Review of Benchmarks for Visual Defect Detection in the Manufacturing Industry,OriginalPaper,"The field of industrial defect detection using machine learning and deep learning is a subject of active research. Datasets, also called benchmarks, are used to compare and assess research results. There is a number of datasets in industrial visual inspection, of varying quality. Thus, it is a difficult task to determine which dataset to use. Generally speaking, datasets which include a testing set, with precise labeling and made in real-world conditions should be preferred. We propose a study of existing benchmarks to compare and expose their characteristics and their use-cases. A study of industrial metrics requirements, as well as testing procedures, will be presented and applied to the studied benchmarks. We discuss our findings by examining the current state of benchmarks for industrial visual inspection, and by exposing guidelines on the usage of benchmarks.","['Engineering', 'Engineering Design', 'Industrial and Production Engineering', 'Computer-Aided Engineering (CAD, CAE) and Design']"
doi:10.1007/978-981-19-5090-2_25,en,Prediction and Analysis of Air Quality Index Using Machine Learning Algorithms,OriginalPaper,"Air pollution, in general, relates to the introduction of toxins into the atmosphere that is toxic to people’s health and therefore the entire ecosystem. It has the potential to be one of the foremost dangerous risks mankind has ever encountered. It hurts cattle, livestock, and trees, among other things. To avoid this issue, machine learning (ML) algorithms must be used to forecast air quality (AQ) from pollution in the transportation field. Therefore, AQ measurement and forecasting have become a significant research subject. Here in this work, we aimed to look at ML-based approaches for AQ forecasting with the highest degree of accuracy. The entire dataset will be evaluated using the supervised ML technique to collect multiple pieces of information such as variable recognition, univariate analysis, bivariate and multivariate analysis, missed value treatments and information confirmation, information cleaning/preparing, and visualization. Our study offers a detailed guide to model parameter sensitivity analysis in terms of results in AQ emissions prediction through accuracy measurement. To suggest an ML-based approach for reliable forecasting of the air quality index (AQI) value by comparing supervised classifier findings in the form of better accuracy. To suggest a ML-based approach for reliably forecasting the AQI value by evaluating supervise classification, ML algorithm prediction outcomes in the form of best accuracy. By predicting AQI, we can recall the major factors that cause pollution and the area affected by pollutants in various places in India.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Artificial Intelligence', 'Data Structures and Information Theory']"
doi:10.1007/978-981-19-2397-5_40,en,Virtual Environment for the Mashing and Boiling Process in Craft Beer Production,OriginalPaper,"Process automation allows to increase production and improve the quality of craft products. This paper presents the implementation of closed-loop control algorithms for a mashing and brewing plant of craft beer. The proposed control scheme is implemented through the HIL technique, for which a virtual environment that simulates the behavior of the industrial process and a control card where the control algorithms are implemented are considered. To represent the behavior of the plant level and temperature processes, the mathematical model of each process is obtained, this model is used for the design of the control algo-rhythms, and the plant is modeled in 3D and incorporated into the graphics engine also has effects of realism together with been 3D in order to increase the level of realism to the process. For user interaction with the environment, an HMI type mantle center is incorporated to visualize and control the process manually, semi-automatically, and automatically, in order to test the control algorithms safely and avoid the risk of instrumentation damage or loss of real materials.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4067-5_19,en,Intelligent Identification and Diagnosis Service of Abnormality Events in the Drainage Network,OriginalPaper,"To detect and prognose drainage pipe network system failures as soon as possible, reduce the environmental, social hazards and losses, this paper proposes an intelligent identification and diagnosis software service. The service can be integrated with application, however, it provides real-time early warning and alarm notifications and auxiliary decision-making information for pipeline network maintenance personnel. It uses IoT technology perception of the water running state and combined with the hydrodynamic model to establish a complete physical map of the pipe network. It integrates weather and environmental information. Then uses data-driven models, deep machine learning, and hydrodynamic models, to recognize abnormal events, diagnose and locate fault causes, and prognose failures of pipe networks, which is a data science method.","['Engineering', 'Civil Engineering']"
doi:10.1007/978-981-19-5221-0_31,en,Improving Accuracy of Ataxic Gait Monitoring Using SVM and ANN,OriginalPaper,Ataxic gait monitoring and assessment of neurological disorders play significant roles in multidisciplinary regions that are supported by computerized signal handling techniques and Artificial Intelligence (AI) devices. This paper focuses on offering a chance of utilizing accelerometric information to identify the disorders more accurately using algorithms such as Artificial Neural Network (ANN) and Support Vector Machine (SVM). The trial dataset incorporates 860 sign fragments for about 16 patients who are ataxic and 19 patients with the control set for a timestamp of 39.6 and 38.6 years individually. The proposed model deals with investigating the recurrence parts of accelerometric flags that are continuously recorded from the human body in several directions using testing recurrence. The profound learning framework involves the recurrence parts in the ataxic gait. The characteristics offered by algorithms like SVM and ANN are discussed along with the functionality which gives a clear understanding of these algorithms.,"['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Sociology, general', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-16203-9_8,en,The Comprehensive Model of Using In-Depth Consolidated Multimodal Learning to Study Trading Strategies in the Securities Market,OriginalPaper,"The paper describes the relevance of machine learning methods, namely training with reinforcement, to the problems of predicting financial time series. An overview of existing applications based on machine learning in the issues of financial market forecasting is presented. The reasons for the popularity of my research topic are highlighted both from the scientific (increasing the number of publications on issues relevant to the research topic over the past five years) and from the practical side. The analysis of scientific works, the subject and purpose of which are related to the issues and objectives of my research and their features are presented. The main problems associated with the problem of predicting stochastic time series are identified. According to the analysis, the purpose of work is defined, and also the list of tasks for the achievement of the set goal is made. The article is devoted to studying the use of the ensemble of neuro-learning networks with the strengthening of the securities trading market. The practical significance of the work is to use the model of efficient distribution of investments in the market. This paper will explore a set of models that use in-depth consolidated learning to explore trading strategies to maximize return on investment. The potential of using acting-critical models as an ensemble has been studied. Models such as Proximal Policy Optimizer (PPO), Advantage Actor-Critic (A2C) and Deep Determinist Police Gradient (DDPG) were used to teach trading strategy. To adapt the model to different situations, analyzes are analyzed according to three algorithms: the Dow Jones average and a portfolio that minimizes fluctuations in the Charpy ratio by balancing risk and return. The article compares ensembles by the method of fixing deep neural networks. To optimize the balance of risk and profit, the indicators of the ensemble model are analyzed. The ensemble and three-component models that apply well to market collapse conditions are considered. The models have learned to use the turbulence index for early stock sales to minimize losses during a stock collapse. The turbulence index threshold is demonstrated using ensemble models to regulate risk avoidance.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5845-8_27,en,An Efficient Algorithm for Multi Class Classification in Deep Neural Network,OriginalPaper,"In comparison to other machine learning techniques, deep neural networks are effective in classifying non-linearly separable data. Because of its simplicity, contemporary gradient-based algorithms such as momentum Stochastic Gradient Descent (SGD) are commonly employed in Deep Neural Networks (DNN). However, the process of convergence is slowed by the choice of an appropriate learning rate and the local minima problem. To address these issues, this research proposes a unique approach for training DNNs called Simulated Annealing Based Gradient Descent (SAGD), which involves optimizing weights and biases. The SAGD technique optimizes the function by combining gradient information with the simulated annealing notion. The learning rate does not need to be manually adjusted with this method. Instead, using the simulated annealing approach, the learning rate is modified automatically for each epoch. The approach is tested utilizing VGG16, ResNet 18 and InceptionV3 architectures on typical multi-class classification data sets such as Iris, MNIST, and CIFAR10. The performance of SAGD and other state-of-the-art gradient descent optimization methods is compared, and it is demonstrated that SAGD performs comparably to existing gradient descent methods.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-15030-2_1,en,Use of Artificial Intelligence in a Cybersecurity Environment,OriginalPaper,"Artificial Intelligence (AI) is the intelligence exhibited by machines. Any system that perceives its environment and takes actions to maximize its chance of succeeding in a goal can be defined as AI. When using digital sensor data, AI-based devices can be used to develop smart advisors, teachers, or assistants. The risks associated with the use of AI technology may be related to operating systems, hardware, algorithms, or system management. Ethics, liability and privacy can also be compromised. Research in this field focuses on the threats and risks of AI and how AI can help solve cybersecurity problems. This study uses the taxonomy classification principle to classify 12 of the most crucial cybersecurity areas. The research method was to gather 10 AI solutions, which were divided into seven different categories of crucial areas of cybersecurity. These AI solutions uses artificial intelligence to detect, predict and block security threats and anomalies. The purpose of the study is to classify the collected AI-based cybersecurity solutions and provide information on what they can offer in solving cybersecurity problems.","['Computer Science', 'Artificial Intelligence', 'Privacy', 'Cryptology', 'Mobile and Network Security']"
doi:10.1007/978-981-19-3679-1_5,en,House Price Forecasting by Implementing Machine Learning Algorithms: A Comparative Study,OriginalPaper,"Discerning property value via state-of-the-art machine learning techniques can evolve the current real-estate market and expose it to the technological frontiers of the modern world. This can potentially have sanguine domino effects such as opening the market to new investors as a result of technically backed price values. The current research paper strives to capitalize on this opportunity by analyzing information and data from an existing online marketplace for buyers and sellers in this industry. It is conjectured that precise prediction of house prices in a particular location through data analytics will create a candid market where prices are not arbitrary, ensuring openness in the market through P2P opportunities which will eliminate middleman charges. The research ventures to extrapolate machine learning techniques to create a model that predicts house prices in Bangalore using a plethora of algorithms such as linear regression, bagging classifier, K-nearest neighbour, XGB, decision tree, gradient boosting, and random forest. An incremental approach is deployed to gather and streamline data, clean, visualize, model and evaluate the models produced. The research is completed with a result from the comparative study, showing the most appropriate algorithm for the given data available is the random forest algorithm.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3951-8_52,en,Miniscule Object Detection in Aerial Images Using YOLOR: A Review,OriginalPaper,"Object detection has made immense improvements in natural images during the last decade but not so much in aerial images. Detection of miniature objects in aerial images remains challenging as they contain only a few pixels and extremely large input sizes. Moreover, tiny objects are easily fooled by the backstory and increase the difficulty of accurate detection. Many algorithms are used for object detection purposes, and YOLOR is one of them. YOLOR “You Only Learn One Representation” is a one-stage detector. It is specially made for object detection, whereas other algorithms include object classification or analysis. In CNN, only, one task is carried out at a time, whereas YOLOR is a unified model useful for multitasking purposes. In this paper, we discussed tiny object detection in aerial images using YOLOR. Based on our research, we found that the AI-TOD dataset contains object instances in eight categories, with 86% of the objects being smaller than 16 pixels in size. The AI-TOD can be used to assess the performance of a variety of small objects. The mean size of objects is approximately 12.8 pixels, which is considerably smaller than the other datasets.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3035-5_23,en,A Comparative Study of Machine Learning Techniques for Credit Card Customer Churn Prediction,OriginalPaper,"A customer is a churner when a customer moves from one service provider to another. Nowadays, with an increasing number of severe competition with inside the market, essential banks pay extra interest on customer courting management. A robust and real-time credit card holder’s churn evaluation is vital and valuable for bankers to preserve credit cardholders. Much research has been observed that retaining an old customer is more than five times easier compared to gaining a new customer. Hence, this paper proposes a method to predict churns based on a bank dataset. In this work, “Synthetic Minority Oversampling Technique” (SMOTE) has been used for handling the imbalanced dataset. Credit card customer churn is predicted using random forest, k-nearest neighbor, and two boosting algorithms, XGBoost and CatBoost. Hyperparameter tuning using grid search has been used to increase the accuracy. The experimental result shows Catboost has achieved an accuracy of 97.85% and tends to do better than the other models.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Statistics, general']"
doi:10.1007/978-981-19-3571-8_37,en,A Novel Marathi Speech-Based Question and Answer Chatbot for the Educational Domain,OriginalPaper,"In any interactive agent, providing a suitable answer plays a vital role in determining the success of that chatbot. In the present research work, speech recognition API and Google Translate API are used to recognize the user’s voice and text translation respectively. We propose the design and implementation of a novel Marathi speech-based educational chatbot using Naïve Bayes classifier. After performing preprocessing, Naive Bayes classifier is used to determine and evaluate the highest probable class. More than 1500 words are used to train the model. The proposed approach is tested with some questions and their topics in the dataset. Brute force keyword matching and string similarity algorithms are implemented to fetch the suitable answer. Confusion matrix is generated to evaluate the performance of classification model. The obtained results prove the robustness of the proposed system.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-5845-8_29,en,Performance Analysis of Machine Learning Algorithms in Heart Diseases Prediction,OriginalPaper,"It is critical to discover aberrant heart conditions early in order to identify heart abnormalities and prevent sudden cardiac death. Cardiovascular infections (CVDs) are the leading cause of death worldwide, killing 17.9 million people year and accounting for 31% of all fatalities. Four out of every five CVD deaths are caused by coronary illnesses and strokes, with 33% of these deaths happening unexpectedly in adults under the age of 70. CVDs are known to cause cardiovascular breakdown, and this dataset comprises 12 elements that can be used to predict a probable coronary sickness. People who have cardiovascular disease or are at high cardiovascular risk (due to the presence of at least one risk factor such as hypertension, diabetes, hyperlipidemia, or a pre-existing illness) require early identification and treatment, which an AI model may give. According to WHO figures, heart disease is the leading cause of non-communicable illness death in India, accounting for 24% of all fatalities. Heart illnesses account for one- third of all deaths worldwide. Heart disease accounts for half of all deaths in the United States and other industrialized countries. Every year, almost 17 million people die from cardiovascular diseases (CVD), and the condition is particularly widespread in Asia. In this post, we will attempt to construct a machine learning model and use various machine learning algorithms. We are comparing their performance and then will suggest which algorithm is going to be model for this specific task. We are going to doing lots of task feature selection, model evaluation and will building another next set of model based on selected model and then we will decide which machine learning model is more generalize. Purpose: The study of a dataset (ECG dataset) and its ability to predict whether or not a person has cardiac disease. A person with a heart condition is represented by 1 and a person without a heart condition is represented by 0. The system will use machine learning to anticipate cardiac disease and get the best result. Conclusion: Nine-classification methods are used to detect the heart disease and evaluate the performance of each model for the given dataset. Logistic Regression has high accuracy among all.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-18487-1_23,en,Weighted Eigenvalue Counts on Intervals for Spectrum Optimization,OriginalPaper,"Power equipment is prone to vibrations. Removing eigenfrequencies of a structure from the interval of working frequencies reduces the probability of resonance during operation. In this contribution, a structural optimization problem is formulated whose objective at a minimum removes all eigenfrequencies from a given frequency interval. We consider systems without damping whose mass and stiffness matrices depend continuously on real parameters. The approach relies on the identity proposed by Futamura for eigenvalue count on intervals. The identity uses a contour integral in a complex plane of a trace of a specially constructed matrix. The contour integral is evaluated numerically using the trapezoidal rule over a circular path. The latter expression is differentiable. Present contribution extends the identity by adding a concave weighting function strictly positive in the interval. Furthermore, an explicit expression for the gradient of the objective and a simple optimization strategy are presented. Finally, a multi-degree of freedom example illustrates the performance of the approach.","['Energy', 'Energy Systems', 'Engineering Fluid Dynamics', 'Structural Materials', 'Engineering Thermodynamics, Heat and Mass Transfer']"
doi:10.1007/978-981-19-2840-6_28,en,Development of a Neighborhood Based Adaptive Heterogeneous Oversampling Ensemble Classifier for Imbalanced Binary Class Datasets,OriginalPaper,"Class imbalance prevails in many real-word datasets. In this paper, a Neighborhood based Adaptive Heterogeneous Oversampling Ensemble Classifier method is proposed to handle class imbalance in datasets. The proposed method adopts an oversampling approach to create a set of balanced representative training datasets. Several base classifiers are built based on those training datasets, and an adaptive heterogeneous ensemble classifier is created. The proposed method is examined with five datasets, and examination results are compared with popular oversampling algorithms. The comparison revealed that proposed method is able to achieve better performance results.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-16281-7_15,en,Towards a Trade-off Between Accuracy and Computational Cost for Embedded Systems: A Tactile Sensing System for Object Classification,OriginalPaper,"The deployment of the inference phase in self–standing systems, which have resource–constrained embedded units, is faced with many challenges considering computational cost of the elaboration unit. Therefore, we propose using a learning strategy based on a loss function that leads to finding the best configuration of the prediction model balancing the generalization performance and the computational cost of the whole elaboration system. We validate our proposal by integrating a tactile sensing system on a Baxter robot to collect and classify data from five daily–life objects using four different algorithms. Results show that the best performance, when the computational cost is not relevant, is achieved by the fully–connected neural network using 16 features, while, when the computational cost matters, the loss function showed that the kernel SVM with 4 features has the best performance.","['Engineering', 'Cyber-physical systems, IoT', 'Machine Learning', 'Robotics and Automation']"
doi:10.1007/978-3-031-18458-1_21,en,State-of-the-Art Lightweight Cryptographic Protocols for IoT Networks,OriginalPaper,"Due to technical improvements, the Internet of Things has enabled the networking of devices capable of collecting vast volumes of data. Consequently, IoT security requirements are crucial. Cryptography safeguards the network's identity, data integrity, privacy, and access control. Since IoT devices impose so many constraints, certain encryption methods are not suited for IoT environment. Therefore, academics have proposed a variety of lightweight cryptographic protocols for protecting data in Internet of Things (IoT) networks. This paper investigates modern lightweight cryptography techniques for IoT networks and evaluates prominent ciphers now in use. Consequently, it divided contemporary into two categories: symmetric lightweight cryptography and asymmetric lightweight encryption. In addition, the security of several newly proposed block cipher and stream cipher methods has been assessed. In addition, the key alterations and potential future study areas have been examined.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16078-3_13,en,Combining Edge Recombination Crossover with Ant Colony Optimisation for Improved Routing,OriginalPaper,"Meta-heuristics are commonly applied to difficult permutation type routing problems such as the Traveling Salesman Problem (TSP). Genetic Algorithms (GA) and Ant Colony Optimisation (ACO) are two of the most successful. However, GAs require specialist crossover operators for permutation problems to avoid repetition. Crossover operators such as Edge Recombination (ER) focus on preservation of parental edges but do not account for edge quality . However, ACO involves ants selecting edges based on pheromone and quality . Consequently, this paper proposes combining GAs and ACO via ER crossover (ER-ACO) whereby ants ensure the quality of preserved parental edges. Applied to a range of TSP instances the ER-ACO crossover method demonstrates considerable improvements over standard ER highlighting the importance of edge quality. Moreover, ER-ACO also demonstrates inserting high quality non-parental edges is highly beneficial. Indeed, ER-ACO crossover is able to achieve solutions within 1–2% of optimal for TSP instances of several thousand cities.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1412-6_55,en,Intelligent Multiple Diseases Prediction System Using Machine Learning Algorithm,OriginalPaper,"As a result of their surroundings and lifestyle choices, people nowadays suffer from a wide range of ailments. As a result, predicting illness at an early stage is crucial. Doctors, on the other hand, struggle to make accurate diagnoses based solely on symptoms. The most challenging task is predicting sickness properly. Machine learning plays a key part in forecasting in order to complete this difficult task. To tackle this challenge, machine learning plays a key role in illness prediction. Medical research creates a vast amount of data every year. Early patient care has benefitted from effective medical data analysis because of the rising quantity of data growth in the medical and healthcare professions. In data mining, disease data is utilised to identify hidden patterns in huge volumes of medical data. Based on the patient's symptoms, we created a broad disease prediction. Machine learning algorithms like ANFIS and CNN are used to properly predict sickness (adaptive network-based fuzzy inference system). The collection of illness symptoms is necessary for disease prediction. For an accurate prognosis, this general illness prediction takes into account the person's lifestyle and medical history. When it comes to illness prediction, ANFIS outperforms CNN by a wide margin (96.7%). ANFIS, on the other hand, does not require as much time or memory to train and test because it does not use the UCI repository dataset. There are several libraries and header files included with the Anaconda (Jupyter) notebook that make Python programming more precise and accurate.","['Engineering', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security']"
doi:10.1007/s40544-022-0596-7,en,Tribo-informatics approaches in tribology research: A review,"['ReviewPaper', 'Review Article']","Tribology research mainly focuses on the friction, wear, and lubrication between interacting surfaces. With the continuous increase in the industrialization of human society, tribology research objects have become increasingly extensive. Tribology research methods have also gone through the stages of empirical science based on phenomena, theoretical science based on models, and computational science based on simulations. Tribology research has a strong engineering background. Owing to the intense coupling characteristics of tribology, tribological information includes subject information related to mathematics, physics, chemistry, materials, machinery, etc. Constantly emerging data and models are the basis for the development of tribology. The development of information technology has provided new and more efficient methods for generating, collecting, processing, and analyzing tribological data. As a result, the concept of “tribo-informatics (triboinformatics)” has been introduced. In this paper, guided by the framework of tribo-informatics, the application of tribo-informatics methods in tribology is reviewed. This article aims to provide helpful guidance for efficient and scientific tribology research using tribo-informatics approaches.","['Engineering', 'Mechanical Engineering', 'Nanotechnology', 'Tribology, Corrosion and Coatings', 'Physical Chemistry', 'Surfaces and Interfaces, Thin Films']"
doi:10.1007/978-981-19-3148-2_35,en,Prediction and Analysis of Stress Using Machine Learning: A Review,OriginalPaper,"In today’s advancing world, as technology is evolving by leaps and bounds, it is also creating various stress symptoms among people. Diseases such as stress, anxiety, depression, and ADHD are commonly found in the younger generation. This is all contributed to various factors such as lifestyle choices, social and economic pressure, and low self-esteem. Workload, immense social and economic pressure, and family responsibilities are other factors that impose increasing levels of stress on individuals. Hence, detection and analysis of stress at early stages can reduce severe consequences and risks that may occur in the future. In modern times, advancement in technology has created a need for evolution in the medical sector. As a result, it is crucial to predict and analyze various symptoms that cause stress so that it is easier to find their treatment as soon as possible. Thus, this evolved the need for bioinformatics to work with machine learning. With the help of various machine learning methodologies, it is now easy to predict and analyze stress in people at their initial stages. In this manuscript, various techniques of machine learning have been examined that are used to analyze stress and its symptoms. These include techniques such as Support Vector Machine (SVM), Logistic Regression, Naïve Bayes, Decision Trees, and Random Forest.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory']"
doi:10.1007/978-3-031-16203-9_20,en,Analysis of Deep Learning Methods in Adaptation to the Small Data Problem Solving,OriginalPaper,"This paper discusses a specific problem in the study of deep neural networks - learning on small data. Such issue happens in situation of transfer learning or applying known solutions on new tasks that involves usage of particular small portions of data. Based on previous research, some specific solutions can be applied to various tasks related to machine learning, computer vision, natural language processing, medical data study and many others. These solutions include various methods of general purpose machine and deep learning, being successfully used for these tasks. In order to do so, the paper carefully studies the problems arise in the preparation of data. For benchmark purposes, we also compared “in wild” the methods of machine learning and identified some issues in their practical application, in particular usage of specific hardware. The paper touches some other aspects of machine learning by comparing the similarities and differences of singular value decomposition and deep constrained auto-encoders. In order to test our hypotheses, we carefully studied various deep and machine learning methods on small data. As a result of the study, our paper proposes a set of solutions, which include the selection of appropriate algorithms, data preparation methods, hardware optimized for machine learning, discussion of their practical effectiveness and further improvement of approaches and methods described in the paper. Also, some problems were discussed, which have to be addressed in the following papers.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-19067-4_6,en,Local-Update and Overlap SGD,OriginalPaper,"In the last two chapters, we studied synchronous and asynchronous SGD, where the workers compute mini-batch gradients and the parameter server aggregates them and updates the model. Both these algorithms and their variants require constant communication between the workers and the parameter server after every iteration.","['Mathematics', 'Algorithms', 'Machine Learning', 'Algorithm Analysis and Problem Complexity', 'Artificial Intelligence', 'Probability Theory and Stochastic Processes', 'Computer Science, general']"
doi:10.1007/978-3-031-19620-1_17,en,Synthesis of Estimation System for UAV Orientation with a Neural Network-Identifier,OriginalPaper,"Traditional algorithms for processing measurement information do not always provide the necessary accuracy of estimation under external influences and require large computing power, which is difficult to implement in conditions of restrictions on the weight and size characteristics of transport UAVs. The use of algorithms for dynamic estimation of the angular orientation of the UAV based on an adaptive model in combination with the use of multilayer feed-forward neural networks allows to reduce the error of estimating the parameters of a dynamic system without significantly increasing computational costs. The article presents a synthesis of an estimation system for UAV orientation with a neural network model identifier as part of an automatic control system, which allows to increase the accuracy of the estimation in comparison with the classical Kalman filter.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-11170-9_3,en,Social Media Sentiment Analysis Related to COVID-19 Vaccinations,OriginalPaper,"The wake of the COVID-19 pandemic has yet again highlighted how vital immunization is for public health. Despite the dramatic spread of SARS-CoV-2 and its variants, there is a rising trend of people refusing to be vaccinated. As a result, governments and health experts must gather and understand public ideas and perceptions about vaccines to design engagement and education efforts about vaccine advantages. Sentiment analysis is a common method for acquiring a broad picture of public opinion, that enables the classification of people as those who are in favor or against vaccination, as well as the determination of the factors that influence their attitudes and beliefs. The purpose of this chapter is to describe the general approach to sentiment analysis in the context of vaccinations and review its different use cases. The chapter’s experimental component integrates the utilization of a dataset retrieved from Kaggle, which contains COVID-19 vaccine-related Twitter data. When attempting to perform sentiment analysis, certain methodological steps need to be considered after data collection, including data pre-processing, technique selection and model construction, as well as model evaluation and results interpretation. Both supervised and unsupervised sentiment analysis methods are investigated in the model construction step, with the former involving the implementation of Support Vector Machines and Logistic Regression algorithms, and the latter involving the use of TextBlob and Valence Aware Dictionary and sEntiment Reasoner (VADER) sentiment analysis tools. The performance of each algorithm and tool is evaluated, as is the performance of each sentiment detection approach in order to select the best performing one. Social media platforms have become a common source of information and misinformation regarding vaccines. Our effort aims to emphasize the importance of mining such readily available public attitudes, as well as forecast opinions and reactions related to vaccine uptake in near real-time. Such insights could be critical in dealing with health emergency situations like the ongoing coronavirus pandemic.","['Computer Science', 'Health Informatics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-6004-8_50,en,Hyper-personalization and Its Impact on Customer Buying Behaviour,OriginalPaper,"Process digitization is one of the important elements in industrial revolution 4.0, with a key focus on customer experience through hyper-personalization. It has a major impact on how, when, why, where, and who elements in buying nature of a customer. Multiple techniques can be used to give targeted personalized messages by using data mining techniques. This research is to understand how customer behaviour like loyalty, willingness to pay more, etc., is impacted. Hierarchical recurrent neural network (HRNN) algorithm can be used to model user interactions, given the parameters like customer ID, timestamp, and user ID to provide recommendations for a given session. Various actions of a customer can be captured via multiple techniques and systems, which is further used for hyper-personalization, i.e. creating a customer offer to cater specific need or interest.","['Engineering', 'Computational Intelligence', 'Cognitive Psychology', 'Personality and Social Psychology', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-3575-6_15,en,A Blockchain Solution for Secure Health Record Access with Enhanced Encryption Levels and Improvised Consensus Verification,OriginalPaper,"Blockchain can be depicted as a permanent record, logging information in a decentralized way. This new innovation has been proposed to widen the horizons of information-driven spaces, including the medical information. Electronic medical records have recorded the course of event, improvement, and treatment of illnesses. So, it has high clinical worth. As healthcare information must be kept private and secure, information security and privacy preserving are the most crucial issues to be handled in healthcare. This paper analyzes and identifies the most pertinent security and privacy issues in existing healthcare systems. To resolve the privacy and security issues, blockchain innovation can act as a robust solution as blockchain technology uses cryptography and consensus verification as basic perspectives alongside decentralized architecture and immutable blocks of data. Various consensus and encryption algorithms of the blockchain technology have been studied in depth, and an overview has been presented in the paper. A novel blockchain-based patient health record (BB-PHR) system is proposed with improvised consensus mechanisms and enhanced encryption levels for medical data access control and protection in the paper. The system enforces consensus verification of patient and hospital administration both for maintaining privacy and tamper proof data access. Proposed system integrates encryption algorithms, access control mechanisms, and smart contract on a blockchain framework comprehensively to address the security and privacy vulnerabilities of a health record. With such a system, we can implement severe access and security control on healthcare information.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-030-95764-3_4,en,How to Design Human–Machine Interaction in Next-Generation Supply Chain Planning,OriginalPaper,"Decision support systems for supply chain planning have been supporting planners over decades to improve their decision-making in many different ways. As next-generation planning systems are leveraging advanced artificial intelligence (AI) technologies, companies must not only determine what decision support to use, but effectively shape how the supply chain planner (“the human”) and the system (“the machine”) work together. At the same time, AI-supported planning systems will change the job profiles and required skill sets of supply chain planners. This chapter provides guidance on what to consider when designing such interactive systems and elaborates on the effect of digitization on supply chain job profiles.","['Business and Management', 'Operations Management', 'Operations Research, Management Science', 'Industrial and Production Engineering']"
doi:10.1007/978-981-19-5224-1_75,en,Classification of Pap Smear Image of Cervix Cell Using Machine Learning Techniques and Transfer Learning-Based Convolutional Neural Network Architecture and Scrutinizing Their Performances,OriginalPaper,"Different cervical pap smear cell categorization schemes have recently been presented, the majority of which were binary classifications of normal and abnormal cells. This paper presents the findings of a comprehensive investigation on machine learning and deep learning algorithms for binary and multi-class classification on pap smear images from the Herlev dataset. There are 917 photos in this collection, divided into seven normal and pathological categories. The Google Colab platform was used to generate models utilizing all of the techniques using scikit learn and the keras library from TensorFlow. To begin, several repetitions of processes such as feature importance selection, data normalization, standardization, PCA, T-SNE, and others have been imposed on models such as SVM and XGBoost in this work for machine learning approaches. Second, it was demonstrated in this work that a transfer learning-based CNN model from deep learning can outperform machine learning models in terms of binary and multi-class classifications. Furthermore, it was discovered in this work how computationally time efficient it is to apply a transfer learning model, which required roughly 25 min for 100 epochs. Finally, with several iterations of processes and outcomes, this work demonstrates that given enough data for a multi-class pap smear image classification system, the transfer learning CNN model has a higher potential to get the best results than the machine learning models used.","['Engineering', 'Communications Engineering, Networks', 'Statistics, general', 'Cyber-physical systems, IoT', 'Sociology, general', 'Professional Computing']"
doi:10.1007/978-981-19-3571-8_57,en,Twitter Sentiment Analysis Using Machine Learning and Deep Learning,OriginalPaper,"Twitter is the widely used microblogging site, where millions of people share their feelings, views, or opinion regarding different things be it a product, service, or events. Huge volumes of data are being produced hourly because of the increase in the number of users. These data are unstructured in nature, and thus, it is a difficult task to analyze them and extract the meaning from it. This paper, however, will concentrate on sentiment analysis of Twitter data. We will perform text mining or opinion mining to obtain a better understanding of public sentiment. In this paper, Python is used to acquire, preprocess, and analyze tweets, after those three different machine learning algorithms and one deep learning algorithm are used for sentiment analysis and comparison is done among them to determine which approach or model gives the best accuracy.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-5090-2_23,en,Image Retrieval Using Neural Networks for Word Image Spotting—A Review,OriginalPaper,"Borah, Naiwrita Baruah, Udayan Since the emergence of the Internet and low-cost digital image sensors, the number of image databases has grown tremendously. These image databases must have efficient image retrieval methods. One such technique is content-based image retrieval. In these databases, one will find charts, graphs, pictures, and even some text. Our main focus is on visual information retrieval by using this data. The idea is to bridge the semantic gap of high-level human perceptions and low-level features. This review was conducted based on an assessment and comparison of the most current CBIR approaches. Machine learning algorithms, similarity matching techniques, and performance assessment methodologies are also included in this study. This study provides an in-depth look into CBIR, covering its theory, concepts, techniques, difficulties, future directions, and performance.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Artificial Intelligence', 'Data Structures and Information Theory']"
doi:10.1007/978-981-19-2065-3_23,en,High Dimensional Data Clustering Using Forward Feature Selection Framework for Medical Data,OriginalPaper,"The advent of the “curse of dimensionality” issue while dealing with medical data as a result of large reduced datasets weakens the power of learning algorithms and requires expensive memory and processing expenses. Feature selection helps improve the performance of machine learning algorithms by decreasing the time it takes to create a learning model and enhancing the accuracy of the learning process. The High Dimensional Forward Feature Selection Clustering (HDFFSC) technique is proposed in this paper, which is a simple yet effective parallel processing method based on Map Reduce. Even though numerous algorithms have been created, they still fall short when dealing with high dimensional data in the medical area. To address the challenges with high dimensional data in the medical area, this paper also provides a Forward Feature Selection (FFS) technique with Artificial Bee Colony (ABC) optimization. Between and between clusters, this architecture enabled both global and local search capabilities. In comparison to standard clustering methods, it also increases clustering performance over chosen UCI medical datasets.","['Engineering', 'Communications Engineering, Networks', 'Artificial Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Machine Learning']"
doi:10.1007/978-981-19-0105-8_35,en,Optimization of BBU-RRH Mapping for Load Balancing in 5G C-RAN Using Swarm Intelligence (SI) Algorithms,OriginalPaper,"Cloud radio access network (C-RAN) is popularly known as centralized RAN which is an architecture for 5G network for process and manage cloud computing in a real-time environment. Cloud RAN (C-RAN) is popularly known as centralized RAN for providing flexibility for capital expenditure as well as operational expenditure. The benefits of C-RAN minimize the total cost ownership (TCO) and also improve the network performance. It provides benefit for low-latency network in 5G network as ultra-reliable low-latency communications (uRLLC). The 5G-CRAN enhances the benefits of not requirement of rebuild the transport networks again. C-RAN architecture is an essential and dynamically mapping of remote radio heads (RRHs) with baseband units (BBUs). Otherwise, it will cause call blocking and less quality of network connections. The proposed paper optimize to reduce the blocking of calls and also balance the load of BBUs by applying Swarm Intelligence(SI)algorithms. In proposed work, the simulation results are proved that nature-inspired computing algorithm will reduce the blocked calls and maximize the balance of processing load of BBUs.","['Engineering', 'Communications Engineering, Networks', 'Artificial Intelligence', 'Computational Intelligence', 'Bioinformatics']"
doi:10.1007/978-3-031-20601-6_20,en,Explainable Artificial Intelligence Powered Model for Explainable Detection of Stroke Disease,OriginalPaper,"Stroke is a very dangerous medical condition that happens when the human blood supply to a certain part of the human brain is cut off. If the blood supply is suddenly restricted or stopped, brain cells start to die. Stroke treatment is essential as the sooner a person receives treatment for a stroke, the less damage is likely to happen to this person. The emerging technology of machine learning can be used for such an application to provide an accurate result and to be taken into account in the treatment process, And with this starting point, Explainable Artificial Intelligence “XAI” come to action, one of those emerging technologies of machine learning that has the role of providing an explainability layer for introducing a level of interpretation, a dataset was collected from Kaggle to develop our experiment for testing a group of machine learning models against each other in detecting stroke, data is preprocessed first with a little cost as the overhead time the XAI will add with training will not be costly at all. At last results indicates that random forest and artificial neural network multilayer perceptron “ANN”, K-nearest neighbor ”KNN” are the best techniques based on their accuracy with accuracy of 0.984, then SHAP XAI Technique was applied with A total of 11 unique features and 1 target variable related to stroke that was identified as ID, gender, age, heart diseases, marriage, work type, residence, BMI, smoking status, its risk factors (such as hypertension and glucose level), and stroke (output variable) with weights of (0.1,0.21,0,0,0,0, 0.1, 0.66, 0.27, 0.1,0) respectively.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-13150-9_10,en,EMG Pattern Recognition: A Systematic Review,OriginalPaper,"EMG (electromyography), which records the electrical activity of our muscles, is a common test for muscle movement. This test helps determine whether there is a nerve injury or a muscle disease present, allowing the best course of treatment to be determined. EMG (electrical muscle activity) signals are used in a wide range of biomedical and neurological applications. It’s a quick overview of pattern recognition using EMG signals, explaining the various models and techniques available. EMG signals can be collected using needle electrodes or wearable devices like the Myo Armband for hand gesture recognition. For the purposes of this study, both cases were considered and analyzed. The electromyographic sensors found in the Myo armband can be used to create cost-effective and easy-to-use prototype models for a variety of applications. Traditional algorithms are characterized by complex computational methods and a high level of variability. Electromyographic signals, on the other hand, can now be analyzed thanks to advances in digital signal processing and mathematical models.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Management']"
doi:10.1007/978-981-19-4990-6_51,en,Visual Heart Rate—A Key Biomarker to Diagnose Depressive Disorder,OriginalPaper,"Depression is a disorder impacting people of all ages globally. If depression is detected at early stage, then it can be diagnosed. According to research, depression affects heart rate of an individual. By observing heart rate, depression can be predicted. In this paper, heart rate is calculated using facial videos as input. To calculate heart rate from facial video, algorithm used is Eulerian video magnification. Heart rate of person suffering from depression is not in normal range. Hence, estimated heart rate is used to train the model using algorithms of machine learning and proved that visual heart rate is key biomarker to diagnose depressive disorder. Performance of three machine learning algorithms is compared by varying test-train ratio.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Wireless and Mobile Communication']"
doi:10.1007/978-981-19-6068-0_38,en,Study of Data Mining Algorithms on Social Network Data for Discovering Invisible Patterns of Social Collaboration,OriginalPaper,"The increased usage of social media by Internet users is generating user-generated eco-logical data, such as text and photos. Popular social networking sites such as Google+, Twitter, and Facebook get a disproportionately large level of Internet traffic. They have a plethora of data about their customers and the links that bind them. There are required to explore and store valuable data from the massive social network datasets, graph-based mining tools, which can simply recreate the structure of the social networks. There are several data analysis tools accessible, each with its own set of benefits and features. Clustering, classification, association, and regression are some of the methods that are utilized to extract useful information from large amounts of data. This technology has a variety of applications in the real world. This paper summarizes data mining technologies and algorithms. The Nystrom technique is the most popular data mining technique to identify the hidden patterns of social collaboration.","['Computer Science', 'Artificial Intelligence', 'Computational Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-6290-5_11,en,Malicious URL Detection Using Machine Learning,OriginalPaper,"In recent years cyberattacks have become destructive and targeted. With technological advancements, diverse threats are launching in a sophisticated way that targets people to defraud them. Many web applications have been struggling to improve the reliability and security of their platforms to protect users from fraud, revenue, or malware. These attacks use malicious uniform resource locators (URLs) to attack web users. These URLs host unwanted content in the form of junk emails, phishing, or unauthorized drive-by downloads. Unsuspecting people click these phishing URLs and become victims of unethical anonymous activities like identity theft (personal or financial details) and installation of viruses. Therefore, it is necessary to detect malicious URLs accurately for resolving security issues. Traditional protection method, such as blacklisting, remains a classical technique for the detection of malicious URLs due to its simplicity but cannot detect unknown malicious URLs; hence, machine learning approaches are being used for achieving better results. This chapter aims to provide a structural understanding of popular feature extraction techniques and machine learning algorithms.","['Computer Science', 'Systems and Data Security', 'Cyber-physical systems, IoT', 'Professional Computing', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1844-5_14,en,Sentiment Analysis Using CatBoost Algorithm on COVID-19 Tweets,OriginalPaper,Sentimental analysis is a study of emotions or analysis of text as an approach to machine learning. It is the most well-known message characterization device that investigates an approaching message and tells whether the fundamental feeling is positive or negative. Sentimental analysis is best when utilized as an instrument to resolve the predominant difficulties while solving a problem. Our main objective is to identify the emotional tone and classify the tweets on COVID-19 data. This paper represents an approach that is evaluated using an algorithm namely—CatBoost and measures the effectiveness of the model. We have performed a comparative study on various machine learning algorithms and illustrated the performance metrics using a Bar-graph.,"['Engineering', 'Communications Engineering, Networks', 'Mobile and Network Security', 'Artificial Intelligence', 'Big Data']"
doi:10.1007/978-1-0716-2699-3_20,en,Data Processing and Analysis in Mass Spectrometry-Based Metabolomics,OriginalPaper,"Metabolomics Metabolomics is the latest of the omics sciences. It attempts to measure and characterize metabolites—small chemical compounds <1500 Da—on cells, tissue, or biofluids, which are usually products of biological reactions. As metabolic reactions are closer to the phenotype, metabolomics Metabolomics has emerged as an attractive science for various areas of research, including personalized medicine. However, due to the complexity of data obtained and the absence of curated databases for metabolite identification, data processing Data processing is the major bottleneck in this area since most technicians lack the required bioinformatics expertise to process datasets in a reliable and fast manner. The aim of this chapter is to describe the available tools for data processing Data processing that makes an inexperienced researcher capable of obtaining reliable results without having to undergo through huge parametrization steps.","['Chemistry', 'Mass Spectrometry', 'Cell Biology']"
doi:10.1007/978-3-031-08693-9_3,en,Multiplications to Multipliers: Performing Arithmetic in Hardware,OriginalPaper,"Getting an algorithm from an idea to actual hardware involves major changes in the way we think about numbers. In this chapter, we describe how floating-point numbers typical of high-level simulation can be represented in such a way that better reflects the fixed register size of hardware. We also explore how arithmetic is performed in hardware and how this can be extended to complex numbers and to vectors and matrices which are more representative of MIMO systems with QAM modulation. This allows us to bridge operations as used in algorithms to the cost and performance of their hardware implementation which allows us to finally understand how different hardware platforms impact how fast a system runs.","['Engineering', 'Circuits and Systems', 'Microwaves, RF and Optical Engineering']"
doi:10.1007/978-3-031-18050-7_47,en,Optimization of Trajectory Generation for Automatic Guided Vehicles by Genetic Algorithms,OriginalPaper,"Continuous improvement of industrial and production processes for efficiency optimization has led to an increase in the need for automatization. Automatic guided vehicles (AGV) are key transport elements when it comes to fulfilling this function, as well as the development and improvement of their navigation and positioning systems. Thus, in this work the use of a Soft Computing evolutive technique, genetic algorithms (GA), is proposed in order to obtain the optimal parameters of a trajectory generation method. An occupancy map model for the environment layout is used in order to check collision events with the AGV. Different scenarios have been simulated to optimize the trajectory length avoiding collisions if possible. Simulation results show that the algorithm is able to minimize the length of the path successfully.","['Engineering', 'Computational Intelligence', 'Industrial and Production Engineering']"
doi:10.1007/978-3-031-15928-2_132,en,Posture Interactive Self Evaluation Algorithm Based on Computer Vision,OriginalPaper,"Many workers and citizens have been forced to make a lifestyle change in the past two years due to the pandemic emergency. In order to keep a high level of personal health, the doctors suggest to do fitness exercises. Before the pandemic it was possible to do these exercises at the gym or during dedicated session in the office supervised by professional trainers. During the pandemic emergency the gyms were closed, the workers were forced to stay home and the people started to do gym exercises by themselves without the control of a professional figure. This situation could lead to several diseases associated to musculoskeletal disorders if the exercises are performed incorrectly. In this work, an approach based on the pose-estimator application OpenPose is developed. The reference exercise is an isometric squat performed by a professional trainer. During the exercise, thanks to a deep neural network, the pose-estimator gets a series of key-points and vectors which represent the user’s pose. A dataset of videos (for both the correct and incorrect postures) has been used to train several machine learning algorithms. The result is an automatic tool that recognizes incorrect poses during the exercise and helps the performer to correct it.","['Engineering', 'Engineering Design', 'Industrial and Production Engineering', 'Computer-Aided Engineering (CAD, CAE) and Design']"
doi:10.1007/978-981-19-2016-5_5,en,Distributed Mathematical Optimization,OriginalPaper,"Recently, distributed optimization has drawn significant attention in signal processing [ 1 ], due to the requirement to obtain decentralized control and decision making in sensor networks as well as large-scale data processing and learning. Because the distributed agents/nodes only process the local data and the information exchanged from direct neighbors, distributed optimization fits well for the applications where the data are received distributively [ 2 ] or the data privacy is of primary importance [ 3 ].","['Engineering', 'Wireless and Mobile Communication', 'Cyber-physical systems, IoT', 'Professional Computing', 'Communications Engineering, Networks']"
doi:10.1007/978-3-031-15374-7_8,en,Learning in the Presence of Multiple Agents,OriginalPaper,"Reinforcement Learning (RL) has emerged as a powerful tool to solve sequential decision-making problems, where a learning agent interacts with an unknown environment in order to maximize its rewards. Although most RL real-world applications involve multiple agents, the Multi-Agent Reinforcement Learning (MARL) framework is still poorly understood from a theoretical point of view. In this manuscript, we take a step toward solving this problem, providing theoretically sound algorithms for three RL sub-problems with multiple agents: Inverse Reinforcement Learning (IRL), online learning in MARL, and policy optimization in MARL. We start by considering the IRL problem, providing novel algorithms in two different settings: the first considers how to recover and cluster the intentions of a set of agents given demonstrations of near-optimal behavior; the second aims at inferring the reward function optimized by an agent while observing its actual learning process. Then, we consider online learning in MARL. We showed how the presence of other agents can increase the hardness of the problem while proposing statistically efficient algorithms in two settings: Non-cooperative Configurable Markov Decision Processes and Turn-based Markov Games. As the third sub-problem, we study MARL from an optimization viewpoint, showing the difficulties that arise from multiple function optimization problems and providing a novel algorithm for this scenario.","['Engineering', 'Electrical Engineering', 'Biomedical Engineering and Bioengineering', 'Computer Systems Organization and Communication Networks']"
doi:10.1007/978-981-19-0151-5_26,en,Stability of Feature Selection Algorithms,OriginalPaper,"Feature selection is in great demand as it is a crucial phase in classification, clustering, and prediction tasks all around the different sectors. The stability of the feature selection process determines the sensitivity of the selection to dataset variation. In bioinformatics, a task of biomarker identification requires selection of disease associated genes (relevant feature subset), to be insensitive to the variations in the training set, which can give confidence to the domain experts and can prevent result manipulation in the real-world applications. Traditional feature selection strategies are ineffective to capture this high sensitivity to the numerous perturbations. This motivates the need of robust feature selection strategy which produces stable feature set across datasets from multiple domains.","['Engineering', 'Biomedical Engineering and Bioengineering', 'Artificial Intelligence', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Biological and Medical Physics, Biophysics', 'Information Storage and Retrieval']"
doi:10.1007/978-3-031-16684-6_16,en,Non-parametric Rank Correlation Trained Single-Hidden Layer Feedforward Neural Networks for Medical Data,OriginalPaper,"Massive amounts of medical data led to a faster, more accurate diagnosis and course of treatment for cancer. Machine learning (ML) algorithms have been developed increasingly in order to process medical data. By embedding knowledge from data into the algorithm’s architecture we customize MLs to provide personalized diagnosis and personalized treatment plan. The goal of this study is to statistically analyze non-parametric correlation coefficients for initializing the input-hidden weight matrix of three single hidden layer feedforward neural networks (SLFNs). A SLFN is able to approximate a continuous function given a training dataset as input for a desired output. Using different non-parametric correlation coefficients, $$\rho , \tau $$ ρ , τ , and $$\gamma $$ γ , we developed three novel SLFNs that have their input hidden layer weight matrix initialized using the above-mentioned correlation coefficients computed between the input and the output. The matrix that contains the hidden output weights is computed in just one step, using the Moore-Penrose pseudoinverse matrix. A statistical analysis is performed for assessing the models’ results when applied on three medical datasets that regard differentiating lung, breast, and liver cancer. The statistical benchmarking showed that the $$\rho $$ ρ -SLFN is superior to the other two. All three models were overall competitive to other state-of-the-art algorithms.","['Engineering', 'Control and Systems Theory', 'Computational Intelligence']"
doi:10.1007/978-981-19-2255-8_2,en,"
            
              
            
            $${{\varvec{l}}}_{{\varvec{1/2}}}$$
            
              
                
                  l
                
                
                  1
                  /
                  2
                
              
            
          -SVD Based Channel Estimation for MmWave Massive MIMO",OriginalPaper,"In millimeter wave(mmWave) massive multiple-input multiple-output (MIMO) system with hybrid precoding structure, the channel estimation is a huge challenge. The paper proposes an effective channel estimation algorithm based on $$l_{{1/2}}$$ l 1 / 2 -SVD idea. The first step is to establish an objective function composed of the weighted sum of $$l_{{1/2}}$$ l 1 / 2 -regular term and error constraint term. Then the singular value decomposition (SVD) pretreatment is used to decrease the selection of the initial value of the angle parameter in the iterative weighting process. Next, the estimated value of the angle parameter is obtained by the gradient descent method. Simulation results exhibit that the proposed scheme has better accuracy than traditional channel estimation algorithms.","['Engineering', 'Communications Engineering, Networks', 'Wireless and Mobile Communication', 'Signal, Image and Speech Processing', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-5331-6_17,en,Encrypto–Decrypto,OriginalPaper,"In present scenario, cybercrimes are increasing in every area of technology. Especially, in text transfer, there is a high chance of a third party breach. Everyone needs to share information with each other through various platforms which is a daily part of life. These days it is a big concern that data might leak and can be misused by someone. To overcome these issues, a model has been created as an encryption and decryption platform to increase privacy in text transfer which leads to making the communication secure. A user-friendly, highly secure, and fast algorithm used in the platform.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-09640-2_8,en,DataCookie: Sorting Cookies Using Data Mining for Prevention of Cross-Site Scripting (XSS),OriginalPaper,"Cross-Site Scripting (XSS) is a vulnerability in web applications; it allows the injection of scripts or malicious code to steal user sessions and cookies or redirect users to malicious sites. According to OWASP, it is included in the category of injections; it is part of the top 10 most frequent vulnerabilities in web applications in 2021. This study presents DataCookie, a model based on the data mining methodology, CRISP-DM, whose objective is to analyze cookies through decision trees. As a result, we developed in Python a script to classify the new cookies according to the rules obtained from the selected decision tree. This classification revealed that 2.19% of the websites visited by users of a public institution on a business day contain XSS vulnerabilities.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Computational Intelligence', 'Security Science and Technology']"
doi:10.1007/978-3-031-16237-4_2,en,Machine Learning Construction: Implications to Cybersecurity,OriginalPaper,"Statistical learning is the process of estimating an unknown probabilistic input-output relationship of a system using a limited number of observations. A statistical learning machine (SLM) is the algorithm, function, model, or rule, that learns such a process; and machine learning (ML) is the conventional name of this field. ML and its applications are ubiquitous in the modern world. Systems such as Automatic target recognition (ATR) in military applications, computer aided diagnosis (CAD) in medical imaging, DNA microarrays in genomics, optical character recognition (OCR), speech recognition (SR), spam email filtering, stock market prediction, etc., are few examples and applications for ML; diverse fields but one theory. In particular, ML has gained a lot of attention in the field of cyberphysical security, especially in the last decade. It is of great importance to this field to design detection algorithms that have the capability of learning from security data to be able to hunt threats, achieve better monitoring, master the complexity of the threat intelligence feeds, and achieve timely remediation of security incidents. The field of ML can be decomposed into two basic subfields: construction and assessment . We mean by construction designing or inventing an appropriate algorithm that learns from the input data and achieves a good performance according to some optimality criterion. We mean by assessment attributing some performance measures to the constructed ML algorithm, along with their estimators, to objectively assess this algorithm. Construction and assessment of a ML algorithm require familiarity with different other fields: probability, statistics, matrix theory, optimization, algorithms, and programming, among others. To help practitioners, specially those of cyberphysical security, to understand the theoretical foundations of ML, before they delve into whole books, we compile the very basics of the first of these two subfields ( construction ) in this chapter. In addition to explaining the mathematical foundations of the field, we emphasize the intuitive explanation and concepts.","['Engineering', 'Cyber-physical systems, IoT', 'Data Engineering', 'Computational Intelligence', 'Big Data', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2188-9_4,en,Equilibrium-Optimized IMC-PD Double-Loop Control Strategy for Industrial Processes with Dead Time,OriginalPaper,This paper deals with the application of equilibrium optimizer (EO) in tuning the proportional-derivative (PD)-based internal model control (IMC) double-loop structure for integrating and unstable industrial processes involving time delays. Integrating and unstable processes with significant dead time encountered in chemical process industry present very challenging control requirements. The unity feedback PID controllers with conventional tuning methods are not effective enough to control the dynamics of such industrial processes. The proposed method involves a stabilizing PD controller in the inner loop which is based upon Routh-Hurwitz (R-H) stability criteria. The ranges of controller gain setting obtained from R-H criteria along with sensitivity considerations are utilized by the equilibrium optimizer algorithm to optimize the outer-loop IMC controller performance. The dynamic response of the proposed structure with EO is compared with that of other algorithms show the effectiveness of the proposed work.,"['Engineering', 'Industrial and Production Engineering', 'Mechatronics', 'Engineering Thermodynamics, Heat and Mass Transfer', 'Energy Storage', 'Materials Engineering']"
doi:10.1007/978-981-19-2016-5_4,en,Centralized Mathematical Optimization,OriginalPaper,"In the past two decades, we have witnessed technical breakthroughs in a wide variety of topics in wireless communications and networking where the key to successful breakthroughs is the use of optimization methods and theorems. Nowadays, optimization is widely reckoned as an indispensable tool.","['Engineering', 'Wireless and Mobile Communication', 'Cyber-physical systems, IoT', 'Professional Computing', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-3035-5_30,en,Comprehensive Survey on Fire Detection with Machine Learning and Deep Learning Models,OriginalPaper,"Fire is an unpredictable dangerous event to the environment and the public. It may cause human and non-human belongings very rigorously. In recent days, many unpredictable events in the world are identified and controlled by computer vision-based machine learning approaches. Among these events, this looks forward to predicting the fire event and saving the human and non-human valuable belonging. Fire detection is a challenging task for the researchers to predict the root cause and alert the nearby ones. In this article, many algorithms have been addressed for fire detection methods from the past two decades that how the computer vision techniques have been grown day by day to predict the fire even. Even though, a formal survey on recent trends to fill the gaps is identified with the last decades. Countless fire detection strategies are developed through machine learning, deep learning, computer vision, etc., with images, video, and sensors. This article discussed a detailed survey that how the fire detection process becomes popular in the research area in recent days. In addition, a proposed new model is to rectify the issues in existing approaches.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Statistics, general']"
doi:10.1007/978-981-19-6004-8_5,en,Analysis of Phishing Base Problems Using Random Forest Features Selection Techniques and Machine Learning Classifiers,OriginalPaper,"Since the Internet is anonymous and uncontrolled, it is more open to phishing attacks, which can trick users to view malicious content in exchange for their personal information. However, the number of victims to this digital attack is significantly increasing due to inadequate security mechanisms. This research study develops a cyberbullying detection system, which can produce features from Twitter text by incorporating a point-wise mutual information approach. Further, a supervised machine learning method is developed for detecting the cyberbullying scenarios. Moreover, the proposed study has employed the sentiment, lexicon, and embedding features along with the PMI-semantic orientation. To apply extracted features, the SVM, Naive Bayes, KNN, decision tree, and random forest algorithm were employed. Experiments employing the proposed framework in a multi-class and binary setting indicate considerable potential in terms of kappa values, increased accuracy, and computed f -values. These findings imply that the proposed framework is a suitable option for recognizing the cyberbullying behavior in online social networks. Finally, the proposed outcomes and baseline features are compared by using various machine learning algorithms. The tenfold cross-validation has generated a highest accuracy of about 90.36%, and all four experiments assessed random forest algorithm based on 80% of the training dataset. The test result has also computed higher accuracy on random forest algorithm based on 20% of the test dataset.","['Engineering', 'Computational Intelligence', 'Cognitive Psychology', 'Personality and Social Psychology', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-16072-1_16,en,"A New Approach for Optimal Selection of Features for Classification Based on Rough Sets, Evolution and Neural Networks",OriginalPaper,"In number recognition, one of the challenges is to deal with the high dimensionality of data that affects the performance of algorithms. On the other hand, pattern recognition allows establishing fundamental properties among sets of objects. In this context, Rough Set Theory applies the concept of super-reducts in order to find subsets of attributes that preserve the capability of the entire set to distinguish objects that belong to different classes. Nevertheless, finding these reducts for large data sets has exponential complexity due to the number of objects per class and attributes per object. This paper proposes a new approach for dealing with this complex problem in real data sets to obtain a close enough to a minimal discriminator. It takes advantage of the theoretical background of Rough Set Theory, especially considering those super-reducts of minimal length. In literature, there is an algorithm for finding these minimal length reducts. It performs well for a small sampling of objects per class of the entire data set. An evolutionary algorithm is performed to extend it over a huge data set, taking a subset of the entire list of super-reducts as the initial population. The proposed discriminator is evaluated and compared against state-of-the-art algorithms and data set declared performance for different models.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-3-031-15509-3_31,en,Using Fuzzy Cluster Analysis to Find Interesting Clusters,OriginalPaper,"Fuzzy clustering algorithms are not only popular within the field of fuzzy sets and systems, but are also often used in other areas. It is clear that membership degrees in fuzzy cluster analysis provide more information than crisp assignments of data objects to clusters. But fuzzy clustering has additional technical advantages compared to classical clustering approaches. Fuzzy clustering algorithms are less prone to converge to undesired results that correspond to local optima of the underlying objective function that is used for clustering. Furthermore, fuzzy clustering enables the definition of cluster validity measures that cannot be used in the context of crisp clustering. These purely technical advantages can be exploited to define fuzzy clustering algorithms that search for single clusters step-by-step. Finally, it is demonstrated how the approach of finding single clusters can be modified to estimate reference intervals or “normal ranges” in laboratory medicine.","['Engineering', 'Data Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-6004-8_32,en,Efficient Data Hiding Model by Using RDH Algorithm,OriginalPaper,"In day-to-day life, information plays a major role. The value of those information becomes higher. So, we need to protect the information from intruders who try to get the secret information. In protecting those information, data compression deals a lot. Compression techniques are of two types which includes lossy and lossless compression. Steganography is the process which is used to protect the information by encrypting the compressed image with secret data and then extract the secret data from the compressed image by decryption. This paper utilizes an reversible data hiding (RDH) algorithm to boost the efficiency of encryption and decryption of the cover image by implementing the steganographic technique. RDH helps to accomplish the reason for picture content security. The encrypted data has been embedded within the cover image using the least significant bit (LSB). The proposed model has been evaluated based on criteria like savings percentage (SP%), compression time (CT), compression ratio (CR), mean squared error (MSE), and peak signal-to-noise ratio (PSNR). In comparison to previous systems that use the RSA algorithm, this technique has improved performance and system methodology.","['Engineering', 'Computational Intelligence', 'Cognitive Psychology', 'Personality and Social Psychology', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-3391-2_36,en,Patent Recommendation Engine Using Graph Database,OriginalPaper,"Accurate analysis of patents is an essential tool for modern companies. The idea behind the patent recommendation engine is to build solutions that enhance the quality as well the quantity of extractable data from a patent and discover meaningful relations, helping companies by spending fewer resources in terms of time and manpower. The recommendation engine is a concept of having the patent data transferred into a graph database and executing queries to answer questions specific to certain business use cases such that the task is significantly easier, less resource-intensive, and less complex when compared to the same being performed by a conventional relational database. The engine concept accepts a single input and forming clusters from the single starting point based on chain queries. It can then run the required algorithms on the clusters formed to select the best-fit data. The recommendation engine uses Neo4j as the database. Neo4j is a NoSQL graph database that focuses more on the relationship between various data rather than the data itself. We extract the data from our existing databases and then ingest them into Neo4j. Cypher queries power the engine that answers very specific questions within very little time.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Statistics, general', 'Cyber-physical systems, IoT', 'Professional Computing', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-3951-8_47,en,PSO and GA-Based RA Schemes for 5G Networks for D2D Communication,OriginalPaper,"Device-to-device D2D communication is considered one of the most important technologies in 5G networks. Throughput of the network increases when using the D2D communication, and the increase is evident in the local communication, which is done through the resources of reused cellular phone users. The cellular user (CU) resource is reused by the device-to-device pair so that they create interference between them and thus result in a decline in throughput. So, in this paper, we proposed the PSO and GA based on a scheme to allocate resources for device-to-device connections in the fifth generation networks. In this scheme, initially and based on the algorithm PSO—which is based on the RA of the 5G network, we describe the numerical results which can be performed sufficient in the obtain of this system. As for the Genetic algorithm (GA), chromosomes are generated at the beginning, so that each chromosome contains a gene. In addition, for all chromosomes that are generated the function of their fitness is measured, and then the best chromosomes are selected according to their fitness values after that, we can applying crossover and mutation to two points of the crossover chromosomes. The base station, depending on the fitness value, allocates the resource block. We performed a performance analysis through MATLAB, which proved the correctness of our scheme.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2538-2_7,en,Green Energy Powered by Smart Grids: A Business Model for Long Term Sustainability,OriginalPaper,"In a small community, a microgrid is a generation source used for scaling down the centralized power system. It generates, distributes and controls the power in the community. It is flexible, reliable as well as can provide uninterrupted power for balancing the load demands of customers having changing power needs. The smart Microgrids connected with the utility grid support the electricity needs of the powering industries. They are very much dependent on modern, integrated, Information and Communication technologies (cloud, fog computing and IoT sensors, etc.). Though Cloud computing provides services at a low cost, the problems are response time, processing time and the management of resources. Fog computing develops as a complement to Cloud computing, providing services and addressing challenges such as latency, security and traffic. Owing to the increasing number of users to the fog servers the energy consumption increases. This paper proposes the VM allocation using the Jaya algorithm in the fog nodes to minimize the energy consumption.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory', 'Mobile and Network Security']"
doi:10.1007/978-3-031-16035-6_5,en,A New Approach for Selecting Features in Cancer Classification Using Grey Wolf Optimizer,OriginalPaper,"The need to detect cancer in early stages is essential for cancer treatment. One of the best ways to classify cancer is with feature (gene) selection to choose the genes that hold the most promise. This step contributes significantly to the classification performance of microarrays and solves the issue of high dimensionality in microarray data. This paper proposes two novel feature selection approaches, both based on the Grey Wolf Optimizer (GWO), to compare and determine the best classifier, whether k-nearest neighbors (KNN) or support vector machine (SVM), with a leave-one-out cross-validation (LOOCV) classifier to classify high dimensional cancer microarray data and solve the feature selection problem. The experiments were implemented on six public cancer microarray data sets to show the remarkable results of the proposed methods. In addition, we compared the proposed algorithms with other recently published algorithms to demonstrate the proposed algorithms’ effectiveness.","['Engineering', 'Computational Intelligence', 'Data Engineering']"
doi:10.1007/978-981-19-1142-2_51,en,Sentiment Analysis of Twitter Data Using Clustering and Classification,OriginalPaper,"Data mining helps in collecting and managing data besides performing analysis and prediction analysis. The process that is implemented to discover useful data patterns may have different names. Statisticians, database researchers, and professional organizations were among the first to use term data mining. The fundamental steps for sarcasm detection are dataset collection, feature extraction, and classification. This work puts forward a new model of sarcasm detection formed by fusing K-mean, PCA, and SVM classifiers together. With respect to common evaluation metrics like accuracy, precision, and recall, the architecture designed for this work is especially productive.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Mobile and Network Security', 'Artificial Intelligence']"
doi:10.1007/978-3-031-19958-5_99,en,Reinforcement Learning Based Graphical User Interface to Solve the Permutation Flow Shop Problem,OriginalPaper,"Scheduling problems are part of typical issues in production management such as manufacturing assembly lines, supply chains, and batch chemical processes. These combinatorial optimization problems are usually solved using operations research approaches. Despite their undoubted assets, the proposed solutions remain usually impractical for the end-user in a manufacturing context. In this context, this work investigates the Permutation Flow Shop Problem (PFSP) which consists in finding a set of jobs sequence on pre-set machines that minimizes all the jobs completion time, such as all jobs pass through all machines in the same order. For the PFSF, a graphic user interface is developed based on a Reinforcement Learning (RL) model. Numerical experimentation was conducted to find accurate parameters’ values combination using non-parametric statistical tests. This leads to very promising solutions visualized with user-friendly interfaces and interactive Gantt charts.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3015-7_32,en,Knowing Your Customers Using Customer Segmentation,OriginalPaper,"This paper presents a customer segmentation review study to know more about the customer, and every successful business starts with knowing its customers. Trying to understand the customers on all levels is essential for companies. The main objective in customer segmentation is to understand their straight requirements, and business is to transform themselves into a crucial business segment to satisfy all their needs. It is vital to retain present customers and attract new ones in this viable market; understanding the customer is very important from this perspective. Different organizations are using the customer segmentation method, analyzing the value of the customer and providing them with better service according to customer need. This review studies the customer segmentation models and the most popular model recency, frequency, and monetary (RFM) to segment customers according to business needs, and segmenting customers according to profitability and seniority defines the customer journey. Also, highlighted are the different types of customer segmentation, customer segmentation models, and customer segmentation applications, which provide great insight into customer segmentation.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Engineering', 'Data Mining and Knowledge Discovery', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-981-19-3035-5_36,en,Efficient Data Flow Graph Modeling Using Free Poisson Law for Fault-Tolerant Routing in Internet of Things,OriginalPaper,"Internet of Things (IoT) is based on characteristics of the Wireless Sensor Network (WSN) in which nodes are dispersed for segregating data for different applications. In IoT, the sensor nodes typically possess heterogeneous properties. Among, few nodes have higher energy and even data aggregation functionality. Generally, in WSNs, efficient cluster-based routing is employed for data transmission. When Cluster Head (CH) fails, data sensed by the sensor nodes cannot be transmitted by the faulty CH. Consequently, the gateway or sink cannot recognize the data in the IoT sufficiently. Hence, processing information in this field was severely affected. This research contribution focuses on paired fault-tolerant cluster routing of the disjoint routes in a data flow graph and introduces a new approach called Free Poisson Law for solving this problem. The proposed Efficient Data Flow Graph Modeling using Free Poisson Law (EDFGM-FPL) algorithm has the aim of reducing latency, energy consumption as well as end-to-end delay, dissipated energy, functional complexity thereby achieving improved packet delivery ratio, throughput, and fault detection rate.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Statistics, general']"
doi:10.1007/978-3-031-15191-0_38,en,Robust Method for Estimating the Fundamental Matrix by a Hybrid Optimization Algorithm,OriginalPaper,"In this paper, we present a new method for estimating the fundamental matrix by a hybrid algorithm that combines the Genetic Algorithm with Levenberg-Marquardt. Compared to classical optimization methods, the estimation of the fundamental matrix by this approach can avoid being trapped in a local minimum and converges quickly to an optimal solution without initial estimates of the elements of the fundamental matrix. Several experiments are implemented to demonstrate the validity and performance of the presented approach. The results show that the proposed technique is both accurate and robust compared to classical optimization methods.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Mobile and Network Security']"
doi:10.1007/978-1-0716-2756-3_16,en,Using “Galaxy-rCASC”: A Public Galaxy Instance for Single-Cell RNA-Seq Data Analysis,OriginalPaper,"rCASC is a modular workflow providing an integrated environment for single-cell RNA-seq (scRNA-Seq) data analysis exploiting Docker containers to achieve functional and computational reproducibility. It was initially developed as an R package usable also through a Java GUI. However, the Java frontend cannot be employed when running rCASC on a remote server, a typical setup due to the significant computational resources commonly needed to analyze scRNA-Seq data. To allow the use of rCASC through a graphical user interface on the client side and to harness the many advantages provided by the Galaxy Galaxy platform, we have made rCASC available as a Galaxy Galaxy set of tools, also providing a dedicated public instance of Galaxy Galaxy named “Galaxy-rCASC.” To integrate rCASC into Galaxy Galaxy , all its functions, originally implemented as a set of Docker Docker containers to maximize reproducibility Reproducibility , have been extensively reworked to become independent from the R package functions that launch them in the original implementation. Furthermore, suitable Galaxy Galaxy wrappers have been developed for most functions of rCASC. We provide a detailed reference document to the use of Galaxy-rCASC with insights and explanations on the platform functionalities, parameters, and output while guiding the reader through the typical rCASC analysis workflow of a scRNA-Seq dataset.","['Life Sciences', 'Cell Biology', 'Bioinformatics']"
doi:10.1007/978-981-19-2940-3_10,en,Real-Time Human–Machine Interaction Through Voice Augmentation Using Artificial Intelligence,OriginalPaper,"In real time, there is a huge demand to access dynamic, personalized, and adaptive information. Interacting through voice augmented systems yields efficient and faithful access to great deal of knowledge. And the obtained information becomes more meaningful and understandable because it is appropriately customized in the aspect of real-time physical, digital, and virtual interactions. The objective of this project is to display the interactions of voice augmentation functions to achieve human to machine interaction (HMI). The quality of the services can be improved with the help of artificial intelligence through deep learning models to illustrate the possibilities of its potential. There exist a good range of applications which include vending machines, billing counters, home assistant, etc. This work includes audio processing, artificial intelligence, text-to-speech conversion, speech to text, audio conversion, various machine learning algorithms and models, implementation using the Internet of things, and applications in various fields, to evaluate the model.","['Computer Science', 'Artificial Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing', 'Sociology, general', 'Computational Intelligence', 'Machine Learning']"
doi:10.1007/978-981-19-2188-9_107,en,Minimization of Trim Loss During Reel Cutting at Paper Mill by Using Different Optimization Algorithms,OriginalPaper,"Trim loss is one of the major issues in the paper industry and occurs during the cutting of master and stocked reels to fulfill the ordered demands of reels with smaller widths. The trims (paper waste) produced during this reel cutting need to be reprocessed and follow a heavy chemical process that causes a significant amount of effluent discharge to the water surface which is hazardous as per environmental concern. Hence, this work aims to reduce the trim loss problem by using the flexible width master reels and stocked over-product and usable leftover reels. The minimization is performed with a linear single objective optimization problem with consideration of different operational and technological constraints. Three different solution approaches named simplex method, particle swarm optimization, and genetic algorithm have been proposed to optimize this trim loss problem employed for solving a real-world industrial problem. Again, the obtained solutions are analyzed in contrast with some reported results to prove the validity of the model and check the efficiency of the algorithms. The optimized result produces minimization in trim production due to which a lesser reproduction required that depletes the chemical use and tends to economic saving and reduction in environmental pollution.","['Engineering', 'Industrial and Production Engineering', 'Mechatronics', 'Engineering Thermodynamics, Heat and Mass Transfer', 'Energy Storage', 'Materials Engineering']"
doi:10.1007/978-3-031-15226-9_32,en,On the Travelling Salesman Problem with Neighborhoods in a Polygonal World,OriginalPaper,"The Travelling Salesman Problem with Neighborhoods (TSPN), as an extension of the broadly studied Travelling Salesman Problem, has many practical applications in robotics. Although several approaches to the problem have been introduced, they assume an environment without obstacles. In this paper, we introduce a method for the TSPN with polygonal neighborhoods taking polygonal obstacles into account. The method splits the problem into two subproblems: the Generalized Travelling Salesman Problem and the Touring Polygons Problem, which are solved sequentially. While the mature metaheuristic called Generalize Large Neighborhoods Search is employed to solve the first subproblem, the second one is solved by modifying the rubber-band algorithm. The experimental results show that the proposed approach outperforms a state-of-the-art algorithm modified for the environment with obstacles by 10–20% in most cases.","['Engineering', 'Control, Robotics, Mechatronics', 'Robotics', 'Computational Intelligence']"
doi:10.1007/978-981-19-6004-8_55,en,Feature Extraction and Selection with Hyperparameter Optimization for Mitosis Detection in Breast Histopathology Images,OriginalPaper,"This paper attempted to detect mitotic nuclei by extracting different features from nuclei patches in the histopathology Images. We extracted features at multiple levels such as pixel, global, and local to find the best combination of features required for efficient mitosis analysis. We then passed an optimal subset of features to three different classifiers by applying the hyperparameter optimization technique. We observed the highest accuracy of 87.4 with a feature combination of the histogram of oriented gradients (HOG), oriented FAST and rotated BRIEF (ORB), center surround extremas (Censure), corner peaks, edge extract, and grayscale pixel value using tree-based pipeline optimization tool (TOPT) as the hyperparameter optimizer with support vector machine (SVM).","['Engineering', 'Computational Intelligence', 'Cognitive Psychology', 'Personality and Social Psychology', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-2225-1_56,en,Discovery of Periodic Rare Correlated Patterns from Static Database,OriginalPaper,"Finding the associations among the itemsets and discovering the unknown or unexpected behavior are the major tasks of rare pattern mining. The support measure has the main contribution during the discovery of low support patterns. As the association of low support patterns may generate a bundle of spurious patterns, other measures are used to find the correlation between the itemsets. A generalization of frequent pattern mining called periodic frequent pattern mining (PFPM) is emerged as a promising field, focusing on the occurrence behavior of frequent patterns. On the contrary, the shape of occurrence in the case of rare pattern mining is not much studied. In this paper, a single scan algorithm called $$ PRCPMiner$$ PRCPMiner is proposed to study the shape of occurrence of rare patterns. The proposed algorithm discovers periodic rare correlated patterns using different thresholds with respect to support, bond, and periodicity measures. The research shows the influence of these thresholds on the runtime performance for various datasets.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Statistics, general', 'Mobile and Network Security']"
doi:10.1007/978-3-031-07823-1_5,en,A Planar Convexity Theory-Based Approach for Connected k-Coverage,OriginalPaper,"This chapter focuses on the problem of connected k -coverage in randomly and densely deployed planar wireless sensor networks. Several applications require k - coverage , where each point in a planar field is covered by at least k sensors simultaneously. This concept of k -coverage helps increase data availability to ensure better data reliability.","['Engineering', 'Communications Engineering, Networks', 'Wireless and Mobile Communication', 'Computational Intelligence', 'Artificial Intelligence', 'Data Engineering', 'Computer Systems Organization and Communication Networks']"
doi:10.1007/978-3-031-16368-5_10,en,Comparative Analysis of Object Detection Methods in Computer Vision for Low-Performance Computers Towards Smart Lighting Systems,OriginalPaper,"Nowadays the object detection research based on machine learning techniques is focused on improving the accuracy and the detection speed of a given algorithm. However, most of such approaches assume substantial amount of computational resources available to the algorithm to make it fairly efficient. Therefore, a vast majority of them are hardly feasible on low-powered and less-capable embedded IoT devices, where the object detection tasks are equally common and usually even more challenging—considering a huge diversity in environmental conditions, camera positions and resolutions, outdoor illuminations and deployments in both urban and offline remote environments. This paper presents a comparative research of different machine-learning object detection approaches targeted specifically towards the low-performance embedded computers in a context of smart street lighting applications. The comparison includes real and synthetic datasets preprocessed for a given detection method, conducted on a Raspberry Pi SoC platform.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks']"
doi:10.1007/978-3-031-13150-9_3,en,Obstacle Finding and Path Planning of Unmanned Vehicle by Hybrid Techniques,OriginalPaper,"With the wide application of unmanned vehicles (UV) in a complex environment, the research on path optimization and obstacle detection system has gradually become an important research part in the field of unmanned vehicle (UV) systems. The basic concept of path planning methods has always been a basic and difficult problem, especially in complex environments, in the effect of the dynamic environment, the safety, smoothness, and real-time requirement. To perform the task in a different environment and follow the exact movement and find the accurate path as well as remove the minimum human hurdle. In this research paper to find the shortest path with the avoidance of human obstacles with optimization techniques with meta-heuristic algorithms such as A*, fuzzy logic, GA, etc. we compare A* and fuzzy logic algorithms with the terms of processing time and path length with obstacle detection for high traffic areas. This research paper was practically implemented by the MATLAB software to simulate UV traversing from starting to endpoints.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Management']"
doi:10.1007/978-981-19-6072-7_2,en,Intelligent Monitoring of Rail Transit System,OriginalPaper,"Rail transit needs intelligent communication and monitoring (or detection and control) to realize the safe and stable operation of trains. This is not only an important condition for the sustainable development of rail transit, but also a backbone technology to ensure the safety and real-time operation of rail transit system.","['Engineering', 'Automotive Engineering', 'Artificial Intelligence', 'Transportation Technology and Traffic Engineering']"
doi:10.1007/978-981-19-2821-5_20,en,Efficient Virtual Machine Migration Algorithms for Data Centers in Cloud Computing,OriginalPaper,"As the technology is growing at a rapid pace, there is an increased demand for various cloud resources and resultant of which is the establishment of large number of cloud data centers (CDCs). A single cloud data center consumes large amount of energy, and eventually, it will lead to the higher operational cost and emission of carbon. To reduce the consumption of energy with better utilization of resources, different virtual machine (VM) and its consolidated approaches have been considered for the dynamic utilization of resources. In this paper, proposed enhanced artificial bee colony (PEA) has been proposed for better migration and placement of various VMs and physical machine (PM) dynamically. There are two distinct phases in this algorithm. Firstly, selection for the location of PM with access delay to the location where it needs to be migrated and secondly, reduction in number of VM migrations. Further, proposed approaches are compared to in terms of SLA-V, energy consumption, number of hosts shutdown, and resource utilization. Results show the gradual reduction in SLA-V by 20 and 31%, number of migrations by 16 and 25% and increase the resource utilization by 8%. There is a better improvement of 13% in energy consumption has been observed in the proposed method compared to others.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-3-031-08246-7_17,en,Genetic Algorithm for the Optimization of the Unequal-Area Facility Layout Problem,OriginalPaper,"The facility layout problem is one of the most important and complex problems in operations management. When the area requirements of departments are different, the problem is known as the unequal-area facility layout problem (UAFLP) and consists of locating a given number of departments within a facility plan, to minimize the total material handling cost, which is the most addressed criteria for the facility layout problems. In this chapter, a genetic algorithm (GA) is presented for solving the UAFLP for the case of a sportswear company. The genetic algorithm uses a two-part chromosome and the flexible bay structure (FBS) to obtain feasible solution alternatives for the facility layout. A set of data instances and parameters are used to validate and tune the genetic algorithm, respectively. The GA is applied to a garment production company showing that the genetic algorithm generates feasible and efficient layout alternatives for the case study.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4182-5_33,en,Light Weight Approach for Agnostic Optimal Route Selection,OriginalPaper,"Transportation plays a vital role in people’s life. A country like India has a lot of diversity; different transport operators use their infrastructure and utilities to provide services. Urban transports are gaining more fame every day as most people use them; they offer good fare rates with reduced time than private transport. But the major problem comes when an individual wants to use it, but doesn’t know which route to take to reach the destination. As most of these operators do not have route optimization and route recommendation facility, giving a bad user travel experience. This paper aims to solve the routing problem in urban transport using a modified two-way Breadth-first search algorithm. It is a stable uninformed graph search algorithm and guarantees optimal solution; our solution solves the problem of routes and aims to reduce the response time to front-end applications when our algorithm is used. We presented a lightweight approach for route recommendations that individual transport operators can use their transportation network to overcome this. Dijkstra’s algorithm is traditionally used for shortest-path calculation that uses the concept of Breadth-first search that guarantees optimal solutions. BFS searches from source to destination, it is slow in graphs with a high branching factor. We introduce a parallel hybrid two-way BFS variant that simultaneously starts BFS from both ends, i.e., source and destination. This variant uses BFS top-down approach, and we add it to a bottom-up parallel pipeline, and as a result, we get a novel approach for route recommendation. We implemented this approach on the BEST Mumbai transportation dataset, analyzed the performance with the existing Dijkstra algorithm, and achieved improvements.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Computer Systems Organization and Communication Networks', 'Statistics, general']"
doi:10.1007/978-981-19-5845-8_41,en,Overview of Data Center Link Load Balancing Technology Based on SDN,OriginalPaper,"The emergence of Internet industries such as big data and cloud computing promotes the rapid development of data centers. The traditional traffic scheduling method is easy to cause load imbalance and link congestion. The concept of elephant and mice flow brings a new idea to the design of load balancing (LB) in data center. In this paper, load balancing technology in data center network link based on software defined network (SDN) technology is summarized. Firstly, this paper classifies the relevant methods of elephant flow detection in data center, and analyzes the advantages and disadvantages of each model. Then, it makes a comprehensive investigation on the rerouting methods of elephant flow and routing optimization strategies. Finally, the paper emphasizes the challenges and future research directions of link load balancing technology in SDN.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3998-3_4,en,Summary of Path Planning Approaches of Multiple UAVs,OriginalPaper,"At present, the multiple UAVs formation is more and more widely used in military and civil fields in modern complicated environment, and the path planning system will play a key role. Both the modeling and solving are important for the path planning problem. In this paper, the path planning approaches of multi-UAVs formation are summarized. Firstly, the development status of typical mission planning projects at home and abroad is introduced, and the development context of the system is combed. The mission planning is divided into task allocation and path planning. Then, the cooperative path planning approach of multi-UAVs formation is analyzed to explore the difficulties of cooperative path planning, and the characteristics of various approaches are summed up, such as the advantages and disadvantages. Finally, the path planning problems worthy of further research in the future are prospected. A comprehensive grasp of path planning will help us to engage in innovative research in related fields.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-981-19-2635-8_74,en,Comparison of Deterministic and Stochastic Global Optimization Methods for Real-Time Generation of Guidance Trajectories,OriginalPaper,"Guidance algorithms for the return flight of suborbital spaceplanes must generate a variety of guidance trajectories that satisfy terminal conditions even in unexpected abort operations. To tackle this issue, a trajectory optimization method that combines convex quadratic programming and a global derivative-free optimization technique in a nested structure has been recently studied by the authors. This hybrid method efficiently explores the three-dimensional Bezier trajectories and associated guidance commands that exactly fulfill the equality terminal conditions and command continuity. In this paper, Monte-Carlo simulations are performed to investigate the applicability of this guidance method to the realistic scenario of unpowered return flight. Six stochastic evolutionary algorithms, a Bayesian optimization method, and three deterministic search algorithms are implemented and tested as global optimizers. They are compared in terms of computational and implementational complexities, robustness, and diversity of solutions obtained. The results show that reliable and real-time trajectory generation is possible, when an optimizer and its settings are properly chosen. It also reveals that diverse trajectories between initial and terminal conditions are successfully generated.","['Engineering', 'Aerospace Technology and Astronautics', 'Engine Technology', 'Automotive Engineering', 'Mechanical Engineering']"
doi:10.1007/978-3-031-19958-5_9,en,Surrogate-assisted Genetic Algorithm for Multi-project Scheduling,OriginalPaper,"The resource constrained multi-project scheduling problem (RCMPSP) is a well-known NP-hard problem. In this study, a surrogate-assisted genetic algorithm (SaGA) is presented for solving the RCMPSP. A non-random initialization starts the SaGA with a certain diversity and quality. A forward-backward improvement (FBI) based local search is utilized to intensify high quality solutions. Surrogation in genetic algorithm (GA) estimates few individual’s fitness rather than determining the actual fitness value. It maintains population’s diversity while optimizing the solution of the GA in the meantime. The performance of the proposed SaGA is examined on standard 10 benchmark examples ranging from 2 to 5 projects in a multi-project set. The comparative computational results with the state-of-the-art algorithms show the effectiveness of the proposed SaGA to achieve a lower value of projects total makespan (TMS).","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3998-3_27,en,UAV Target Detection Algorithm Based on Improved YOLOv4,OriginalPaper,"In recent years, UAV (Unmanned Aerial Vehicle) has developed rapidly and has been widely used in various fields, which has also posed a great threat to the security of military bases, government departments and other sensitive areas. Considering the problem of low accuracy and insufficient datasets of current algorithm in the target detection of “low, and slow small” UAV, and in order to improve the real-time detection performance of “low, and slow small” UAV, this paper proposes an improvement strategy of anchor, and obtains the anchor size suitable for UAV dataset through K-means++  clustering algorithm, making the size of anchor more targeted. Meanwhile, the different loss functions and IoU related threshold parameters for research, analysis of different thresholds, and the influence of different loss functions for UAV detection precision, thus by selecting the best loss function and the threshold is set to YOLOv4 target detection algorithm is improved, further, enhancing the YOLOv4 for “low, and slow small” UAV detection accuracy.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-3-031-21203-1_24,en,An MCTS-Based Algorithm to Solve Sequential CFGs on Valuation Structures,OriginalPaper,"In recent work, a generalised form of characteristic function games has been introduced, where certain sequences of coalition structures (and not a single one) are considered as solutions. Such games have later been extended to allow valuation structures to be used to restrict the allowed solutions for each game in the sequence; the resulting game is called SEQVS . This paper introduces an algorithm to solve instances of SEQVS based on Monte Carlo Tree Search. We experimentally evaluate the algorithm by comparing its performance against a heuristic algorithm appearing in the literature. We show that in settings containing many constraints, our algorithm outperforms the existing heuristic approach.","['Computer Science', 'Artificial Intelligence']"
doi:10.1007/978-981-16-9523-0_72,en,Recognizing Energy Wasting Households Using Data Mining and Incorporating the Cybersecurity Concept,OriginalPaper,"In India, the government provides with subsidies to people on the basis of their electricity bills yet the energy consumption has seen no change. Customers take no effort in reducing the same. In our paper, we are trying to rank residential apartments based on their monthly electricity consumption rating. Firstly, we take in data for the monthly electricity consumption of 50 apartments. Thereby, we apply K-means clustering algorithm to divide those apartments into 5 categories (best, good, average, bad, and worst) on the basis of their electricity consumption. Finally, with the help of 6 different machine learning algorithms, namely logistic regression, decision tree, Gaussian Naive Bayes, K-nearest neighbor (KNN), support vector machine (SVM), random forest, we fit these models onto the data we collect from the residential apartments. This helps us classify any new residents into the above 5 categories. We split data into train and test data in the ratio 75:25. The accuracy of the classification model we get is in the range 80 to 100%. To secure the personal data of residents that we store we used AES encryption and decryption algorithm which is the best encryption algorithm till date.","['Engineering', 'Industrial and Production Engineering', 'Surfaces and Interfaces, Thin Films', 'Energy Systems']"
doi:10.1007/978-981-19-3571-8_62,en,A Text Classification Optimization Framework for Prodigious Datasets,OriginalPaper,"This paper introduces Tunicate Swarm Algorithm-based Hierarchical Attention Network (TSA-HAN). TSA-HAN is the combination of Tunicate Swarm Optimization Algorithm (TSA) that uses jet propulsion and Swarm Intelligence and Hierarchical Attention Network (HAN) which makes use of leveled document structure. The proposed optimized algorithm is used for text classification. The performance of TSA-HAN is evaluated based on five parameters, namely accuracy, TPR, TNR, precision, and FNR. For this, purpose self-created dataset named real-time dataset consisting of 5000 documents and popular datasets, i.e., Reuters datasets and 20-Newsgroup datasets, have been utilized and the potency of the said optimized algorithm has been further compared with an existing improved sine cosine algorithm (ISCA). The comparative analysis results show that TSA-HAN performs slightly better than ISCA.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-16072-1_19,en,Robust Control Design Solution for a Permanent Magnet Synchronous Generator of a Wind Turbine Model,OriginalPaper,"The paper addresses the development of a perturb and observe algorithm implemented for maximum power point tracking control of a permanent magnet synchronous generator. It is shown that this algorithm tracks the optimum operation point and provides fast response even in the presence of faults. The strategy implements the tracking algorithm by using real—time measurements, while providing maximum power to the grid without using online data training. The solution is simulated in the Matlab and Simulink to verify the effectiveness of the proposed approach when fault–free and faulty conditions are considered. The simulation results highlight efficient, intrinsic and passive fault tolerant performances of the algorithm for electric generators and converters with low inertia.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3148-2_36,en,Hybrid Gorilla Troops Optimizer-Based NMF Algorithm for Integrative Data Analysis,OriginalPaper,"Cancer subtype identification using integrative analysis of high-dimensional and heterogeneous multi-omics data has gained a lot of attention. Clustering analysis using data integration has become a desirable approach to obtain hidden substructure of the datasets reflecting the correlation between and within the data. In this paper, for integrative clustering of multi-omics data joint non-negative matrix factorization (jNMF) and sparse-jNMF has been adopted. The nature of NMF is iterative and is inherently non-convex, non-differentiable and multimodal, therefore, the initial point estimation of the NMF factor matrices to a great extent affects the quality of the solution. Metaheuristics optimized initialization of NMF is considered as a favorable choice. In this paper, high-dimensional GTO encoded structure (HD-GTO)-based initialization of jNMF and sparse-jNMF has been proposed. The experimental results are conducted on two multi-omics cancer datasets. It is observed that HD-GTO-guided initialization of sparse-jNMF shows improvement in accuracy and purity when compared with other state-of-the-art metaheuristics. Experimental results also confirm that HD-GTO sparse-jNMF produces 3.5% average improvement in accuracy and 4.1% average improvement in purity on two datasets when compared with jNMF.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory']"
doi:10.1007/978-3-031-16368-5_6,en,The Comprehencive Approach to Big Data Preprocessing,OriginalPaper,"Nowadays, Big Data research is making significant progress. The paper is devoted to optimizing the process of Big Data pre-processing. The existing shortcomings of input datasets that lead to a decrease in their quality in systems that Big Data processing have been identified. The main methods of pre-processing of data sets are considered. The ways to Big Data clearing are described using of which allows to correct distorted data. The existing approaches ways to designing the architecture of Big Data processing systems are analyzed and microservice architecture was used for their flexible processing. The possibilities of Big Data pre-processing have been expanded due to the improved method of data clearing based on the text data processing templates. The proposed advanced flexible complex of algorithms for Big Data pre-processing with a high level of fault tolerance allows increasing the accuracy of data further processing. Software realization (web-applications) of proposed algorithms complex for data cleansing methods with proposed improvements and microservice architecture was developed. The efficiency of the proposed architecture for the Big Data pre-processing system based on microservices is shown on practice.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-2016-5_6,en,Applications: Resource Allocation for Human-Centric 6G Cellular Network,OriginalPaper,"In this chapter, we first consider the scenario where the base stations in 6G cellular network are cooperative in Sect.  6.1 . There, the first case study comprises cooperation between base stations by Cooperative Multi-Point (CoMP) and the modern multiple access technique non-orthogonal multiple access (NOMA) for multi-operator downlink transmissions in Sect.  6.1.1 . The downlink channel model corresponds to Sect.  1.3 . Then, in Sect.  6.2 , we study scenarios and case studies in which the base stations in the 6G cellular network are not fully cooperating. In Sect.  6.2.1 , a multi-carrier multiple-antenna downlink transmission with NOMA and imperfect channel state information at the transmitter (CSIT) is considered. The broadcast channel model corresponds to Sect.  1.3 where imperfect CSIT is modelled by worst-case analysis. In Sect.  6.2.3 , we make a step back and consider the general slow-fading Gaussian interference channel (GIC) from Sect.  2.3.1 and review the utility maximization problems over general rate regions. Next, in Sect.  6.2.4 , the fast-fading GIC is studied and novel ergodic capacity region results are derived. Finally, in Sect.  6.2.5 , the focus lies on multi-user beamforming optimization algorithms for non-collaborative base stations in multi-cell downlink transmission.","['Engineering', 'Wireless and Mobile Communication', 'Cyber-physical systems, IoT', 'Professional Computing', 'Communications Engineering, Networks']"
doi:10.1007/978-3-031-19958-5_86,en,A Hybrid DC Algorithm for an Optimization Problem with Semi-continuous Variables and Cardinality Constraint,OriginalPaper,"A difference-of-convex (DC) program is an optimization problem with a convex feasible region whose objective is as a difference of convex functions. DC algorithm (DCA) is an efficient method able to find good-quality solutions to DC programs in a short amount of time. Optimization problems with semi-continuous variables and cardinality constraint have many applications in practice; however, their resolution is very challenging and time-consuming by available solvers. Motivated by different existing reformulations and approximations of the zero norm, this paper proposes four reformulations and approximations for the binary restriction to get four different DC models associated with the original model with semi-continuous variables and cardinality constraint. Then, it presents DCA-based heuristics to solve each DC program. The proposed heuristics are then integrated into a hybrid algorithm. Computational experiments over datasets of index-tracking problem compare the four DCA-based heuristics. Further, the performance of the proposed hybrid algorithm is evaluated in comparison with the relevant methods in the literature.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-17548-0_12,en,An Adaptive Self-detection and Self-classification Approach Using Matrix Eigenvector Trajectory,OriginalPaper,"Motivated by the rapid development of the next generation artificial intelligence, we propose a novel adaptive self-detection and self-classification algorithm using matrix eigenvector trajectory in the paper. This algorithm’s mathematical inferences are also described and proved theoretically. The proposed algorithm is used in a multi-class bearing faults classification problem to validate its effectiveness. Results show that in an online data processing scenario, it can automatically adapt to new data patterns so that self-detection and self-classification can be realized by monitoring the eigenvector evolution trajectory. By comparing with other machine learning algorithms, we have validated that the proposed algorithm does not require explicit training, its required data processing time dropped more than 78% and achieved the same classification accuracy on new testing data.","['Engineering', 'Data Engineering', 'Computational Intelligence']"
doi:10.1007/978-981-19-2600-6_38,en,Histogram Based Initial Centroids Selection for K-Means Clustering,OriginalPaper,"K-Means clustering algorithm is one of the most popular unsupervised clustering algorithms which can be used for segmentation to analyze the data. It is an algorithm based on centroids, where the distances are calculated to assign a point to a cluster. Each cluster is associated with a centroid. The selection of initial centroids and the number of clusters play a major role to decide the performance of the algorithm. In this context, many researchers worked on, but they may not reach a goal to cluster the images in minimum runtime. Existing histogram based initial centroid selection methods are used on grayscale images only. Two methods, i.e., Histogram based initial centroids selection and Equalized Histogram based initial centroids selection to cluster colour images have been proposed in this paper. The colour image has been divided into R, G, B, three channels and calculated histogram to select initial centroids for clustering algorithm. This method has been validated on three benchmark images and compared to the existing K-Means algorithm and K-Means++ algorithms. The proposed methods give an efficient result compared to the existing algorithms in terms of run time.","['Engineering', 'Data Engineering', 'Statistics, general', 'Machine Learning', 'Artificial Intelligence', 'Data Storage Representation', 'Data Structures and Information Theory']"
doi:10.1007/978-981-19-2538-2_17,en,Machine Learning and Sensor Roles for Improving Livestock Farming Using Big Data,OriginalPaper,"A multi-user peer-to-peer relay network with a multi-channel system was examined for relay beam design. MU-MIMO solves the challenge of limiting the maximum power consumption per relay while maintaining minimal SNR. It has the potential to change the way we think about animal agriculture. On a broader scale, As a result of this research, animal producers may produce more meat and other animal products by utilising sensor technology. Sensors, big data, AI, and ML are used to help animal farmers decrease production costs, improve efficiency, improve animal welfare, and produce more animals per hectare. It also discusses the limits of devices. Various uses of animal farming devices are examined in order to see whether they may assist farmers enhance animal health, boost profitability, and reduce their environmental effect. To increase animal husbandry efficiency, we employ the Decision Tree algorithms, Support Vector Machine (SVM) and k-means.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory', 'Mobile and Network Security']"
doi:10.1007/978-981-19-2225-1_18,en,A Novel Cuckoo Search Optimized RBF Trained ANN in a Nonlinear Channel Equalization,OriginalPaper,"In this article, a new approach to modeling a nonlinear channel is proposed. In these works, a new cuckoo search algorithm trained with radial basis function neural networks (RBFNN) is applied in the non linear channel for equalization. The efficiency of the proposed algorithm enhanced through the search process by the integration of discovery and exploitation. Therefore, instead of Levy mutated step size operator in CS, the Cauchy mutated operator is used to create the step size which will make a random number which is used to generate a new solution for the global search. The performance of the proposed equalizer can be evaluated by estimating MSE and BER by considering popular nonlinear channels and added with nonlinearities. The consequences of the simulation show the presentation of our projected equalizer better than existing neural networks-based equalizers available in the literature.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Statistics, general', 'Mobile and Network Security']"
doi:10.1007/978-981-19-4052-1_6,en,Startup Profit Predictor Using Machine Learning Techniques,OriginalPaper,"Startups focus on uplifting and transforming the old markets by bringing in new technologies that may possess the power to bring a revolution in the world. Hence, they find it very essential to keep their venture in a profitable position from beginning itself so that they can achieve their goals sustainably. Intelligent systems which use machine learning can process huge amount of statistical data and can be used to predict profits based on the startup’s various expenses and other parameters. This can help them in regulating their expenses and grow quickly. The predictor makes use of four parameters, i.e., spend on R&D, administration, marketing ( www.aitpoint.com , Last accessed 12 June 2021 [ 1 ]), and the location where the startup is based out of, and predicts an approximate value of the profit that it is most likely to make. On finding the perfect dataset, data preprocessing and data visualizations were done. The data was split for training and testing and the score of the model obtained on the test dataset was 0.9691. The startup profit predictor was successfully built using random forest regressor model and it can be used for making profit predictions with 96.91% accuracy.","['Engineering', 'Computational Intelligence', 'Information Storage and Retrieval', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Data Structures and Information Theory', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16072-1_55,en,MR-VDENCLUE: Varying Density Clustering Using MapReduce,OriginalPaper,"The volume of data generated, processed, and consumed in the digital world is exponentially increasing. The clustering of such a huge volume of data, known as big data, necessitates the development of highly scalable clustering methods. Density-based algorithms have attracted researchers’ interest because they help to better understand complex patterns in spatial datasets. As a result, they are capable of discovering clusters with varying shapes. However, most of the density-based algorithms are challenged by the discovery of clusters with varying density and the ability to cluster big datasets. The VDENCLUE algorithm was proposed to discover clusters with varying densities. However, VDENCLUE incurs high computation overhead, which is impractical for large datasets. In this paper, a parallel approximated variant of VDENCLUE is proposed, called MR-VDENCLUE. Besides discovering clusters with arbitrary shapes, MR-VDENCLUE can discover clusters with varying densities and scale up to handle big datasets.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-3-031-08815-5_9,en,Optimal Resource Allocation for Public Safety Device to Device Communication Using PSO,OriginalPaper,"The Device to Device (D2D) communication allows two different devices in close proximity to communicate directly among themselves without relaying through the base stations (eNodeB or eNB). The D2D communication offloads the traffic from eNB and thus, has many advantages, including higher throughput and less end-to-end delay. Though the PSC was basically invented for Public Safety Communication (PSC) and to help the first responders, its distinct advantages have attracted other commercial applications as well. The eNB treats all the D2D applications equally during resource allocation and does a uniform resource allocation where one application is engaged in commercial activities. At the same time, the other saves one’s life. Thus, in this work authors proposed a novel optimized resource allocation algorithm for D2D applications which prioritizes PSC over commercial applications. In order to achieve the objective, Particle Swarm Optimization (PSO) technique was employed in the proposed work. Furthermore, a new weighted average fitness function was designed for PSO to suit the requirements. The proposed algorithm was simulated in NS-3, and the results were taken for different iterations. It was observed that the PSO algorithm for the designed fitness function achieved the local and global optimum values in a considerable amount of time. It was apparent from the results that PSC D2D pairs produced convincing results when compared to D2D pairs with commercial applications.","['Engineering', 'Computational Intelligence', 'Transportation Technology and Traffic Engineering']"
doi:10.1007/978-3-031-16868-0_15,en,Deep Neural Architecture Pruning,OriginalPaper,"The majority of NAS algorithms are intended to identify the optimal CNN architectures for a specific task. CNNs utilized for image classification and recognition problems demand strong hardware, such as data centers as well as GPU workstations, for training and inference. As a consequence, many models are incompatible with consumer hardware like portable appliances and smartphones. Nowadays, if a developer wants to execute computer vision problems on these devices, they must have a constant internet connection, which may not always be available or dependable enough to perform such tasks effortlessly for users. As a result, it is extremely desired to develop algorithms and techniques that lower the complexity of computing in CNN models.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5574-7_1,en,Introduction,OriginalPaper,"As the most important fossil energies on earth, coal, oil and natural gas are difficult to regenerate. If they are used without any restraint, we will face the depletion of these energies in the near future. Besides, the combustion of fossil fuels will produce a large number of hazardous substances.","['Engineering', 'Control, Robotics, Mechatronics', 'Energy Systems', 'Computational Intelligence']"
doi:10.1007/978-981-19-3250-2_10,en,GPU-Friendly FRW Algorithms for Electrostatic Computation Problems,OriginalPaper,"With the advancement of fabrication technology, the electrostatic coupling has increasing impact on the performance of very large-scale integrated (VLSI) circuits and micro-electromechanical systems (MEMS). For the structures in VLSI circuits which are mostly rectilinear geometries, the floating random walk (FRW) method using cubic transition domains has been successfully applied to calculate the electric capacitances among interconnect wires. It is also applicable to the calculation of electric field intensity, which becomes important for nowadays nanometer-technology circuits. In this chapter, an efficient approach is presented to parallelize the FRW algorithm with the graphic processing units (GPUs). GPU-friendly algorithmic flow and data structure are designed to reduce the divergence among random walks and the time of accessing the device memory. The techniques accelerating the extraction of multi-dielectric structures and for extracting multiple nets concurrently are also discussed. Numerical results are presented with several simple structures and larger ones from real VLSI circuits or MEMS. The results validate the accuracy of the presented techniques and demonstrate several tens times speedup due to the GPU-based parallel computing.","['Engineering', 'Electronics and Microelectronics, Instrumentation', 'Engineering Mathematics']"
doi:10.1007/978-3-031-12409-9_7,en,Deep Learning,OriginalPaper,"The core of this book are deep learning methods and neural networks. This chapter considers deep feed-forward neural (FN) networks. We introduce the generic architecture of deep FN networks, and we discuss universality theorems of FN networks. We present network fitting, back-propagation, embedding layers for categorical variables and insurance-specific issues such as the balance property in network fitting, as well as network ensembling to reduce model uncertainty. This chapter is complemented by many examples on non-life insurance pricing, but also on mortality modeling, as well as tools that help to explain deep FN network regression results.","['Mathematics', 'Applications of Mathematics', 'Statistics for Business, Management, Economics, Finance, Insurance', 'Machine Learning', 'Data Structures and Information Theory', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2821-5_25,en,Optimizing Job Scheduling Problem Using Improved GA + CS Algorithm,OriginalPaper,"Soft computing-based several techniques had already been applied previously in various industrial applications. This paper tries to provide application of various algorithms on job scheduling problem. The expected future needs of industry are based on proper application of these algorithms. In single objective optimization, point is to discover a schedule that limits general culmination time known as makespan. The paper represents comparative study of algorithms shows calculation of reduced makespan. Modified computation allocates jobs precisely than GA. Thus after applying, it is found that performance of hybrid genetic-cuckoo search algorithm approach is effective in finding ideal solutions contrasted with that of different methodologies.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-3-031-15191-0_25,en,HDFS Improvement Using Shortest Path Algorithms,OriginalPaper,"In the previous version of the article “data processing on distributed systems: storage challenge” we presented a new approach for the storage, management and exploitation of distributed data in the form of small files, such as the case of message exchanges real-time localization in port activity. During this approach, we managed to optimize more than 30% of information management using the classic HADOOP/YARN/HDFS architecture [ 11 ]. Considering that in a HADOOP ecosystem with several data processing nodes, access to the right node, containing the desired data, in the optimal time presents a major challenge and very important research avenues for researchers and scientists [ 15 ]. In this paper, we will see together that the marriage between mathematical algorithms and computer magic can give us very encouraging and very important results. Indeed, one of the principle that manifests itself is the theory of graphs, especially the calculation of the shortest path to optimally reach the data on a few nodes in an architecture of a few hundred nodes or even thousands [ 16 ]. After several research and comparison, Dijkstra’s algorithm is the chosen algorithm for calculating the shortest path in a HADOOP/HDFS system.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Mobile and Network Security']"
doi:10.1007/978-3-031-13588-0_55,en,Automatic Lung Segmentation with Seed Generation and ROIFT Algorithm for the Creation of Anatomical Atlas,OriginalPaper,"This paper describes the development of an algorithm to automatically generate seeds for lung CT (Computed Tomography) segmentation. The segmentation algorithm used is ROIFT (Relaxed Oriented Image Foresting Transform), a seed-based method for segmenting 3D images. Internal and external seeds are required for ROIFT. The internal and external seeds are automatically generated using the 2D watershed segmentation algorithm. Segmented images are transformed into a polyhedral model using the marching cubes algorithm. The segmented lungs will be used to create an anatomical atlas of the thoracic region. In this initial phase, 100 DICOM images were segmented. The anatomical atlas will be used as a regularization to solve the electrical impedance tomography of the human chest. Future work considers the segmentation of the ribs, skin, airways, and heart.","['Engineering', 'Engineering Mathematics', 'Computational Intelligence']"
doi:10.1007/978-981-19-3998-3_53,en,Multi-agent Reinforcement Learning for a Special Formation Problem,OriginalPaper,"For a long time, the formation control problem has been one of the core problems in the field of multi-agent collaboration. It’s goal is to make multiple agents form a formation in the tasks and move to a designated target point. In this paper, the reinforcement learning method is used to deal with a special formation problem, and the mean field theory is applied to Multi-Agent Deep Deterministic Policy Gradient (MADDPG) algorithm to make it effective in large-scale multi-agent formation problems. The algorithm is compared with MADDPG and Deep Deterministic Policy Gradient (DDPG) algorithm. In the simulation experiment, a team of UAVs are initialized at random positions in the two-dimensional space. The goal is to make the UAVs form an equilateral triangle with the shortest total displacement. We model the formation problem. In our algorithm, a reward function is designed based on the goal of making equilateral triangle formation and requirement of the shortest total displacement; Moreover, we define the equilateral triangle criterion and use it to evaluate the formation effect of multi-agent reinforcement learning. The results show that, compared with DDPG and MADDPG algorithms, MADDPG algorithm using the mean field method has obvious advantages over MADDPG and DDPG in terms of convergence speed and success rate in the formation problem.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-3-031-16865-9_50,en,An Approach to Enhance Quality of Services Aware Resource Allocation in Cloud Computing,OriginalPaper,"A new technology called cloud computing has revolutionized the way services are delivered to businesses and consumers. As an online service, it offers a variety of options to registered users. Quality of service (QoS) requirements must be reached in order for the customer to be completely satisfied. As a result of its impact on other issues faced by cloud users and providers alike, QoS-aware resource allocation is the most essential issue in resource allocation. There is no effective solution that meets both the needs of the service provider and the consumer, yet it is still regarded a difficulty by many. This research aims to reduce the amount of time needed to assign cloud resources, improving overall performance. The social spider algorithm (SSA) is presented to map resources with the suitable job in order to fulfill the specified objectives and handle the complexity of the resource allocation issue. In order to simulate spider foraging behavior, SSA created an algorithm. It focuses on the spider, its prey, and the strength of its vibrations. This is how a victim gets out of the spider web: by attempting to release itself from the web, which creates vibrations in the web. At that point, every spider in that web was able to pick up on the vibration. The more fit the sufferer is, the greater the strength of the vibrations. Vibration intensity created on the web determines the victim’s potential. In the cloud, the job is the spider, and the resource is the prey. In terms of resource fitness, task fitness is seen as the ability to make effective use of available resources. Using DEV-C++ to construct the suggested technique, tests have shown that it saves execution time by up to 10% while simultaneously improving service quality. In terms of execution time, the SSA algorithm with first fit exceeds the SSA algorithm with best fit, while the best fit excels in terms of utilization. Furthermore, when the SSA algorithm is compared to the SSCWA method, the SSA algorithm performs better in terms of execution time, usage, and throughput. The SSA results in improved resource allocation, which results in higher QoS parameters and performance. Additional QoS considerations, such as resource dependability, are a conceivable possibility in the future. Additional research may be done to speed up the execution time even more.","['Engineering', 'Computational Intelligence', 'Data Engineering']"
doi:10.1007/978-3-031-14537-7_19,en,Optimisation of Robotic Disassembly Sequence Plans for Sustainability Using the Multi-objective Bees Algorithm,OriginalPaper,"In recent years, remanufacturing Remanufacturing has become critical for environmental protection and natural resource conservation. The purpose of the work reported in this chapter is to find the best plan for product disassembly Disassembly , the first step in the recovery of end-of-life products, balancing the three goals of sustainability Sustainability —economic, energy and environmental. The study proposes three strategies: reuse Reuse , remanufacturing Remanufacturing and recycling Recycling . The Multi-objective Multi-objective Bees Algorithm (MOBA), Non-dominated Non dominated Sorting Sorting Genetic Algorithm II (NSGA II) and Pareto Envelope-based Selection Algorithm II (PESA II) are used to create solutions for two case studies. In this work, MOBA outperforms other algorithms in finding Pareto optimal solutions for robotic disassembly Disassembly sequence planning in all cases.","['Engineering', 'Robotics and Automation', 'Artificial Intelligence', 'Industrial and Production Engineering', 'Professional Computing', 'Robotics', 'Machine Learning']"
doi:10.1007/978-981-19-7842-5_15,en,Practice System of Ant Colony Optimization Algorithm in Business Administration,OriginalPaper,"AS a result of routine business management in the practical application of such problems as low efficiency, the content is not fine, so if you want to optimize the effect of market regulation, improve business management efficiency, and ensure quality of market operation, need to be in the original content on the basis of reasonable use of information technology management idea, this is also discusses the main problems of the current market industry. Based on the application of particle swarm optimization (PSO), this paper integrates it with ant colony algorithm, and then uses the whole process of fine management mode to carry out visual and cyclic supervision and scheduling of the whole market inspection process. The results of this study can improve actual work efficiency, strengthen industrial and commercial scheduling management, and reduce the work pressure faced by industrial and commercial personnel. It is the work content of enterprise management that is more standardized.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-1-4842-8954-9_8,en,Classification Algorithm–Based Recommender Systems,OriginalPaper,A classification algorithm-based recommender system is also known as the buying propensity model . The goal here is to predict the propensity of customers to buy a product using historical behavior and purchases.,"['Computer Science', 'Machine Learning', 'Python', 'Artificial Intelligence']"
doi:10.1007/978-3-031-20029-8_18,en,Multi-Version Concurrency Control to Reduce the Electric Energy Consumption of Servers,OriginalPaper,"The MVCC (Multi-Version Concurrency Control) is so far proposed to increase the concurrency of multiple conflicting transactions and the scalability of a distributed system. However, the larger number of transactions are concurrently performed, the larger amount of electric energy is consumed by servers in a system. In our previous studies, the EEMVTO (Energy-Efficient Multi-Version Timestamp Ordering) algorithm is proposed to not only reduce the total electric energy consumption of servers but also increase the throughput of a system by not performing meaningless write methods on each object. In this paper, the IEEMVTO (Improved EEMVTO) algorithm is newly proposed to furthermore reduce the total electric energy consumption of servers by not performing meaningless read methods in addition to meaningless write methods. The evaluation results show the total electric energy consumption of servers can be more reduced in the IEEMVTO algorithm than the EEMVTO algorithm.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence']"
doi:10.1007/978-3-031-14537-7_16,en,Bees Traplining Metaphors for the Vehicle Routing Problem Using a Decomposition Approach,OriginalPaper,"In this study, the bees traplining Traplining metaphor was adopted for the Bees Algorithm Bees Algorithm, THE (BA) and the Combinatorial Bees Algorithm Bees Algorithm (BA C ) and applied to solve the vehicle routing problem Vehicle routing problem . The two-parameter Continuous and Combinatorial Bees Algorithms (BA 2 and BA C2 ), equipped with a traplining Traplining metaphor intensifier Intensifier , Bees Routing Optimiser Bees routing optimiser (BRO), were used to solve the capacitated vehicle routing problem Vehicle routing problem with a decomposition Decomposition approach. In the first phase of the proposed method, the two-parameter Bees Algorithm (BA 2 ) was employed to solve the capacitated facility location problem, resulting in clusters of customers that did not violate the vehicles’ capacity. Then, BA C2 combined with BRO Bees routing optimiser was used to produce the routing plan for each cluster. BA 2 and BA C2 implement the traplining Traplining foraging Foraging point technique of bees Bees , which integrates their exploratory and exploitative search mechanisms, to simplify parameter Parameters setting and use their threat avoidance tactics to intensify the solution. The results of comparisons with other BA versions indicate that the proposed algorithm improves the accuracy of the basic version by at least 4% while speeding it up fourfold.","['Engineering', 'Robotics and Automation', 'Artificial Intelligence', 'Industrial and Production Engineering', 'Professional Computing', 'Robotics', 'Machine Learning']"
doi:10.1007/978-981-19-1142-2_66,en,Overview of Security Approaches Using Metamorphic Cryptography,OriginalPaper,"Initially, researchers employed only one information security technique either cryptography or steganography to secure the communication. But later, researchers stress on the amalgamation of both cryptography and steganography, and this amalgamation is popularly known as metamorphic cryptography. Steganography can be classified on the basis of cover medium. This paper surveys the different metamorphic cryptography approaches which uses image as cover media for securing the data. This paper also covers general concepts of cryptography, steganography, classification of metamorphic cryptography, and evaluation parameters like PSNR, MSE.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Mobile and Network Security', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5615-7_6,en,Fast Path Planning for Fixed-Wing Unmanned Aerial Vehicle with Multiple Constraints,OriginalPaper,"Aiming at the problem of fixed-wing unmanned aerial vehicle (UAV) path planning, considering the actual flight conditions and flight performance of UAV, a multi-constraint UAV path planning model is constructed with the minimum flight range and correction times as the objective function. The improved A* algorithm is used to solve the problem: in order to adapt to the model, the objective function of the model is used as the evaluation function; in order to speed up the search efficiency, the branch and bound method is used for iterative search. The simulation results show that: the model can achieve bi-objective optimization, and it is reasonable. Compared with the traditional A* algorithm, the improved algorithm can better balance the optimization flight range and correction times, and save the algorithm planning time, and effectively complete the fast path planning of fixed-wing UAV with multiple constraints.","['Engineering', 'Transportation Technology and Traffic Engineering', 'Computational Intelligence', 'Automotive Engineering', 'Energy Policy, Economics and Management', 'Mechanical Engineering']"
doi:10.1007/978-981-19-0098-3_56,en,Detection of Faulty Steel Used in Construction Industry Using Machine Learning Algorithms,OriginalPaper,"The construction industry consumes nearly half of global steel production. Every year, nearly 3 billion tonnes of raw materials are utilized to manufacture steel products, mainly for building purposes alone. Detecting faulty steel plays a major role utilizing the quality of manufactured building products, which in turn lowers the maintenance cost. In recent days, advanced analytical tools and machine learning algorithms have gained more popularity in fault diagnosis in steel products. In this work, Naive Bayes, support vector machine, and bagging classifier are applied to detect faulty steel and perform performance evaluation in terms of precision, recall, and accuracy. Detection of fault type is used to accomplish some prevention measures with respect to occupational safety.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Statistics, general', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2821-5_56,en,Artificial Intelligence Techniques to Restrain Fake Information,OriginalPaper,"In the current world, there has been an upsurge in the use of social networking sites like Facebook, WhatsApp, Twitter, etc. These are considered suitable sites for the exchange of messages and sharing pictures and videos. Besides providing entertainment to the users, sometimes the information circulating on these platforms may be fake or misleading. In this chapter, we reviewed the literature on AI technologies that address the issue of fake news detection, the process of information flow, different data sets to detect fake news, and future perspectives to improve the credibility of information.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/11663_2022_18,en,"Advances of Semiconductor Gas Sensing Materials, Structures, and Algorithms for Breath Analysis",OriginalPaper,"This chapter discusses sensor-array-based devices for breath analysis highlighting electronic noses as a prominent example. The sections within the chapter examine material design advances to demonstrate progress in materials selection and innovative sensor structures. In sum, these advances have contributed to a significant increase in the surface ratio of sensors. This has led to a growth in the number of active sites available for sensors to detect particles within the surrounding environment. Besides, a discussion of parametric resonance and excitation applied to sensor-based breath analysis devices is presented as both a hardware and software improvement. Current sensors have the potential to become more relevant and reliable for clinical diagnosis by utilizing parametric resonance. An analysis of a review on the development of carbon nanomaterials concludes the chapter by discussing the current challenges relating to sensor array devices, machine learning algorithms, and the application of breath analysis as a whole. A further emphasis is placed on the fact that parametric resonance can serve as a smart algorithm to meet those challenges.","['Chemistry', 'Analytical Chemistry', 'Mass Spectrometry', 'Materials Science, general', 'Spectroscopy/Spectrometry', 'Medicinal Chemistry']"
doi:10.1007/978-981-19-2126-1_21,en,A Comprehensive Study on Automatic Emotion Detection System Using EEG Signals and Deep Learning Algorithms,OriginalPaper,"Emotion refers to a person’s current mental and cognitive condition. It demonstrates that it plays a dynamic function in communication, decision-making, and physical health. The development of a human emotion recognition system shifted the focus of research in a variety of fields, including cognitive science, computer science, psychology, neuroscience, and artificial intelligence. Emotion recognition is a subset of the brain–computer interface (BCI). Speech, facial expressions, and EEG data all can be used to determine emotions. EEG waves have shown to be an excellent choice for automatic emotion recognition because they cannot be faked like speech or facial expressions. The purpose of this work is to conduct a survey of emotion recognition using deep learning techniques. The benefits of employing deep learning algorithms in the extraction and categorization of EEG signals are investigated. This study could pave the way for more research into the usage of deep learning techniques to EEG-based emotion recognition systems.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Machine Learning', 'Big Data', 'Computer Systems Organization and Communication Networks']"
doi:10.1007/978-981-19-3571-8_1,en,Review of Different ML Techniques Used for Heart Disease Prediction,OriginalPaper,"Over the last few decades, heart disease has long been the major cause of death worldwide. As a result, anticipating cardiac disease in its early phase will be beneficial to people from all across the world, allowing them to take required treatment before it becomes serious. The primary goal of this paper is to present a comprehensive review of different predictive techniques like Fuzzy K Nearest Neighbors (KNN) classifier, Artificial Neural Network (ANN), Support Vector Machine (SVM), Logistic Regression (LR), KNN Classification, Naive Bayes, Random Forest (RF), Decision Tree (DT), Linear Regression, etc., on the basis of various metrics and tools used for evaluation of these methods as well as the dataset used for evaluation of these techniques is also described in this paper.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-3679-1_45,en,An Exploration of Machine Learning and Deep Learning Techniques for Offensive Text Detection in Social Media—A Systematic Review,OriginalPaper,"The increasing popularity of usage of social media platforms such as Facebook, Twitter, and What’s App has also given a potential to spread hatred or to cause harassment or inconvenience by using offensive and abusive texts on these platforms. It has been identified that offensive language is a significant problem for the safety of both social platforms and their users. The circulation of offensive or abusive language to the online community undermines its reputation, scares away users and also directly affects their mental growth. Offensive or abusive text just not only affects users but also affects stakeholders such as governments, autonomous organizations, and social media platforms. Every day such stakeholders have to spend long hours to remove such content manually from these platforms. So, there arises the need to detect offensive and abusive text in user’s posts, messages, comments, blogs, etc., automatically. To address this issue, detection of offensive/abusive text in user’s message, posts, comments, blogs, etc., has become a crucial task in recent times. There are various machine-learning and deep learning approaches existing in literature to identify such abusive texts. We have followed a systematic review process, in which we aim to explore the various machine learning or deep learning approaches adopted by various researchers to detect and the offensive/abusive speech in user’s textual posts, messages, comments, blogs, etc. This systematic review will help to strengthen the design and implementation of a new and efficient approach for automatic detection and removal of abusive or offensive text in user’s message or post. This deep exploration of the existing techniques will further have strong benefit to people, society, government, and social platforms in order to avoid spreading of hatefulness, harassment through social media.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5244-9_8,en,Application of Machine Learning in Climate Change for Transport Sector—Literature Review and Data Preparation,OriginalPaper,"In this chapter, an attempt has been made to review various works of literature from different perspectives, like how transport and climate change are interrelated. Various research works carried out in the transport sector with the help of machine learning and deep learning algorithms are reviewed. From the literature, it is observed that countries like the USA, the UK, Canada, and France are working at the forefront to solve the climate change problem caused by the transport sector. The popular machine learning algorithms used by the authors are k-nearest neighbor (KNN), decision tree, logistic regression, etc. Besides, with the advancement in technology, the application of deep learning techniques, natural language processing (NLP), artificial neural network (ANN), long short-term memory (LSTM), and many other algorithms are used to solve the problem of climate change to achieve the net-zero goal. In the later section of this chapter, a dataset has been identified for the identified problem statement. Finally, there is a discussion on the material and methods that are used for exploratory data analysis and building a model.","['Engineering', 'Computational Intelligence', 'Sustainable Development', 'Artificial Intelligence', 'Data Structures and Information Theory', 'Machine Learning']"
doi:10.1007/978-3-031-15191-0_5,en,A Novel Hybrid Classification Approach for Predict Performance Student in E-learning,OriginalPaper,"Predicting educators' learning outcomes at some stage in their educational career has gotten a considerable interest. It supplied essential facts that can aid and recommend universities in making rapid judgments and upgrades that will enhance the success of students. In the tournament of the COVID-19 epidemic, the boom of e has increased, enhancing the quantity of digital studying data. As a result, machine learning (ML)-based algorithms for predicting students’ performance in virtual classes have been developed. Our proposed prediction is a novel hybrid algorithm for predicting the achievements of freshmen in online courses. To enhance prediction results, hybrid gaining knowledge of mix many models. The Voting is a useful technique that is extremely fine when solely one model is present. The researchers concluded that our approach used to be the most successful accuracy performance of 99%.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Mobile and Network Security']"
doi:10.1007/978-981-19-6004-8_64,en,"A Comparative Study of SVM, CNN, and DCNN Algorithms for Emotion Recognition and Detection",OriginalPaper,"The practical implications of human facial emotion recognition (FER) have sparked interest in the research community. The primary focus in FER is to map diverse face emotions to their corresponding emotional states. The traditional FER is split into two sections: feature extraction and emotion recognition. The fast evolution in the field of Artificial Intelligence has given a significant and an amazing contribution to the world of technology. Since traditional algorithms is failed to satisfy human demands in real time. Machine learning and deep learning algorithms have had a lot of success in diverse applications including classification systems, recommendation systems, pattern recognition, and so on. Human emotion is very critical to determining a person's thoughts, behaviours, and feelings. Because, it is inherent feature extraction mechanism from images. FER makes effective use of deep neural networks, notably Convolutional Neural Networks (CNN). Multiple works just with a few layers to overcome FER concerns have been presented on CNN. Standard shallow CNNs with simple learning algorithms, on the other hand, have limited extraction of features capabilities when it concerns extricating emotion information from resolution high photos. Most present approaches have the problem of just considering frontal photos (i.e., ignoring side views for convenience), despite the fact that views from all angles are necessary for a realistic facial emotion recognition system. Deep learning can be used to build an emotion detection system, and various applications such as feedback analysis, face unlocking, and so on can be carried out with high accuracy. The goal of this research is to develop a Deep Convolutional Neural Network (DCNN) model that can distinguish between five different human face expressions.","['Engineering', 'Computational Intelligence', 'Cognitive Psychology', 'Personality and Social Psychology', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-1607-6_80,en,Determination of Antibiotic Resistance Level in Klebsiella using Machine Learning Models,OriginalPaper,"Antimicrobial drug resistance (AMR) in bacteria is a public health hazard and is growing alarmingly. There is a development of multidrug-resistant organisms due to the selective pressure exerted on organisms by drugs. Due to delay in antibiotic susceptibility testing results, artificial intelligence (AI) is employed to control the organism’s resistance against the last resort drugs and speeding up the AMR detection process. Therefore, machine learning (ML), a mathematical tool for AI, is used. For this study, 6 classification ML models were used to train and forecast the resistance of β-lactam drugs in Klebsiella pneumoniae and were carried out on orange tool. Out of the 6 ML classifier models, KNN and random forest outperformed the remaining 4 classifiers. The purpose of this research was to develop an AI-based model to classify strains based on specific features.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4017-0_1,en,Introduction to Machine Learning for Hardware Security,OriginalPaper,"Computing devices have become the basis of our modern lives, and hardware has long been considered as the backbone of trust for all computing systems. Various software attacks and defense mechanisms, mainly based on cryptographic measures, have been widely analyzed and applied in a variety of applications. In comparison to software security, hardware security as a topic is relatively new, and its importance has drastically increased in recent years due to the multiple attacks on hardware that were thought to be immune to attack. Hardware security is no different than any other field of security that focuses on launching attacks to steal assets and on strategies designed to protect them. In particular, the topic of hardware security is focused on situations where the assets are hardware components that contain secrets of electronic components, such as cryptographic keys and other sensitive information [ 1 ].","['Engineering', 'Circuits and Systems', 'Artificial Intelligence', 'Mathematics, general', 'Special Purpose and Application-Based Systems', 'Computer Science, general']"
doi:10.1007/978-3-031-20257-5_5,en,A Systematic Review on Student Failure Prediction,OriginalPaper,"Today, students tend to drop out of school more easily. It is necessary to find out what causes students to have such school failure in order to try to help them succeed in their school life. For this purpose, it is necessary to acquire data about students, and the area of Educational Data Mining (EDM) appears. EDM aims to develop methods for exploring data recovered from educational environments, thus allowing us to try to understand and predict student success [ 1 ]. Early prediction of school failure may be cornerstone on the effort of avoiding it. This paper presents a systematic review of school failure prediction systems in students up to high school. The goal is identify the main methods developed and tested, as well as the algorithms used in this task. For that intent, six papers were identified in the SCOPUS repository as relevant for include in the review.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16865-9_57,en,SQL Injection Detection Using Machine Learning with Different TF-IDF Feature Extraction Approaches,OriginalPaper,"The risk of attacks on web systems increased with the reliance of web systems in a wide range of businesses, and attackers invent new techniques to crack these systems. According to OWASP SQL injection stays one of the top 10 web applications security risks. This research use machine learning to detect SQL injection attacks, we used four machine learning models to detect SQL injection attacks. An insight into the data showing that data preparation and feature extraction have influenced the detection accuracy. The used training dataset is a combination of live requests extracted from user requests log file and a training dataset contains records of benign and malicious SQL queries. Then we compared the use of these models in term of detection quality and speed of training, results showed that Support Vector Model achieved highest detection accuracy with .997 accuracy followed by Extreme Gradient Boosting with .995 accuracy. In other hand Naïve Bayes using N-gram level feature extraction model was the fastest model it required 6 ms to train the classifier.","['Engineering', 'Computational Intelligence', 'Data Engineering']"
doi:10.1007/978-981-19-1610-6_30,en,Machine Learning Analysis in the Prediction of Diabetes Mellitus: A Systematic Review of the Literature,OriginalPaper,"In recent years, diabetes mellitus has increased its prevalence in the global landscape, and currently, due to COVID-19, people with diabetes mellitus are the most likely to develop a critical picture of this disease. In this study, we performed a systematic review of 55 researches focused on the prediction of diabetes mellitus and its different types, collected from databases such as IEEE Xplore, Scopus, ScienceDirect, IOPscience, EBSCOhost and Wiley. The results obtained show that one of the models based on support vector machine algorithms achieved 100% accuracy in disease prediction. The vast majority of the investigations used the Weka platform as a modeling tool, but it is worth noting that the best-performing models were developed in MATLAB (100%) and RStudio (99%).","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5331-6_6,en,Empirical Analysis of Crop Yield Prediction and Disease Detection Systems: A Statistical Perspective,OriginalPaper,"Crop-imagery is categorized into three different types, which are near-field images, satellite images and drone-based images. All these image types can be processed in order to determine crop growth, crop diseases and finally crop yield. Different algorithms have been proposed over the years which determine one or more of these parameters using a series of image segmentation, feature extraction, feature selection, classification and post-processing steps. Each of these steps requires a specialized set of algorithms to be employed in order to design an effective crop-image processing system. Due to the wide variety of algorithms present in the given field of work, selection of the most optimum algorithm set for a given application is often ambiguous. For instance, if an application is trying to process satellite imagery, then identification of best image-fusion methods for effective classification requires a lot of research, and thus increases delay for designing the system. In order to reduce this ambiguity, this paper reviews these algorithm sets which identify the best techniques in terms of statistical parameters for a given application. Accuracy and error rate have been compared between different algorithms in order to give a clear idea about the performance of these algorithms.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-13150-9_23,en,Development of a Chi-Square Approach for Classifying Ischemic Stroke Prediction,OriginalPaper,"Stroke is a subsequent cause of death in the world and a primary reason for infirmity, with a high rising in developing countries. Most strokes are caused by an ischemic stroke which is a result of arterial occlusion. In most cases, strokes are found in people aged 55 and above. They occur more often in men than women although women tend to fall, victim, when they are older, they are more likely to die from it. A doctor will usually use physical examination and family history to diagnose stroke. They could also get an idea of the location of the symptoms. The best way to determine the root cause is through a Magnetic Resonance Imaging (MRI) scan. However, Doctors are humans and can have eye defects which could cause misreading of the diagnosis. Emotions could also affect our judgment as we are all humans. Therefore, this paper proposes a Convolutional Neural Network (CNN) and Support Vector Machine (SVM) for stroke classification. Chi-square was used for feature selection to remove irrelevant features from the dataset. The dataset used is obtained from the Kaggle website, the dataset contains several risk factors with more than 500 instances. The risk factors contain features that can cause blockage or cut off of blood flow to the brain. An accuracy of 95.91%, a precision of 95.37%, and a sensitivity of 98.10% were attained. The study will help the physicians to accurately predict ischemic stroke with ease and faster than conventional methods. They will also give future directions for researchers to build and make improvements on the method to enhance prediction and diagnosis for strokes and other relevant diseases.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Management']"
doi:10.1007/978-981-19-2821-5_21,en,Lung Disease Detection Using Machine Learning Approach,OriginalPaper,"The objective of this work is to identify clinical factors that modulate the risk of progression to lung diseases such as asthma, chronic obstructive pulmonary disease (COPD), emphysema, lung cancer, bronchitis, and allergies among patients using data extracted with assistance from machine learning algorithms. In this work, we have gathered 250 instances along with 14 attributes. These information have been gathered from patients experiencing various lung illnesses alongside different indications. The lung illnesses trait contains two sorts of class which are ‘Positive’ and ‘Negative.’ ‘Positive’ implies that the individual has lung illness. The dataset has been trained using K-fold cross-validation technique. Four machine learning algorithms have been used for analysis which are logistic regression, random forest, KNN, and Bayesian networks.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-7369-7_3,en,Classification in Wineinformatics,OriginalPaper,"“ How does a wine achieve 90+ scores? ” is the main problem to be solved in this chapter. In order to answer the question, the problem of classification with a target label, different types of classification algorithms and evaluation methods are presented. Classification models are built on all three datasets to predict whether a wine may receive a score above 90 points.","['Computer Science', 'Data Structures and Information Theory', 'Artificial Intelligence', 'Machine Learning', 'Natural Language Processing (NLP)', 'Knowledge based Systems', 'Business Information Systems']"
doi:10.1007/978-981-19-4676-9_23,en,An Exploration of Machine Learning and Deep Learning-Based Diabetes Prediction Techniques,OriginalPaper,"Diabetes is now one of the world’s leading chronic diseases, affecting the middle-aged and elderly in most cases. This disease will gradually transform a person into death. There is an imbalance in blood glucose with the consequence of this disease that prompts the production of lower insulin. Medical science for the treatment of this disease is now advancing steadily. In addition to this, research focused on artificial intelligence (AI) is now advancing to define the stage of diabetes so that steps can be taken by everyone. A state-of-the-art analysis of various techniques for predicting diabetes is seen in this paper. For the last decade, several techniques based on machine learning (ML) and deep learning (DL) have been focusing on diabetes prediction. This research shows a summary of the published literature on the prediction of diabetes in the last six years. A recommendation system for observing the health of a patient through a web portal is proposed at the end of this article.","['Engineering', 'Computational Intelligence', 'Systems and Data Security', 'Artificial Intelligence', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-981-19-5224-1_27,en,Visualizing Commenters Opinions Through Topic Analysis,OriginalPaper,"With the rapid development in the computer science and technology domain, the eruption of available data is observed in this decade. Online platforms are becoming more and more capable day by day and therefore can capture thousands of customer reviews and comments on a single post. Dealing with this gigantic amount of high-dimensional text data leads to several problems for the post owner and data analysts. Furthermore, a significant percentage of this high-dimensional text data is not important and can be proficiently concentrated to lower dimensions by using several advanced dimensionality reduction methods. Topic modeling methods are used to summarize text data efficiently and are a good way of analyzing a huge amount of text data. In the recent years, many topic modeling approaches are introduced and are used to gain fruitful insights from the considered dataset. This paper aims to suggest the most effective known model by analytically comparing several existing topic models on the taken dataset. Also, some modifications to the existing algorithms are suggested to generate more understandable and accurate results.","['Engineering', 'Communications Engineering, Networks', 'Statistics, general', 'Cyber-physical systems, IoT', 'Sociology, general', 'Professional Computing']"
doi:10.1007/978-981-19-4676-9_57,en,A Systematic Review on Approaches to Detect Fake News,OriginalPaper,"The widespread use of social media and digital content, it is extremely important for people and society to be able to assess the trustworthy sources transmitting information through social media platforms. Fake news is not a new notion, but widespread and frequent circulation of fake news is an issue nowadays. Fake news might lead to annoyance, influencing and deceiving society or even nations. There are a number of ways of identifying fake news. By performing a systemic literary evaluation, we identify the major existing techniques to identify fake news and how such approaches may be implemented in various scenarios. A comprehensive description of factors that promote and circulate fake news, challenges to identify such sources, and techniques used to determine the fake news is prepared and discussed to minimize the impact of fake news.","['Engineering', 'Computational Intelligence', 'Systems and Data Security', 'Artificial Intelligence', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-3-031-20601-6_19,en,Pleural Effusion Detection Using Machine Learning and Deep Learning Based on Computer Vision,OriginalPaper,"Pleural effusion is one of the serious chest diseases that affect human life depending on the causes, such as malignant tumors, liver, kidney or chest failure, and the risks increase with the delay in diagnosis and treatment. In recent years, artificial intelligence (AI) has achieved a significant development in the medical field. As part of artificial intelligence, deep learning (DL), machine learning (ML), and computer vision (CV) have become very important in the diagnosis and treatment of diseases, as they help in terms of early and accurate diseases diagnosis and suggesting the best treatments. Furthermore, with the widespread use of medical images in diagnosing diseases, the need for computer vision, machine learning, and deep learning to analyze and understand those images, and to help clinicians make quick and accurate diagnoses has increased. In this paper, machine learning model i.e., artificial neural network (ANN), and deep learning models i.e., AlexNet, GoogleNet, SqueezeNet, and DarkNet19, are used to detect the presence or absence of pleural effusion in Chest X-ray14 dataset images. We have used 80% of the dataset for training the models, and the remaining 20% for testing.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16049-3_11,en,The Processes: From Masys (or MaSys) to Single Entities and to Unified Arrays,OriginalPaper,"In this chapter, the organizational evolution related to the system of processes from Masys to single entities and to unified arrays is presented and discussed. The main errors of the traditional value chain models and the first structural attempts in the subdivision of processes are presented and discussed. The management of the key criteria for the analysis and evaluation of the overall performance of an organization, the classification and evaluation of KPIs in a structure-based processive organization, the combinatorial Theory of Organisational Structural analysis on three levels: general (macrostructural) configuration, processive (intermediate) and microstructural and the analysis of a process based on a combinatory structure of masys are also developed and discussed as well as some theoretical considerations regarding masys classification and their integration with the organizational Quantum Pairs and the evaluating criteria for the levels of possession and application of the three categories of Quantum pairs in a generic masys structure including some fundamental variables regarding the definition of masys and the general structural theory of organizations. The critical aspects regarding the processes of an organization related to the digital transformation, to the integrability of the organizational processes, to the construct of arrays of processes and the field modelling criteria on how to obtain a unified field are also thoroughly designed and discussed as well as the transformations from the cylindrical to the pseudosphere configuration of an organization in relation to the integration of material and symbolic structures for the unification of all processes.","['Business and Management', 'Organization']"
doi:10.1007/978-3-031-11058-0_77,en,On the Problems of Algorithmization of Automated Decision Support,OriginalPaper,"One of the recognized approaches to improving management efficiency is the automation of this process, including through the use of decision support systems. The paper analyzes the existing approaches to the algorithmization of automated decision support, their shortcomings. It is concluded that the current situation, which is determined by the absence of standard algorithms for the decision support process, slows down the process of creating and introducing such systems into management practice. Based on the analysis of the state of the subject area, proposals have been synthesized for grouping all algorithms by type: for trivial situations and for situations requiring user intervention in the process of developing a set of alternatives. Based on the formalization of the representation of the decision support process, the concepts of “standard” and “extended” cycles are introduced, which provide support for decision making in trivial and nontrivial situations, respectively. At the same time, under the “standard” cycle, it is proposed to understand the search for an optimal solution under the conditions of a given objective function and constraints. An “extended” cycle is understood as a search for a non-trivial solution that cannot be obtained without modifying the objective function, removing or changing part of the constraints set before starting the search for a solution. The proposed algorithmic approach most fully corresponds to the modern understanding of an automated decision support system and, potentially, will speed up the process of introducing such systems into management practice.","['Engineering', 'Control and Systems Theory', 'Control, Robotics, Mechatronics', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-3590-9_15,en,Towards Design of a Novel Android Malware Detection Framework Using Hybrid Deep Learning Techniques,OriginalPaper,"Malware designers have switched their focus to the android platform as a result of the widespread use of android smartphones in our daily lives. There is  some exiting state-of-the-art techniques whose performance needs to be improved in malware detection for android based system. In this paper, we have proposed a novel android malware detection framework using hybrid deep learning techniques. In the proposed framework, at first pre-processing steps are employed to get optimized feature set. For the feature selection, this paper has used gain information and Pearson correlation coefficient techniques in which k-best features are selected using the gain information technique. Furthermore, the Pearson correlation technique is applied to remove the features which have similar coefficients and do not contribute much to overall results. For the detection of malware, optimized feature-based dataset is used for training of the proposed hybrid of bidirectional long short-term memory (BiLSTM) and merged sparse auto-encoder (MSAE) with softmax deep learning model. Performance analysis of the proposed malware detection framework is compared with three state-of-the-art techniques such as CNN-BiLSTM, CNN-LSTM and CNN-GRU in terms of accuracy, f 1-score, precision and recall. It is observed that the proposed framework performs better than the existing models.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security', 'Mobile and Network Security']"
doi:10.1007/978-981-19-5845-8_26,en,Image Classification Using Quantum Machine Learning,OriginalPaper,"When quantum algorithms are used in machine learning systems, it is referred to as “quantum machine learning.” An approach known as “quantum-enhanced machine learning” utilizes a quantum computer to evaluate classical data to boost machine learning. Data may be processed and stored more quickly and efficiently with the help of quantum machine learning. Using neural networks as analogies for physical systems is an important part of quantum machine learning. This paper summarizes the CIFAR-10 dataset. For the dataset, “five training batches and one testing batch” are used to divide the ten thousand photographs. One thousand images from each class are randomly selected for inclusion in the test batch. Even though each batch comprises all of the remaining photographs, some batches have a greater number of images from a particular category. It is estimated that each training batch contains around 5000 photographs. This section includes an evaluation of the classifier’s overall performance. Quantum neural networks describe “a parameterized quantum computational model best” implemented “on a quantum computer” (QNN). Third-party libraries such as PyTorch, Qiskit, and matplotlib are frequently loaded into the program. PyTorch is a popular option for GPU and CPU-based Deep Learning applications because it is built on Torch rather than merely Python. All of your quantum computing needs may be met by Qiskit, a Python library. Importing it will be necessary after the system is installed. Creating static, animated, and interactive graphics is easy with Matplotlib, a Python toolkit. To begin, we need to identify the quantum layers that will make up the circuit’s structure.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1142-2_19,en,Malicious Website Detection Based on URL Classification: A Comparative Analysis,OriginalPaper,"Phishing has been one of the most frequent cyber threats in the recent decade, prompting an increase in anti-phishing research and the development of numerous solutions for detecting and preventing phishing assaults. This paper identifies the system’s vulnerabilities and adversaries’ tactics to deceive Internet users into trusting the malicious email or website and providing sensitive information and credentials. For this study, the relevant URL features are retrieved from the collected dataset that includes phishing and legitimate URLs of websites. The correlation among different features is studied that can help users to identify fake web URLs by scanning phishing specific properties. This paper also analyzes the performance outcome of the machine learning, ensemble, and deep learning techniques on the collected dataset. Each model’s performance is compared and measured, and random forest and gradient boosting with XGBoost are found to be the best optimal model for phishing binary classification problem in terms of accuracy (97.3%).","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Mobile and Network Security', 'Artificial Intelligence']"
doi:10.1007/978-981-19-0105-8_54,en,Sentiment Analysis on COVID-19 News Videos Using Machine Learning Techniques,OriginalPaper,"Coronavirus disease (COVID-19) has affected all walks of human life most adversely, from entertainment to education. The whole world is confronting this deadly virus, and no country in this world remains untouched during this pandemic. From the early days of reporting this virus from many parts of the world, many news videos on the same got uploaded in various online platforms such as YouTube, Dailymotion, and Vimeo. Even though the content of many of those videos was unauthentic, people watched them and expressed their views and opinions as comments. Analysing these comments can unearth the patterns hidden in them to study people’s responses to videos on COVID-19. This paper proposes a sentiment analysis approach on people’s response towards such videos, using text mining and machine learning. This work implements different machine learning algorithms to classify people’s sentiments and also uses text mining principles for finding out several latent themes, from the comments collected from YouTube.","['Engineering', 'Communications Engineering, Networks', 'Artificial Intelligence', 'Computational Intelligence', 'Bioinformatics']"
doi:10.1007/978-3-031-18050-7_50,en,Control Tuning by Genetic Algorithm of a Low Scale Model Wind Turbine,OriginalPaper,"The continuous rise of wind energy makes it necessary to design controllers that make turbines more and more efficient. However, control designs are usually developed in simulation, which does not consider the many factors that affect control in a real turbine. An intermediate step, before testing them on turbines, is to check them on prototypes. In this paper, a first design of a laboratory scale model of a wind turbine (WT) is proposed, with the aim of testing different control algorithms. The model is built with commercial hardware and “ad hoc” circuits. Two control loops have been implemented; an external loop that commands the electric charge, and an internal loop that controls the pitch of the blades. The controllers have been tuned first experimentally, obtaining the best possible behavior by trial and error. Using genetic algorithms, the most optimal values for the controller are obtained, improving the response of the system. The operating and functional modes of a real WT have been also replicated on the model using a microcontroller programmed with the Arduino IDE input-output. Results obtained using optimized conventional controllers prove the correct performance of the prototype.","['Engineering', 'Computational Intelligence', 'Industrial and Production Engineering']"
doi:10.1007/978-981-19-5221-0_40,en,Diabetes Mellitus Disease Prediction Using Machine Learning Classifiers and Techniques Using the Concept of Data Augmentation and Sampling,OriginalPaper,"Diabetes Mellitus (DM) is emerging as a chronic disease that is predominant disease in many developing countries including India. The disease is caused when there is abnormality in the blood glucose due to inefficient production of insulin in the body. There is no specific cure for the disease as of today; however, medication is provided in order to control the effect of the disease in the body. The Diabetes disease prediction has been one of the major advancements in the medical field. Deep Learning and Machine Learning (ML) concepts play an important role in performing the prediction mechanism of diseases in today’s healthcare sector. Various ML Algorithms can be used for the process. Some of them include Support Vector Machine (SVM), XGBoost (XGB), K-Nearest Neighbour (KNN), Random Forest (RF), Light Gradient Boosting Machine (LGBM), Gradient Boosting (GB), etc. The dataset used in the paper is Pima Dataset taken from the UCI Repository. In addition to the normal approaches, Data Augmentation is done on the dataset to balance the inequality in the data and provides better accurate results. The results obtained show that the Algorithms GB, RF and LGBM provide the highest accuracy in comparison with the other algorithms.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Sociology, general', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-6068-0_31,en,Sentiment Analysis of Stress Among the Students Amidst the Covid Pandemic Using Global Tweets,OriginalPaper,"Covid-19 pandemic has affected the lives of people across the globe. People belonging to all the sectors of the society have faced a lot of challenges. Strict measures like lockdown and social distancing have been imposed several times by governments throughout the world. Universities had to incorporate the online method of teaching instead of the regular offline classes to implement social distancing. Online classes were beneficial to most of the students; at the same time, there were many difficulties faced by the students due to lack of facilities to attend classes online. Students faced a lot of challenges, and a sense of anxiety was prevalent during the uncertain times of the pandemic. This research article analyzes the stress among students considering the tweets across the globe related to students stress. The algorithms considered for classification of tweets as positive or negative are support vector machine (SVM), bidirectional encoder representation from transformers (BERT), and long short-term memory (LSTM). The accuracy of the abovementioned algorithms is compared.","['Computer Science', 'Artificial Intelligence', 'Computational Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-3571-8_28,en,Student’s Employability Concern for Colleges and Universities,OriginalPaper,"Educational data mining (EDM) is acquiring extensive favor in the education field due to its predictive potential. Mostly, the previous efforts in this area were only governed to predict the student’s performance based on academic results. These days, education has become aligned with employment and so along with academic grades, the skills of an individual equally contribute. Prediction of students’ accomplishments in the campus during placements at the beginning stages can give students an idea about the preparations they need to make to become market-ready. Also, for those students who have very poor performance, proactive or motivating actions can be taken at the college or university level to build their performance. The proposed model is a case study that can be executed in college for placement improvement keeping in mind the requirements of both the company as well as students opting for placements.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-3998-3_107,en,Exponentially Convergent Distributed Robust Nash Equilibrium Seeking Based on Continuous Disturbance Attenuation Functions,OriginalPaper,"This paper studies distributed Nash equilibrium seeking for games with second-order players affected by external disturbances. Three kinds of continuous functions, namely an approximated signum function, a saturation function and a power function, with time-varying and decaying parameters are employed to handle the disturbances. Compared with signum function based sliding mode algorithms, the proposed functions have the following advantages. First, they effectively eliminate the side effects caused by disturbances. Second, chattering phenomenon resulted from the standard signum function based sliding mode control is relaxed to some extent. Based on the above functions, distributed Nash equilibrium seeking strategies are constructed and analyzed by utilizing Lyapunov stability analysis. It is proven that the proposed methods are globally exponentially convergent. Finally, the effectiveness of the proposed algorithms is verified by integrating MATLAB and V-REP.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-981-19-4863-3_3,en,IPL Analysis and Match Prediction,OriginalPaper,"A comprehensive analysis of the complete IPL dataset and visualization of different highlights necessary for IPL assessment is performed. Many machine learning (classification) algorithms have been used to compare and predict the winner of the match. Every game has its own requirements; similarly, the T-20 game also has its own which were not satisfied by current models. By using Python, the intricacy of data analysis is reduced as it shows the analysis results using visual portrayals. The dataset is loaded, and pre-processing is done trailed by feature selection. Four machine learning (classification) algorithms such as decision tree, K-nearest neighbour, SVM, and random forest are applied, and the outcomes are compared. The best of the four classification techniques is then applied to anticipate the winner of the match and visualize the results as graphs.","['Engineering', 'Computational Intelligence', 'Engineering Design', 'Machine Learning', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-4676-9_36,en,Predictive Analytics of Logistic Income Classification Using Machine Learning,OriginalPaper,"Accurate income data is one of the hardest piece of data to obtain across the world. Subsidy Inc. company delivers subsidies to individuals based on their income. We wish to develop an income classifier system for individuals. The income prediction model is designed using logistic regression classifier. The logistic regression model is a machine learning classification approach for predicting the likelihood of a categorical dependent variable. In this work, we also made an experiment to compare machine learning algorithms logistic regression with K-nearest neighbor on a dataset with dimension 473,421 rows and with 15 different number of columns or attributes. This experiment results show that logistic regression classifier performs better with 90% accuracy where as KNN gives an accuracy of 87%.","['Engineering', 'Computational Intelligence', 'Systems and Data Security', 'Artificial Intelligence', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-981-19-6068-0_33,en,Data Analysis in Clinical Decision Making—Prediction of Heart Attack,OriginalPaper,"The changing lifestyle has impacted each and every organ of our body, especially the heart. The diseases related to the heart can bring your life to a halt. The increased cholesterol level in the body and chest pain can be an indicator of bad heart health. Heart attack is a major cause of casualty in today’s time. The unhealthy lifestyle along with the work culture which involves sitting on the desk for a long time has induced heart-related risk in human beings. The early prediction of heart diseases, the situation where a person may suffer from heart attack, can be helpful in saving lives. Modern technologies such as data analysis using data mining can help in early detection and diagnosis of heart-related diseases avoiding heart attacks. In this work, we propose a comparative feature selection followed by classification method to analyze heart attack dataset to predict whether that a person can suffer from heart attack or not. The “orange”—data mining tool has been used for this study. The machine learning models such as decision tree, support vector machine, and KNN have been used for analysis. The proposed method also determines the key features that are effective in predicting a patient with heart disease. The analysis of the result shows highest prediction accuracy: 85% support vector machine by considering top-ranked attributes including chest pain, thal rate, number of maximum heart rate achieved, and exercise-induced angina into consideration.","['Computer Science', 'Artificial Intelligence', 'Computational Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-2821-5_27,en,A Survey: Lightweight Cryptography Study for Healthcare Devices and Applications Within the Internet of Things,OriginalPaper,"The Internet of things (IoT) is growing more prevalent and popular in recent years as a result of interconnected entities that allow millions of gadgets to talk with one another. We can call IoT an evolution of the Internet, and it has gotten. In recent years, there has been a lot of interest from researchers. The IoT is significant because it allows many low-resource and restricted devices to communicate, calculate, and process many operations and make decisions in the communication network. With each technological improvement, the creation of intelligent systems with high communication and data collection capabilities becomes achievable, opening up new opportunities for a wide range of IoT applications, notably healthcare systems. On the other hand, everything is useful and is not without problems and challenges. There are several difficulties to deploying IoT in the real world, ranging from tiny sensors to servers, such as interoperability, portability, accessibility, privacy, and information security. In this article, we present a complete survey of IoT technologies, processes, statistics, and success stories applied to healthcare, with an emphasis on the security threats and needs of IoT cryptography, technology, and IoT device trends.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4863-3_22,en,Classification of High-Dimensionality Data Using Machine Learning Techniques,OriginalPaper,"In the digitization world, a large volume of information is being produced across a few areas such as medical services, creation, Web, and associations. Machine learning techniques are utilized to reveal designs among the train of this information for decision-making. Not all the features in the datasets produced are significant for preparing the machine learning (ML) algorithms. A few features may be not important and some probably won’t influence the result of the forecast. Disregarding or eliminating these immaterial or less significant features reduces the weight on ML algorithms. In this work, principal component analysis (PCA) is researched on different most popular ML algorithms, Naïve Bayes, support vector machine (SVM) classifier and KNN classifier, using freely accessible MINIST dataset. Experimentation results demonstrate that ML algorithms with PCA produce better outcomes when dimensionality of the datasets is high.","['Engineering', 'Computational Intelligence', 'Engineering Design', 'Machine Learning', 'Communications Engineering, Networks']"
doi:10.1007/978-3-031-20241-4_14,en,Converting Algorithms into Tangible Solutions,OriginalPaper,"Two main concerns drive the architectural practice: the design and the construction of buildings. This makes the creative practice highly dependent on construction viability, most design decisions having to consider, among others, the available materials and construction techniques and the associated manufacturing costs. Nevertheless, the desire to conceive complex geometries has always been present in architecture, often leading to innovative solutions and structures that go beyond what had been done to date. The emergence of computational design in the last decades has further accentuated this ambition by providing architects with unprecedented design freedom. The realization of such shapes, however, is not as easy as its 3D modeling due to limitations in the available manufacturing strategies. In this paper, we address this problem with Algorithm Design (AD), a design approach based on algorithms, presenting a design workflow that benefits from its (1) geometric freedom in developing facade design solutions and (2) expressiveness in converting and detailing the obtained solutions for manufacturing. We evaluate our proposal with an algorithmically developed prototype of a geometrically complex facade. The aim is to illustrate its potential in exploring design alternatives that consider multiple design criteria, while automatically detailing them for construction and producing the corresponding technical documentation. We also intend to demonstrate the importance of the proposal’s flexibility in considering different construction schemes that, in turn, result in different aesthetic outcomes and manufacturing needs.","['Engineering', 'Building Construction and Design', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence', 'Statistics, general']"
doi:10.1007/978-981-19-3788-0_27,en,Assessment of Aircraft Conditions in Flight,OriginalPaper,"When flight conditions become more difficult, the pilot needs to control a greater number of parameters than in normal modes. This results in higher workload on the pilot and an increase in the probability that some mistakes will be made when operating highly automated aircraft. The problem lies in the fact that in such situations, the pilot is to perform operations safely regarding the use of both the flight control system and the air traffic control system, even if the number of information signals exceeds that which can be processed by the pilot. The article presents the results of a study on the assessment of different methods by which the aircraft status can be determined and its control systems can be monitored. The study was conducted due to the need to meet stringent requirements in flight safety regarding pilots’ ability to serve as backups when flying highly automated aircraft. In order to do this, pilots need to develop an integral skill in processing static and dynamic information coming to them from various sources.","['Engineering', 'Aerospace Technology and Astronautics', 'Engine Technology', 'Engineering Thermodynamics, Heat and Mass Transfer']"
doi:10.1007/978-1-4842-8261-8_4,en,Identity Provisioning,OriginalPaper,"The first step in the life of an identity is its creation. If Descartes had lived in the time of Internet identity, he might have quipped, “Ego signati sursum, ergo sum” (I signed up, therefore I am). Provisioning is the act of establishing identities and accounts for your application. As defined in Chapter 2 , an identity includes at least one identifier and various additional user profile attributes. An online account is associated with an identity and can be used to access protected online resources. The objective of the provisioning phase is the creation or selection of a repository of user accounts and identity information that will be used in the authentication and authorization of users as they access protected resources. This chapter will describe options and considerations for provisioning.","['Computer Science', 'Security']"
doi:10.1007/978-3-031-18275-4_6,en,Findings,OriginalPaper,"This chapter describes the outcome of the empirical research. Therefore, the results are structured and grouped to give answers to the defined sub-questions. The guidance was that the interview participants are speaking about their AI product or service and not about a general AI perspective.","['Business and Management', 'IT in Business', 'Business Ethics', 'Engineering Ethics', 'Organization', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2538-2_1,en,A Novel Meta-Classifier Framework Approach for Land Use Land Cover Classification,OriginalPaper,"Land covers only 29% of the total earth’s surface, the remaining 71% is covered by ocean. 7.7 billion people live on this 29% of the earth's surface. Humans will be able to maintain a balance between human activities and the natural conditions of the earth through wise land use/land cover. Also, the earth’s development will be continual and sustainable. A machine learning model that allows humans to assort the land use/land cover will greatly assist humans in keeping track of changes in land use as a resource. This paper, present a new meta-classifier framework that incorporates state-of-the-art algorithms such as support vector machine (SVM), K-Nearest Neighbors (KNN), Tree, AdaBoost, Artificial Neural Network (NN), and Random Forest (RF) for land use land cover classification. This is the first meta-classifier approach for LULC that we are aware of. The algorithms in the first layer of the architecture are given a variety of multi-spectral and geographic satellite bands provided by Sentinel-2 satellite images. The proposed architectures organize satellite images into subcategories such as water bodies, forests, slums, parking lots, airports, and buildings. With a classification accuracy of 91.3%, our proposed framework outperformed modern algorithms (SVM, Tree, KNN, AdaBoost, RF and NN). Statistical measurements are used to examine accuracy further.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory', 'Mobile and Network Security']"
doi:10.1007/978-981-19-3951-8_57,en,Forecasting Election Result via Artificial Intelligence Approach: NLP and Machine Learning,OriginalPaper,"As election day approaches, politics, elections, and candidates are all topics that come up regularly in conversations. Citizens anticipate their favored candidate to be selected, and they try to predict how likely it is that their preferred candidate will be elected, as well as how likely it is that the other candidates will be elected. The goal of this article is to use NLP and machine learning algorithms to forecast the election outcome from Twitter data. For preprocessing, NLP technologies were used on the dataset. For a better result from machine learning models, punctuation and stop words were removed, lower casing, tokenization, stemming, and lemmatization were utilized. Then, using machine learning techniques such as LGBMClassifier, LogisticRegression, ExtraTreeClassifier, DecisionTreeClassifier, RandomForestClassifier, GaussianNB, and KNeighborsClassifier, each result was generated based on the input feature, which was tweet and user information, respectively. When the tweet was used as a variable, the total result was about 80% of the accuracy score, while the user information variable accounted for roughly 60% of the accuracy score. As a result of this finding, it is determined that the tweet column is a far more significant component than the user information one. Pre-trained models would be used for additional study, with the goal of getting a higher accuracy score and applying this outcome to the next Korean election.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-3-031-13314-5_7,en,Equity & Inclusion,OriginalPaper,"When beginning our research on equity, diversity, and inclusion under the umbrella of FemTech.dk research, we engaged with new literature, theory, and analytical approaches from research on equity and inclusion – research we did not know prior to FemTech.dk but which has been fundamental to our activities. In this chapter, we introduce the theoretical vocabulary we have learned as we entered this research space. Our purpose is to provide a short introduction to the most important concepts we found essential and relevant for our purpose of exploring diversity in computer science and to give readers a quick introduction to the most important concepts, which they then can use to initiate equity work in their institutions.","['Computer Science', 'The Computing Profession', 'Computers and Society', 'Gender Studies']"
doi:10.1007/978-3-031-12851-6_32,en,A Step Towards Quantifying the Uncertainty of the Soil Mechanical Response Through the Use of Genetic Algorithms,OriginalPaper,"This article proposes a methodology based on genetic algorithms to quantify the uncertainty of soil mechanical response through an optimization tool for the automatic parameter calibration of constitutive models. The optimization tool was developed in order to improve not only the efficiency of the parameter calibration process, but also to establish an objective framework for quantifying material uncertainty by even considering the natural variability resulting from laboratory investigations. This tool was validated for the Hypoplastic constitutive model using Karlsruhe fine sand and considering odeometer tests and triaxial tests under both drained and undrained conditions. The “best fitting” or global parameters are calibrated with the tool based on the aggregate of the experimental data and a methodology is proposed whereby an uncertainty based approach is utilised for the determination of parameter bounds. In addition, a range of different parameter “sets” or local parameters can be determined, where the model parameters are calibrated separately for each of the various ‘planes’ or loading paths of geotechnical interest, e.g. ε 1 -q. The potential of the tool is demonstrated by a comparison of finite-element simulations of a braced excavation using the Hypoplastic constitutive model, performed using the global and local calibrated parameter sets.","['Engineering', 'Geoengineering, Foundations, Hydraulics', 'Geotechnical Engineering & Applied Earth Sciences', 'Offshore Engineering']"
doi:10.1007/978-3-031-17254-0_3,en,Smart Factory Framework,OriginalPaper,"The Smart Factory Framework consists of a detailed representation and analysis of the 44 generic use cases. These use cases are relevant to a company's operational strategy. A detailed understanding of the use cases is critical for selection and prioritization. In this chapter, each use case is described and summarized in a standardized manner to provide information about the nature and application of each use case.","['Engineering', 'Engineering Economics, Organization, Logistics, Marketing', 'Management', 'Manufacturing, Machines, Tools, Processes', 'Robotics and Automation']"
doi:10.1007/978-3-031-06870-6_6,en,"Big Data, Analytics, Transparency and Quality of Experience",OriginalPaper,"We have previously discussed big data analytics as part of smart information systems, but we will revisit them in this chapter in tandem with the idea of transparency and how this affects the overall quality of experience of the users in smart information systems. Previously, we have looked at the data itself and the motivation for the use of synthetic data, whereas now we will approach the area of big data and big data analytics more holistically. In fact, when we say big data, we are referring to extremely large datasets that are quite challenging to work with with traditional database management tools. These have provided new opportunities but also new risks explored in this chapter, along with how this is experienced from the user perspective in terms of trust.","['Engineering', 'Communications Engineering, Networks', 'User Interfaces and Human Computer Interaction', 'Computer Applications']"
doi:10.1007/978-981-19-1412-6_58,en,State of the Art of Ensemble Learning Approach for Crop Prediction,OriginalPaper,"Agriculture has a captious part in maintaining a large population. It plays a decisive role to forward our country’s economic development. Crop cultivation has been the most prominent problem in recent days due to changes in weather patterns. This has a significant impact on crop productivity, either directly or indirectly. As a result, new technologies might be brought up for use in order to overcome this problem and uplift crop output. In this research proposal, we have explored IoT by choosing the smart farm and digital technology and explaining the management of heterogeneous data for agriculture. We proposed an IoT-HELE-based smart farming prediction and intelligent agriculture analytics model and a decision support system that effectively predicts crop production by utilizing cutting-edge machine learning and deep learning techniques. In this model, ensemble voting results in a more efficient, sustainable, and profitable agriculture enterprise. The multi-source dataset from the National Research Council (CNR), an ISTAT, and an IoT sensor will be analyzed. This work is presented through a new innovative idea after a rigorous literature review; presumably, it is valuable and increases the productivity of an agricultural firm.","['Engineering', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security']"
doi:10.1007/978-3-031-17746-0_27,en,Is Artificial Intelligence the Ideal Partner for Blockchain and Crypto Currencies?,OriginalPaper,"For several years everyone, companies and individuals have been more and more interested in new technologies concerning the blockchain, crypto currencies and also in the development of artificial intelligence. Blockchain is a technology that should transform our societies in depth, by providing a decentralized and ultra-secure system, and constitute the crypto currencies basis. Artificial intelligence is a new technology created to facilitate daily lives. But its application remains very technical and little known to the public. Both artificial intelligence and blockchain are technologies that are helping to change the world, but their applications are currently very technical and little known to the public. The present article tries to study the combination between blockchain technology and Artificial Intelligence and how this combination, can be so beneficial for the optimization of crypto-currency trading. The contribution of our work is to try to improve the notion of the use of these two new technologies, while trying to reveal the impact that can be generated on the financial, economic and social level. Our work will be organized as follows: In the first section we will define the blockchain concepts, and the artificial intelligence. In the second section, we will present the implication and effects between artificial intelligence and blockchain in the first place and in a second part, we will present the impact on cryptocurrencies. And finally we will present our conclusion. Certainly our work has limits, which can be surpassed by empirical work to affirm or not our basic hypothesis.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Business Information Systems']"
doi:10.1007/978-981-19-3998-3_48,en,Maximum-Relevance and Maximum-Complementarity Feature Selection with Random Forest,OriginalPaper,"In feature selection for high-dimensional data, in order to select the minimum number of features that can well explain the target, it requires finding the relevant features to the predictive target, as well as removing the redundant information by discovering the feature interactions. Existing approaches usually measure the feature interactions using relevance between features without considering their joint dependencies on the target. In this paper, we propose a new feature selection criterion, Maximum-Relevance and Maximum-Complementarity (MRMC). Besides the relevance with the target, MRMC takes into consideration the complementary information of a candidate feature to a selected feature or feature subset when predicting the target. We then present an efficient approach to calculate the information complementarity between features with random forests. Finally we implement MRMC Feature Selection using sequential forward search (SFS). Experimental results on 18 data sets show that SFS-MRMC achieved the best overall performances compared with other information-theoretical feature selection methods and RF-RFE.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-3-031-04435-9_19,en,A Study about Automated Optical Inspection: Inspection Algorithms Applied in Flexible Manufacturing Printed Circuit Board Cells Using the Mahalanobis Distance Method 1,OriginalPaper,"The main objective of this work is to investigate the behavior of an Automated Optical Inspection (AOI) robustness algorithm employed in a high-yield Printed Circuit Board (PCB) assembly Flexible Manufacturing Cell (FMC) utilizing neural networks and the machine learning concept with a focus on the comparison between different modeling options and techniques to predict and actuate the occurrence of failures in electronic components at the run-time assembling in a high-yield production line. A locally Flexible Manufacturing Cell (FMC) or Flexible Manufacturing System (FMS) is an artificial intelligence (AI) composite structure where sensors and actuators (small devices compared to the involved AOI FMC system) interact with the hosting media, creating PCBs gaps imaging as a coupled effect of AOI algorithms and Mean Time Between Failures (MTBF) in the FCM structure. This effect typically creates imaging gaps at lower frequencies than those that would be observed in the PCBs. An introduction about colored PCBs electronic components background modeling, Kernel methods, multi-model algorithms, Kalman filters, and Mixture of Gaussians (MoG) is given. The main technique used regarding electronic component failure calculus is the Mahalanobis Distance, which is initially applied using classical image subtraction equations and a classical Bandlets board model.","['Social Sciences', 'Science and Technology Studies']"
doi:10.1007/978-3-031-19958-5_54,en,Comparative Performance of Tree Based Machine Learning Classifiers in Product Backorder Prediction,OriginalPaper,"Early prediction of whether a product will go to backorder or not is necessary for optimal management of inventory that can reduce the losses in sales, establish a good relationship between the supplier and customer and maximize the revenues. In this study, we have investigated the performance and effectiveness of tree based machine learning algorithms to predict the backorder of a product. The research methodology consists of preprocessing of data, feature selection using statistical hypothesis test, imbalanced learning using the random undersampling method and performance evaluating and comparing of four tree based machine learning algorithms including decision tree, random forest, adaptive boosting and gradient boosting in terms of accuracy, precision, recall, f1-score, area under the receiver operating characteristic curve and area under the precision and recall curve. Three main findings of this study are (1) random forest model without feature selection and with random undersampling method achieved the highest performance in terms of all performance measure metrics, (2) feature selection cannot contribute to the performance enhancement of the tree based classifiers, and (3) random undersampling method significantly improves performance of tree based classifiers in product backorder prediction.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5221-0_63,en,Comparative Study of Recommendation Algorithms on Yelp Dataset,OriginalPaper,"In this work, we compare various recommendation algorithms on the Yelp dataset by exploiting multiple collaborative filtering algorithms. We use an innovative and novel method to represent the yelp dataset using a weighted bipartite graph in which the weight of the links contain a value which signifies the rating that the user has given to the business which is then used as a measure for recommendation. The nodes are represented by users and businesses. Later, we discuss different standard methods used for recommendation, we then attempt to experiment and do a comparative study on those algorithms with the Yelp dataset. The goal is to construct a customized recommender system which will exactly predict a user’s preference for a restaurant.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Sociology, general', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-07654-1_3,en,AI-Enabled Pregnancy Risk Monitoring and Prediction: A Review,OriginalPaper,"Accessibility to antenatal healthcare services remains a critical challenge in rural India. According to a recent survey, the mortality ratio of pregnant mothers is 113 for each 100,000 live births from 2016 to 2018 period. Proper follow-ups and patient-specific lifestyle changes are required to get rid of many complications in pregnancy. Due to the lack of qualified professionals, non-uniform accessibility of facilities, and affordability of expenses, the majority of people are not receiving proper medical care. AI-enabled remote monitoring systems improve patient-centred access to quality services and guidance for proactive self-management. In this chapter, we review various AI and machine learning techniques applied for remote pregnancy monitoring and risk prediction.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Computer Communication Networks', 'Computational Intelligence']"
doi:10.1007/978-3-031-19715-4_3,en,Most Common Oral Health Conditions,OriginalPaper,"This chapter explores in detail the most common Oral Health conditions and outlines the implementation of AI in detection and diagnosis parallely. After providing a clear insight on the prevalence of oral diseases, this chapter elaborates on the aetiology, classification, diagnosis and treatment aspects of conditions like dental caries, periodontal diseases, oral cancer, oral manifestation HIV infection, oro-dental trauma, NOMA, cleft lip & palate and oral manifestation of systemic diseases. This chapter concludes by laying out the global epidemiological overview of oral disease.","['Engineering', 'Biomedical Engineering and Bioengineering', 'Dentistry', 'Artificial Intelligence', 'Machine Learning']"
doi:10.1007/978-981-19-1142-2_33,en,Unravel the Outlier Detection for Indian Ayurvedic Plant Organ Image Dataset,OriginalPaper,"Image-based outlier detection has been a fundamental research problem for machine learning and computer vision researchers. This paper unravels the outlier detection process for the data preparation framework of the Indian Ayurvedic plant organ image dataset. While creating dataset the outlier images might get introduce due to human or device errors. Identification and rectification of such outlier images are crucial part for creating clean dataset. This paper evaluated and compared four well-known and state-of-the-art outlier detection algorithms, namely Isolation Forest, Local Outlier Factor, Histogram-Based Outlier Score, and One-Class Support Vector Machine for detecting the outliers from the dataset of Indian Ayurvedic plant organ images. For this experiment dataset containing 690 images of “ Centella asiatica ” was used and augmented to generate more image samples. In total, 21 morphological, geometric, color, and texture features have been extracted from each plant organ image. The experiment shows the isolation forest giving superior results with 91% accuracy, at the same time Histogram-Based Outlier Score proves to be the fastest in execution time.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Mobile and Network Security', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3148-2_72,en,Fake Video News Detection Using Deep Learning Algorithm,OriginalPaper,"Nowadays in the modern era, the Internet is one of the most ubiquitous so everyone is addicted to the various resources which are available on online mode. The resources such as news are available on various online platforms such as Facebook, Twitter, and WhatsApp. Due to social media platforms the rapid spread of the news in a very short time. The news which is spread over the various people cannot be recognized whether it is correct or fake news. So, this fake news can generate many consequences. Fake news is one of the major issues in the modern era and can influence decisions. As the result to overcome fake news, the various latest technologies that are machine learning algorithms can be applied to overcome this situation. In this paper, a novel framework is proposed that is mainly used on various natural language techniques is detect whether the news is fake or not. The various algorithms which are been used such as logistic regression (LR), random forest (RF), naïve Bayes classifier (NBC), web scrapping (WS), and deep neural network (DNN) algorithms were used to detect the fake news. A self-collected dataset was used in this work which consists of more than 200 news videos from various sources. Deep neural network has obtained 98% of accuracy which was the highest among all the models.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory']"
doi:10.1007/s00125-022-05744-z,en,"Automated insulin delivery: benefits, challenges, and recommendations. A Consensus Report of the Joint Diabetes Technology Working Group of the European Association for the Study of Diabetes and the American Diabetes Association","['ReviewPaper', 'CONSENSUS REPORT']","A technological solution for the management of diabetes in people who require intensive insulin therapy has been sought for decades. The last 10 years have seen substantial growth in devices that can be integrated into clinical care. Driven by the availability of reliable systems for continuous glucose monitoring, we have entered an era in which insulin delivery through insulin pumps can be modulated based on sensor glucose data. Over the past few years, regulatory approval of the first automated insulin delivery (AID) systems has been granted, and these systems have been adopted into clinical care. Additionally, a community of people living with type 1 diabetes has created its own systems using a do-it-yourself approach by using products commercialised for independent use. With several AID systems in development, some of which are anticipated to be granted regulatory approval in the near future, the joint Diabetes Technology Working Group of the European Association for the Study of Diabetes and the American Diabetes Association has created this consensus report. We provide a review of the current landscape of AID systems, with a particular focus on their safety. We conclude with a series of recommended targeted actions. This is the fourth in a series of reports issued by this working group. The working group was jointly commissioned by the executives of both organisations to write the first statement on insulin pumps, which was published in 2015. The original authoring group was comprised by three nominated members of the American Diabetes Association and three nominated members of the European Association for the Study of Diabetes. Additional authors have been added to the group to increase diversity and range of expertise. Each organisation has provided a similar internal review process for each manuscript prior to submission for editorial review by the two journals. Harmonisation of editorial and substantial modifications has occurred at both levels. The members of the group have selected the subject of each statement and submitted the selection to both organisations for confirmation.","['Medicine & Public Health', 'Internal Medicine', 'Metabolic Diseases', 'Human Physiology']"
doi:10.1007/978-981-19-7622-3_5,en,Vehicle Localization and Navigation,OriginalPaper,"The chapter describes the introduction of vehicle localization and navigation, related work done in-vehicle localization and navigation, and message passing in the Internet of things based on cloud vehicles. Furthermore, the chapter also covers vehicle navigation and localization, road detection and tracking in autonomous vehicles, and integrated Global Positioning System-enabled vehicles. This chapter also describes multiple sensors-based multiple object tracking, vehicle navigation and tracking on the Internet of things-based cloud vehicles, issues and challenges in-vehicle localization and navigation. Accurate and reliable location is significant for self-driving cars and other systems that help people drive: navigation and global place for intersection driving with a low-cost autonomous car with low-cost sensors in cities. To get a better idea of where the vehicle is, look at where it is about the lane and stop signs. First, the car learns where it is on the digital map and where the next lane and stop line are in the next intersection with the help of a Global Positioning System and odometer. A system that drives the car to its destination on its own, and researchers talked about it. Also, it does is use information from inertial sensors to make things move faster. A self-driving car can see where it is going by using radio detection and ranging, light detection and ranging, Global Positioning System, and computer vision, as well as other things. This system has a rotatable laser range finder that can see any obstacles.","['Engineering', 'Communications Engineering, Networks', 'Automotive Engineering', 'Transportation Technology and Traffic Engineering', 'Computer Applications']"
doi:10.1007/978-981-19-2635-8_51,en,A Novel UAV Path Planning Method Based on Layered PER-DDQN,OriginalPaper,"Path planning is a key technology for Unmanned Aerial Vehicles (UAVs) to complete the operational mission in a complex battlefield environment. A step-by-step path planning method based on the Layered Double Deep Q-Network with Prioritized Experience Replay (Layered PER-DDQN) is proposed in this paper. The novel method is constructed by combining the threat avoidance network and collision-free network based on the PER-DDQN framework. By analyzing the current environment of the UAV, the networks output threat avoidance action vector and obstacle avoidance action vector, and the method does a weighted summation of the action vectors according to the weight of the subproblems to obtain the final action. The simulation experiment verifies that the Layered PER-DDQN path planning method has better convergence and practicability than the Deep Q-Network and A* algorithm.","['Engineering', 'Aerospace Technology and Astronautics', 'Engine Technology', 'Automotive Engineering', 'Mechanical Engineering']"
doi:10.1007/978-981-19-4960-9_33,en,An Exploratory Study-Based Analysis on Loan Prediction,OriginalPaper,"A good amount of people seeking loans in India has enlarged to a greater extent and the reasons for it could be many. The Employees working in banking sectors are deprived of knowledge to judge or foresee whether a customer (good or poor) will be able to pay the debt of the loan at the stipulated interest rate. Throughout the financial system, banking institution offer a variety of services, but lines of credit remains their primary and the biggest source of income. As a consequence, banking businesses will prosper from the revenue produced on the mortgages they make. Lending, or whether consumers return the money or default on one’s loans, actually impact a banking institutions’ financial statement. The banking institutions non-performing investments will be diminished by estimating mortgage. Consequently, more exploration into this event happening is needed. Because detailed estimations are crucial and essential for sufficient service, various methodologies must be assessed and analyzed. Our study and work research seeks to provide a comprehensive review of lending estimation systems and structures that employ prediction methods and techniques flourished and developed after recent years. In this study and paper, researchers studied the learning techniques as well as the raw datasets utilized for training and test sets. The system model’s precision is also discussed. Our work also provides a quick overview of a few datasets that can be used to anticipate loan/mortgage analysis. Recent and future trends are also spotlighted.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Professional Computing']"
doi:10.1007/978-981-19-3951-8_13,en,Recommendation Model for Students Dropout at Ba Ria-Vung Tau College of Technology,OriginalPaper,"In recent years, the phenomenon of students’ dropout has become more and more common among first year students at Ba Ria-Vung Tau College of Technology. Therefore, in this paper, it is proposed to build a model to recommend the possibility of students’ dropout. All the student data, stored in the system from 2017 to 2018, is used as the model training dataset. The student dataset in the academic year 2018–2019 is used to test the performance of the proposed model. There are 4 models has been tested, including K-means, Decision Tree, Neural Network, and Support Vector Machine. In this paper, measuring metrics including accuracy, precision, recall, f1-score are used to evaluate the performance of these models. Experimental results show that the neural network model and the support vector machine model give the best results, with the same accuracy from 95 to 96%. However, the neural network model gives results with a higher f1-score, and has the similarity of precision and recall. Therefore, the neural network was chosen as the model to recommend possibility of students’ dropout at Ba Ria-Vung Tau College of Technology.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-3-031-21333-5_18,en,First Experiences in the Process of Developing a Low-Cost Machine Learning Prototype Model Using an Open Access Dataset of Chronic Kidney Diseases – A Case of Study,OriginalPaper,"Kidney disease is a global health problem, with an increasing number of new patients yearly; the same happens in Panama. The demand for dialysis, hemodialysis, and other costly treatments is also rising. In most cases, the problem is detected at an advanced stage; therefore, it is essential to create a model that could warn the medical doctor about the possibility of disease or see early signs of renal disease. This work presents the first experiences of analyzing, developing, and comparing three machine learning algorithm prototype models that could early alert the medical doctor of possible chronic kidney disease using an open-access dataset in the patient being the Naïve Bayes model the more accurate. Collecting a Panamanian chronic kidney disease dataset and training the models with national patient data is strongly suggested.","['Engineering', 'Data Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-19958-5_16,en,Fall Detection System Based on Pose Estimation in Videos,OriginalPaper,"Fall is a serious public health issue, especially for the elderly. There are many studies on fall detection, with the goal of ever-increasing the accuracy, flexibility, and feasibility of implementation in real life. In the last 5 years, the release of many highly-accurate, real-time, open-source pose estimation models offers a unique opportunity to develop effective and easy-to-deploy fall detection systems. In this study, we build two threshold-based fall detection algorithms respectively using the OpenPose and MoveNet pose estimation model. We evaluate the algorithms on two public datasets, namely UR Fall Detection and Charfi2012 dataset. The algorithm using OpenPose achieves an accuracy rate of 68.04% and the one using MoveNet 70.79%. We discuss the benefits of using pose estimation models in detecting falls, as well as the limitations of threshold-based algorithms, and suggest future research directions.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1844-5_41,en,Comparative Study of SVM and KNN Machine Learning Algorithm for Spectrum Sensing in Cognitive Radio,OriginalPaper,"The fast growth of wireless technology in today’s scenario has paved huge demand for licenced and unlicenced frequencies of the spectrum. Cognitive radio will be useful for this issue as it provides better spectrum utilisation. This paper deals with the study of machine learning algorithm for cognitive radio. Two supervised machine learning techniques namely SVM and KNN are chosen. The probability of detection is plotted using SVM and KNN algorithms with constant probability of false alarm. Comparison of the two machine learning methods is made based on performance with respect to false alarm rate, from which KNN algorithm gives better spectrum sensing than SVM. ROC curve is also plotted for inspecting the spectrum when secondary users are used.","['Engineering', 'Communications Engineering, Networks', 'Mobile and Network Security', 'Artificial Intelligence', 'Big Data']"
doi:10.1007/978-3-031-13150-9_6,en,Machine Learning for Recognition and Classification of Visual Art Architecture: A Survey,OriginalPaper,"Advancement in the field of computational algorithms diverted the focus of researchers to use these algorithms in the preservation of Visual Art Architecture. There are few research literature works available in this field, but these become the base for further future research work in the better advancements in the preservation of architecture. These few related works are listed in the paper. The paper focuses on the main outcomes of the available literature and findings for future possibilities in the field. The research works of these researchers were classified, described, analyzed, and compared in the different sections of the paper. The research was classified into three proposed classes based on similarities and dissimilarities among the research works, which are further classified into sub-class based on some special parameter. The comparison of these research works was done based on parameters proposed class, Algorithm used in the research, common evaluation matrix Classification Accuracy.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Management']"
doi:10.1007/978-981-19-2397-5_21,en,Scheduling of Cloud Computing Tasks via Intelligent Optimization Methods,OriginalPaper,"Distributed green cloud datacenters (DGCDs) are increasingly deployed around the world. DGCDs integrate many renewable sources to provide clean power and decrease their operating cost. They are spread over multiple locations, where renewable energy availability, bandwidth prices and grid electricity costs have high geographical diversity. This paper focuses on delay-bounded applications in DGCDs and performs cost and energy-effective scheduling of multiple heterogeneous applications subject to delay-bound constraints. The minimization problem of operational cost of DGCDs is formulated and successfully solved by using Firefly, bat, and simulated annealing-bat algorithms. Data-driven experiments are conducted to assess and compare their effectiveness to solve it. The Firefly algorithm is shown to well outperform its peers.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3590-9_20,en,Survey on Heart Disease Prediction Using Machine Learning Techniques,OriginalPaper,"In this decade, heart disease (HD) commonly referred as cardiovascular disease (CVD) becomes the major cause of mortality globally. It links a slew of risk factors for heart disease with an urgent need for precise, dependable, and practical methods for making an early diagnosis as well as managing the disease. In the healthcare industry, data mining is just a typical approach for analyzing large count of data. They use a variety of machine learning (ML) and data mining approaches to examine the large count of complicated medical data, assisting doctors in the prediction of HD. The goal of this survey is to conduct a review on 25 papers contributed toward HD prediction via ML models. Moreover, the review analyzed the diverse ML models used for prediction purpose. Further, it reviews and analyzes the features that are intake for predicting the disease. Subsequently, the comprehensive study in each contribution offers the performance attainments. Moreover, the analytical review in certain contributions reveals the highest performance attainments. In addition, the various tools used in the reviewed papers are also examined. At last, the survey expands with different research gaps and its issues which are helpful for the researchers to encourage enhanced future works on HD prediction via ML models.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security', 'Mobile and Network Security']"
doi:10.1007/978-3-031-11748-0_4,en,Cross-Silo Federated Neural Architecture Search for Heterogeneous and Cooperative Systems,OriginalPaper,"In many cooperative systems (i.e. autonomous vehicles, robotics, hospital networks), data are privately and heterogeneously distributed among devices with various computational constraints, and no party has a global view of data or device distribution. Federated Neural Architecture Search (FedNAS) was previously proposed to adapt Neural Architecture Search (NAS) into Federated Learning (FL) to provide both privacy and model performance to such uninspectable and heterogeneous systems. However, these approaches mostly apply to scenarios where parties share the same data attributes and comparable computation resources. In this chapter, we present Self-supervised Vertical Federated Neural Architecture Search (SS-VFNAS) for automating FL where participants have heterogeneous data and resource constraints, a common cross-silo scenario. SS-VFNAS not only simultaneously optimizes all parties’ model architecture and parameters for the best global performance under a vertical FL (VFL) framework using only a small set of aligned and labeled data, but also preserves each party’s local optimal model architecture under a self-supervised NAS framework. We demonstrate that SS-VFNAS is a promising framework of superior performance, communication efficiency and privacy, and is capable of generating high-performance and highly-transferable heterogeneous architectures with only limited overlapping samples, providing practical solutions for designing collaborative systems with both limited data and resource constraints.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Machine Learning']"
doi:10.1007/978-981-19-2126-1_17,en,Significance of Artificial Intelligence in COVID-19 Detection and Control,OriginalPaper,"Almost, every country on the globe has been infected by the COVID-19 pandemic disease. As of November 2021, there had been 259,095,804 COVID-19 cases reported worldwide, with 5,184,396 deaths as a result of the pandemic disease. Because the SARS-CoV-2 virus is highly infectious, healthcare systems are looking to advanced innovative technology such as data science, deep neural network (DNN), and Internet of Things (IoT) to combat the spread of COVID-19 pandemic disease. The purpose of this work is to identify, discuss, and highlight the significant applications of AI-based technology to combat the COVID-19 pandemic. The detailed study is done on the database records of Google Scholar, Research Gate, ACM, IEEE, Web of Science, CINAHL, Science Direct, and Scopus by using the keywords COVID-19, healthcare system, and AI. Based on this research, AI-enabled healthcare systems can help with identifying, tracking, and forecasting outbreaks, diagnosing, identifying non-compliant or infected individuals, and developing drugs and vaccines. This technology reduces healthcare workers workload while also being highly reliable and accurate. AI aids healthcare workers in recognizing symptoms and assisting in the rapid treatment of a COVID-19-infected patient. AI uses robotics and automation technique to combat COVID-19.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Machine Learning', 'Big Data', 'Computer Systems Organization and Communication Networks']"
doi:10.1007/978-981-19-3590-9_21,en,Machine Learning-Based Forecasting Technique for Crop Yield: A Study,OriginalPaper,"Agriculture plays an important role in the global economy and the survival of the species. Agriculture is an important part of the Indian economy, with agriculture providing a living for more than half of the Indian people. Crop yield forecasting is an important agricultural problem. Agricultural yield depends primarily on weather conditions (rainfall, temperature, etc.), pesticides. Machine learning algorithm and methods used for weather forecasting and crop yield prediction very frequently for the better results. Several research for agricultural development has been advocated, with the goal of developing an accurate and efficient model for predicting crop yields. This research investigates the various machine learning approaches used in agricultural yield estimation and gives a complete analysis based on the techniques’ accuracy.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security', 'Mobile and Network Security']"
doi:10.1007/978-3-031-07322-9_32,en,A New Unsupervised Learning Approach for CWRU Bearing State Distinction,OriginalPaper,"As one of the most relevant components in rotary machinery, ball bearings play an important role in diverse areas. To research bearing health state and remaining useful lifetime, several datasets have been developed. Among these datasets, Case Western Reserve University (CWRU) dataset is the most commonly used for bearing diagnosis. A large variety of approaches are applied on CWRU dataset and generating good even the tendency of perfect results. However, most of these approaches are based on supervised learning approaches and focus on classification of bearing faults. In this contribution, in difference to well-known existing approaches, an unsupervised approach combining autoencoder with k-mean is applied on the CWRU dataset. Firstly, the original data are segmented into proper parts. Segments in time domain are transformed to time-frequency domain by adjusting the window length and window function using Short-Time Fourier Transform (STFT), and an associated spectrogram is generated. Spectrogram features are extracted using autoencoder and clustered using K-mean. Various metrics are used to evaluate the performance of the proposed approach. All metrics values demonstrate that this approach could distinguish CWRU bearing from fault-free state to faulty state. As a new result, the requirement of related training datasets of the other approach is – for fault detection – no longer necessary in the future.","['Engineering', 'Building Repair and Maintenance', 'Cyber-physical systems, IoT', 'Industrial and Production Engineering']"
doi:10.1007/978-3-030-96276-0_1,en,Algorithmic-Generative Architecture,OriginalPaper,"The chapter briefly describes the meaning and evolution of the term “parametric” with the different meanings associated with the design process and the purely geometric-formal perspective. In Industrial Design, as in multi-scale architectural design, the explication of algorithmic thinking promotes research directions based on the centrality of the concept of code-procedure for building geometric-informative models. The representation of complex geometric shapes, through the visual programming of digital algorithms (generative, algorithmic and computational modelling), in addition to bringing about a methodological and applicative renewal, has made it possible to initiate trans-disciplinary investigations. The semantic and digital three-dimensional model simulates, collects and manages not only geometric data, but also structural, energy related and construction aspects of an artefact, putting them in relation with each other and thus improving the interaction and dialogue between the design figures involved in the process. Form-finding simulation and latest generation digital manufacturing techniques are described, preparatory to the study and design of bamboo structures, described in the following chapters. The chapter concludes by focusing the attention on some recent experiments of exhibition pavilions, temporary architectural structures that lend themselves well to possible applications of bamboo with new design and construction approaches.","['Engineering', 'Building Materials', 'Light Construction, Steel Construction, Timber Construction', 'Sustainable Development']"
doi:10.1007/978-981-19-4193-1_52,en,Scope of Machine Learning in Mobile Wireless Sensor Networks,OriginalPaper,"This work highlights the scope machine learning approaches in Mobile Wireless Sensor Networks. As Mobile Wireless Sensor Network faces numerous challenges in terms of energy conservation, data collection and aggregation, fault tolerance, QoS. Sink Mobility, etc. Machine learning is the branch of Artificial intelligence used to analyse data for making predictions, so as to get the optimized results. Here, work shows how the machine learning approaches can be used in sensor networks to improve network performance by extending lifetime, data collection and aggregation, handling mobility of sink node, QOS, fault tolerance, etc.","['Engineering', 'Computational Intelligence', 'Information Storage and Retrieval', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Data Structures and Information Theory', 'Artificial Intelligence']"
doi:10.1007/978-1-0716-2780-8_19,en,"Differential Expression, Functional and Machine Learning Analysis of High-Throughput –Omics Data Using Open-Source Tools",OriginalPaper,"Today, –omics analyses, including the systematic cataloging of messenger RNA and microRNA sequences or DNA methylation patterns in a cell population, organ or tissue sample, allow for an unbiased, comprehensive genome-level analysis of complex diseases, offering a large advantage over earlier “candidate” gene or pathway analyses. A primary goal in the analysis of these high-throughput assays is the detection of those features among several thousand that differ between different groups of samples. In the context of oral biology, our group has successfully utilized –omics technology to identify key molecules and pathways in different diagnostic entities of periodontal disease. A major issue when inferring biological information from high-throughput –omics studies is the fact that the sheer volume of high-dimensional data generated by contemporary technology is not appropriately analyzed using common statistical methods employed in the biomedical sciences. Furthermore, machine learning Machine learning methods facilitate the detection of additional patterns, beyond the mere identification of lists of features that differ between groups. Herein, we outline a robust and well-accepted bioinformatics Bioinformatics workflow for the initial analysis of –omics data using open-source tools. We outline a differential expression analysis Differential expression analyses pipeline that can be used for data from both arrays and sequencing Sequencing experiments, and offers the possibility to account for random or fixed effects. Furthermore, we present an overview of the possibilities for a functional analysis of the obtained data including subsequent machine learning Machine learning approaches in form of (i) supervised classification algorithms in class validation and (ii) unsupervised clustering in class discovery.","['Medicine & Public Health', 'Anatomy', 'Biomedicine, general']"
doi:10.1007/978-981-19-2840-6_24,en,Krishi Mitra: Crop and Fertilizer Recommendations System Using Machine Learning Algorithm,OriginalPaper,"Farming is a livelihood for many people in India, especially in rural parts. Many people in this field are unaware of technological innovations and keep using old farming techniques and the same cropping pattern. But in today's highly technological world, we can use various technologies to help them to select an appropriate crop according to soil condition, good fertilization for farms etc. We can use the data such as the amount of Nitrogen, Phosphorus, Potassium, rainfall and other environmental parameters to select the most suitable crops. In this paper we are training a machine learning algorithm to predict the crop, also we suggest fertilizers based on N, P, K and crop values. The model trained using various machine learning algorithms. Then we chose a model trained by random forest because of its high accuracy. Lastly, integrated the model with a website using Flask API.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-5292-0_21,en,Machine Learning-Based Algorithms for Prediction of Chronic Kidney Disease: A Review,OriginalPaper,"Nowadays, machine learning plays a significant role in healthcare system, medical information, and identification. This technique also uses understanding of several significant medical issues, such as diabetes projection, heart observation, and coronavirus identification. Machine learning is one of those tools that is commonly used in many fields because different datasets do not require different algorithms. Machine Learning is a subset of artificial intelligence. Machine learning can be a superior option for reaching high performance in predicting CKD and useful for other diseases, as this technique uses selected features and their different types of data forms under different conditions to predict CKD. Here, in this study, comprehensive survey of ten studies is presented where different machine learning models are compared for their efficiency and accuracy. The main aim of this study is to observe and analyze various machine learning models used, also to explore the datasets used, pre-processing techniques used, feature selection techniques used and to compare these models to find out which model provide us the best results. The study can help in smooth implementation of the work in the future which can be further to get the best possible result. In this study, machine learning can be a solution to this problem as it performs best in detection and evaluation using an algorithm. During this study, it was found that the filter feature selection methods used with correct threshold value which is suitable for dataset, it provides best accuracy over other feature selection method and also, any model dataset acquired before training needs to be pre-processed. The main goal of existing papers is to investigate, design and develop machine learning depend prediction model for CKD and to design a model to analyze and represent the knowledge of the field.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-3-031-21203-1_5,en,On Normative Reinforcement Learning via Safe Reinforcement Learning,OriginalPaper,"Reinforcement learning (RL) has proven a successful technique for teaching autonomous agents goal-directed behaviour. As RL agents further integrate with our society, they must learn to comply with ethical, social, or legal norms. Defeasible deontic logics are natural formal frameworks to specify and reason about such norms in a transparent way. However, their effective and efficient integration in RL agents remains an open problem. On the other hand, linear temporal logic (LTL) has been successfully employed to synthesize RL policies satisfying, e.g., safety requirements. In this paper, we investigate the extent to which the established machinery for safe reinforcement learning can be leveraged for directing normative behaviour for RL agents. We analyze some of the difficulties that arise from attempting to represent norms with LTL, provide an algorithm for synthesizing LTL specifications from certain normative systems, and analyze its power and limits with a case study.","['Computer Science', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5221-0_15,en,An Insight of Anomaly Detection Using Machine Learning Algorithm in Healthcare Digitalization,OriginalPaper,"Anomaly detection algorithms can be used to discover anomalous behaviour and outliers in a dataset, perhaps revealing new information regarding the development of a disease. While there has been a lot of research comparing anomaly detection performance on public datasets, there has not been as much research comparing unsupervised and supervised physiological datasets. When applied to healthcare data, machine learning algorithms can provide a solution to patients by lowering their risks. As a result, the primary goal of this study is to assess the impact of anomaly detection using a machine learning algorithm in health care, as well as the steps involved in the digitalization of healthcare datasets during anomaly detection.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Sociology, general', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-030-98546-2_29,en,Defining Machine Learning,OriginalPaper,Machine learning is a dynamic concept that has been (and continues to be) developed and theorized from multiple perspectives within different disciplines. It defies attempts to arrive at a single fixed definition.,"['Engineering', 'Biomedical Engineering and Bioengineering', 'Health Informatics', 'Health Psychology', 'User Interfaces and Human Computer Interaction']"
doi:10.1007/978-3-031-21203-1_30,en,Evaluating Adaptive and Non-adaptive Strategies for Selecting and Orienting Influencer Agents for Effective Flock Control,OriginalPaper,"Flocks navigate for large distances, moving in a coherent path through space, under mutual influence of flock members. Such influences may include repulsion, orientation, and attraction. Certain applications give rise to the need to control the movements of flocks, e.g., circumventing critical zones. Researchers have investigated the problem of seeding flocks with a percentage of externally controlled agents to achieve effective flock control. Recent studies of flock control include orthogonal directions of (a) selecting influencing or leader agents and (b) orienting the leader agents. We build on these studies and evaluate combinations of selecting and orienting choices for fast convergence of the flock to follow desired travel directions with both adaptive and non-adaptive selection and orientation algorithms. We evaluate the effectiveness of combined flock control strategies under different physical world models. We explore the case of non-looping (non-toroidal) environments and attempt to overcome their challenges. (This is a continuation of work presented here [3]).","['Computer Science', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16868-0_17,en,Distribution Training Framework for Architecture Design,OriginalPaper,"As discussed in Part I, for the time-consuming issue of the ENAS methods, there are two primary categories of available acceleration methods. First, various acceleration approaches for DNN evaluation are proposed, including weights sharing [ 1 ], low fidelity [ 2 ], and prediction model [ 3 ]. However, the reduction of training in these methods introduces bias in the estimation of DNN performance. Second, many well-known distributed parallelism techniques have been developed to accelerate large-scale DNN training, the most common ones include model parallelism and data parallelism.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-11051-1_107,en,Icebreaker Fleet Management in Simulation Models of the Arctic Marine Transport Systems,OriginalPaper,"The report raises the issue of reflecting the processes of planning and dispatching the icebreaker fleet exploitation in the simulation models of the Arctic transport systems. Due to the theory of agent and discrete-event simulation, icebreakers can be considered as resources that help entities (cargo vessels) to move along to the process diagram. It means, that any such simulation model must include a certain intelligent algorithm for operational planning of icebreakers’ work, which would adequately reflect the logic of their dispatching in real icebreaking fleet management practice. Several alternative approaches for assigning support tasks to icebreakers are considered: ad hoc “greedy” algorithms, a heuristic algorithm for placing icebreakers on areas of responsibility, the use of built–in as well as third party optimization engines. So, we attempt to view the subject from different points of view and to present a range of specific solutions from different development teams. The analysis and comparison of these methods are carried out on test scenarios and configurations of the simulated transport system.","['Engineering', 'Control and Systems Theory', 'Control, Robotics, Mechatronics', 'Communications Engineering, Networks']"
doi:10.1007/978-3-031-18461-1_41,en,Utilizing Machine Learning to Predict Breast Cancer: One Step Closer to Bridging the Gap Between the Nature Versus Nurture Debate,OriginalPaper,"with breast cancer, scientists have been trying to find the most effective solutions and treatments. Moreover, studies on genes through machine learning were conducted. By identifying the factor that influences breast cancer the most, this knowledge can be used to prevent or treat patients with breast cancer appropriately. Furthermore, the result of this experiment extends onto the debate of nature versus nurture. If the result concludes that Only Gene or Only Mutation has a stronger effect on tumors, then it weighs nature more in this debate. Likewise, if Only Others is the dominant factor, then this emphasizes the nurture more in this debate. Gathered data was processed and went through eight different machine learning algorithms to predict the tumor size and stage. The ‘Others’ was concluded as the most influential factor for the tumor. Among the ‘Others’, the type of breast surgery and the number of chemotherapy received were identified with the highest correlation with tumor size and stage. In conclusion, this solidifies the nurture’s stance on the debate. The data on the external effects and the usage of a developed machine learning model can be adopted to improve the experiment because they would increase the accuracy of the result.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4960-9_57,en,Models and Algorithms for Optimization of the Backup Equipment for the Intelligent Automated Control System Smart City,OriginalPaper,"Algorithms for a neural network analyzer (NA) used in the decision support system (DSS) during the selection of the composition of the backup equipment (CBE) for intelligent automated control systems (IACS) for Smart City were proposed. A model, algorithms and corresponding software have been developed to solve the optimization problem of choosing a CBE capable of ensuring the uninterrupted operation of the IACS both in cases of technological failures and in cases of destructive interference in the operation of the IACS by the attackers. The proposed solutions help to reduce the cost of determining the optimal CBE for IAMS by 15–17% in comparison with the results of known calculation methods. The results of computational experiments are presented to study the degree of influence of the number of outputs on the analyzer on the efficiency of the functioning of the CBE for the IACS.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Professional Computing']"
doi:10.1007/978-3-031-07021-1_2,en,Modern Cryptography for ADS-B Systems,OriginalPaper,"Modern cryptography has been proven to be a mature technology to protect the security of wireless communication, so it should be workable to secure ADS-B wireless broadcasts. Specifically, by evaluating the practicability and effectiveness of cryptographic methods in the aviation industry, where technology is complex and cost-saving, it can be concluded that cryptography can indeed safeguard the ADS-B system. In this chapter, we first briefly introduce modern cryptography and then discuss some cryptographic primitives that are proper for securing ADS-B.","['Engineering', 'Communications Engineering, Networks', 'Computer Communication Networks', 'Cyber-physical systems, IoT', 'Computational Intelligence']"
doi:10.1007/978-3-031-06780-8_20,en,"Machine Learning for Automotive Cybersecurity: Challenges, Opportunities and Future Directions",OriginalPaper,"Connected autonomous vehicles (CAVs) hold the promise of not only improving functional safety but also improving mobility and the efficiency of transportation systems. CAVs can be viewed as a cyber-physical system that contains a large number of minicomputers called electronic control units (ECUs). In order for ECU subsystems to share information and operate efficiently, they are typically networked via various in-vehicle networks (IVNs). Such IVNs include the controller area network (CAN), local interconnected network (LIN), media-oriented system transport (MOST), FlexRay and automotive Ethernet. These IVNs are used to connect safety-critical and non-critical components of the vehicle, including brakes, airbags, engine control, active safety devices, the electronic stability program and adaptive cruise control. Although these IVNs provide some luxury functions and improve the functional safety of the vehicles, the use of in-vehicle communication networks can pose serious security threats to CAVs. Several incidents have been reported showing that intruders are able to access vehicle information, even for safety critical tasks. As the IVNs architecturally are not designed to defend against these attacks, additional methods are needed for security. In recent years researchers are taking advantage of advances in more powerful computing hardware, as well the availability of huge amounts of network data and proposing machine learning-based frameworks to secure these IVNs. To the best of our knowledge, these frameworks lack details such as how to apply machine learning for IVN security. Most of them are focused on the selection of machine learning algorithms to improve attack detection rates. As a result, these frameworks become uninterpreted since they took a lot of time in order to reproduce their result. An efficient successful machine learning system depends not only on the selected machine learning algorithm but also on the quality of data. This chapter aims to bridge this research gap by developing a generalized machine learning pipeline designed to defend against existing and emerging cyberattacks on IVNs. The chapter starts with an overview of IVNs, threat modeling of IVNs followed by machine learning-based defense mechanisms against existing and emerging cyberattacks targeted at these IVNs. The last section of the chapter outlines future directions of using the proposed machine learning approach as a solution against vehicle-based cyberattacks for the next generation of vehicles.","['Engineering', 'Automotive Engineering', 'Computational Intelligence', 'Transportation Technology and Traffic Engineering', 'Signal, Image and Speech Processing']"
doi:10.1007/978-3-031-19620-1_15,en,Draft-Based Learning Model to Discover Data from a Cognitive Causal Model,OriginalPaper,"In this research, we present a novel learning model using the draft causal model (DCML); this model is based on a generative approach that uses the spectral properties of the causal model graph. This article addresses the problem of cognitive causal model (CM) learning in complex systems (with nonnumeric and unobservable variables), which is represented by a directed weighted signed graph. The challenge is to find a way to generate training data that expresses specific spectral representative features of the model, i.e., its image, and then, to train the model using this image and obtain an adjacency matrix that satisfies the requirements of the modeled system. The learning criterion is the receipt of the first (or any other) rank in the response vector by the target vertex, which according to the decision-maker, personifies the directionality of the modeled system under the constraints that ensure the adequacy of the model. The presented DCML model implements semi-supervised learning with a generative instantiation mechanism and represents a new application of generative learning for a class of CMs in the absence of observable variables.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16868-0_3,en,Architecture Design for Stacked AEs and DBNs,OriginalPaper,"As introduced in Part II, altering n in Eq. (1) could learn numerous different representations, but only those that perform exceptionally well on the machine learning tasks linked with them are given attention.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-18461-1_42,en,Recognizing Mental States when Diagnosing Psychiatric Patients via BCI and Machine Learning,OriginalPaper,"A psychiatric disorder is any disorder that interferes with a person’s thoughts, emotions, or behavior, including anxiety disorders, and depressive disorders. In order to diagnose these disorders, patients are often required to go through a series of diagnostic tests that demand concentration for accurate results. This paper aims to lower misdiagnoses that result from the lack of concentration in patients by developing an algorithm that recognizes mental states using 989 columns of EEG brain wave data. These data columns were entered into a train split function and analyzed using different classification models of Decision Tree, Logistic Regression, Random Forest, Gradient Boosting, Adaptive Boosting, K-neighbors, LGBM, and XGB. The control experiment analyzed the raw dataset, the second and third experiments utilized feature extraction algorithms of PCA and ICA analysis respectively, and the fourth experiment used correlation matrix analysis to produce accuracy scores. The highest accuracy score of 98.19% was produced by the LGBM Classifier in the control experiment and the most efficient feature selection method was PCA. The highest PCA processed data yielded an accuracy score of 87.7% using the random forest classification model while the correlation matrix analysis yielded an accuracy score of 80.04% using the LGBM classifier. These findings will allow psychologists and psychiatrists to provide methods to help patients answer all questions at a sustained level of sufficient concentration, ultimately allowing a higher percentage of proper diagnoses to be made.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3148-2_34,en,An Improvement to Test Case Prioritization Techniques Using Machine Learning,OriginalPaper,"Regression Testing is an important process every time new changes are integrated in the software product. Managing test cases becomes important in this scenario, where testers need to retest or select test cases based on the changes incorporated. Machine learning can reduce the effort of testers by providing a simplified approach in test case management. Prioritization of test cases can be taken as an initial step of handling bulk test cases and arranging them on the basis of certain priority. Several methods were proposed in the past that handle test cases in case of regression testing. This paper proposes a novel methodology that uses unsupervised machine learning algorithm to prioritize the test cases. Methodology contributes toward risk-based approach whose objective is to prioritize the test cases by identifying the most risky areas first. It categorizes the test cases in clusters representing different priority level. Our proposed approach is based on four essential factors namely the Change-Module mapping, Degree of Coupling between effected modules, Test Coverage Reports and Test Execution Results. Research objective relies on exploring how dynamic change information when combined with white box testing parameters and unsupervised machine learning can be beneficial in categorizing test cases. Paper also presents analysis of the existing literature related to test case prioritization, identified research gaps and expected contribution toward the literature.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory']"
doi:10.1007/978-3-031-07254-3_19,en,Sparse Array (Nonlinear) Guided Wave Imaging for Localization of Damage in Composites,OriginalPaper,"Composite materials are subjected to an increasing importance in critical components commonly used for automotive, aerospace and other modern industrial sectors. Yet, these composites are quite susceptible to damages and defects which can be introduced during the manufacturing and/or operational life. Reconstruction Algorithm for the Probabilistic Inspection of Damage (RAPID) and Delay and Sum (DAS) are well-known guided wave imaging techniques capable to reveal the presence of damage in a sparse ultrasonic sensor network. In this study, several factors in RAPID are investigated to understand their influence on the quality of the reconstructed damage map for a composite laminate with an inter-ply defect. A critical comparison between RAPID and DAS is performed in terms of their accuracy and calculation cost. Finally, results are presented on a baseline-free probabilistic imaging modality by exploiting nonlinear wave/defect interactions.","['Engineering', 'Building Repair and Maintenance', 'Cyber-physical systems, IoT', 'Industrial and Production Engineering', 'Monitoring/Environmental Analysis', 'Analytical Chemistry']"
doi:10.1007/978-981-19-2004-2_11,en,Performance Analysis of Spectrum Sensing Algorithms,OriginalPaper,"The work involves designing and implementing conventional spectrum detection systems for the orthogonal frequency division multiplexing (OFDM) structure. The different detection algorithms are used to assess the performance of the system at the end of the receptor. The structure efficiency is explored by analysing Pd Vs SNR for various spectrum sensing techniques. The performance of the system was examined by simulating the energy detection (ED), matching filter (MF) and cyclostationary method in MATLAB 2014. The result of the projected work reveals that the cyclostationary exceeds the ED and MF technique and achieved a gain of 2 and 3.2 dB.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Artificial Intelligence', 'Materials Science, general']"
doi:10.1007/978-981-19-7100-6_13,en,Sediment Transport Modeling through Machine Learning Methods: Review of Current Challenges and Strategies,OriginalPaper,"Sediment transportation in rivers is considered as an important issue for designing and planning the water resources projects and can damage the environment. Therefore, modeling the components of sediment load, including suspended sediment load, bed-load, and total load in rivers is of greatest significance. Effective modeling of sediment load components remains a challenging task since their complicated hydrological procedure. On this account, this chapter aims to appraise the role of machine learning methods in modeling the sediment transport and review the different strategies for increasing the level of modeling accuracy. For this purpose, an overview of machine learning approaches and a discussion of challenges and opportunities of modeling sediment transport which have relatively replaced time-consuming conventional mathematical techniques are provided.","['Life Sciences', 'Ecosystems', 'Ecology']"
doi:10.1007/978-3-031-16075-2_56,en,Deep Learning and Support Vector Machine Algorithms Applied for Fault Detection in Electrical Power Transmission Network,OriginalPaper,"In this paper, an interesting application of machine learning algorithms is presented. The main idea consists of applying both deep-learning and support vector machine supervised machine learning approaches to improve the quality and to guarantee the stability and the reliability of an electric power transmission system. These techniques are used mainly to detect, classify, and consequently locate faults in the electric power transmission network. To test the performance of the proposed techniques, the standard IEEE 14-bus power system is used. The fault free, the one fault and the multiple fault cases are investigated. Faults are applied to the IEEE 14-bus system and simulated using SimPowerSystems toolbox of Matlab. The accuracy score is used to compare the proposed techniques performances. Different results proved that studied machine learning methods made correct predictions. Nevertheless, the deep learning algorithm performances are proved while classifying all types of faults. Simulation results demonstrate that the deep learning technique can achieve an accuracy of 100% compared to the support vector machine which had an accuracy of 87%.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-1-0716-2819-5_1,en,"Interrogating the Human Diplome: Computational Methods, Emerging Applications, and Challenges",OriginalPaper,"Human DNA sequencing protocols have revolutionized human biology, biomedical science, and clinical practice, but still have very important limitations. One limitation is that most protocols do not separate or assemble (i.e., “phase”) the nucleotide content of each of the maternally and paternally derived chromosomal homologs making up the 22 autosomal pairs and the chromosomal pair making up the pseudo-autosomal region of the sex chromosomes. This has led to a dearth of studies and a consequent underappreciation of many phenomena of fundamental importance to basic and clinical genomic science. We discuss a few protocols for obtaining phase information as well as their limitations, including those that could be used in tumor phasing settings. We then describe a number of biological and clinical phenomena that require phase information. These include phenomena that require precise knowledge of the nucleotide sequence in a chromosomal segment from germline or somatic cells, such as DNA binding events, and insight into unique cis vs. trans -acting functionally impactful variant combinations—for example, variants implicated in a phenotype governed by compound heterozygosity. In addition, we also comment on the need for reliable and consensus-based diploid-context computational workflows for variant identification as well as the need for laboratory-based functional verification strategies for validating cis vs. trans effects of variant combinations. We also briefly describe available resources, example studies, as well as areas of further research, and ultimately argue that the science behind the study of human diploidy, referred to as “diplomics,” which will be enabled by nucleotide-level resolution of phased genomes, is a logical next step in the analysis of human genome biology.","['Life Sciences', 'Genetics and Genomics']"
doi:10.1007/978-981-19-2704-1_1,en,Introduction,OriginalPaper,"This chapter first introduces the fundamental concepts of massive Internet-of-Things (IoT) access. The severe limitations of conventional cellular network-based IoT solutions are summarized from the perspectives of network architecture, random access procedure, and multiple access techniques. A comprehensive overview of the related literature is further provided to present the recent advances in massive IoT access in research community. Finally, the organization of the book is briefly summarized.","['Engineering', 'Wireless and Mobile Communication', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-09687-7_18,en,Artificial Intelligence in Education as a Rawlsian Massively Multiplayer Game: A Thought Experiment on AI Ethics,OriginalPaper,"In this chapter, we reflect on the deployment of artificial intelligence (AI) as a pedagogical and educational instrument and the challenges that arise to ensure transparency and fairness to staff and students . We describe a thought experiment: ‘simulation of AI in education as a massively multiplayer social online game’ (AIEd-MMOG). Here, all actors (humans, institutions, AI agents and algorithms) are required to conform to the definition of a player. Models of player behaviour that ‘understand’ the game space provide an application programming interface for typical algorithms, e.g. deep learning neural nets or reinforcement learning agents, to interact with humans and the game space. The definition of ‘player’ is a role designed to maximise protection and benefit for human players during interaction with AI. The concept of benefit maximisation is formally defined as a Rawlsian justice game, played within the AIEd-MMOG to facilitate transparency and trust of the algorithms involved, without requiring algorithm-specific technical solutions to, e.g. ‘peek inside the black box’. Our thought experiment for an AIEd-MMOG simulation suggests solutions for the well-known challenges of explainable AI and distributive justice.","['Psychology', 'Psychology, general', 'Computer Applications', 'Education, general', 'Philosophy of Mind', 'Artificial Intelligence']"
doi:10.1007/978-3-031-15858-2_6,en,Model-Free Optimal Tracking Control and Multi-Agent Synchronization,OriginalPaper,"This chapter focuses on output feedback optimal tracking problem using reinforcement learning. The issue of discounting factor is discussed in the context of tracking problems. A two degree of freedom approach is presented that enables the learning of the feedback and feedforward control parameters and circumvents the need of discounted cost functions. First, a single agent tracking problem is solved using the proposed approach. Then, the scheme is extended to solve the optimal synchronization problem of a multi-agent system. We consider both state feedback and output feedback designs. The effectiveness of these algorithms is demonstrated by numerical examples.","['Mathematics', 'Systems Theory, Control', 'Control and Systems Theory', 'Optimization']"
doi:10.1007/978-981-19-0151-5_1,en,Comprehensive Study—A Deep Learning and Machine Learning Classification Methods for Cardiogram Images,OriginalPaper,"An echocardiogram is one of the heart testing techniques which is widely used in medical field for test and detecting the human heart illness, at present stage of heart functions, diseases, blood flow identification and any other issues to predict. In medicine, the resolution and quality of the pictures are most important. The problem of the medical images is not able to find issues as sooner and also various kinds noises mixed with it. This paper completely analysis the cardiovascular issue in all the multiple fields of technical views surveyed, with basic related issues to cardio diseases pattern identification and its identify the category of the diseases. At most challenging tasks are removing the noises, classifying and recovering the images in advanced technology with less cost. The machine learning techniques and models will help to improve the quality of the pictures and classify the images to practice for clinical and research purpose.","['Engineering', 'Biomedical Engineering and Bioengineering', 'Artificial Intelligence', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Biological and Medical Physics, Biophysics', 'Information Storage and Retrieval']"
doi:10.1007/978-981-19-3590-9_37,en,Effective Heart Disease Prediction Using Machine Learning—Modified KNN,OriginalPaper,"People suffering from heart diseases have been increased these days. Although many instruments are available to predict heart diseases, they are expensive and unaffordable by common people. In this situation, machine learning plays an important role. The main goal of this paper is to predict whether the patient is suffering from heart disease, by using machine learning. Here, five algorithms such as, K-nearest neighbor (KNN), support vector machine (SVM), decision tree (DT), random forest classifier, and modified KNN are used. Based on the accuracy attained by these algorithms, modified KNN that shows 94.0% accuracy which is higher among all the algorithms, and has been considered for the main application, which refers to web application where inputs are taken from the user to predict the presence of heart illness.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security', 'Mobile and Network Security']"
doi:10.1007/978-981-19-5438-2_19,en,"An 
            
              
            
            $$H_i/H_\infty $$
            
              
                
                  H
                  i
                
                /
                
                  H
                  ∞
                
              
            
          -Optimal Fault Diagnosis Scheme for Satellite Attitude Control Systems",OriginalPaper,"Fault diagnosis for satellite attitude control systems is practically meaningful for improving the safety and reliability of satellites. In observer-based robust FD, one major concern is to answer if the choice of a threshold satisfies an acceptable trade-off between FAR and FDR. Besides, knowledge of fault isolability is useful for answering how difficult it is to isolate a fault from another one. With these in mind, the design and performance analysis of an $$H_i/H_\infty $$ H i / H ∞ -optimal fault diagnosis system are performed in this chapter for satellite attitude control systems, which concerns with fault detectability and fault isolability.","['Engineering', 'Control and Systems Theory', 'Mathematical and Computational Engineering', 'Systems Theory, Control']"
doi:10.1007/978-981-19-1607-6_1,en,Smart Wearable Shoes Using Multimodal Data for Visually Impaired,OriginalPaper,"The visually impaired people’s ultimate goal is to walk freely and comfortability indoors and outdoors. They fear to hit into steps, stones, or uneven floor. Wearable technologies whether image-based or sensors-based provide a solution. However, image-based technologies have issues of detecting an obstacle accurately with no delay. The sensors-based technologies have limitations of the data quality. Therefore, the sensors need to be fitted closer to the obstacles to capture the data, and they require filter to remove the noise data. This work presents a novel wearable, simple, low-cost, user-friendly device. It supports visually impaired to walk in different areas. The system provides accurate data to support visually impaired detecting the obstacles surround them, i.e., front, left, right, and back. It works in multiple environments. The shoes will help them to walk indoors and avoid obstacles on the floor. In outdoors, like pedestrian road, parks, or forests, it will detect pit holes and pumps. The proposed system consists of three parts. The first part, which is a low-cost Internet of things (IoT) system, attaches sensors to shoes to collect data about the context. The second part works like a filter to remove the noise data. Four anomaly machine learning algorithms are applied to choose the most accurate—K-NN, SVM, decision tree, and random forest. The third part is a risk level assessment using fuzzy rules. The results of comparing the anomaly algorithms accuracy show that the random forest is 0.99 with a std. dev ± 0.01. The fuzzy rules defined the three different ranges for the levels of risk.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-17073-7_1,en,“Algozit” Programming Environment for Continuum Mechanics Problem-Solving,OriginalPaper,"The specific features of the “Algozit” programming environment for functional-object implementation of numerical experiment algorithms in continuum mechanics are investigated. Not only “Algozit” architecture is described, but also the technology providing visibility of complex algorithm representations with convenient program debugging, being based on visual programming of functional-object schemes, is proposed. Implementation of a mathematical model for multi-layer fabric package behavior under rigid element impact is described. Numerical modeling results and the correlation with physical experiment data are presented.","['Mathematics', 'Numerical Analysis', 'Computational Mathematics and Numerical Analysis']"
doi:10.1007/978-981-19-4162-7_12,en,Intelligent Disease Analysis Using Machine Learning,OriginalPaper,"Heart diseases include disordered functioning of heart which can be saved through early diagnosis. This diagnosis needs a lot of time to perceive the patient through an accurate approach for treatment. Technical advancements are a boon to healthcare domain for analyzing huge amounts of data generated by various hospitals. These data can be further preprocessed and filtered according to the disease analysis. In this paper, logistic regression (LR) and support vector machine (SVM) models are incorporated for effective prediction of heart disease. The results achieved are 93% accurate when the datasets are compared with SVM model.","['Engineering', 'Computational Intelligence', 'Data Mining and Knowledge Discovery', 'Systems and Data Security', 'Mobile and Network Security', 'Information Systems Applications (incl. Internet)']"
doi:10.1007/978-981-19-3951-8_8,en,Study of Decreasing Traffic Routing System Using VANET Hybrid Ant Colony Optimization,OriginalPaper,"Presenting the paper which is green strategy to reduce the network traffic congestion is an important step toward improvement for VANET infrastructure as we consider the dynamically changeable infrastructure of the RSU. With the latest technique of ad hoc network routing in computing generation and communications protocols, we are able to retrieve any form of sensors data and get maintain off in actual-time vehicles traffic congestion at every location of roadside using GPS. This routing technique observes and introduces a latest algorithms that goals to optimize the route selection of Internet site online traffic road congestion in actual-time primarily based mostly on the ant colony optimization algorithm and VANET communication system. The VANET is used as a communication era a good way to exchanging the routing table information among several vehicles and routes. The principle of the ACO is used to compute the shortest routing path that can be observed by way of the using force to handle the congested path. The proposed protocol is based totally on a multi-hop count scenario, in which all region CHs routers work collectively to expose the street and highway traffic congestion and assist the drivers to fast arrive at their destination locations through the use of the tremendous routes with less congestion. Simulation results evaluate that the proposed method can consumes very less time to cover the whole distance traveled from source to destination with optimized path, while compared to the traditional “shortest distance covering technique”.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-3-031-07322-9_28,en,Damage Detection in Rods via Use of a Genetic Algorithm and a Deep-Learning Based Surrogate,OriginalPaper,"This research demonstrates the use of genetic algorithms for damage detection in isotropic rods. The spectral element method and a deep-learning-based surrogate model is utilized for simulating wave propagation in an isotropic cracked rod. The genetic algorithm employs results (“numerical experiment"") obtained from the spectral element model and the deep-learning-based surrogate to determine the optimized crack locations and crack depths as output parameters. The objective function used in the genetic algorithm is the mean square error between the response obtained from spectral element model and the deep-learning-based surrogate model.","['Engineering', 'Building Repair and Maintenance', 'Cyber-physical systems, IoT', 'Industrial and Production Engineering']"
doi:10.1007/978-981-19-2004-2_22,en,Time Series Analysis of Cryptocurrency: Factors and Its Prospective,OriginalPaper,"In the recent time as well as the last decade cryptocurrency has been one of the most discussed topic among the researchers all around the world. Different economies across the globe have seen a lot of growth of cryptocurrency over the time and bitcoin especially has seen a growth of 1100% that is why time series analysis of cryptocurrency is of immense significance. Time series analysis can be referred to as the process of taking into consideration a sequence of different points which are observed over a specific time interval. A large number of people start investing into cryptocurrencies without having any knowledge or analyzing the cryptocurrency market because of the hype it has these days and suffer huge losses so designing a model which can predict accurately as to how different cryptocurrencies would behave on basis of previous record can be very helpful and it can help some people in making profit rather than suffering loss. This paper presents a comparative overview of different algorithms like RNN, Linear Regression, GARCH, and ARIMA which can be used for time series analysis and concludes as to which algorithm is best suitable for time series analysis by considering different parameters like RMSE, MAE, etc., Besides this, it also analyzes the different factors which affect the prices of cryptocurrency.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Artificial Intelligence', 'Materials Science, general']"
doi:10.1007/978-3-031-18458-1_8,en,Is Free-Viewpoint Video the Future of Online TV?,OriginalPaper,"The future of digital entertainment may lie in the development of free-viewpoint video and television, allowing users to navigate multiple video streams of an event to select new perspectives. In this paper, we describe a prototype free-viewpoint video system capable of computing in real-time video panorama from five HD cameras. The stitching process is pipelined to distribute the computations between numerous processing nodes organized as a GPU cluster to create visually appealing panoramas at 30 Hz without noticeable blurring or boundary artifacts. We also present how the system can be scaled-up to deal with larger number of cameras and how to deliver free-viewpoint TV using commercial IPTV technology.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-0095-2_41,en,Indigenous Non-invasive Detection of Malnutrition-Induced Anemia from Patient-Sourced Photos Using Smart Phone App,OriginalPaper,"The proposed online-based malnutrition-induced anemia detection smart phone app is built, to remotely measure and monitor the anemia and malnutrition in humans by using a non-invasive method. This painless method enables user-friendly measurements of human blood stream parameters like hemoglobin (Hb), iron, folic acid, and vitamin B12 by embedding intelligent image processing algorithms which will process the photos of the fingernails captured by the camera in the smart phone. This smart phone app extracts the color and shape of the fingernails, will classify the anemic and vitamin B12 deficiencies as onset, medieval, and chronic stage with specific and accurate measurements instantly. On the other dimension, this novel technology will place an end to the challenge involved in the disposal of biomedical waste, thereby offering a contactless measurement system during this pandemic Covid-19 situation.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Systems and Data Security', 'Artificial Intelligence', 'Computational Intelligence']"
doi:10.1007/978-3-031-18461-1_39,en,A Systematic Review of Machine Learning and Explainable Artificial Intelligence (XAI) in Credit Risk Modelling,OriginalPaper,"The emergence of machine learning and artificial intelligence has created new opportunities for data-intensive science within the financial industry. The implementation of machine learning algorithms still faces doubt and distrust, mainly in the credit risk domain due to the lack of transparency in terms of decision making. This paper presents a comprehensive review of research dedicated to the application of machine learning in credit risk modelling and how Explainable Artificial Intelligence (XAI) could increase the robustness of a predictive model. In addition to that, some fully developed credit risk software available in the market is also reviewed. It is evident that adopting complex machine learning models produced high performance but had limited interpretability. Thus, the review also studies some XAI techniques that helps to overcome this problem whilst breaking out from the nature of the ‘black-box’ concept. XAI models mitigate the bias and establish trust and compliance with the regulators to ensure fairness in loan lending in the financial industry.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3796-5_5,en,Machine Learning Techniques for Predicting Dengue Outbreak,OriginalPaper,"Dengue fever is one of the well-renowned mosquito-borne diseases that appear in tropical and subtropical regions of the Earth. The transmission of dengue can be related to climatic variables since it is spread by mosquitoes. Using the environmental data collected by various government agencies, we try to predict the amount of dengue fever cases reported weekly in two cities, San Juan, Puerto Rico, and Iquitos, Peru. This study aims to design two time series-based nonlinear regression models (NLRM) and a data manipulation technique using different parameters such as temperature, vegetation and rainfall data and incorporating time series, dimension reduction for better prediction of dengue outbreak. This study considers three different modelling techniques: interpolation, gradient boosting regression and random forest regression. Parameters were tuned and adjusted for optimal performance. Results are based on prediction accuracy and mean absolute error (MAE). The performance was analysed, and the result points out that the gradient boosting regression performs significantly better than the other models and is therefore considered to be a better approach. Future results can be improved by obtaining large amounts of meaningful data and implementing better models associated with time series predictin g .","['Engineering', 'Communications Engineering, Networks', 'Systems and Data Security', 'Artificial Intelligence', 'Software Engineering/Programming and Operating Systems', 'Computational Intelligence']"
doi:10.1007/978-3-031-13714-3_11,en,Heuristics Design,OriginalPaper,"The last chapter of the book gives some advice on developing heuristics. It discusses the difficulty of modeling the problem and gives an example of decomposing the problem into a chain of more manageable sub-problems. Secondly, it proposes an approach for the design of a specific heuristic. Finally, some techniques for parameter tuning and comparing the efficiency of algorithms are reviewed.","['Business and Management', 'Operations Research/Decision Theory', 'Optimization', 'Computational Mathematics and Numerical Analysis', 'Algorithms', 'Computational Science and Engineering', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3571-8_20,en,Surakhsha Kavach: ML-Based Cross-platform Application for COVID-19 Vulnerability Detection,OriginalPaper,"Suraksha Kavach app is the way of detecting vulnerability of COVID-19 attack of person. As people were not aware at an early stage, so many people were suffering at a large number leading to serious consequences. So, the idea of ML-based app is to make people aware regarding their vulnerabilities of COVID-19 attack which will help people to take precautions at an early stage to avoid further serious consequences and protect themselves and their family. Overall, this app will be easily available on any platform which will help people to easily access and take the benefit of it. We have arrived at a conclusion that ML-based Suraksha Kavach app is a much viable solution for the people to take precautionary measures at an early stage.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-07322-9_62,en,Offline Algorithm Selection of CMA-ES Variants in Bayesian Optimal Sensor Placement: Application to Buildings and Recommendations to the Philippine Instrumentation Practice,OriginalPaper,"The application of Optimal Sensor Placement (OSP) algorithms has been advancing in Structural Health Monitoring (SHM). Among many approaches, this study focuses on a Bayesian OSP algorithm optimized using the Covariance Matrix Adaptation Evolution Strategy (CMA-ES) – a blackbox algorithm for continuous problems. The increase in the number of CMA-ES variants warrants the non-trivial selection problem. Nonetheless, it is difficult to say if such a step has been well-conducted in the investigated SHM literature. Hence, this study aimed to improve the existing OSP framework by adding an offline algorithm selection methodology and to demonstrate the framework’s application to buildings. Application to the ASCE benchmark structure showed that the discrete implementation of CMA-ES outperforms a discrete reformulation that used binomial sampling. OSP results were also found to agree with existing literature. Furthermore, case studies quantify that for an undamaged structure, sensor placement that is well-distributed according to the location of the columns and stiffeners gives high-quality OMA results. For damaged structures, sensors should be placed near the damaged region, and failure to do so showed a reduction of MAC value by 0.1. Lastly, with insight from industry research of the Philippine SHM landscape, these conclusions were found to be potential recommendations to improve the current developing practice compared to the international state-of-the-art.","['Engineering', 'Building Repair and Maintenance', 'Cyber-physical systems, IoT', 'Industrial and Production Engineering']"
doi:10.1007/978-981-19-5403-0_25,en,A Modified Teaching-Learning-Based Optimization Algorithm for Traveling Salesman Problem,OriginalPaper,"In this investigation, we propose a modified teaching-learning-based optimization algorithm (mTLBO) for solving the traveling salesman problems. We design an mTLBO with Boltzmann selection, novel upgradation strategy in the teaching phase, and interactive group-based crossover for learners in the learning phase. In the teaching phase, we focus on different learning abilities of different subjects of individual learners and in the learning phase, learners are randomly divided to form different groups; it helps to maintain the diversity of the population and to avoid premature convergence. The proposed algorithm is tested against benchmark functions from TSPLIB. The results are compared with the proposed mTLBO, TLBO and standard Genetic Algorithm with Roulette wheel selection, cyclic crossover and random mutation. The effectiveness of the proposed algorithm is shown through statistical test ANOVA.","['Engineering', 'Computational Intelligence', 'User Interfaces and Human Computer Interaction', 'Data Structures and Information Theory', 'Artificial Intelligence', 'Data Mining and Knowledge Discovery']"
doi:10.1007/978-981-19-2764-5_6,en,A Framework for Glaucoma Diagnosis Prediction Using Retinal Thickness Using Machine Learning,OriginalPaper,The project mainly focuses to detect a Glaucoma percentage in a person’s eye. Glaucoma is an eye disease which is mainly responsible for vision impairment. So it is necessary to detect the presence of Glaucoma in the early stages. If detected in the early stage we can control our intra ocular pressure by adopting lifestyle changes and by using some other medications. The lifestyle changes may include exercising regularly and reducing stress. Hence the early detection of Glaucoma can help people from losing their vision. A machine learning model has been proposed which tells the Glaucoma percentage of the eye. In this we are giving a fundus image as the input to the model and it tells the Glaucoma percentage. This Glaucoma percentage can be detected using two things that are optic cup and optic disk. To measure the Glaucoma percentage it is necessary to find the optic cup ratio to optic disk ratio. Generally health eye optic cup ratio to optic disk ratio is less than 0.5. In Glaucoma eye the optic cup ratio to optic disk ratio is greater than 0.5. By using this concept we are going to develop the model.,"['Energy', 'Energy Systems', 'Artificial Intelligence', 'Machine Learning', 'Cyber-physical systems, IoT', 'Professional Computing', 'Power Electronics, Electrical Machines and Networks']"
doi:10.1007/978-981-19-4182-5_31,en,Enhancing the Security of JSON Web Token Using Signal Protocol and Ratchet System,OriginalPaper,"User Authentication is crucial for every application. Initially, session variables were used. If a session ID was compromised, lost, or stolen, the user’s identity was compromised. This resulted from session IDs having a long lifespan and the tendency of most users not to log out of their accounts. JSON web tokens (JWTs) Tokens were introduced to overcome this problem and are currently considered industry standards. JWTs are secured using base 64 encryption and session variables. They have a shorter lifespan as compared to session variables. Even then, it is highly susceptible to Man-in-the-Middle attacks, especially over unsecured networks. Internal attack vectors also pose a significant threat in this particular scenario. To counter this problem, we explore the possibility of using the Signal algorithm with a double ratchet system to encrypt our JWTs to add a new layer of security. The result is an algorithm capable of securing primary JSON payloads in an end-to-end manner. This research aims to increase the security of JWTs using a ratchet system.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Computer Systems Organization and Communication Networks', 'Statistics, general']"
doi:10.1007/978-3-031-18516-8_21,en,Efficient Coronavirus Herd Immunity Optimizer for the UAV Base Stations Placement Problem,OriginalPaper,"This paper proposes an improved version of the Coronavirus Herd Immunity Optimizer (CHIO) algorithm, called RFDB-CHIO, for solving the Unmanned Aerial vehicle carried Base Stations (UAV-BSs) placement problem in 5G networks. The proposed RFDB-CHIO is based on the integration of the Roulette Fitness Distance Balance (RFDB) selection mechanism into the original CHIO algorithm. RFDB-CHIO is validated in terms of user coverage and mean coverage radius under 16 scenarios with different numbers of drones and users. The simulation results demonstrated that RFDB-CHIO obtained better results than CHIO, Whale optimization algorithm (WOA), and Grey Wolf Optimization (GWO) algorithms.","['Engineering', 'Complexity', 'Computational Intelligence', 'Control and Systems Theory']"
doi:10.1007/978-981-19-2840-6_13,en,Nonlinear Integrity Algorithm for Blockchain Based Supply Chain Databases,OriginalPaper,"With an ever-growing global supply chain, supply chain management(SCM) is becoming more complex and competitive because of continuous development in global supply chain. In recent years, the blockchain has grown with the promise of becoming a “ trust machine “. However, this technological innovation can foster trust and transparency in many other sectors. In the industrial sector, for example, it could have interesting applications in production ecosystems and in particular in improving supply chain performance, offering the opportunity to increase speed and quality with potential cost savings ranging from 12 to 50%. the computation power required to setup and maintain a blockchain is expensive because of Computing hash for each block added to the blockchain and validating blocks. In this paper we proposed a nonlinear Integrity algorithm which works efficiently in terms of run-time and hash-bit variation with dynamic hash size and data size when compared it with traditional hashing algorithms like whirlpool, SHA, MD5.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-030-98140-2_6,en,Synaptic Scaling and Homeostasis,OriginalPaper,"Synaptic scaling is a hypothesis that is accepted by many neuroscientists. Its main premise is that both excitatory and inhibitory synaptic weights that feed inputs to a neuron are scaled up or down together as needed to bring the neuron’s membrane potential to its homeostatic level. Adjusting the weights directly affects the sum (SUM) which is proportional to the membrane potential. With synaptic scaling, large weights adapt faster than small weights. This also happens with % Hebbian-LMS. Both adaptive algorithms have the same objective, to restore the neuron to homeostasis. Both algorithms require the same signals for adaptation, namely the X-vector and the error. Synaptic scaling operates with a common mode, excitatory and inhibitory weights scale up or down together. % Hebbian-LMS implements a differential mode so that when excitatory weights scale up, the inhibitory weights scale down, etc. Nature could implement either algorithm, but % Hebbian-LMS has the advantage of requiring less weight change to achieve error correction. Physical evidence supporting synaptic scaling also supports % Hebbian-LMS. The algorithms are identical with excitatory synapses but not so with inhibitory synapses.","['Engineering', 'Biomedical Engineering and Bioengineering', 'Complex Systems', 'Machine Learning']"
doi:10.1007/978-3-031-08693-9_8,en,Algorithm to Hardware: FFT as a Case Study,OriginalPaper,"In this chapter we propose a novel design flow. This is neither the hardware design flow of ASICs or FPGAs nor a design flow typical of algorithm development. Instead, it bridges the gap between the two. We go through well-defined steps to translate an idea into a form suitable for hardware implementation. We use the OFDM modulator/demodulator as a design example and use it to illustrate how major design decisions can be made about the datapath and the controller. This includes fixed-point analysis, isolation and design of processing units, parallelism and pipelining, hardware reuse, memory allocation and partitioning, state machine design, and design of flexible micro-coded controllers.","['Engineering', 'Circuits and Systems', 'Microwaves, RF and Optical Engineering']"
doi:10.1007/978-981-19-2397-5_3,en,Divide to Federate Clustering Concept for Unsupervised Learning,OriginalPaper,"In this paper, the concept of divide and federate is evaluated to find the clusters that are different in densities and shapes and are contaminated with noise. The proposed divide-and-federate clustering method is based on the density and distance evaluation of the data. Wherein, the first phase of the algorithm divides the data into different sub-clusters based on the density evaluation with respect to all the data dimensions and, in the second phase, the small sub-clusters are federated with large sub-clusters to create the actual data clusters. The federation phase of the proposed clustering method is based on the distance evaluation of clusters and is merged based on the close proximity of neighbors. The proposed clustering algorithm is capable of handling noisy data through the integration of an outlier detection preprocessing method. The usefulness of the proposed algorithm is demonstrated with some examples of complex synthetic benchmark functions.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3148-2_68,en,Empowered MapReduce and Deep Trust Management for Mitigation of Void and Energy Hole in WSN-IoT,OriginalPaper,"The most prevalent challenges in wireless sensor networks (WSNs) are occurrence of void holes and energy holes, which shorten the lifetime of sensor nodes and cause rapid energy depletion. Most of the existing literatures are not suited for energy depletion due to indeterminacy in selection of cluster heads and uneven distribution of sensor nodes in WSN. The optimized clustering in presence of noisy and border lying sensor nodes is the main disadvantage while using the standard energy hole alleviation algorithms. This paper improves the process of alleviating void hole occurrence in WSN by devising a wedge-based partitioning to distribute the sensor nodes evenly. The standard Fuzzy C-Means algorithm’s efficiency is low when dealing a huge volume of traffic with limited memory. Another difficulty is how to optimize Fuzzy C-Means clustering is a major challenge and it is achieved by integrating MapReduce framework to improve clustering reliably. The MapReduce based Fuzzy C-Means clustering is developed in this research work to determine the optimized cluster head in presence of indeterminacy due to the dynamic nature of the environment and mobility of sensor nodes. Hence, it can perform parallel clustering of sensor nodes to improve the speed of the algorithm. Additionally, security is also considered as an important factor to accomplish better energy consumption in WSN. This proposed work introduced a deep neural network-based trust management scheme to overcome the issue of data packet loss and time delay. The simulation results proved that the proposed Empowered MapReduce and Deep Trust Management (EMR-DTM) with its ability of tristate mechanism greatly overcomes the problem of energy depletion and secure data transfer more precisely compared to other standard state-of-the-art clustering algorithms in WSN-IoT.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory']"
doi:10.1007/978-981-16-9967-2_40,en,Safeguarding Cloud Services Sustainability by Dynamic Virtual Machine Migration with Re-allocation Oriented Algorithmic Approach,OriginalPaper,"Data centres are networking platforms which exhibit virtual machine workload execution in a dynamic manner. As the users’ requests are of enormous magnitude, it manifests as overloaded physical machines resulting in quality of service degradation and SLA violations. This challenge can be negotiated by exercising a better virtual machine allocation by dint of re-allocating a subset of active virtual machines at a suitable destined server by virtual machine migration. It is exhibited as improved resource utilization with enhanced energy efficiency along with addressing the challenge of impending server overloading resulting in downgraded services. The aforesaid twin factors of enhanced energy consumption and enhanced resource utilization can be suitably addressed by combining them together as a single objective function by utilizing cost function based best-fit decreasing heuristic. It enhances the potentials for aggressively migrating large capacity applications like image processing, speech recognition, and decision support systems. It facilitates a seamless and transparent live virtual machine migration from one physical server to another along with taking care of cloud environment resources. The identification of most appropriate migration target host is executed by applying modified version of best-fit decreasing algorithm with respect to virtual machine dynamic migration scheduling model. By executing the selection algorithm, the hotspot hosts in cloud platform are segregated. Subsequently, virtual machine-related resource loads are identified in descending order with respect to hotspots. The resource loads pertaining to non-hotspot hosts are identified in ascending order. Next, the traversing manoeuvring in non-hotspot hosts queue is exercised for identification of the most appropriate host to be reckoned as migration target host.","['Computer Science', 'Computer Systems Organization and Communication Networks', 'Computational Intelligence', 'Artificial Intelligence', 'Wireless and Mobile Communication', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-1029-6_32,en,Using Data Mining for Prioritizing Roof Rehabilitation Works,OriginalPaper,"Roofing systems require frequent inspection and rehabilitation due to their continuous exposure to the elements. For large owners who manage many buildings, the low resolution of inspection data leaves many roofs being classified at critical condition. This makes the allocation of the limited rehabilitation funds a very challenging task. To help identify top priority roofs, this study uses clustering techniques to offer a more granular classification of roofing criticality. Clustering is a data mining technique that can group datapoints into distinct clusters of similar attributes. The study uses inspection data from 400 roofs collected from the Toronto District School Board and compares the clustering results of various techniques in terms of roofing severity levels. Based on the study results, the K-Means algorithm has been determined to be most useful. This study is expandable to other asset types and contributes to improving the efficiency of the fund allocation process.","['Engineering', 'Building Materials', 'Geoengineering, Foundations, Hydraulics', 'Transportation Technology and Traffic Engineering', 'Environment, general']"
doi:10.1007/978-981-19-5217-3_19,en,A Multi-objective Optimization Approach of Green Building Performance Based on LGBM and AGE-MOEA,OriginalPaper,"This paper proposes a novel multi-objective optimization approach for green building performance combining Building Information Model (BIM) and artificial intelligence (AI) algorithms. LGBM and AGE-MOEA algorithm are respectively utilized to construct the prediction and optimization model, and finally the multi-objective optimization process for total site energy consumption, CO2 emission and discomfort hours can be achieved by changing values of 12 corresponding level-2 indicators. The pareto front and the optimal solution are obtained. The applicability and effectiveness of the optimization method are verified by a practical case, and the results suggest that: (1) the accuracy of LGBM prediction model is as high as 99.975%; (2) under the multi-objective optimization of AGE-MOEA algorithm, the green performance metrics of building information model has improved by 14.32%, which is better than that of widely used NSGA-II and NSGA-III algorithms under the same conditions; (3) the setting of HAVC system is the biggest factor affecting the performance of green buildings.","['Engineering', 'Civil Engineering', 'Public Policy', 'Arts']"
doi:10.1007/978-3-031-05516-4_3,en,Modeling of Unsafe Areas for Swarm Autonomous Agents,OriginalPaper,"In the motion tasks of an autonomous vehicle it is necessary to consider the position of individual obstacles and various unsafe zones. We consider a multi-agent system whose motion is carried out towards a common goal according to algorithms of swarm behavior based on Reynolds rules: speed matching, collision avoidance with neighbors and attraction to neighbors. Three approaches to modeling swarming behavior based on articles (Olfati-Saber, Flocking for multi-agent dynamic systems: algorithms and theory. IEEE Trans Autom Control, 51(3), 2016; Olfati-Saber, Murray, Flocking with obstacle avoidance: cooperation with limited communication in mobile networks. In: 42nd IEEE international conference on decision and control, vol 2, 2022–2028) are presented. The peculiarities of this work are that the approaches considered together help to realize such a model of motion, which ensures the avoidance of collision with all available types of obstacles. The method is intended for implementation in those spaces, where there will be many autonomous vehicles. The main problem is that when a dynamic obstacle is encountered, congestion can occur—the agents closest to the obstacle react quickly, while distant agents do so with a lag and create crush. The goals of this paper are to propose a method of indirectly transmitting danger information between swarm members without using communication channels. This means that those robots that do not see the danger can get information about it from other agents by observing their behavior. For this purpose, a method of escaping from a pack from a “predator” based on Q-learning is implemented.","['Engineering', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Cities, Countries, Regions', 'Artificial Intelligence', 'Statistics, general']"
doi:10.1007/978-981-19-3998-3_134,en,Distributed Cluster Fusion Estimation Under Correlated Noise Conditions,OriginalPaper,"In this paper, considering the problem of distributed cluster fusion estimation, a two-layer fusion structure is proposed for discrete time-varying linear systems with multiple sensors. In the first layer of the fusion structure, considering the noises correlation between process noise and measurement noises, as well as the mutual interference between measurement noises in the cluster, a centralized information filtering method is designed, and local state fusion estimations are obtained. In the second layer of the fusion structure, a distributed cluster fusion estimation algorithm is presented for the clusters, where the weight matrix is obtained under the minimum variance by the least square method. Finally, a numerical simulation of target tracking proves effectiveness of the proposed algorithm.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-981-19-1610-6_17,en,A Novel Video Prediction Algorithm Based on Robust Spatiotemporal Convolutional Long Short-Term Memory (Robust-ST-ConvLSTM),OriginalPaper,"Recently, video prediction algorithms based on neural networks have become a promising research direction. Therefore, a new recurrent video prediction algorithm called “Robust Spatiotemporal Convolutional Long Short-Term Memory” (Robust-ST-ConvLSTM) is proposed in this paper. Robust-ST-ConvLSTM proposes a new internal mechanism that is able to regulate efficiently the flow of spatiotemporal information from video signals based on higher-order Convolutional-LSTM. The spatiotemporal information is carried through the entire network to optimize and control the prediction potential of the ConvLSTM cell. In addition, in traditional ConvLSTM units, cell states, that carry relevant information throughout the processing of the input sequence, are updated using only one previous hidden state, which holds information on previous data unit already seen by the network. However, our Robust-ST-ConvLSTM unit will rely on N previous hidden states, that provide temporal context for the motion in video scenes, in the cell state updating process. Experimental results further suggest that the proposed architecture can improve the state-of-the-art video prediction methods significantly on two challenging datasets, including the standard Moving MNIST dataset, and the commonly used video prediction KTH dataset, as human motion dataset.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1844-5_2,en,Selection of a Rational Composition of İnformation Protection Means Using a Genetic Algorithm,OriginalPaper,"This article describes a modified genetic algorithm (MGA) for solving a multicriteria optimization problem for the selection and optimization of the information security means (ISM) quantity for sets located on the nodes of the informatization objects’ (OBI) distributed computing system (DCS). Corresponding computational experiments were carried out, during which it was shown that MGA is distinguished by a sufficiently high efficiency. The time spent on solving the problem of the options evaluation for selecting and optimizing the placement of DSS sets along the DCS nodes for OBI, when using MGA, is approximately 16–25.5 times less in comparison with the indicators of the branch-and-bound method. The proposed approach of the MGA usage for solving the above written problem is characteristically exhibited by its integrated approach. In contrast to similar studies devoted to this problem, which, as a rule, consider only some aspects of information security (e.g., assessing the risks for OBI, comparing different information security systems, building maps of cyberthreats, etc.), the approach we are extending makes it possible to combine all areas of ISM selection in the process of the OBI information security (IS) contours optimization. The DSS module for solving the problem of selecting and optimizing the number of information security systems for the sets located on the nodes of the informatization objects’ DCS was described.","['Engineering', 'Communications Engineering, Networks', 'Mobile and Network Security', 'Artificial Intelligence', 'Big Data']"
doi:10.1007/978-3-031-21203-1_13,en,A Hybrid Model of Traffic Assignment and Control for Autonomous Vehicles,OriginalPaper,"This paper proposes a multi-agent based method to describe traffic control optimization for autonomous vehicle assignment problems on road networks. We first present a formal model for abstract road networks. We then extend the road network model into a game-theoretical model based on population games to describe the behavior of autonomous vehicles under intelligent traffic control. Based on this model, we investigate a traffic control optimization problem that aims to improve the efficiency of road networks and provides an algorithm to find an approximate solution. Lastly, our algorithm significantly reduces the total delay of the road network, as demonstrated by the results of our experiments with the Aimsun ( https://www.aimsun.com ) simulation software.","['Computer Science', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3391-2_31,en,Future Gold Price Prediction Using Ensemble Learning Techniques and Isolation Forest Algorithm,OriginalPaper,"Previously, gold is a mineral with unique characteristics that draw people's attention for a variety of reasons, including its high demand in jewelry. In addition to other forms of payment, gold was utilized to finance commercial transactions all over the world. Moreover, gold is a national financial asset, and different states preserved and grew their gold holdings, indicating that they were affluent and forward-thinking. Across the globe, central banks keep precious metals such as gold for loans and other requirements of the people. In India and other parts of the globe, gold can be used to offer as a compliment. Gold prices are heavily influenced by global commodity demand and supply. Inside this article, we are going to predict the gold rate for the next 30 days and also find the predictions of the financial year 2020–21, next fiscal year 2021–22, and until the middle of the following fiscal year 2022–23 using ensemble learning technique and isolation forest algorithm. We used information from the Internet to create predictions using the ensemble learning method and unsupervised-based approach. In this paper, we have forecasted the predictions of gold rate using different algorithms which will give better accuracy based upon above techniques. And also by applying these techniques in the whole gold dataset, we are going to compare the accuracy using ensemble and isolation forest algorithms which will give better results at all.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Statistics, general', 'Cyber-physical systems, IoT', 'Professional Computing', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-1607-6_69,en,Distributed Deep Reinforcement Learning for Resource Allocation in Digital Twin Networks,OriginalPaper,"With the rapid growth of the wireless network scale and the aggressive development of communication technology, the communication network connection is required to drift to digits in order to ameliorate the network efficiency. Digital twin (DT) is one of the most promising techniques, which promotes the digital transition of communication networks by establishing mappings between virtual models and physical objects. Nevertheless, due to the limitation and heterogeneity of equipment resources, it is a great challenge to provide efficient network resource allocation. To solve this problem, the authors propose a novel network paradigm based on digital twin to build the topology and model of the communication system. Then a distributed deep reinforcement learning (DRL) method is designed to dispose the problem of resource allocation in cellular networks, and an online–offline learning framework is proposed. Firstly, the offline training is carried out in the simulation environment, and the DRL algorithm is applied to train the deep neural network (DNN). Secondly, in the process of online learning, the real data are further utilized to fine-tune the DNN. Numerical results illustrate the superiority of the proposed method in terms of average system capacity. In the case of different user densities, the performance of the proposed algorithm has more advantages than that of benchmark algorithms and has better generalization ability.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-13714-3_5,en,Local Search,OriginalPaper,"Improvement methods constitute the backbone of most metaheuristics. These methods repeatedly perform slight, local modifications on a current solution to the problem. Hence, for any solution, a set of neighbor solutions must be defined. Clearly, the definition of this set depends on the problem modeling. However, a natural neighborhood may turn out to be either too small to lead to quality solutions or too large, inducing prohibitive calculation times. Various approaches have been proposed to enlarge the neighborhood, such as the filter and fan method or the ejection chains. For reducing the neighborhood size, typical strategies are the granular search and the candidate list.","['Business and Management', 'Operations Research/Decision Theory', 'Optimization', 'Computational Mathematics and Numerical Analysis', 'Algorithms', 'Computational Science and Engineering', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16072-1_24,en,Arcface Based Open Set Recognition for Industrial Fault,OriginalPaper,"In industry, fault classification is important to avoid economic losses. Fault type classification is an important because fault detection and classification before equipment shutdown allows accurate maintenance. However, it is difficult to define all fault types in advance. It is impossible to know everything in advance what kind of fault will occur. Therefore, we propose an Arcface-based open set recognition method. We propose an algorithm that can classify a known fault type or an unknown fault type by fusion of a deep learning-based classification model and a distribution model that can estimate whether it is a known type. We apply the proposed method to the AHU dataset. The proposed model shows better performance compared to the existing methods.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4960-9_3,en,An Integrated Terrestrial-Satellite Cellular 5G Network Routing Protocol Using Reinforcement Learning Techniques,OriginalPaper,"The integrated terrestrial-satellite cellular networks are the vital module of next generation Internet (NGI) communication services such as 5G, because of its enormous benefits such as extensive broad coverage, higher flexibility, and uninterrupted services. This network employs a satellite network component in the terrestrial cellular 5G infrastructure to deliver interaction services to users who are unable to transmit over the land-based cellular tower signal network. The existing satellite routing algorithms has the pitfall of ignoring the users’ requests for resources based on the different snapshot of the satellite network. These algorithms cannot have maximum utilization of the resources and generate congestion. The proposed routing protocol is the finite-state Markov decision model with combinatorial optimization and reinforcement learning algorithm known as Q-learning technique-oriented routing algorithm (QLRA) which allows to select best possible paths corresponding to the changing state of the network. The converging time of QLRA is gradual because of the loop created during routing process or handover impact in the procedure of finding best route. To resolve these challenges, Q-learning routing algorithm (QLRA) enhanced with the split-based speed-up converging technique known as speed-up Q-learning routing algorithm (SQLRA). Simulation experimental outcomes proposed SQLRA which has improved performance in the integrated terrestrial-satellite cellular 5G networks based on throughput, delay, error rate, and time.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Professional Computing']"
doi:10.1007/978-3-031-19499-3_8,en,Practical Approaches for Robot Dynamic Model Implementation for Control and Simulation Purposes,OriginalPaper,"A robot dynamic model is time variable, highly non-linear and characterized by coupling effects among the robot joints. Consequently, a derivation and implementation of a robot dynamic model, which is used for purposes of control, simulation, and mechanical design, often represents a challenging task. The last couple of decades saw a great amount of research with the aim to achieve better ease of use (development) and computational efficiency of robot dynamic algorithms. Recently, general-purpose robot modeler/simulator software that enables numerical calculation of robot inverse dynamics problem for user-developed robot model and input joint trajectories are being increasingly used by a wider range of robot developers for robot control purposes. In this study, two different practical approaches to account for robot dynamics for purposes of robot control, trajectory generation, mechanical design and simulation, are discussed. The first approach includes an efficient solution for forward dynamics using a novel modified recursive Newton–Euler algorithm, which is used for simulation, mechanical design, and trajectory generation. The second approach is based on modern software tools usage, for the purposes of simulation and control. Both strategies for implementation of robot dynamic model are based on developed 3D models of robots in CAD software and 3D modelers. Applied approaches are demonstrated in three different case studies. Discussion on the benefits of the presented approaches is given.","['Engineering', 'Computational Intelligence', 'Mathematical and Computational Engineering']"
doi:10.1007/978-3-031-13150-9_37,en,Futuristic Approach for Intelligent Cognitive Radio Using Different Machine Learning Algorithms,OriginalPaper,"As the utilization of spectrum is increasing rapidly with the increase of wireless devices Cognitive radio (CR) is a novel approach introduced by FCC which provide enhancement in the utilization of available spectrum. It can be done with the help of smart radio devices. It senses the presence of primary users (PUs) in order to use the spectrum more efficiently in their absence. Secondary Users (SUs) plays the role of smart radios for sensing the radio environment. Machine learning (ML) is serving as one of the most important factor to facilitate intelligent CR networks. It not only enhances the performance but also gives much more accurate results. There is an ever growing interest for using the algorithm of machine learning in Cognitive Radios. Various learning models that can be applicable for CR networks are demonstrated in this paper. The author recapitulates the method stepwise and design a learning-based cooperative secondary network, by giving emphasizes on factors that lay an impression on detection performance. Recent learning techniques are also highlighted in this paper with their applications in cognitive radio. Author also tries to shown a relationship between cognitive radio and Software defined radios.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Management']"
doi:10.1007/978-3-031-19958-5_91,en,Hybrid Shuffled Frog Leaping Algorithm Using the Angle and Sigma Compared with 4 Benchmark Function,OriginalPaper,"This proposed algorithm presents a Hybrid Shuffled Frog Leaping Algorithm (SFLA) using the angle and sigma in the updating process. In the original SFLA, the idea of the moving process toward a better solution is uniformly random. But, this proposed concept is sum up, angle and sigma into updating through position to increase the search space, which is not happening on a direct line during the process. Since the optimum solution is might not on the direct line while the algorithm is in the process. The proposed method explores the prospect of the Hybrid SFLA in an updating process by using the angle and sigma in the updating process. The experiment uses the Benchmark function to try out the proposed method. This paper chooses the 4 Benchmark functions to test the proposed method. The experimental was shown in the graph convergence rate comparison shows the confluence of the proposed Hybrid SFLA with the 4 Benchmark function.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-19032-2_51,en,Generative Adversarial Networks as an Approach to Unsupervised Link Prediction Problem,OriginalPaper,"An unsupervised approach for the problem of link prediction in a graph representing a subject area is described. The approach is based on the usage of the generative adversarial networks architecture to generate vectors that can be transformed into a set of edges. The approach is validated on a graph built with the data extracted from a file archive. Main results achieved are discussed, together with advantages and disadvantages of the approach and potential prospects of the algorithm.","['Engineering', 'Computational Intelligence', 'Machine Learning', 'Neurosciences']"
doi:10.1007/978-981-19-3951-8_46,en,"A PSO-Optimized Fixed and a PSO-Optimized Neural Network-Adaptive Traffic Signal Controllers for Traffic Improvement in Santo Domingo, Dominican Republic",OriginalPaper,"Satisfying the mobility demand is one of the biggest concerns arising with the increase of urban population. With many people in the road network, traffic congestions are present in most of the cities in the world. The Distrito Nacional in Santo Domingo, capital city of Dominican Republic, is a notorious example of this phenomenon. Unfortunately, all the efforts to improve traffic experience there have had little success. With this work, two models have been developed using Particle Swarm Optimization (PSO): a PSO-Optimized Fixed Traffic Signal Control (PSO-FTSC) and a PSO-Optimized Neural Network-Adaptive Traffic Signal Control (PSO-NN-ATSC) that uses 4 neural networks to predict phase times. The intersection of 27 de Febrero Avenue corner with Winston Churchill Avenue was simulated using Simulation of Urban Mobility (SUMO), minimizing the time loss per vehicle during optimization. These models, PSO-FTSC and PSO-NN-ATSC, present reductions of 17% and 24% of mean time loss, respectively. These promising results may lead to a decrease of fuel consumption, reducing the consequent air pollution, as well as to an improvement of businesses and people’s productivity and mental health.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-981-16-9967-2_55,en,Fuzzy C-Means Clustering of Network for Multi Mobile Agent Itinerary Planning,OriginalPaper,"Mobile agent (MA) works potentially efficiently in reducing network bandwidth consumption for distributed computing. In an MA-based system, a small-sized processing code is transmitted through the network rather than the raw data. Using strong migration capability, MA’s processing code is being executed at each targeted node. Subsequently, useful and significant information is delivered to the intended user. Despite its benefit, MA has its issues also. Finding the appropriate number of MAs to be dispatched, the set of targeted nodes and their sequence of migration are the major issues related to multi-mobile agent itinerary planning (MIP). This paper tries to find a suitable number of MAs by considering the size of the data payload of a single MA and the load to be carried out by the MAs from the whole network. Moreover, this paper gives an idea of partitioning the given network into load balanced and nonoverlapping clusters using a fuzzy c-means clustering algorithm.","['Computer Science', 'Computer Systems Organization and Communication Networks', 'Computational Intelligence', 'Artificial Intelligence', 'Wireless and Mobile Communication', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-11295-9_6,en,Electronic Device Designed for Object Recognize and Navigation Assistant by Artificial Vision for People with Visual Impairment,OriginalPaper,"In this project, a prototype of object recognition and mobility aid is developed for people with visual disabilities using artificial vision, stereo vision, and neural networks. This prototype has two operation modes, the first generates obstacle-free routes using mobile robotics navigation algorithms and the second recognizes the objects that are around the user and indicates what type of objects there are and where they are placed in the work environment, this information is delivered to the user through spanish audio messages. The system design was developed in the Python programming language in a single board computer Raspberry pi 4B. The prototype has two web cameras that were used to acquire the visual environment.","['Social Sciences', 'Sociology, general', 'Urban Studies/Sociology']"
doi:10.1007/978-981-19-2225-1_15,en,A Novel Application of HPSOGWO Trained ANN in Nonlinear Channel Equalization,OriginalPaper,"In a communication channel, there is a possibility of distortions such as ISI, CCI, and another source of noise that interfere with useful signals, and the signal becomes corrupted. Therefore, equalizers are needed to counter such types of distortions. In this paper, we presented a nature-inspired hybrid algorithm which is an amalgamation of PSO and GWO. The proposed algorithm is called HPSOGWO. During this work, we pertain to ANN trained with the proposed HPSOGWO in the channel equalization. The foremost initiative is to boost the flexibility of the variants of the proposed algorithm and the utilization of proper weight, topology, and transfer function of ANN in the channel equalization. The performance of the proposed equalizer can be evaluated by estimating MSE and BER by considering popular nonlinear channels and added with nonlinearities. Extensive simulations show the performance of our proposed equalizer, better than existing NN-based equalizers also as neuro-fuzzy equalizers.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Statistics, general', 'Mobile and Network Security']"
doi:10.1007/978-981-19-3590-9_45,en,Secure Image Steganography Approach for Hiding Compressed Data,OriginalPaper,"Abdul-Zaher, Khadija M. El-MagdSewesy, Adel Abo Mohamed, Marghany Hassan Steganography is the technique of hiding a secret message inside a normal, non-confidential file, or message to avoid detection. The main challenge in steganography is to build a balanced system that resists attacks and hides a large amount of data while maintaining high quality. To overcome these challenges, many algorithms have been developed, some of which are better than others in a certain direction. In this chapter, an improved steganography approach is proposed where more than one method is combined to obtain a more secure algorithm with high quality and capacity. First, Gzip compression technique is used to compress the mystery message which increases the capacity of the proposed algorithm. Next, the p-Fibonacci method is used to randomize the locations of the pixels that hide the ambiguous message which improves the security of the proposed scheme. Then, the pixel value modification (PVM) technique with modulus function is used to embed the secret message raising the embedding capacity and quality. This approach overcomes the limitations of the previous methods because it is providing a secure with high embedding capacity system. To estimate the security of the proposed scheme, we used histogram, entropy, and chi-squared analysis to apply statistical attacks on the stego-image. Later, the experimental results show that the proposed methods provide high embedding capacity while maintaining good performance with large payload. For a payload of 204,800 B, we achieved a PSNR of 55.91 DB. The drawbacks of the previous methods are completely eliminated. The proposed scheme is more effective than previous steganography schemes in terms of quality, capacity, and security.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security', 'Mobile and Network Security']"
doi:10.1007/978-3-031-17576-3_10,en,Comparative Study on Arabic Text Classification: Challenges and Opportunities,OriginalPaper,"There have been great improvements in web technology over the past years which heavily loaded the Internet with various digital contents of different fields. This made finding certain text classification algorithms that fit a specific language or a set of languages a difficult task for researchers. Text Classification or categorization is the practice of allocating a given text document to one or more predefined labels or categories, it aims to obtain valuable information from unstructured text documents. This paper presents a comparative study based on a list of chosen published papers that focus on improving Arabic text classifications, to highlight the given models and the used classifiers besides discussing the faced challenges in these types of researches, then this paper proposes the expected research opportunities in the field of text classification research. Based on the reviewed researches, SVM and Naive Bayes were the most widely used classifiers for Arabic text classification, while more effort is needed to develop and to implement flexible Arabic text classification methods and classifiers.","['Engineering', 'Computational Intelligence', 'Machine Learning', 'Big Data']"
doi:10.1007/978-3-031-07258-1_79,en,Application of Nullspace-Based Fault Detection to an Aircraft Structural Part Under Changing Excitation,OriginalPaper,"A suitable combination of different methods and measurement techniques is often required for Structural Health Monitoring (SHM) of objects in situ. In the field of aerospace applications, the current research project “Combined acoustic and modal structure monitoring” is dealing with the development of a robust SHM system for damage identification in carbon-fiber-reinforced polymer (CFRP) structures under realistic and varying loads. The methods combined within the project are based on guided waves, acoustic emission, and different vibration monitoring techniques. The present paper deals with the application of the nullspace-based fault detection algorithm (NSFD) as a part of a holistic concept for the monitoring of an aircraft door surround structure. Due to the great sensitivity to changes in the statistical properties of the measured data, the algorithm reacts very sensitively to structural changes, but also to changes in the environmental conditions, such as changes in the external loads. In this paper, the impact of changing excitation conditions on the NSFD damage indicator is analyzed. Therefore, two different formulations for the NSFD algorithm are studied and compared concerning their sensitivity and robustness against changes of the external loads. Since the sensitivity and the results depend also on the algorithm set-up parameters, these are analyzed and taken into account. The evaluation of the results considers both, the robustness to the influence of the varying excitation and the sensitivity to damages in the analyzed structure. The theory and the algorithms are successfully tested with measured data sets from a CFRP-airplane structure.","['Engineering', 'Building Repair and Maintenance', 'Cyber-physical systems, IoT', 'Industrial and Production Engineering', 'Monitoring/Environmental Analysis', 'Analytical Chemistry']"
doi:10.1007/978-3-031-10004-8_2,en,Reconstruction Algorithms,OriginalPaper,"The idea of fluorescence molecular tomography (FMT) relies on the fact that the fluorophores may preferentially accumulate in diseased tissue such as tumors, hence providing enhanced sensitivity for disease detection. It is also true that the lifetime of fluorophores in tissue can potentially provide tissue functional information such as tissue oxygenation, pH, and enzyme. As indicated in Chap. 1 , a mathematical model-based reconstruction algorithm is crucial in FMT which allows for the formation of a spatial map of fluorophore concentration and/or lifetime in tissue. In this Chapter, we first briefly discuss linear algorithms and then describe in detail a nonlinear algorithm based on the iterative finite element solution to the fluorescent photon diffusion equation.","['Engineering', 'Biomedical Engineering and Bioengineering', 'Microwaves, RF and Optical Engineering', 'Imaging / Radiology', 'Biomedicine, general', 'Biological and Medical Physics, Biophysics']"
doi:10.1007/978-981-19-4960-9_22,en,In Silico Analysis for Identifying Influential Descriptors of PTP1b Enzyme in Diabetes,OriginalPaper,"Feature selection methods are useful for finding crucial elements in a model as well as reducing the model's complexity to improve accuracy. The variable selection algorithm chooses a few of the prediction variables to express a target variable. In this work, a high-dimensionality dataset of 82 PTP1b inhibitors with 358 variables known to exhibit anti-diabetic activity were selected to identify few influential descriptors as important variables necessary for inhibiting PTP1b enzyme, which is overly expressed in type-2 diabetes. Two feature selection algorithms such as caret and Boruta were employed in the study. Model based and model independent metrics were used to evaluate variable importance where it was observed that few common variables such as Ly, MR, ASP as being significant in describing the associated properties of PTP1b inhibitors. The RFE algorithm with backward selection process resulted in a 5-variable model with higher predictive ability based on low RMSE value of 0.3928 and high R -squared value of 0.8251. A multiple linear regression analysis using the top 5 most important variables resulted in R 2 value 0.6715. On the other hand, Boruta analysis on 82 PTP1b inhibitors with 358 variables resulted in nearly 38 variables as important features in defining activity contributions, however, the R 2 value was much lower than caret method. Hence, regression analysis and outlier test were performed based on features selected by caret method. Finally, it can be stated that caret algorithm is the better choice to select features when using high-dimensionality datasets.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Professional Computing']"
doi:10.1007/978-981-19-4863-3_17,en,A Hybrid Model of Latent Semantic Analysis with Graph-Based Text Summarization on Telugu Text,OriginalPaper,"In this paper, we are proposing a hybrid model of latent semantic analysis with graph-based xtractive text summarization on Telugu text. Latent semantic analysis (LSA) is an unsupervised method for extracting and representing the contextual-usage meaning of words by statistical computations applied to a corpus of text. Text rank algorithm is one of the graph-based ranking algorithm which is based on the similarity scores of the sentences. This hybrid method has been implemented on Eenadu Telugu e-news data. The ROUGE-1 measures are used to evaluate the summaries of proposed model and human-generated summaries in this extractive text summarization. The proposed LSA with Text rank method has a F 1-score of 0.97 as against the F 1-score of 0.50 for LSA and 0.49 of Text rank methods. The hybrid model yields better performance compared with the individual algorithms of latent semantic analysis and Text rank results.","['Engineering', 'Computational Intelligence', 'Engineering Design', 'Machine Learning', 'Communications Engineering, Networks']"
doi:10.1007/978-3-031-19620-1_27,en,Learning Adaptive Parking Maneuvers for Self-driving Cars,OriginalPaper,"This paper addresses the autonomous parking for a vehicle in environments with static and dynamic obstacles. Although parking maneuvering has reached the level of fully automated valet parking, there are still many challenges to realize the parking motion planning in the presence of dynamic obstacles. One of the most famous autonomous driving platforms is the Baidu Apollo platform. In the Apollo platform, this problem is solved using the classic method hybrid A*. However, this method has two main downsides. Firstly, it generates in some parking scenarios, trajectories that consist of many partitions with different gear types and sizes. Such trajectories are intractable by a self-driving car when testing the Apollo planner on more realistic data coming from a simulator such as SVL. Secondly, the built-in algorithm does not have the ability to interact with dynamic obstacles, which might lead to a collision in some critical parking scenarios. To overcome these issues, we proposed a method based on reinforcement learning, which uses the RL-policy (from POLAMP) allowing us to take into account the kinematic constraints of the vehicle, static and dynamic obstacles. The proposed method was fully integrated into the Apollo platform with developed Cyber RT nodes, which were used for publishing the parking trajectory from our algorithm to the SVL simulator through a ROS/Cyber bridge. The final model demonstrates transferability to the previously unseen experimental environments and flexibility with respect to built-in hybrid A*.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-15226-9_31,en,Application of Genetic Algorithm for Vector Field Guidance Optimization in a UAV Collective Circumnavigation Scenario,OriginalPaper,"Optimizing the trajectories of autonomous unmanned aerial vehicles (UAVs) in a decentralized cooperative tracking of a ground target is not a trivial undertaking. In this case, the UAV formation is a complex interconnected nonlinear system. This paper investigates a genetic algorithm for optimizing the trajectories of UAVs engaged in cooperative target tracking by means of vector field guidance, thus performing collective circumnavigation. Computational modeling shows that the genetic algorithm can effectively address trajectory optimization. Post-optimization reduction in the fitness function value is noted. Another finding is that it is necessary, when tuning the UAV heading controllers, to minimize not only the error of distance to the circular path around the target but also the relative inter-UAV distance error.","['Engineering', 'Control, Robotics, Mechatronics', 'Robotics', 'Computational Intelligence']"
doi:10.1007/978-981-19-5574-7_2,en,Adaptive Mixed Edge Detection of Furnace Flame Image,OriginalPaper,"Edge Furnace  detection is one of the major research field in image processing. Through edge detection, the target area and background area can be effectively divided. Besides, the contour and shape of the target area can also be obtained, which provides a basis for calculating the centroid and other important position parameters of the target area. However, due to the complexity of the furnace Furnace  environment in coal-fired power plants Coal-fired power plant , the existing edge detection algorithms generally can not be directly used to deal with discontinuous edges, coarse edges, false edges, etc.","['Engineering', 'Control, Robotics, Mechatronics', 'Energy Systems', 'Computational Intelligence']"
doi:10.1007/978-3-031-20257-5_2,en,Evaluation Test Generation Model Using Two Intervals of Difficulty and Keywords,OriginalPaper,"The Covid-19 pandemic has brought to light some of the shortcomings in the educational systems. One of these is related to the evaluation methods that are outdated and lack efficiency. The solution, proposed in this paper, uses two intervals of difficulty and a list of keywords as part of the input for a genetic algorithm. Each question in the returned list respects certain rules regarding its difficulty and it belongs to a certain selected topic, described by one or more keywords. Also, as a genetic algorithm requires its setting parameters, this paper analyses the impact of each of them on the final result.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16868-0_13,en,Encoding Space Based on Directed Acyclic Graphs,OriginalPaper,"Although CNN-GA [ 1 ] is totally automated, the generated architectures have a restricted connectional structure since it employs an encoding strategy that encodes the building blocks into a linked list that can be extended to any depth during the process of evolution. Each linked list encoding building block is a “skip layer” or a pooling layer, where the skip layer containing a skip connection and two convolutional layers [ 1 ].","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4676-9_43,en,Privacy Conserving Using Fuzzy Approach and Blowfish Algorithm for Malicious Personal Identification,OriginalPaper,"As we know that when we exchange data through the network, system needs more security and approval. Generally, crisp algorithms are used for extraction and identification of data. When we use crisp logic, it is very complex and tedious work, so we recommend a Fuzzy approach for data extraction. Security is the main part of data exchange. In this article, we have to discuss how Fuzzy logic is used in Blowfish algorithm to secure communication. Multimodal images use the rules of the Fuzzy logic Fuzzy inference system to design a 64-bit Blowfish algorithm that increases security and improves performance. This algorithm helps protect data from unauthorized access and runs faster. Our proposed algorithm is designed using MATLAB R2017a. We also discussed the pros and cons of Fuzzy and Blowfish.","['Engineering', 'Computational Intelligence', 'Systems and Data Security', 'Artificial Intelligence', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-981-19-3632-6_68,en,Analysis and Comparison of Automatic Image Focusing Algorithms in Digital Image Processing,OriginalPaper,"The selection of image focus discrimination function is the basis for obtaining high-quality images in automatic image scene measurement. The performance of several digital image processing algorithms for automatic image focus discrimination is compared comprehensively, and the calculation speed, uniqueness, accuracy and sensitivity of different algorithms are analyzed quantitatively. Firstly, this paper briefly summarizes the imaging principle and focusing principle of digital image processing automatic image focusing, and then from the image information entropy function, gray gradient function, frequency domain evaluation function, and other evaluation functions. Finally, the area selection and focus search algorithm of digital image processing window are described from the aspects of depth of field and focal depth, algorithm selection and algorithm improvement direction. The above analysis results of the characteristics of image focusing discriminant function have guiding significance for the automatic focusing control required by image automatic measurement.","['Engineering', 'Cyber-physical systems, IoT', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing']"
doi:10.1007/978-981-19-4193-1_32,en,Chaos-Based Image Encryption with Salp Swarm Key Optimization,OriginalPaper,"Substantial data is being transferred across the unsecured channel; with this considerable data transfer comes the need to protect this data. Thus, to achieve security during transmission, several encryption algorithms have been proposed. Chaos-based maps are widely employed for multimedia encryption due to their characteristics, like pseudo-randomness sensitivity to initial conditions. Inspired by researchers, we proposed an image security algorithm based on a chaotic tent map integrated with the Salp Swarm Algorithm (SSA) for key generation and optimization, for grayscale images. A diffusion and permutation are carried out in each round to make it secure. A simple XOR function is applied to encrypt and decrypt the data. Different statistical analysis has been applied to images, and results has been discussed to justify proposed techniques effectiveness.","['Engineering', 'Computational Intelligence', 'Information Storage and Retrieval', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Data Structures and Information Theory', 'Artificial Intelligence']"
doi:10.1007/978-981-19-0448-6_9,en,Energy-Efficient User Scheduling and Power Control for Multi-Cell OFDMA Networks Based on CDI,OriginalPaper,"In this chapter, we investigate the energy-efficient user scheduling and power control for multi-cell orthogonal frequency division multiple access (OFDMA) networks based on channel distribution information (CDI). Section  9.1 introduces the motivation of developing energy-efficient user scheduling and power control with CDI. Section  9.2 presents the system model and formulates the problem. Section  9.3 develops the centralized joint user scheduling and power control algorithm, and Sect.  9.4 develops the decentralized power control scheme. Section  9.5 presents the simulation results, and Sect.  9.6 concludes this chapter.","['Engineering', 'Wireless and Mobile Communication', 'Energy Systems']"
doi:10.1007/978-981-19-3998-3_36,en,Similar Formation Problem with Biased Random Measurement Errors,OriginalPaper,"The similar formation problem affected by biased random measurement errors is studied in this paper. In practical application, the measurement data of agents is disturbed by biased random errors, which invalidates the existing similar formation algorithm. Hence, an improved similar formation algorithm is designed in this paper to eliminate the influence of biased errors. Based on the 2-rooted measurement topology, communication edges and measurement edges are appropriately added. Then, using the geometric relationship between agents, agents convert biased random errors into unbiased random errors online. Moreover, the decreasing gain of the algorithm ensures that agents can asymptotically converge to a similar formation of the generic target formation in the sense of mean square. The numerical simulation verifies the conclusion of this paper.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-981-19-2879-6_8,en,Huawei CLOUD Enterprise Intelligence Application Platform,OriginalPaper,"This chapter mainly introduces Huawei CLOUD Enterprise Intelligence (EI), including Huawei CLOUD EI service family. It focuses on Huawei ModelArts platform and Huawei EI solutions.","['Computer Science', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5751-2_8,en,Multi-objective Bi-directional V2G Behavior Optimization and Strategy Deployment,OriginalPaper,"The mitigation of peak-valley difference and power fluctuations are of great significance to the economy and stability of the power grid. The concept of the vehicle to grid (V2G) technology makes it possible to integrate electric vehicles (EVs) into the grid as distributed energy resources and provide power balancing service to the grid. This chapter introduces a V2G scheduling approach that can provide power balancing services to the grid while mitigating the battery aging phenomenon. Firstly, an intelligent V2G behaviour management framework is presented, which enables the comprehensive utilization of prediction information in V2G scheduling. Then, a commonly used multi-objective V2G behavior optimization model is introduced, in which minimal battery degradation and grid load fluctuation are the optimization objectives. Meanwhile, a multi-population collaborative mechanism, which is particularly designed for the V2G scheduling problem and has been proved effective in previous literature, is also introduced to improve the performance of the heuristic optimization-based V2G scheduling model. Two commonly used real-time strategy deployment methods: fuzzy logic and neural network, are further introduced for online V2G scheduling. With the presented methods, grid-connected electric vehicle (GEV) energy storage capacity can be scheduled to provide power balancing services to the grid while significantly mitigating battery aging.","['Engineering', 'Control, Robotics, Mechatronics', 'Mechanical Engineering', 'Automotive Engineering', 'Cyber-physical systems, IoT', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-3951-8_64,en,Performance Evaluation of Sine Cosine Algorithm-Based Controllers for LFC in an Isolated Hydropower System Integrated with Energy Storage System,OriginalPaper,"In this paper, performance evaluation of I, PI, and PID controllers have been carried out for load frequency control (LFC) in an isolated hydropower generating system (HPGS). The primary objective of LFC is to maintain the electrical power system frequency at a pre-specified level. A population-based bio-inspired optimization algorithm called sine cosine algorithm (SCA) has been utilized for the optimization of I, PI, and PID controllers. The integral of time-squared absolute error (ITSE) has been considered as an objective function in this study for the optimization process. Load disturbance of 20% has been considered in an isolated HPGS for performing various simulation studies. The system under study is also integrated with a superconducting magnetic energy storage system (SMES). The effects of adding SMES in an isolated HPGS have been analyzed. From the results obtained, it has been observed that the SCA optimized PID controllers perform better as compared to SCA optimized I and PI controllers for LFC in the system under consideration. Also, by adding an energy storage system, there is a considerable reduction in the value of ITSE, peak undershoot, peak overshoot, mean value, peak to peak value, and RMS value of the system’s dynamics.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5303-3_4,en,ECG Signal Detection and Lossless Data Compression Techniques for Implantable Cardiac Pacemaker Systems,OriginalPaper,"The current trends and medical scenarios have given birth to several QRS-complex detection algorithms. The striking feature of all these detection algorithms is reduced power consumption which is an enabler of wearable devices. The research in wearable devices has integrated both unified lossy and lossless data compression techniques together. The research advancements in cardiac health monitoring have made it quantifiable to note the reduction in the sensor power by 2–5 times. It is comprehended that implementation and combination of two distinct hardware setups for QRS-complex detection and compression lead to increased system computations and power. Therefore, it is of utmost importance to have a joint QRS-complex detection and lossless data compression algorithm. In this chapter, an improved wavelet transform-based joint ECG detection, and data compression algorithm applicable for the implantable cardiac pacemaker system is presented.","['Engineering', 'Circuits and Systems', 'Biomedical Engineering and Bioengineering', 'Signal, Image and Speech Processing']"
doi:10.1007/978-981-19-7083-2_3,en,Evolutionary Multi-objective Federated Learning,OriginalPaper,"Different from model quantization and partial model uploads presented in the previous chapter, evolutionary federated learning, more specifically, evolutionary federated neural architecture search, aims to optimize the architecture of neural network models, thereby reducing the communication costs caused by frequent model transmissions, generating lightweight neural models that are better suited for mobile and other edge devices, and also enhancing the final global model performance. To achieve this, scalable and efficient encoding methods for deep neural architectures must be designed and evolved using multi-objective evolutionary algorithms. This chapter presents two multi-objective evolutionary algorithms for federated neural architecture search. The first one employs a probabilistic representation of deep neural architectures that describes the connectivity between two neighboring layers and simultaneously maximizing the performance and minimizing the complexity of the neural architectures using a multi-objective evolutionary algorithm. However, this evolutionary framework is not practical for real-time optimization of the neural architectures in a federated environment. To tackle this challenge, a real-time federated evolutionary neural architecture search is then introduced. In addition to adopting a different neural search space, a double sampling strategy, including sampling subnetworks from a pretrained supernet and sampling clients for model update, is proposed so that the performance of the neural architectures becomes more stable, and each client needs to train one local model in one communication round, thereby preventing sudden performance drops during the optimization and avoiding training multiple submodels in one communication round. This way, evolutionary neural architecture search is made practical for real-time real-world applications.","['Computer Science', 'Machine Learning', 'Privacy', 'Cryptology']"
doi:10.1007/978-981-19-3387-5_2,en,HDR Fusion Algorithm Based on PCNN and over Exposure Correction,OriginalPaper,"For traditional HDR fusion algorithm based on mapping functions, the artificial determination of the over exposure region often ignores the spatial distribution and the relation of pixels of the image brightness. In this paper, a stimulated HDR fusion algorithm based on pulse coupled neural network is proposed. For the proposed algorithm, first obtain the external stimuli according to the maximum image brightness, calculate whether the pixel “fires” or not and determine the over exposure region. Then alter the value of external stimuli to perform iteration and construct judgment matrix to make sure that every pixel in the image “fires”. The image irradiance is linear with the illuminance and exposure time. Obtain the brightness mapping function using linear fitting, and synthetize HDR image with over exposure correction algorithm to eliminate artifacts. The algorithm mainly has the following advantages: 1. It fully considers the spatial distribution of the image brightness. 2. For the imaging of different scenes, it self-adapts to separate exposure regions. 3. It performs mapping according to the imaging principles and obtains the mapping function without the exposure time. 4. It reduces the quantitative error of synthetizing image, and the artifacts in the transition region. The algorithm proposed in this paper is experimented under multiple scenes, and the image entropy and spatial frequency are improved greatly.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Aerospace Technology and Astronautics']"
doi:10.1007/978-981-19-3998-3_72,en,Differentially Private Distributed Online Linear Regression over a Time-Varying Network,OriginalPaper,"This paper investigates the problem of private distributed online linear regression over a time-varying network consisting of several connected nodes, in which the scenario of full information feedback is taken into account. The goal is that each node is able to yield a linear predictor fitting the network-wide data accurately while the privacy of the participating nodes can be preserved. To achieve this goal, we design a differentially private distributed online linear regression algorithm. Moreover, we show that the proposed algorithm is $$\varepsilon $$ ε -differentially private and attains a regret upper bound in $$\mathcal {O}(\sqrt{T})$$ O ( T ) for general convex local loss function, where T is the total number of iterations. Finally, the effectiveness of the developed algorithm is verified through a numerical experiment.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-981-19-5403-0_24,en,Optimal Path Planning with Smart Energy Management Techniques Using Dijkstra’s Algorithm,OriginalPaper,"The classical Dijkstra’s algorithm is a well-known popular algorithm for finding shortest path in any research area. But in many situations, it was observed that though Dijkstra’s algorithm provides the shortest path from source to destination, the path produced huge energy consumption because of road condition and different route parameters. In such cases, there is a need of consideration of some parameters like road condition, traffic congestion, and route parameters with Dijkstra’s algorithm for finding shortest path with minimum energy consumption. In this context, authors proposed an optimal path planning with smart energy management techniques using Dijkstra’s algorithm. In this paper, proposed method provides shortest path with minimum energy consumption considering all route parameters. The proposed technique not only improves the efficiency of the vehicles but also provides the optimal utilization of available resource.","['Engineering', 'Computational Intelligence', 'User Interfaces and Human Computer Interaction', 'Data Structures and Information Theory', 'Artificial Intelligence', 'Data Mining and Knowledge Discovery']"
doi:10.1007/978-981-19-4147-4_47,en,Multi Parametric Optimization of Dry Turning of Titanium Alloy (Ti6Al4V Graded 5) using Coated Carbide Insert: A Novel Hybrid RSM-Artificial Gorilla Troop Optimization and Dingo Optimization Algorithm,OriginalPaper,"The present research piloted dry turning of titanium alloys (Ti-6Al-4V Grade 5) utilizing modern titanium carbonitrides chemical vapor deposition (MT-CVD) coated carbide tool inserts. The impacts of cutting parameters such as feed rate, cutting speed, and depth of cut on output responses such as cutting forces, flank wear, and surface roughness were investigated using a Box-Behnken design based on response surface methodology (RSM). To find the optimum cutting condition, a newly developed hybrid optimization method, namely RSM-linked Artificial Gorilla Troop Optimization Algorithm and Dingo Optimization Algorithm, was utilized. The flank wear along with cutting force was recorded when the depth of cut was less while better surface finish was achieved with lower cutting speed. Additionally, analysis of variance was used to determine the most important component in each of the three responses, followed by a confirmatory test that revealed a high degree of agreement between anticipated and experimental results. As per the analysis of variance (ANOVA) results, the depth of cut was determined to be the most crucial component in attaining the lowest cutting force, flank wear, and surface roughness responses. The results obtained using the artificial gorilla optimization algorithm and the dingo optimization algorithm are found to be more precise than those obtained using the RSM-designed experimentation of dry turning operations, as cutting force, surface roughness, and flank wear have been minimized by utilizing the factor settings achieved using both the artificial gorilla optimization algorithm and the dingo optimization algorithm.","['Engineering', 'Materials Engineering', 'Robotics and Automation', 'Structural Materials', 'Biomaterials']"
doi:10.1007/978-981-19-3387-5_169,en,Application of Improved GRNN Algorithm for Task Man-Hours Prediction in Metro Project,OriginalPaper,"In order to improve the accuracy and efficiency of subway project task man-hours prediction, a generalized regression neural network (GRNN) prediction model based on the improved Sparrow Search Algorithm is proposed. And a prediction study was carried out on the task man-hours of subway projects, and the factors affecting the design task man-hours were analyzed by taking the architectural profession as an example. The algorithm of this paper was used to predict. The results show that the improved GRNN algorithm proposed in this paper has a smaller error and a higher accuracy, and it has great potential for application in the prediction of the task man-hours of subway projects.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Aerospace Technology and Astronautics']"
doi:10.1007/978-981-19-3998-3_89,en,Hierarchical Planning Strategy Based on Differential Game for UAV Swarm,OriginalPaper,"UAV swarm confrontation is undoubtedly the most important part of future warfare, so the research on large-scale UAV confrontation is of great significance. This paper mainly discusses the scheduling strategy of interceptor UAVs and proposes a hierarchical planning algorithm based on differential game theory. After dividing the global map into regions, the map information is processed through the network density evaluation model(NDEM), then use the improved D* algorithm to search for the path. In each local region, we utilize the differential game theory to determine the optimal path. The algorithm realizes the rapid and uniform distribution of large-scale UAVs and provides an effective method for efficient interception.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-981-19-3998-3_61,en,Cooperative Path Planning Algorithm of UAV in Urban Environment Based on Improved Pigeon Swarm Algorithm,OriginalPaper,"For the urban environment with dense obstacles, narrow space and complex air flow, the UAV cooperative path planning method is studied. The selection method of cooperative path in urban environment is proposed. A multi UAV cooperative path planning method based on Cauchy mutation pigeon intelligent optimization algorithm (ECM-PIO) is proposed, which avoids the optimization deviation of the traditional pigeon swarm algorithm in the process of path optimization and overcomes the disadvantage that the traditional pigeon swarm algorithm is easy to fall into local optimization. The simulation results verify the advancement of the proposed cooperative path planning method of UAV in urban environment based on ECM-PIO.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-981-19-2821-5_39,en,Computation Offloading Scheme Classification Using Cloud-Edge Computing for Internet of Vehicles (IoV),OriginalPaper,"In recent years, there is development in the field of computing devices; Internet of Things (IoT) becomes the latest trend. IoT comprises ubiquitous things that are associated with day-to-day life of individuals like smartphones, smart TV, laptops, and now vehicles too. Internet of Vehicles (IoV) has become the latest area of research used to develop applications in the field of traffic management and road safety. A collaborative approach of cloud and edge computing is termed cloud-edge computing. To manage the enormous amount of IoT devices and the coordination among IoT, the cloud and edge concept of computation offloading is required. In the process of computation offloading, tasks are computationally offloaded to the cloud data center that enhances the resource utilization of the cloud server and minimizes the energy utilization for the tasks. This paper represents the literature review related to various computational offloading schemes in cloud-edge computing proposed as part of the study. The resources comprise of related book chapters and research papers from different publishers of international and national reputes. The study is carried out with the analysis of various computation offloading schemes in cloud-edge computing for the Internet of Vehicles. In addition, computing technologies like cloud computing, edge computing, and computation offloading for the Internet of Vehicles (IoV) were also discussed.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-3-031-19067-4_2,en,"Calculus, Probability and Order Statistics Review",OriginalPaper,"In this chapter, we will begin by reviewing some concepts from calculus and probability that are essential to understanding the error and runtime analyses of various distributed SGD algorithms that we will study in the rest of the book.","['Mathematics', 'Algorithms', 'Machine Learning', 'Algorithm Analysis and Problem Complexity', 'Artificial Intelligence', 'Probability Theory and Stochastic Processes', 'Computer Science, general']"
doi:10.1007/978-981-19-0095-2_4,en,Real-Time Assessment of Live Feeds in Big Data,OriginalPaper,"An extremely challenging proposition is constructing a functional, well-designed, and reliable big data application that supplies to a variety of end-user latency necessities. Let alone constructing applications that work for the problem at hand, it can be discouraging plentiful to just keep up with the fast pace of technology innovation happening in this space. But, there are assured high-level architectural concepts that can help to imagine how diverse types of applications fit into the big data architecture and how several of these technologies are renovating the existing enterprise software scene. Big data analytics is used to gather valuable findings, identify trends and detect patterns from the ocean of information. Proficient operators say its vital to assess the prospective business significance that big data software can offer. This paper presents a study of the lambda architecture enterprise design to build a data-handling back-end on cloud, assuring intense, high throughput, and dense data demand provided as services. This paper also covers the advantages proposed by the lambda architecture and how effectively it can be used across wide range of use cases across the industry. Based on the experience gathered during this research—this paper also discusses the challenges those would be posed by lambda architecture.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Systems and Data Security', 'Artificial Intelligence', 'Computational Intelligence']"
doi:10.1007/978-3-031-07258-1_54,en,A Virtual Reality Environment for Developing and Testing Autonomous UAV-Based Structural Inspection,OriginalPaper,"Unmanned aerial vehicles (UAVs) equipped with imaging and laser sensors have shown their benefits in structural health inspection due to their aerial mobility, low cost, and efficiency. However, UAV applications in practice are limited by their level of automation, and man-piloted operation dominates to date. With vehicle automation on the horizon, autonomous structural inspection systems via robotic vehicles have become a possibility. Nonetheless, significant challenges exist for testing and validating in a physical environment. This paper proposes a virtual reality framework for developing autonomous UAV-based structural health inspection systems. The framework, built atop a gaming engine, implements algorithmic virtual sensing and control of a UAV that flies virtually in a complex built environment. In this paper, we test this framework with a virtual UAV with an open-loop control approach for structural health inspection, including waypoint-based control and simultaneous localization and mapping. We further discuss its full potential as an aerial robotics learning and validation platform for developing advanced data-enabled structural-space exploration, optimal control, and damage assessment.","['Engineering', 'Building Repair and Maintenance', 'Cyber-physical systems, IoT', 'Industrial and Production Engineering', 'Monitoring/Environmental Analysis', 'Analytical Chemistry']"
doi:10.1007/978-981-19-2065-3_46,en,Reviewing Fake News Classification Algorithms,OriginalPaper,"Fake news is a terminology that has a different meaning to different people. At its bb in part because they are so easily and quickly shared online. In this paper, we propose a method of classifying fake news using Passive Aggressive classifier (PAC) [ 1 ] and afterward we also compare the results given by this model with machine learning classification algorithms like Naïve Bayes, Decision Trees Classifier (DTC), Random Forest Classifier (RFC), K-Nearest Neighbor (KNN), Support Vector classifier (SVC), Logistic Regression and Deep Learning algorithms like Long Short-Term Memory (LSTM) and Bi-Directional LSTM. ‘Bag of Words’ and TF-IDF technique are used to convert the textual data into vectors.","['Engineering', 'Communications Engineering, Networks', 'Artificial Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Machine Learning']"
doi:10.1007/978-981-19-5090-2_19,en,Sentiment Analysis to Find Sentence Polarity on Tweet Data,OriginalPaper,"In this present age, everyone uses social media. Whilst ideas spread through these mediums can be colourful, there are certain views of people which are shared with a tone of negativity, mischief and offensiveness to them as well. One of the most used of such social media platforms include Twitter, which is a platform where messages with limited word limit are sent by the people. This present work, thus, is about analysing the polarity of a tweet by using millions of data achieved through Natural Language Processing (NLP). We collected a large dataset of tweets which are marked by levels of polarity from negative to positive. We use Machine Learning algorithms on this dataset to detect the polarity of the tweet. Here we have used Multinomial Naïve-Bayes, Complement Naïve-Bayes and Logistic Regression classifier to find the polarity of tweets. The dataset size is 1.6 million and we got the best result using Logistic Regression. The highest accuracy is 78.05%.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Artificial Intelligence', 'Data Structures and Information Theory']"
doi:10.1007/978-3-031-17554-1_12,en,Information Technology Platform for Automation of Decision-Making Processes by the Organizational Management System,OriginalPaper,"The chapter examines the development problems of specialized tools for mathematical and computer modeling, information technology support for automation of the preparation and decision-making process by appropriate organizational management systems (OMS) with advanced tools for meaningful data processing and user interface of competitive electricity market participants operating in complex relationships and potential risks. The peculiarities of the electricity market functioning are determined, which require advanced computer simulation tools that provide market participants with the opportunity to formulate and accept strategies for their own behavior in different segments of the competitive market. Existing solutions and research in the field of creating modern software tools for modeling, forecasting and optimizing the functioning of energy markets in the world are analyzed. The development direction of such tools is determined and the structural-functional composition of the information technology platform for OMS is proposed, that is represented by the functional components of the preparation and decision-making process to develop a strategy for market participant`s own behavior on its segments. The basics of creating an information technology platform for building decision support systems (DSS) for energy companies as entities/subjects of the electric energy market, a feature of which is a new formalization of the components of the DDM (Data-Dialog-Model) paradigm, are considered. In particular, typical operations of the decision maker interaction in the performance of functional tasks that are interrelated with data processing methods are classified. A unified model of the DSS data structures is proposed, which defines common approaches to representing market entities at all management levels through the selection of their properties and relationships and creation of a unified system of classifiers, reference catalogs that ensure the operation of the entire set of mathematical models of computational and analytical problems that are logically and informationally interconnected between itself according to its intended purpose, input and output data parameters of energy companies on the market, optimization and forecasting algorithms.","['Energy', 'Energy Systems', 'Energy Policy, Economics and Management', 'Control and Systems Theory']"
doi:10.1007/978-3-031-08093-7_10,en,Towards Managing Covid-19 Using Artificial Intelligence and Big Data Analytics,OriginalPaper,"Coronavirus Diseases (COVID-19) is an infectious disease caused by a newly discovered coronavirus that becomes world pandemic with 200 countries recorded affected, and nearly 1 million people died. Starting from Wuhan in December 2019, within three months, the spread across global with high reproduction rates (R Rates). There is evidence in one case, it spread to more than 100 people and creates his pandemic cluster. As the pandemic contributes to a large volume of data, Artificial Intelligence (AI) and Big Data Analytics (BDA) play a huge role in understanding the pan-demic to help necessary action can be deployed. Researchers and developers are increasingly using artificial intelligence, machine learning, and natural language processing to track and contain coronavirus and gain a more comprehensive understanding of the disease. So far, due to new diseases, there is a limited study to cover how AI and BDA will help in fighting COVID-19. Therefore, we provide a comprehensive analysis of the existing and potential of using AI and BDA to manage the COVID-19 outbreak based on COVID-19 Outbreak Life Cycle phases; detection, spread, management, recovery. We also presented the challenges needed to be overcome for BI in BDA in the fighting. To conclude, these findings show the necessity of AI and BDA as a critical tool to understand COVID-19 and there a lot of ongoing intensive works have been carried out to cope with COVID-19.","['Engineering', 'Mathematical and Computational Engineering', 'Business Mathematics', 'Data Engineering']"
doi:10.1007/978-981-19-3951-8_29,en,A Hybrid Model for Review Analysis Using Deep Learning,OriginalPaper,"Consumer reviews are shown to be critical for a variety of business applications. When product opinions/reviews are considered, purchase decisions are better. Reviewing client feedback, on the other hand, aids in enhancing sales and, as a result, benefits the company. A platform is provided by the e-commerce giants such as Flipkart, Amazon, where the users can share their experiences and provide real insights about the performance of a product to future buyers. A greater understanding of the technologies employed in sentiment analysis is required to computationally assess the sentiments in the text which is highly unstructured data. For sentiment analysis, machine learning and deep learning algorithms are commonly utilised. Lexicon-based techniques are also used for the same purpose depending on the text and the desired outcomes. A hybrid approach is presented in this work, providing a platform to rate and publish reviews about the product with utmost transparency. For sentiment classification of reviews, a deep learning model convolutional neural network (CNN) in conjunction with long short-term memory (LSTM) is discussed. In the proposed work, over 4,00,000 reviews have been classified into positive and negative sentiments.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-3-031-04780-0_1,en,System Engineering Basics,OriginalPaper,"The design of a spacecraft control system is first of all a system engineering task. In the first chapter, we describe the most important system engineering aspects, such as mission objectives, interfaces and functional architecture of a control system, and important system design rules. In this context, we focus on attitude control.","['Engineering', 'Mechanical Engineering', 'Aerospace Technology and Astronautics']"
doi:10.1007/978-981-19-0151-5_4,en,Analysis of Machine Learning and Deep Learning Algorithms for Detection of Brain Disorders Using MRI Data,OriginalPaper,"Brain diseases impact more than 1 billion people worldwide and include a wide spectrum of diseases and disorders such as stroke, Alzheimer’s, Parkinson’s, Epilepsy and other Seizure disorders. Most of these brain illnesses are subjected to misclassification, and early diagnosis increases the possibilities of preventing or delaying the development of these disorders. Magnetic Resonance Imaging (MRI) plays an important role in the diagnosis of patients with brain disorders and offers the potential of non-invasive longitudinal monitoring and bio-markers of disease progression. Our work focuses on using machine learning and deep learning techniques for the preemptive diagnosis of Schizophrenia using Kaggle data set and Alzheimer’s using TADPOLE data set comprising of MRI features. Since the number of works using TADPOLE data set is minimum, we have chosen this for our study. Machine learning algorithms such as support vector machine (SVM), Decision Tree, Random Forest, Gaussian Naive Bayes, and 1D-CNN deep learning algorithm have been used for the classification of the disorders. It has been observed that Gaussian NB performed the best on Schizophrenia data, while Random Forest outperformed on Alzheimer’s data compared to the other classifiers.","['Engineering', 'Biomedical Engineering and Bioengineering', 'Artificial Intelligence', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Biological and Medical Physics, Biophysics', 'Information Storage and Retrieval']"
doi:10.1007/978-3-031-19032-2_41,en,Integration of Data and Algorithms in Solving Inverse Problems of Spectroscopy of Solutions by Machine Learning Methods,OriginalPaper,"This study presents the results of solving the inverse problem of determining the concentrations of heavy metal ions of multicomponent solutions by their Raman and absorption spectra using integration of machine learning algorithms and integration of optical spectroscopy methods. It is shown that if the integrated methods differ much by their accuracy, then their integration is not effective. This is observed both for algorithmic integration and for integration of physical methods.","['Engineering', 'Computational Intelligence', 'Machine Learning', 'Neurosciences']"
doi:10.1007/978-3-031-16598-6_15,en,Digital Transformation in Tourism: An Intelligent Information System Proposition for Hotel Organizations,OriginalPaper,"The digital transformation process in the tourism industry has been developing further in recent years. In addition to the active use of traditional information technologies, access to data has become relatively easy thanks to the use of smart technologies in this sector, and it has become even more important to interpret this data and improve visitor experiences in line with visitors’ expectations. In this study, which is based on the digitalized tourism perspective called Tourism 4.0 and Smart Tourism, following the Industry 4.0 prospect, digital transformation and the role of digital tools in the accommodation dimension of the tourism sector is discussed and it is aimed to propose an end-to-end smart management system. Thanks to this system which is composed of multiple data collection tools, a relational database for data storage, and interspersed information system modules including a recommendation system, the preferences of the users could be examined to achieve maximum customer satisfaction, and it could be possible to make suggestions for better spending their time in their current visits in line with their preferences. The uniqueness of the chapter is that it simulates the end-to-end digitalization process of accommodation businesses, which is an aspect that has not been discussed in the literature before.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-07322-9_49,en,Hybrid Training of Supervised Machine Learning Algorithms for Damage Identification in Bridges,OriginalPaper,"Hybrid approaches for training machine learning algorithms to identify damage in bridges rely on the use of both monitoring and numerical data. While monitoring data account for normal operational conditions of the undamaged structure, numerical data are often confined to scenarios that seldom occur in the lifespan of the bridge, like extreme temperature events or damage, although previous research of the authors showed it can also be used to augment the data acquired under regular service. This paper presents a hybrid approach for damage identification and applies it to Z-24 Bridge. To enable the classification of damage, supervised learning algorithms are employed. Unlike unsupervised learning, which relies on unassigned data and is suited for novelty detection, supervised learning uses labeled data corresponding to undamaged and damaged scenarios of the structure, enabling the transition from damage detection and localization to damage type and severity. A hybrid database is constructed using monitoring and numerical data corresponding to undamaged scenarios and numerical data corresponding to damage scenarios. The damage scenarios comprise various degrees of settlement of a bridge pier and a landslide near the same pier. Several common supervised learning algorithms are trained with the hybrid data and a comparison of the results is provided.","['Engineering', 'Building Repair and Maintenance', 'Cyber-physical systems, IoT', 'Industrial and Production Engineering']"
doi:10.1007/978-3-031-16865-9_52,en,QR Codes Cryptography: A Lightweight Paradigm,OriginalPaper,"A QR Code is a two-dimensional barcode scanned by a digital device or smartphone that holds data as a sequence of pixels in a square-shaped pattern. QR codes are widely employed in commercial tracking systems, encoding URLs, contact information, map coordinates, and physical and digital documents. Nowadays, several smartphones have built-in QR readers; they are often employed in marketing and advertising campaigns. More recently, QR codes have recreated a critical role in tracing COVID-19 pandemic exposure and slowing the spread of the virus. Web attackers can encode malicious URLs of custom malware or phishing site into a QR code, which could violate or disclose personal or financial information on a smartphone’s data when scanned. This study investigates several symmetrical lightweight cryptography (LWC) algorithms to enhance QR code protection. Modern well-defined LWC features (performance and security) are compared and evaluated. The results adopt reliable and safe mechanisms for QR codes’ security issues.","['Engineering', 'Computational Intelligence', 'Data Engineering']"
doi:10.1007/978-3-031-19958-5_17,en,Detecting Spam SMS Using Self Attention Mechanism,OriginalPaper,"Short Message Service (SMS) is swiftly emerging as the most secure method of communication due to its extensive coverage, dependability, and power efficiency. When compared to application to person (A2P) communications, person to person (P2P) texting is less secure, allowing anyone to send messages, which could result in an assault. Spammers take use of this chance to transmit dangerous content, engage in destructive actions, and harass others. Furthermore, such messages might waste a lot of time, and vital messages can be missed. Therefore, reliable spam identification in SMS has emerged as a critical issue. More recent extension of self–attention mechanism in transformer increases the ability of context in natural language processing. Transformer such as Bidirectional Encoder Representations from Transformers (BERT) works better than Recurrent Neural Networks (RNNs) and Convolutional Neural Networks (CNNs) for its scanning ability in both order (left to right, right to left) and generating context. This paper interpreted a spam detection model based on self mechanism using BERT on kaggle dataset. Our proposed model outperforms than the machine learning algorithms and deep learning with accuracy 98.80%.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-14630-5_13,en,Mediatization: From Gutenberg to Unlimited Media and Datafication,OriginalPaper,"Since the birth of modern media until Internet, communication has been profoundly transformed and through it culture, society, forms of power and the creation of economic wealth. This essay examines this long-lasting process by exploring the idea of mediatization. It is a historical movement of co-implication of symbolic forms, technologies, contexts and communicative frameworks that has altered communication practices, their scope and meanings through the introduction and reception of new technologies (mechanical, electrical, digital) and by institutions (publishers, media companies, propaganda and public relations bureaux, advertising, technological platforms). We argue that it is a non-linear process, with several stages, intensified in our days, with aspects very critical to freedom and democracy, but whose outcome is open.","['Philosophy', 'Philosophy of Technology', 'Science and Technology Studies', 'History of Technology']"
doi:10.1007/978-981-19-1412-6_12,en,Diabetes Mellitus Prediction Through Interactive Machine Learning Approaches,OriginalPaper,"Diabetes is a long-term illness that has the potential to disrupt the global healthcare system. Based on the survey report of International Diabetes Federation (IDF), there are around 382 millions of people, who are affected by diabetes worldwide. This number will have increased to 592 million by 2035. Diabetes is a disease characterized by an increase in blood glucose levels. Elevated blood glucose is characterized by frequent urination, increased thirst and increased hunger. Diabetic consequences include kidney failure, blindness, heart failure, amputations and stroke, to name a few. When we ingest food, our bodies turn it into sugars or glucose. Machine learning is a new field of data science that investigates how computers learn from their prior experiences. The objective of this study is to develop a system that can detect diabetes in a patient early and more accurately using a combination of machine learning techniques. The objective of this study is to use four supervised machine learning algorithms to predict diabetes: Support Vector Machine, logistic regression, random forest and k-nearest neighbour. Each algorithm is used to calculate the model's accuracy. The model with the best accuracy for predicting diabetes is then picked. This paper proposes a comparative study for accurately predicting diabetes mellitus. This research also aims to develop a more efficient approach for identifying diabetic disease.","['Engineering', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security']"
doi:10.1007/978-981-19-5224-1_14,en,A Survey of Learning Techniques for Detecting DDOS Assaults,OriginalPaper,"The distributed denial-of-service (DDOS) exploit is one of the most catastrophic assaults on the Internet, disrupting the performance of critical administrations offered by numerous organizations. These attacks have become increasingly complicated, and their number has been steadily increasing, making it harder to detect and respond to such assaults As a result, a sharp security system (IDS) is necessary to detect and control any unexpected system traffic behavior. In a DDOS Assaults, the intruder delivers a stream of packets to the server while exploiting known or unknown flaws and vulnerabilities.","['Engineering', 'Communications Engineering, Networks', 'Statistics, general', 'Cyber-physical systems, IoT', 'Sociology, general', 'Professional Computing']"
doi:10.1007/978-981-19-5403-0_32,en,MultiStrategy Algorithmic Trader,OriginalPaper,"Algorithmic trading, also known as “algo trading”, is a trading paradigm that follows a set of algorithms to place trades which can generate profits at high frequency and volume, theoretically impossible for a human trader. These trading algorithms are derived from strategies which encompass mathematical models. The practice of “algo trading” is quickly gaining traction in the world of fin-tech due to its automated approach toward trading and provision of increased liquidity in the market. We believe retail intraday traders across India should have tools to automate their daily trades based on the strategies they employ, seamlessly and effectively. Intraday trading requires the constant presence of a trader throughout the hours of a trading day, incapacitating them from focusing on other responsibilities such as their day jobs. Furthermore, currently, the few present algorithmic trading software consist of expensive fees and/or a confusing UI/UX experience for novice traders. Furthermore, problems faced by intraday traders worldwide, due to usage of algorithmic trading software include complex and incomprehensible user interfaces, trading of illiquid securities, handling of special days, exorbitant trading and brokerage fees, and multiple risks including regulatory, financial, reputational, operational and technological risks. We propose a clean, lightweight and object oriented approach toward algorithmic trading, eliminating the need for commercial algorithmic trading software. This proposed novel system aims to allow high frequency, multi-threaded trading strategies based on technical indicators such as MACD, Moving Averages, Relative Strength Index, Candlestick patterns, to be run parallely, reducing latency in high volume trades.","['Engineering', 'Computational Intelligence', 'User Interfaces and Human Computer Interaction', 'Data Structures and Information Theory', 'Artificial Intelligence', 'Data Mining and Knowledge Discovery']"
doi:10.1007/978-3-662-65625-9_14,en,Capacity Management,OriginalPaper,"Work center capacity utilization, like levels of inventories in stock and work-in-process, increases the flexibility of logistics planning & control. Capacity resources have to be estimated for every planning term. Flexibility in medium- and short-term planning often requires long-term arrangements. In Figure 14.0.0.1, the tasks and processes covered in this chapter are shown against a darker background, referring back to the basic model introduced in Figure 5.1.4.2. Sections 1.2.4, 5.3.3, and 5.3.4 provide useful overviews for this chapter.","['Engineering', 'Engineering Economics, Organization, Logistics, Marketing', 'Operations Management', 'IT in Business', 'Industrial Organization', 'Organization']"
doi:10.1007/978-981-19-4182-5_14,en,Big Data Disease Prediction System Using Vanilla LSTM: A Deep Learning Breakthrough,OriginalPaper,"An intelligent disease prediction system using Vanilla LSTM (Long Short Term Memory) is proposed in the paper. The proposed algorithms were tested only on small data due to limited access to data. Later on, a huge dataset of disease prediction was collected from various research institutes and the existing algorithms were not able to bring predictions after training. So, the prediction system with the help of deep learning was designed and vanilla LSTM was used for classification. The algorithm showed significant improvement over the existing algorithm not only in terms of accuracy which is 98.67%, but also in terms of computation complexity.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Computer Systems Organization and Communication Networks', 'Statistics, general']"
doi:10.1007/978-3-031-19067-4_5,en,Asynchronous SGD and Staleness-Reduced Variants,OriginalPaper,"In Chap.  we saw that synchronous distributed SGD suffers from tail latency due to straggling workers. Its straggler-resilient variants K -sync and K -batch-sync SGD overcome the straggling delay, but they end up discarding partially completed gradient computation at one or more workers, thus reducing the statistical efficiency of the algorithm and adversely affecting the error convergence.","['Mathematics', 'Algorithms', 'Machine Learning', 'Algorithm Analysis and Problem Complexity', 'Artificial Intelligence', 'Probability Theory and Stochastic Processes', 'Computer Science, general']"
doi:10.1007/978-3-031-06780-8_8,en,Artificially Intelligent Active Safety Systems,OriginalPaper,"To better connect the Artificial Intelligence and Vehicle Control Communities, the SAE set of terms and definitions for Active Safety Systems is used to discuss modern applications of artificial intelligence to Active Safety Systems. This chapter begins with an introduction to the technology enabling Active Safety Systems and its impact on improving on-road safety. A new dataset is introduced that captures the prevalence of Active Safety Systems in the United States (U.S.) automotive industry for the model year 2021. Three different analyses are performed on this dataset to demonstrate its potential value in studying the offered Active Safety Systems in the U.S. automotive industry. Finally, promising Artificial Intelligence applications to the automotive industry are presented from the fields of deep learning, reinforcement learning, and imitation learning. An example of reinforcement learning applied to Automatic Emergency Braking is provided and demonstrates that reinforcement learning agents can learn policies that are effective in avoiding a collision. This chapter concludes that Artificial Intelligence will play a critical role in the future of automotive safety systems.","['Engineering', 'Automotive Engineering', 'Computational Intelligence', 'Transportation Technology and Traffic Engineering', 'Signal, Image and Speech Processing']"
doi:10.1007/978-981-19-3938-9_9,en,Assessment of Nonlinear Optimization Algorithms on Weighted Least-Square-Based Method for Re-Entry Prediction,OriginalPaper,"Accurate prediction of space object re-entry time and location is important to mitigate impact risks. There are several uncertainties associated with the orbital propagation models, atmospheric density models and observational data which make the problem of re-entry prediction challenging. An integrated model based on weighted least-square error function minimization to estimate an essential ballistic parameter (EBP) is implemented and has been found to work well for re-entry predictions. The process requires manual intervention due to reasons namely, (i) wide search range, (ii) outlier removal, (iii) lack of good initial guess, (iv) presence of invalid ballistic parameters in the search range and (v) variation in EBP during the re-entry exercise. This paper presents the implementation of optimization logic for EBP estimation to reduce user-interference and automatize the complete re-entry prediction procedure. This is based on assessment of optimization algorithms, for re-entry prediction of different space objects, subjected to their sensitivity to initial guess, convergence and number of function evaluations. Some failure cases are also presented, and methodology implemented to overcome these failure cases is discussed here.","['Engineering', 'Mathematical and Computational Engineering', 'Optimization', 'Machine Learning']"
doi:10.1007/978-981-19-3998-3_21,en,IMFlySim: A High-Fidelity Simulation Platform for UAV Swarms,OriginalPaper,"The development of unmanned aerial vehicles (UAVs) shows the development trend of high intelligence and UAV Swarms, which makes the UAV Swarms flight trails in the real environment expensive and time-consuming. The current simulation platforms that can serve UAV swarms have problems such as insufficient number of nodes, low visual rendering fidelity, lack of intelligent interfaces, and poor real environment reproduction. This paper proposes a high-fidelity simulation platform for UAV swarms, which is a multi-node simulation platform based on Client/Server (C/S) architecture with Unreal Engine as the rendering engine and JSBSim as the physical engine. JSBSim can realize multi-model, high-frequency hardware-in-the-loop data simulation and Unreal Engine provides data interface for intelligent sensing and decision algorithms. The C/S architecture can increase the maximum number of hardware-in-the-loop simulation nodes to meet the UAV swarms flight requirements. In this paper, simulation experiments of fixed-wing are conducted and compared with the flight test, the error is between -2.851017 and 3.108375, with a mean of -0.034536 and a variance of 0.476047. The error always fluctuates around 0, and this result is not bad. Finally, this paper successfully realized formation flight simulation.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-3-031-15509-3_49,en,Fast CP Model Fitting with Integrated ASD-ALS Procedure,OriginalPaper,"The CP decomposition is the most appropriate tool for modeling data arrays with a trilinear structure. Model fitting can be hindered by several issues, including computational inefficiency, bad initialization, excessive modeled noise, sensitivity to over-factoring and collinearity. Many algorithms have been proposed for parameter estimation, each with specific strengths and weaknesses. Fast procedures tend to be less stable and vice-versa. Stability is usually prioritized by preferring the least-square approach ALS, albeit slow and sensitive to excess factors. As a solution integrated methods have been proposed in the literature. First, estimation is initialized with a fast procedure to ensure competitive speed then results are refined with ALS to improve precision. In this work, we implement a novel integrated algorithm called INT-3 where ASD steps are concatenated with ALS. ASD was selected because of its remarkable speed and low memory consumption requirements. INT-3 performance is tested against ALS on artificial data.","['Engineering', 'Data Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4182-5_17,en,The Implementation of Object Detection Using Deep Learning for Mobility Impaired People,OriginalPaper,"The Object detection technique is used to locate and identify objects in images and videos. To train a model, deep neural nets are used in conjunction with complex algorithms to detect objects in real-time using machine learning applications and deep learning. People with visual impairments have difficulties when it comes to autonomous mobility; despite walking on a well-known path, they can encounter multiple hazards along the way. In this paper, the MobileNet Single Shot Multibox Detector (SSD) algorithm is implemented using transfer learning; so that it can be integrated with a smart walking stick for mobility-impaired people using Raspberry Pi v3 B+.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Computer Systems Organization and Communication Networks', 'Statistics, general']"
doi:10.1007/978-981-19-2535-1_25,en,Stock Market Prediction Using Deep Learning Algorithm: An Overview,OriginalPaper,"A stock market, sometimes referred to as an equity market, is a gathering of buyers and sellers of stocks that represent company ownership. In this market, various investors sell and acquire shares based on stock availability. Stock trading is an important practice in the world of finance, and it is the cornerstone of many enterprises. A developing country’s rapid economic development, such as India’s, is dependent on its stock market. It is crucial in today’s economic and social environment. The stock market’s ups and downs have an impact on stakeholders’ benefits. Stock market value prediction has long captivated the interest of investors and researchers because of its complexity, inherent ambiguity, and ever-changing nature. “Stock market prediction” is a method of trying to anticipate the worth of a given “stock” in the coming days. This is performed by considering historical stock values as well as price variances throughout the previous days. Due to market volatility, forecasting stock indices is definitely tough, necessitating an accurate forecast model. Recent advancement in stock market prediction technology is machine learning, which produces forecasts based on the values of current stock market indices by training on their prior values. The term “machine learning” (ML) refers to a subdivision of “artificial intelligence” (AI) in which we train machines with data and use test data to forecast the future. This study presents an overview of deep learning techniques that are currently being used to anticipate stock market movements and predictions.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5845-8_24,en,"Comparative Analysis of Machine Learning and Deep Learning Algorithms for Real-Time Posture Detection to Prevent Sciatica, Kyphosis, Lordosis",OriginalPaper,"People must incorporate a “work from home” strategy because of the COVID-19 outbreak. In today's pandemic situation, due to working from home, employees are working for long hours, and spending long hours is a pretty challenging task. Nowadays, irrespective of age concerns, sciatica, Kyphosis, and lordosis are becoming a significant problem even for youngsters. The longest nerve in our body is sciatica, which causes severe pain due to stress applied while sitting in the wrong posture. It gets compressed with our lower back discs, which may lead to severe radiating pain from our lower back disc to the entire right leg, and a person can't even perform his daily activities comfortably. To prevent these problems, sitting posture while working should be maintained correctly. This work mainly focuses on preventing employers, and students from sciatica, Kyphosis, and Lordosis health issues. We used all kinds of sitting postures that interact while working with a laptop, classified which posture was good, and predicted which stance led to health issues. We used Convolutional Neural Network and K-Nearest Neighbor machine learning algorithms to predict the correct sitting postures. In KNN, we followed two techniques to improve the performance: using Edge detection. The other method we used was detecting facial landmark detection and plotting their respective rotational angles. So by using this technique, we improved the accuracy and precision rate compared to the classical Edge detection. We also trained the model with CNN, which gives good results. We performed a comparative analysis to pick the best model to integrate with OpenCV to make it real-time.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1412-6_1,en,IoT-Assisted Crop Monitoring Using Machine Learning Algorithms for Smart Farming,OriginalPaper,"Agriculture expansion is critical to the economic prosperity of any country. Agriculture employs more than 60% of the Indian population, either directly or indirectly. Nowadays, monitoring the crop is the challenging task in the world. In this article, data has been collected from various sensors to propose an IoT-assisted hybrid machine learning approach for obtaining an effective crop monitoring system. Crop monitoring system here means predicting as well as detecting diseases of crops. This study is about leveraging existing data and applying regression analysis, SVM, and decision tree to predict crop diseases in diverse crops such as rice, ragi, gram, potato, and onion. Among the applied methods, SVM outperforms regression, DT methods. The training and testing accuracy of Gram has 96.29% and 95.67%, respectively.","['Engineering', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security']"
doi:10.1007/978-3-031-21333-5_8,en,Emotion Recognition from Human Gait Using Machine Learning Algorithms,OriginalPaper,"The analysis of human gait has been widely used in the clinical field, e.g., for the early diagnosis of some diseases. On the other hand, it is possible to associate movement patterns during gait with several human behaviors, such as emotions. The main objective of this work is to generate models to classify three discrete emotions: happy, sad, and angry, considering the neutral state as an additional class. A set of features were extracted from the 3D position of the human skeleton during walking sessions. A descriptive analysis of the data was performed in order to select the best subsets of joints for recognizing the emotions. The models were built with the algorithms: kNN, Random Forest, and a meta-classifier (boosting). The best results were obtained with boosting with a mAP of 0.77 for balanced data, and 0.79 for unbalanced data. The results were promising when using methods based on shallow machine learning, a deep learning approach is currently being worked on.","['Engineering', 'Data Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-20650-4_13,en,White Blood Cell Classification of Porcine Blood Smear Images,OriginalPaper,"Differentiating white blood cells has been a fundamental part of medical diagnosis as it allows the assessment of the state of health of various organ systems in an animal. However, the examination of blood smears is time-consuming and is dependent on the level of the health professional’s expertise. With this, automated computer-based systems have been developed to reduce the time taken for examination and to reduce human error. In this work, an image processing technique was explored to investigate the classification of white blood cells. Through this technique, color and shape features were gathered from segmented nuclei and cytoplasms. Various deep learning algorithms where transfer learning methods were also employed for comparison. Experimental results showed that handcrafted features via image processing are better than features extracted from pre-trained CNNs, achieving an accuracy of 91% when using a non-linear SVM classifier. However overall, deep neural networks were superior in WBC classification as the fine-tuned DenseNet-169 model was found to have the highest accuracy of 93% against all used methods.","['Computer Science', 'Artificial Intelligence', 'Computers and Education', 'Data Mining and Knowledge Discovery', 'Information Systems Applications (incl. Internet)', 'Computer Appl. in Social and Behavioral Sciences', 'Image Processing and Computer Vision']"
doi:10.1007/978-3-031-04137-2_34,en,Machine Learning Procedures for Daily Interpolation of Rainfall in Navarre (Spain),OriginalPaper,"Kriging is by far the most well known and widely used statistical method for interpolating data in spatial random fields. The main reason is that it provides the best linear unbiased predictor and it is an exact interpolator when normality is assumed. The robustness of this method allows small departures from normality, however, many meteorological, pollutant and environmental variables have extremely asymmetrical distributions and Kriging cannot be used. Machine learning techniques such as neural networks, random forest, and k -nearest neighbor can be used instead, because they do not require specific distributional assumptions. The drawback is that they do not take account of the spatial dependence, and for an optimal performance in spatial random fields more complex machine learning techniques could be considered. These techniques also require a relatively large amount of training data and they are computationally challenging to implement. For a reduced number of observations, we illustrate the performance of the aforementioned procedures using daily rainfall data of manual meteorological gauge stations in Navarre, where the only auxiliary variables available are the spatial coordinates and the altitude. The quality of the predictions is carefully checked through three versions of the relative root mean squared error (RRMSE). The conclusion is that when we cannot use Kriging, random forest and neural networks outperform k -nearest neighbor technique, and provide reliable predictions of rainfall daily data with scarce auxiliary information.","['Engineering', 'Engineering Mathematics', 'Data Engineering', 'Statistics for Engineering, Physics, Computer Science, Chemistry and Earth Sciences', 'Computational Intelligence', 'Mathematical Applications in Computer Science']"
doi:10.1007/978-981-19-3788-0_21,en,Aircraft Position-Fixing in a Multilateration System,OriginalPaper,"The problem of increasing the level of civil aircraft flight safety in zones with no radar control for economic and geographic reasons is solved by applying a multi-position surveillance system. A promising means of data exchange between an aircraft and an air traffic controller (ATC) is automatic dependent surveillance-broadcast (ADS-B) which provides transmission of aircraft navigation information. The problem of aircraft position-fixing in a multi-position surveillance system on the basis of multilateration technology in a stochastic statement has been formulated and its solution with the help of modern methods of optimal signal filtration has been proposed. To implement range tracking and pseudorange measurements in a multilateration (MLAT) system, the authors propose applying a second-order filter. An a priori model of signal delay dynamics has been proposed in order to synthesize a filter of the tracking system. Using the selected model for signal delay time, a Kalman-filter-based algorithm of optimal estimation and its characteristics were examined. The paper describes theoretical and experimental studies of a multilateration surveillance system and factors influencing its operation. The accuracy characteristics within the system coverage in accordance with the presumed location were analyzed. The research on characteristics of an MLAT system with a variant of station location in the Bodaybo region of Irkutsk regional center of air traffic management (ATM) was carried out.","['Engineering', 'Aerospace Technology and Astronautics', 'Engine Technology', 'Engineering Thermodynamics, Heat and Mass Transfer']"
doi:10.1007/978-3-031-10784-9_27,en,A Cost-Effective and Quality-Ensured Framework for Crowdsourced Indoor Localization,OriginalPaper,"With the increasing user demands for the ubiquitous availability of location-based services, and the acknowledgement of their substantial business prospects, researchers have extensively studied indoor localization techniques that do not rely on the Global Positioning System (GPS) or other localization technologies that do not work well in indoor environments. Thanks to the rapid advancement of the machine learning technologies, many of the indoor localization schemes utilize machine learning and pattern recognition techniques based on the received signal Signals strength indicator Indicators to estimate indoor locations of mobile Mobile devices. One of the key challenges for deploying such machine learning-based indoor localization systems is the labor-intensive and time-consuming tasks of annotating radio maps Maps with the corresponding position information in advance Advances . One could exploit crowdsourcing Crowdsourcing to solve the problem of radio signature collection, while there are various uncertainties Uncertainties about the location annotations contributed by the crowd, which can affect the performance of the localization model. We propose a crowdsourcing Crowdsourcing -based indoor localization framework, ALCIL, which utilizes the active learning technique to collect the informative data to improve the performance of the model under a certain cost. We then employ global and local optimization Optimization strategies considering the multiple attributes of locations to improve the accuracy Accuracy of location prediction Predictions in different dimensions. In addition, we propose a sample selection method based on a stream-based active learning so as to improve the quality of radio maps Maps and enhance the performance of the indoor localization model without penalizing the location-annotation process. The effectiveness of the proposed framework is verified through the experiments in the context of practical multi-story buildings. Our experiment shows that the proposed method can localize users’ mobile Mobile devices accurately at the given fixed budget.","['Engineering', 'Computational Intelligence', 'Robotics and Automation', 'Transportation Technology and Traffic Engineering', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5845-8_50,en,Comparison of Supervised Machine Learning Algorithms for Predicting Employee Performance on Real Time Dataset,OriginalPaper,"Various important factors are there for a developer that are efficient to provide profitability to an organization. It is important to know the progress of a developer as an individual. The organization may help these developers to become the most productive version of themselves by various methods. These methods will tend to provide an economic value and improve the performance of an employee as well as the organization. A survey has been made to generate the reviews which directly or indirectly influence the performance criteria such as job satisfaction, performance, productivity, etc. More than 1200 people participated in the survey and based on that Machine Learning has been applied. Finally, after performing several learning algorithms XGBoost performed well and provided a training and testing accuracy of 92.6% and 93% respectively.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-21062-4_12,en,Evolving Swarm Formations for Odour Source Localisation,OriginalPaper,"Odour source localisation is a hard problem with many applications. Over the years, researchers have drawn inspiration from Nature to devise many single-robot approaches. Swarm approaches have been growing in popularity, as they offer redundancy to the loss of agents, flexibility, scalability and enable experimenters to employ simpler robots. Many existing swarm approaches make use of robot formations. In this work, we focus on optimising the shape of a swarm formation for finding and tracking odour plumes. We do so by using a genetic algorithm, thus avoiding the cumbersome trial-and-error process that experimenters typically follow to hand-design the formations. The swarm is guided by a leader, which is controlled by a bio-inspired search strategy using the perceptions of the entire swarm. The results show that the evolved formations of three and five robots consistently outperform a single robot and that the best evolved three robot formation is more successful than the hand-designed swarms of three and five robots. As a result, one could opt by using the evolved three robot formation, minimizing the amount of robots needed. Conversely, in case there is a high risk of loss of robots, the evolved five robot formation could be preferable.","['Computer Science', 'Robotics', 'Robotics and Automation', 'Computational Intelligence']"
doi:10.1007/978-3-031-13150-9_26,en,Machine Learning Approaches for Classifying the Peace-War Orientations of Global News Organizations’ Social Media Posts,OriginalPaper,"The study used the existing conceptualizations of peace and war journalism to create supervised machine learning text classifiers trained and tested to identify the war or peace orientations of news stories posted on social media. Peace-oriented journalists promote peace initiatives, ignore differences, and promote conflict resolution. In contrast, war-oriented journalists promote differences between opposing parties and instigate violence as means to resolving conflicts. Using Naïve Bayes, Logistic Regression, Decision Trees, Random Forests, and Support Vector Machines (SVM), the study trained and tested five computational models to detect the peace or war orientations of the news posted on social media. The results indicate that Random Forest has the highest predictive accuracy for predicting war or peace orientations of online news stories. Naïve Bayes ranked the least accurate algorithm for predicting peace or war orientations of online news stories.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Management']"
doi:10.1007/978-3-031-11047-4_5,en,Circuit analysis,OriginalPaper,"Ensuring correct functionality of an integrated system requires accurate evaluation of the on-chip electrical characteristics. General purpose analysis methods, based on modified nodal analysis (MNA) and the partial element equivalent circuit method, enable accurate analysis of the behavior of power networks. The runtime of these methods however grows superlinearly with the size of the system, rendering these techniques impractical for analyzing modern VLSI systems. Different methods for accelerating MNA are reviewed in this chapter. In domain decomposition, for example, circuit analysis is efficiently parallelized, enabling faster processing if large computational resources are available. Using hierarchical matrices, the sparsity pattern of the Laplacian matrix is exploited to reduce the complexity of the analysis process. Alternative algorithms for circuit analysis are also reviewed, including the infinite mesh grid model and random walks. These techniques reduce the complexity of the circuit analysis process by avoiding costly MNA to evaluate the electrical behavior of an integrated system.","['Engineering', 'Circuits and Systems']"
doi:10.1007/978-3-031-15191-0_4,en,A New Telecom Churn Prediction Model Based on Multi-layer Stacking Architecture,OriginalPaper,"Customer retention costs four times less than new customer acquisition for telecom operators. This has made churn prediction an important issue for major service providers around the world. For this reason, significant investments are increasingly devoted to the development of new anti-churn strategies. Machine Learning is among the new approaches used today in this area. In the proposed work, we constructed a multilayer Stacking Network, composed of a set of 8 selected trained models, based on grid search cross-validation. The model we suggested scored the best result in terms of accuracy, 80.1%, higher than any of its base models.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Mobile and Network Security']"
doi:10.1007/978-981-19-2658-7_8,en,Cryptography,OriginalPaper,"Cryptography is a technique of securing info and communications through the use of codes so solely those people for whom the data is meant will are aware of it and method it. Therefore, preventing unauthorized access to info. The prefix “crypt” suggests that “hidden,” and the suffix graph suggests that “writing.”","['Engineering', 'Communications Engineering, Networks', 'Mobile and Network Security', 'Crime Control and Security', 'Systems and Data Security']"
doi:10.1007/978-3-031-07242-0_13,en,Cloud Computing Sca lability,OriginalPaper,"Scalability is the capacity and capability of a system to adapt to changes in the demand. In this chapter, we will look at driving factors that cause a change in demand, such as remote work and telemedicine in the recent years. Then we will look at the ways in which datacenters and networks grow in response to adapt to the rising demands. This includes new protocols and architectures, while meeting the customers’ latency expectations. Some scalability Machine learning models in the Cloud will be examined. No discussion about growth and scaling is complete without the cost optimization, so we will look at a few practical choices in the Cloud.","['Engineering', 'Circuits and Systems', 'Communications Engineering, Networks', 'Computer Communication Networks']"
doi:10.1007/978-981-19-3148-2_16,en,Predictive Analysis on Customer Churn Using Machine Learning Algorithms,OriginalPaper,"Customers are said to be the most important aspect of every business, as a business cannot function without the customers. Customer retention is one of the key drivers of business growth and is said to be as important as customer acquisition. This study aims at providing a predictive analysis on customer churn in the telecommunication industry using machine learning algorithms. A hybrid model classification consisting of random forest (RF) and XGBoost classifiers as well as a voting/ranking system that combines both logics and decisions to bring about a singular classification output is proposed. The hybrid model achieved an accuracy of 95.92%, true positive of 81.6%, and true negative of 98.45%. The random forest had a 95.32% accuracy, and the XGBoost had an accuracy of 95.68%. The hybrid model produces a better performance than the random forest model and XGBoost model.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory']"
doi:10.1007/978-3-031-07179-9_1,en,"Machine Learning Application in Food Safety, Production, and Quality",OriginalPaper,"The demand for high-quality food and low-cost production has increased the need to automate and optimize supply chain processes. The recent trends in emerging artificial intelligence technologies offer new solutions for many of the agri-food problems. In the last two decades, many studies on the application of machine learning have successfully improved the speed and/or accuracy of many processes in the food supply chain. This paper provides a brief survey of the application of machine learning techniques to the food supply chain to discuss the challenges such as efficient real-time data collecting, quickly and meaningfully unraveling massive or complex data, and automation of decision-making without human intervention. Moreover, this paper reviews the recent application of machine learning techniques that have already been proposed and applied in food safety, food quality, and food production domains.","['Life Sciences', 'Food Microbiology', 'Big Data', 'Big Data/Analytics', 'Food Science']"
doi:10.1007/978-3-031-11058-0_9,en,Real-Time 3D Surround View System for Vehicle Based on Panoramic Stitching Image,OriginalPaper,"In recent years, the introduction of augmented reality in ADAS has become an active research topic. Such a system contributes to a more controllable, comfortable, and safe driving in the city. The surround view is one such system, which could be expanded by artificial intelligence. This paper presents one approach to designing a real-time surround view multi-camera system on Jetson Tegra TX2. The algorithm for finding intrinsic and extrinsic camera parameters based on compute homography matrix from descriptors of feature points was implemented on CPU and computing only once. To achieve real-time, the algorithms of geometric, photometric alignment and blending were implemented on GPU and use CUDA technology. Texture mapping on 3D bowl mesh using OpenGL ES. A virtual camera is used to achieve a 360° view. Experiment results show a surround view system with a good stitched quality and acceptable performance. Further development of the research project is presented.","['Engineering', 'Control and Systems Theory', 'Control, Robotics, Mechatronics', 'Communications Engineering, Networks']"
doi:10.1007/978-3-031-11748-0_9,en,Rethinking Importance Weighting for Transfer Learning,OriginalPaper,"A key assumption in supervised learning is that training and test data follow the same probability distribution. However, this fundamental assumption is not always satisfied in practice, e.g., due to changing environments, sample selection bias, privacy concerns, or high labeling costs. Transfer learning (TL) relaxes this assumption and allows us to learn under distribution shift. Classical TL methods typically rely on importance weighting —a predictor is trained based on the training losses weighted according to the importance (i.e., the test-over-training density ratio). However, as real-world machine learning tasks are becoming increasingly complex, high-dimensional, and dynamical, novel approaches are explored to cope with such challenges recently. In this chapter, after introducing the foundation of TL based on importance weighting, we review recent advances on joint and dynamic importance-predictor estimation. Furthermore, we introduce a method of causal mechanism transfer that incorporates causal structure in TL. Finally, we discuss future perspectives of TL research.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Machine Learning']"
doi:10.1007/978-3-030-92989-3_3,en,Hybrid Imaging Detectors in X-Ray Phase-Contrast Applications,OriginalPaper,"X-Ray Phase-Contrast Imaging (XPCI) techniques are gaining increasing interest not only within the synchrotron radiation community, where most of them were first developed and implemented, but also among X-ray imaging experts who make use of standard laboratory sources. While conventional X-ray imaging typically depicts the attenuation of an investigated sample, XPCI allows access to complementary information such as refraction and ultra-small-angle-scattering (USAXS). These additional contrast sources lead to a major enhancement in the visibility of structures featuring poor attenuation contrast such as in biological soft tissues and plastic-based samples. Additionally, the USAXS signal reveals inhomogeneities on a scale smaller than the system’s spatial resolution, being suited for the investigation of a wide range of microparticulate samples, spanning, e.g., from lung tissues to composite materials. Independently from XPCI, recent years have witnessed unprecedented development in the field of hybrid X-ray imaging detectors. Novel devices have both led to major advantages over conventional indirect conversion detectors, such as higher efficiency and/or higher spatial resolution, and opened up entirely new possibilities, such as pixel-based energy discrimination of photons, spectral performances, and super-resolution imaging. In this framework, the aim of the chapter is to provide a link between XPCI and novel detector technologies, focusing on the specific role of detectors in the phase signal formation process for the most common XPCI techniques. Adding to the theoretical background, several successful examples of state-of-the-art detectors’ integration with XPCI are provided, as well as a number of foreseeable applications strongly leveraging on novel detectors’ performances.","['Engineering', 'Circuits and Systems', 'Biomedical Engineering and Bioengineering', 'Microwaves, RF and Optical Engineering']"
doi:10.1007/978-3-031-19958-5_40,en,Evolutionary Reinforcement Learning for Solving a Transportation Problem,OriginalPaper,"Deep Reinforcement Learning (DRL) has shown great success in some fields such as image recognition and automation, but its application in logistics and transportation such as vehicle routing problems remains very limited. However, Evolutionary-based Algorithms (EA) were commonly used to solve combinatorial optimization problems. As a matter of fact, very few papers have dealt with applying a combination between EA and RL to solve NP-hard optimization problems. In this work, we propose an Evolutionary Reinforcement Learning (ERL)-based approach that couples an EA with a DRL framework to solve a vehicle routing problem. Precisely, the proposed method seeks to optimize the policy generated by the deep neural network. The weights of the actor play a crucial role in off-policy methods. Using an EA, we will generate a population of weights and feed them to the DRL framework in order to get a better result for the VRP. Computational experimentation has been conducted to assess the performance of the proposed approach compared to the existing literature. We found that applying the EA to the dynamic encoder weights yields the best results.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-13150-9_36,en,A Random Forest-Based Ensemble Technique for Malware Detection,OriginalPaper,"With the widespread development of Internet interconnectivity, the opportunities for digital attacks have widened, many of which have damaging and severe implications. Malware is one type of cyber assault that is becoming more prevalent day by day. The conflict between security researchers and malware creators is an ongoing battle with the quick evolution of malware as technological innovation develops. Analysts are researching to identify it, while cybercriminals devise methods to conceal it. Researchers have proposed several approaches to identify malware, of which the machine learning approaches are prevalent. An ensemble-based approach has been proposed in this paper, consisting of C-means and Random Forest approaches and Local Outlier Factor, which outperforms the existing methods.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Management']"
doi:10.1007/978-981-19-3015-7_12,en,"An Extreme Machine Learning Model for Evaluating Landslide Hazard Zonation in Nilgiris District, Causative Factors and Risk Assessment Using Earth Observation Techniques",OriginalPaper,"In Nilgiris mountain regions, landslide is one of the most severe hazards, damages natural resources, and disturbs the ecosystem and environment. It creates a substantial loss to agriculture, forest, wealth and scratches major architectural constructions in the mountainous region. This proposed work aims to distinguish the range of the spatial vulnerability of landslide using ensembled machine learning models, including AdaBoost, random forest algorithms, and gradient boosting decision tree algorithms. Seven conditioning factors namely slope angle, slope aspect, land use, geomorphic features, distance from road, drainage density, and lineament density and a total of 272 landslide historical locations with a ratio of 70/30 were used to construct the spatial database. Estimate the efficacy of the ensembled models using evaluation metrics like precision, recall, F1-score, MAE, MCE, MSE, Kappa and AUC score. Results concluded that the land-use factor, vegetable crop area, is prone to high vulnerability zone in the study area. Additionally, results show that among all the ensembled machine learning models, the AdaBoost algorithm’s classification gives the highest accuracy value of 88.96%. However, the gradient boost decision classifier also outperformed with an accuracy value of 78.43%, and the random forest algorithm gives 72.61%.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Engineering', 'Data Mining and Knowledge Discovery', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-981-19-8202-6_30,en,Deep Learning-Based Matching of Sar Images with Optical Images,OriginalPaper,"There are essential differences between optical and SAR remote sensing imaging in terms of mechanism, so the geometric and physical properties of optical and SAR images are extremely different, which makes it more difficult to match images. We designed and improved a deep learning network, firstly, we extracted the high-dimensional features of the image using convolutional neural network, then we used nearest neighbor search for feature matching, in order to reduce the false matching points, we introduced MAGSAC + + to eliminate the outlier points, finally, we compared with SIFT_KNN_BBS and orb_feature_matching matching algorithms. The results show that the matching of heterogenous remote sensing images using deep learning approach has high accuracy and robustness.","['Engineering', 'Signal, Image and Speech Processing', 'Computer Applications', 'Geography, general', 'Earth System Sciences']"
doi:10.1007/978-981-19-1669-4_25,en,A Wavelet-Based De-Noising Speech Signal Performance with Objective Measures,OriginalPaper,"Speech signals are complex. Their quality can diminish drastically due to the interference of different types of noises. A system is required to de-noise the noisy speech signals and turn them into clean speech signals. As these types of noises are large, enhancing speech signals often becomes a difficult task. Traditional speech enhancement algorithms like spectral subtraction and Weiner filtering prove unsatisfactory in a non-stationary noise environment. Thus, removing noise and getting a clean speech directly are difficult, so we need immense methods to tackle the noise. In this study, we use discrete wavelet transform and MATLAB software to de-noise a speech signal taken from the speech corpus database. The objective of our proposed method is to reduce the noise of a speech signal better than the previous methods. This method deals with the speech signals of various areas where there is more noise which is difficult to get plain speech signals. The threshold values of the noisy signal are taken down first and then are compared with the de-noised signal. The performance of the proposed method is analyzed by objective speech quality measures like signal-to-noise ratio, segmental snr and frequency spectral SNR. The results show that the proposed model with the DWT feature improves the quality and intelligibility of a speech signal. The proposed model is easy to implement and helps to reduce the noise of a speech signal.","['Engineering', 'Signal, Image and Speech Processing', 'Circuits and Systems', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-05347-4_4,en,Investigating Bad Smells with Feature Selection and Machine Learning Approaches,OriginalPaper,"Code Smell is a piece of code that is designed and implemented poorly and it gives adverse effect on the software quality and maintenance. Now, a day’s machine learning based techniques have been extensively used towards code smell research. The main objective of this research is to optimise the features of Android code smells in terms of software metrics using feature selection technique based on Correlation on 2896 instances of open-source projects which are extracted from GitHub. Further, we have examined the performance measures like accuracy, precision, F-measure and execution time etc. with the reduced features data set of Android code smells. This paper also discussed about implementation of correlation-based feature selection algorithm to reduce the features of code smells. Then, the data has been analyzed with 4 machine learning algorithms that are Logistic Regression, Stochastic Gradient Descent (SGD), Simple Logistic and Sequential minimal optimization (SMO). The performance metrics for the above-mentioned machine learning algorithms with and without performing the feature selection have been compared. The computed outcome shows that the best accuracy and lesser execution time for all 3 considered Android code smells have been achieved using Logistic Regression algorithm. After feature selection the accuracy has increased up to 16%, 25% and 4.7% for NLMR, MIM and DTWC code smells respectively. Meanwhile, the other performance measures have also been increased.","['Mathematics', 'Mathematical Modeling and Industrial Mathematics', 'Risk Management', 'Engineering Economics, Organization, Logistics, Marketing']"
doi:10.1007/978-981-19-6149-6_2,en,Machine Learning in Process Monitoring and Control for Wire-Arc Additive Manufacturing,OriginalPaper,"Wire-arc additive manufacturing (WAAM) is an arc-based directed energy deposition approach that uses an electrical arc as a source of fusion to melt the wire feedstock and deposit layer by layer. It’s applicable in fabricating large-scale components. At this stage, there are still some issues that need to be researched deeply, such as manufacturing accuracy control, process parameters optimization, path planning, and online monitoring. Machine learning is a new emerging artificial intelligence technology, which is more and more applied in modern industry. In this study, a machine learning based control algorithm was applied in melt pool width control. To monitor the WAAM process, deep learning algorithms were applied in anomalies recognition. At the same time, machine learning methods were employed to predict the deposited surface roughness during the WAAM process.","['Engineering', 'Control, Robotics, Mechatronics', 'Artificial Intelligence', 'Industrial and Production Engineering', 'Control and Systems Theory']"
doi:10.1007/978-981-19-5292-0_25,en,Cloud Service Anomaly Traffic Detection Using Random Forest,OriginalPaper,"Cloud computing allows customers to access a variety of cloud services, as well as data storage and computational resources, with no data overhead. Consequently, it is vulnerable to Distributed Denial of Service (DDoS) assaults. Several agreed computers are utilised a DDoS attack to attack network services and hosts, resulting in flooding of messages, corrupted packets, and connection requests, and loss of service to the valid user. The use of network-connected devices is fast increasing in the digital era, which leads to an increase in cyberattacks. DDoS attacks are growing more difficult to spot among them. We may reduce redundancy and error rate in the classification process by using the random forest technique, as well as eliminate all empty/missing values from the data set. When we use the random forest algorithm rather than the Naive Bayes algorithm, we receive a 100% high accuracy rate. In the random forest algorithm, the false positive rate is 0.00. The main objective is to detect whether the request from IP address is an attack or not.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-3-031-08651-9_13,en,Brain Imaging Methods in Social and Affective Neuroscience: A Machine Learning Perspective,OriginalPaper,"Machine learning (ML) is a subarea of artificial intelligence which uses the induction approach to learn based on previous experiences and make conclusions about new inputs (Mitchell, Machine learning Machine learning . McGraw Hill, 1997). In the last decades, the use of ML approaches to analyze neuroimaging data has attracted widening attention (Pereira et al., Neuroimage 45(1):S199–S209, 2009; Lemm et al., Neuroimage 56(2):387–399, 2011). Particularly interesting recent applications to affective and social neuroscience include affective state decoding, exploring potential biomarkers of neurological and psychiatric disorders Psychiatric disorders , predicting treatment response, and developing real-time neurofeedback Neurofeedback and brain-computer interface protocols. In this chapter, we review the bases of the most common neuroimaging techniques, the basic concepts of ML, and how it can be applied to neuroimaging data. We also describe some recent examples of applications of ML-based analysis of neuroimaging data to social and affective neuroscience issues. Finally, we discuss the main ethical aspects and future perspectives for these emerging approaches.","['Biomedicine', 'Neurosciences', 'Social Sciences, general']"
doi:10.1007/978-3-031-19620-1_16,en,Machine Learning-Based Predictive Modeling of Mechanical Properties of Coatings,OriginalPaper,"In this paper, two-layer coatings of the TiAlN system for different values of the relative thicknesses of the constituent isotropic layers and their mechanical properties are considered. Modeling of the indentation process of the considered coatings was performed in the finite element system ANSYS. The hardness of the coatings was determined on the basis of the data of the indentation diagrams. Also, the work proposed an approach to determine the initial parameters of the coatings (geometric and mechanical parameters of the layers) at a given hardness. The effectiveness of machine learning algorithms for solving the problems under consideration is demonstrated. The inverse problem of predicting the hardness of the coating was solved with high accuracy by the ensemble algorithm Extremely Randomized Trees. We have been shown to be able to find a solution in the presence of multiple ambiguous solutions, including continuous ambiguity. It was shown that high accuracy in solving the presented problems is achievable if the number of elements in the training sample is more than a thousand elements.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-6737-5_23,en,A Dataset Preparation Framework for Education Data Mining,OriginalPaper,"Education data mining (EDM) is an important application domain of data mining. It focuses on generating interesting, novel, and useful patterns in benefit of academia. Institute Graduation Rate prediction, student dropout prediction, student group formation, students’ performance prediction, and student failure analysis are some of the challenging problems to address in field of education data mining. For education domain, useful research is conducted with either online available datasets or local dataset available with the organization. Dataset preparation for generalized analytical use is a challenge for field of EDM. Much of the time of the researchers is invested in identification and preparation of proper dataset that can be used for development of novel techniques and algorithms. In this paper, a novel framework of EDM dataset preparation is presented. Illustratively, this framework is successfully applied and tested for Institute Graduation Rate prediction problem. It is vital for researchers to have data at hand first to carry out further research. This paper illustrates a framework by which, education domain researchers could prepare datasets from huge data repositories as per their application need.","['Computer Science', 'Computer Communication Networks', 'Computer Applications', 'Computer System Implementation', 'Artificial Intelligence', 'Image Processing and Computer Vision']"
doi:10.1007/978-981-19-2840-6_46,en,An Accuracy Based Comparative Study on Different Techniques and Challenges for Sentiment Analysis,OriginalPaper,"The use of social media has gained more popularity in the modern society. People provide their own opinions on different subjects such as, social issues, news, events and products, on the web. Sentiments are generated by large number of people in social media. The user’s sentiments are useful in uplifting a society in educational, commercial and business aspects. Sentiment analysis is the procedure to analyze the sentiment of textual matter in social networks. Sentiment Analysis constitutes a tool to take out the requisite content from the web. This analysis is also performed to collect the opinion for the assessment. Various techniques exist to execute this job. Different challenges are observed when the sentiment analysis is computed. This paper surveys on the respective methods for Sentiment Analysis and the different challenges faced by each technique.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-07179-9_6,en,Algorithms to Localize Food Contamination Events in Blockchain-Based Trusted Food Supply Chains,OriginalPaper,"Enhancing the traceability of the food supply chain is important for food system safety and security. The Centers for Disease Control and Prevention (CDC) estimate over 47.8 million people are affected by foodborne diseases every year in the United States. The key inference problems in the food supply chain are diffusion source estimation and recall (inferring states of unobserved nodes), with noisy and incomplete observations. Recall aims to determine which food items to destroy before human consumption. However, the existing tracing mechanisms for the food supply chain are costly and inefficient. Unsurprisingly, the cost of recall is very high: typical industry estimates of direct costs for a single recall are $10 million. Blockchain-based ledgers are now being introduced to improve traceability, due to interoperability, transparency, and decentralization. This blockchain data will enable new artificial intelligence algorithms to infer contamination sources and recall actions. Unlike the extensive prior work on diffusion source estimation for undirected graphs with noiseless observations, the underlying network structure of the blockchain data is a directed acyclic graph (DAG) since it captures events unfolding in time. Moreover, assuming complete and noiseless node state information is impractical for real-world problems. For example, the RFID sensors that capture supply chain data may mislabel or misidentify an item. We develop a heuristic, termed generalized Jordan center, to estimate the source of a spreading process on a DAG based on noisy and incomplete observations and show that it is the maximum likelihood estimate under fairly general conditions. Our proposed heuristic is parameter-free and can be evaluated efficiently by a message-passing-like algorithm. We demonstrate the efficacy of our approach on network and sensor models of transparent supply chains.","['Life Sciences', 'Food Microbiology', 'Big Data', 'Big Data/Analytics', 'Food Science']"
doi:10.1007/978-981-19-4193-1_25,en,A Comparative Survey of Consensus Algorithms Based on Proof of Work,OriginalPaper,"Blockchain is the foundation of cryptocurrencies and many other industries such as healthcare, supply logistics, and so on. It is a system of distributed ledger that is now attracting lot of research attention. Peer-to-peer and cryptography technologies are essential components of blockchain, as are consensus procedures that ensure blockchain systems’ transparency, decentralization, and security. The Proof of Work (PoW) consensus protocol is now adopted by most blockchain systems, although other variations are available. We examine PoW and its six variants and analyze their pros, cons, scalability, maintenance cost, block generation time, transaction cost, energy consumption, validator selection criteria, mining profitability, and 51% attack in this study.","['Engineering', 'Computational Intelligence', 'Information Storage and Retrieval', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Data Structures and Information Theory', 'Artificial Intelligence']"
doi:10.1007/978-3-030-79827-7_45,en,"Tight-Binding Models, Their Applications to Device Modeling, and Deployment to a Global Community",OriginalPaper,"Tight-binding has become the state-of-the-art for realistically sized nanoscale device modeling. It has been implemented by multiple advanced device modeling research groups in conjunction with multiple quantum transport methodologies. Industry has begun to adopt some of the advanced codes and is beginning to implement company internal versions. Commercial software vendors are adopting the methodologies and are beginning to deploy the approaches into their commercial TCAD products. Intense software development combining tight-binding with the non-equilibrium Green’s function (NEGF) Non-equilibrium Green’s function (NEGF) approach and quantum transmitting boundary method (QTBM) for quantum transport began in 1994 at Texas Instruments. Acceptance of NEGF and tight-binding began with wider adoption in about 2004. The past 25 years have resulted in many model advancements, numerical technology development, and physics exploration that is by far too large to be covered here comprehensively. We start by setting forth the requirements for realistic modeling of extended nanoscale devices (Sects. 45.1 and 45.2 ), which include a full quantum mechanical treatment, atomistic interface treatments, atomistic representations of crystal symmetries, polarization, strain, and bond directions, and embedding into macroscopic fields such as electromagnetic potentials and long-range strain. We then proceed to describe the essential definitions and features for empirical tight-binding (Sect. 45.3 ). Sections 45.4 , 45.5 , and 45.6 address numerical issues of tight-binding in terms of transfer matrices, Green’s functions, and parallel scaling. Section  45.7 is dedicated to several applications around quantum dots and nanowires. We highlight million-atom quantum dot simulations and focus on carrier transport though silicon nanowires. We demonstrate how effective masses and bandgaps become design parameters at the nanoscale, how heavy masses are desirable for end-of-roadmap transistors, and how coherent transport assumptions break down. The nanowire simulations can be duplicated by everyone on nanoHUB.org. Section  45.8 highlights the widespread use of tight-binding within nanoHUB applications. Section  45.9 concludes this chapter.","['Engineering', 'Circuits and Systems', 'Electronic Circuits and Devices', 'Electronics and Microelectronics, Instrumentation']"
doi:10.1007/978-981-19-3951-8_72,en,Multilevel Hybrid Model for the Prediction of Quantitative Structure–Activity Relationship in Drug Discovery,OriginalPaper,"Identification of the activity induced by the macromolecular structures of the humans is of paramount importance for discovering a new drug in the pharmaceutical laboratories. In present study, a novel multilevel hybrid classification model is developed by combining the unsupervised and the supervised machine learning algorithms for the prediction of biological response elicited by the molecules depending upon their chemical properties. These properties comprised of the size of the molecule, its shape, the chemical constitution of it, etc. The proposed model of hybrid multilevel classification achieves 80% accuracy in predicting the biological activity with repeated 15-fold cross-validation. The proposed model is compared with the existing classification models, i.e., random forest classifier, Naive Bayes classifier, support vector machine and k-nearest neighbours, and outcome of proposed model is better.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1412-6_57,en,Empirical Study on Method-level Refactoring Using Machine Learning,OriginalPaper,"Because of the importance of software refactoring for software code quality and stability, this research primarily emphasizes whether refactoring can be vital to identify probable software components for future refactoring. Modularity, reusability, modifiability, maintainability, and service-oriented development may all be improved with refactoring. This fact encourages academics to develop a new and improved machine learning paradigm for restructuring OO software. We have made a multi-purpose optimization effort to assess the OOP-based software systems or components refactoring in this work. This research intends to exploit and optimize OOP software metrics to examine code quality by performing refactoring. Our objective is to develop a highly resilient and efficient ensemble computing model for refactoring prediction at the method level into a machine learning framework using software metrics as features. The focus is on applying enhanced state-of-art data acquisition, data preprocessing, data imbalance resilient re-sampling, feature extraction, and selection, followed by improved ensemble-based classification. This work will also focus on the types of project work for different kinds of classification.","['Engineering', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security']"
doi:10.1007/978-1-4842-8954-9_4,en,Collaborative Filtering,OriginalPaper,Collaborative filtering is a very popular method in recommendation engines. It is the predictive process behind the suggestions provided by these systems. It processes and analyzes customers’ information and suggests items they will likely appreciate.,"['Computer Science', 'Machine Learning', 'Python', 'Artificial Intelligence']"
doi:10.1007/978-981-19-6068-0_28,en,Early Detection of Stroke Risk Using Optimized Light Gradient Boosting Machine Approach Based on Demographic Data,OriginalPaper,"Stroke is a clinical condition wherein blood vessels inside the brain rupture, resulting in brain damage. Symptoms may appear if the brain's blood flow and other nutrients are disrupted. Early identification of different stroke warning signals can assist in lessening the severity of the stroke. This research study identifies early stroke diseases by utilizing an ensemble learning strategy using clinical data such as BMI, hypertension, average glucose level, heart disease, smoking status, and other factors of several individuals from Bangladesh. This study suggests utilizing the light gradient boosting machine (LGBM), an ensemble learning technique, to identify stroke risk prediction, with the data resampled and the parameters modified using grid-search. The proposed method's performance has been validated using a variety of machine learning algorithms, including DT, KNN, MLP, LDA, LR, SGD, GNB, and QDA. The experimental findings revealed that the proposed model surpasses all other performance measures such as precision, accuracy, TPR, TNR, FPR, F 1 -score, and AUC-ROC.","['Computer Science', 'Artificial Intelligence', 'Computational Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-0968-9_24,en,Towards Occupant-Centric Facility Maintenance Management: Automated Classification of Occupant Feedback Using NLP,OriginalPaper,"Location-specific occupant feedback is crucial information for facility management since it reflects occupant satisfaction on the facility and informs corrective maintenance. However, the current facility maintenance management (FMM) system cannot effectively collect location-specific occupant feedback, resulting in the inefficiency and ineffectiveness of FMM. This research explores a mobile social network approach for location-specific feedback collection in FMM. Specifically, this research develops a natural language processing (NLP)-based machine learning algorithm to classify the occupant feedback collected from the social network application automatically. In turn, the proposed approach could facilitate occupants’ participation and occupant feedback solicitation and assist facility management (FM) personnel in locating and navigating the reporting issues. The Waikato Environment for Knowledge Analysis (Weka) is utilized for training and testing machine learning algorithms based on historical records. The trained model can retrieve the essential information to facilitate FM decision-making based on occupants’ input data (e.g., location and textual information). The technical feasibility of mobile social network applications to report FMM feedback and concerns was demonstrated using a case study. This research contributes to the body of knowledge by an NLP-based model that automatically processes the location-specific occupant feedback for FMM. Future work will focus on developing a prototype application for FMM based on our findings.","['Engineering', 'Building Materials', 'Geoengineering, Foundations, Hydraulics', 'Transportation Technology and Traffic Engineering', 'Environment, general']"
doi:10.1007/978-3-031-08580-2_12,en,Shop Product Tracking and Early Fire Detection Using Edge Devices,OriginalPaper,"With the blooming of Internet of Things technology, edge device applications have become very popular in many areas. However, edge devices have constraints on power and resources that make edge device applications different from conventional applications. This paper proposes an architecture for tracking shop products and detecting early fire detection using computer vision that can be implemented in edge devices. Experimental results showed that the proposed architecture could be a feasible application that can be deployed to support staff in retail stores.","['Engineering', 'Computational Intelligence', 'Biomedical Engineering and Bioengineering', 'Artificial Intelligence']"
doi:10.1007/978-3-031-19958-5_5,en,Metaheuristic Solver for Problems with Permutative Representation,OriginalPaper,"Today, a large proportion of combinatorial optimization problems can be efficiently formulated as a mixed-integer program and solved with an exact solver. However, exact solvers do not scale well and thus custom metaheuristic algorithms are being designed to provide better scalability at the cost of no optimality guarantees and time-consuming development. This paper proposes a novel formalism for a large class of problems with permutative representation, together with a metaheuristic solver addressing these problems. This approach combines the advantages of both exact and metaheuristic solvers: straightforward problem formulation, scalability, low design time, and ability to find high quality solutions. Three different problems are formulated in the proposed formalism and solved with the proposed solver. The solver is benchmarked against the Gurobi Optimizer and significantly outperforms it in experiments with a fixed computational budget.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3015-7_33,en,A Alzheimer’s Disease Detection and Classification Using Customised Convolutional Neural Network,OriginalPaper,"Alzheimer's disease (AD) is regarded as acute diseases that cause death in humans, especially in those over the age of sixty, so it must be detected early in order to take preventative steps. In this paper, a supervised customised convolutional neural network (CCNN) is proposed for AD detection and classification using magnetic resonance imaging (MRI). AD is a form of dementia that causes memory, thinking and behavioural issues. Symptoms usually appear gradually and progressively worse. In the proposed system, we have used customised CNN classifier with five convolutional layers and five max pooling layers for the better classification of AD in four categories mild, moderate, very mild and none. Performance of the proposed CNN is evaluated on ADNI standard and results have obtained for multi-class classification of the disease. The proposed system gives the appropriate outcome for the classes mild, moderate, none, and very mild. The accuracy provided by proposed algorithm is 97.2% which is comparatively higher than the other existing algorithms.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Engineering', 'Data Mining and Knowledge Discovery', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-981-19-3590-9_47,en,Comparative Analysis of Machine Learning Approaches of Prediction of Diabetes Consequences in Pregnancy with Implications of Data Matrices,OriginalPaper,"Aruna Kumari, A. Santosh Kumar, Henge Diabetic retinopathy is a key reason of blindness in the working-age people. When treatment is more difficult, gestational diabetes occurs during pregnancy for some women, and it means glucose levels are too high when some pregnant women. This is developed due to hormones released from the placenta. Try to avoid eating simple carbohydrates food, take more vegetables for good health and it controls the blood sugar levels. Gestational diabetes generally passes away after the childbirth. If you are unrefined, it causes difficulties to your child, in the stage of premature birth and stillbirth. The danger of early childbirth due to diabetes mellitus, gestational is larger if mom develops diabetes before the 24th week of pregnancy, the risk for developing diabetes later in life. Sometimes it converts type 2 diabetes also in later stage of life. A well person 102.5 and 169.5 for a diabetes mellitus person, insulin’s moderate by the goal is certainly dissimilar, A normal human for 107 as well as diabetic mellitus person for 140, plasma glucose concentration two hours in an oral glucose acceptance test, triceps skin fold thickness in mm a non-diabetic person for 27 and 32 for a diabetic person. Blood pressure for a fit person 70 and 74.5 for a diabetic person. A fine person for 30.1 and 34.3 for a diabetic mellitus person for body mass index weight in kg/height in m $$^2$$ 2 , age in years, consider number of times pregnant, calculate diabetes pedigree function. Then after apply some complexity on algorithms to increase the accuracy use hyperparameters on light gbm then after apply the grid search and add the K-neighbour’s to light gbm with voting classifier we got accuracy of 94.1%, the result was also very close to the best result found and this shows the right hyperparameters light gbm and grid search can be good and practical classification on medical history.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security', 'Mobile and Network Security']"
doi:10.1007/978-981-19-6068-0_46,en,Efficient Ensemble Learning Based CatBoost Approach for Early-Stage Stroke Risk Prediction,OriginalPaper,"A stroke is a medical disorder in which the blood arteries in the brain rupture, resulting in a loss of consciousness. When the brain’s blood and other nutrients flow are interrupted, symptoms may manifest. According to the estimations of the World Health Organization (WHO), stroke is the leading global cause of death and disability. Though, several machine learning methods have been developed for effective identification and prediction of the risk involved in early stage stroke, the problem is sill at infancy. In this paper, an ensemble-based method to learn the CatBoostClassifier has been proposed as an effective tool for early stroke prediction. Stroke prediction dataset is used to test the method. The prediction accuracy of the proposed model is found to be greater than that of earlier research, demonstrating the efficacy of the model.","['Computer Science', 'Artificial Intelligence', 'Computational Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-11748-0_14,en,A Study on Efficient Reinforcement Learning Through Knowledge Transfer,OriginalPaper,"Although Reinforcement Learning (RL) algorithms have made impressive progress in learning complex tasks over the past years, there are still prevailing short-comings and challenges. Specifically, the sample-inefficiency and limited adaptation across tasks often make classic RL techniques impractical for real-world applications despite the gained representational power when combining deep neural networks with RL, known as Deep Reinforcement Learning (DRL). Recently, a number of approaches to address those issues have emerged. Many of those solutions are based on smart DRL architectures that enhance single task algorithms with the capability to share knowledge between agents and across tasks by introducing Transfer Learning (TL) capabilities. This survey addresses strategies of knowledge transfer from simple parameter sharing to privacy preserving federated learning and aims at providing a general overview of the field of TL in the DRL domain, establishes a classification framework, and briefly describes representative works in the area.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Machine Learning']"
doi:10.1007/978-3-031-20029-8_7,en,Energy-Consumption Evaluation of the Tree-Based Fog Computing (TBFC) Model,OriginalPaper,"It is critical to reduce the energy consumption of information systems to realize green societies. The IoT (Internet of Things) is so scalable that millions to billions of computers and devices are interconnected in types of networks and accordingly huge amount of energy is consumed. In our previous studies, the TBFC (Tree-Based Fog Computing) model is proposed to energy-efficiently realize the IoT, where fog nodes are hierarchically structured and application processes are distributed to not only servers in clouds but also fog nodes. The energy consumption of fog nodes in the TBFC model is obtained for a collection of sensor data simultaneously issued by device nodes in the evaluation. In this paper, we evaluate the TBFC model in terms of total energy consumption of nodes where each device node periodically sends sensor data. In the evaluation, we show the energy consumption of the TBFC model is smaller than the cloud computing (CC) model of the IoT.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence']"
doi:10.1007/978-981-19-5073-5_5,en,Membership Functions for Fuzzy Support Vector Machine in a Noisy Environment,OriginalPaper,This chapter introduces the compounding of General Purpose Membership Functions (GPMFs) for overcoming class noise in a Fuzzy Support Vector Machine (FSVM). Traditional membership functions (MFs) characterize all samples of the class with a single MF.,"['Computer Science', 'Machine Learning', 'Computational Intelligence', 'Pattern Recognition']"
doi:10.1007/978-981-19-2225-1_50,en,Quality Estimation of Change-Point Detection by the Signals Ratio Algorithm for Random Processes,OriginalPaper,"The change-point detection method based on decision-making statistics is considered. The average number of delay steps of the change-point detection and the average number of delay steps of detecting the returns of the statistical properties to the initial values are constructed as the mathematical models for the algorithm based on decision-making statistics with the signals ratio equations. The mathematical models for the average number of delay steps of detecting the returns of the statistical properties to the initial values are proposed for the first time. Proposed mathematical models for the average number of delay steps of the change-point detection have no limitation on the values of the algorithm's parameters, unlike already known ones. To ensure that the change-point detection in real-time systems will be done with a delay not exceeding a given value, it is critical that the obtained models already allow choosing the algorithm's parameters with the worst-case orientation.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Statistics, general', 'Mobile and Network Security']"
doi:10.1007/978-981-19-3590-9_57,en,Classification of DNA Sequence Using Machine Learning,OriginalPaper,"In the field of medical information research, the genetic series is widely used as a component of a category. One of the applications of ML is biochemistry. Bioinformatics is an interdisciplinary science that uses computers and communication science to understand biological data. One of its most difficult tasks is to distinguish between regular genes and disease-causing genes. The classification of gene sequences into existing categories is utilized in genomic research to discover the functions of novel proteins. As a result, it is critical to identify and categorize such genes. We employ ML approaches to distinguish between infected and normal genes using classification methods. AdaBoost has a high degree of precision; relative to the bagging algorithm and Random Forest Algorithm, AdaBoost fully considers the weight of each classifier. To generate a sequence of weak classifiers, an AdaBoost-based learning approach is used to find the most ‘informative’ or ‘discriminating’ features. The identification cascade structure can also help to limit false-positive results. This study provides an overview of the mechanics of gene sequence classification using ML Techniques, including a brief introduction to bioinformatics and important challenges in DNA Sequencing with ML.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security', 'Mobile and Network Security']"
doi:10.1007/978-3-031-16213-8_5,en,Assessment of Land Cover Changes in the Allala Watershed Based on Object Based Image Analysis Using Landsat and Sentinel-2 Images,OriginalPaper,"The coastal city of Ténès, located in northwestern Algeria, is exposed to several natural hazards, such as floods, earthquakes, landslides, and forest fires. Due to human activities, socio-economic constructions, agricultural activities, and the resulting population acceleration, land cover and land use (LULC) dynamics in the city are changing over time. Hence, the understanding of LULC changes and its interactions with human activities and natural hazards is essential for appropriate land management and decision-making. In this study, we investigate LULC changes in the Allala watershed, including the city of Ténès, using remote sensing methods and Geographic Information System (GIS) tools. Object-based image analysis (OBIA) based on random forest (RF) and support vector machine (SVM) machine learning algorithms was performed to provide LULC classification maps, and then, LULC changes were assessed using GIS. In order to assess LULC changes, we used three images acquired using remote sensing, corresponding to 3 years; 1999, 2009, and 2020. A Sentinel-2 image and two Landsat images were used as input data in our methodology. Our LULC classification results showed that RF outperformed SVM on the three input data periods, with an overall accuracy of 95.6% obtained with the Sentinel-2 image. Given the changes over time, it is clear that the Allala watershed has undergone significant changes over the years, particularly an increase in building infrastructure and agricultural land due to population and urbanization growth. Analyzing and mapping the trends of LULC changes in the study area provide a basis for strategic planning and managing, and results of LULC changes can be used as a decision support tool and provide further help in regional and national land management.","['Earth Sciences', 'Oceanography', 'Computer Applications', 'Geography, general', 'Water, general', 'Pollution, general', 'Ecology']"
doi:10.1007/978-3-031-16368-5_26,en,Modification of Capon’s Method for Several Radio Sources Coordinates Determining by the Shape of the Electromagnetic Wave Phase Front,OriginalPaper,Inefficiency of classical Capon’s method of bearing angles estimation of radio sources of far-field region with the flat phase front of electromagnetic wave was shown for bearing angles estimation of radio sources with spherical phase front of electromagnetic wave located in the intermediate-field region relatively to the inputs of linear antenna array of radio direction finder. A modification of Capon’s method to deal with the spherical electromagnetic wave front is proposed and some simulation results of bearing angles estimation for several radio sources located simultaneously in the intermediate-field and far-field regions are presented.,"['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-3716-3_23,en,Feature Selection Based on Gaussian Ant Lion Optimizer for Fault Identification in Centrifugal Pump,OriginalPaper,"Fault diagnosis of the rotating machinery using vibration signal is largely carried out by experience with some prior knowledge of the signal. The diagnosis process is simplified by using machine learning algorithms. The learning capabilities and classification performance of such machine learning models are mostly influenced by the quantity and quality of the input features. Thus, the appropriate selection of a subset of the most prominent features for machine learning becomes essential to eliminate redundancy of high dimension or irrelevant measurements of the features. In this paper, a filter-based feature selection technique is introduced to select the optimal feature space. A Gaussian ant lion optimization (GALO) is put in with a filter-based selection technique to select the feature subset from a high dimension feature dataset obtained from the vibration signals of centrifugal pump under different health conditions (normal, clogging, wheel cut and blade cut). The K-nearest neighbour (KNN) classifier is applied to the selected feature subset to find the classification accuracy. In addition, the proposed method has been compared with other art of work. The results reveal that the proposed GALO-KNN with filter-based feature selection technique outperforms both in feature reduction and classification accuracy and secures the best feature subset with less computational effort. Thus, the proposed method is capable enough to perform the selection task and shows excellent potential in fault diagnosis.","['Engineering', 'Machinery and Machine Elements', 'Robotics and Automation', 'Manufacturing, Machines, Tools, Processes', 'Control, Robotics, Mechatronics']"
doi:10.1007/978-981-19-1142-2_26,en,An Unsupervised Machine Learning Approach to Prediction of Price for Taxi Rides,OriginalPaper,"Taxi services are the primary method of transportation in urban areas. With the advent of technological sophistication and digital innovation used by companies like Uber and Ola, taxi businesses are undergoing a rapid transformation. Various methods have been developed by product engineers of software companies in the past, but they did not consider the demand for a customer’s ride in a particular region. In this paper, a machine learning-based model has been proposed having the capability to automatically classify booking points into different areas based on optimizing the within-cluster sum of squared distances to estimate the taxi demand in different geographical zones of a city. A robust and accurate price prediction model has been developed which would assist in predicting the price of rides from one fixed location to another fixed location based on the time and location of booking.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Mobile and Network Security', 'Artificial Intelligence']"
doi:10.1007/978-3-031-18458-1_28,en,Analyzing Secure Protocol for Majority Based Pairing in Attribute Chameleon Hash Consensus,OriginalPaper,"In this paper, we are proposing the security analysis of our protocol Majority based Authority Pairing in Attribute based Chameleon Hash Function or MAP-ABCHC. Our MAP-ABCHC is an enhancement of the trap door key used to create hash function in Chameleon Hash CHF. Encryption is one of the key technologies for safeguarding confidentiality and/or privacy. Attribute based encryption (ABE) has become one of the encryption mechanisms ensuring privacy and anonymity. MAP-ABCHC, ABE and CHF to generate the trap door key. We encrypt the trap-door key using ABE and Proxy Re-Encryption (PRE) with attribute and access policy. The advantages of our proposed MAP-ABCHC protocol are to share the trap door key with majority of nodes in the system and increase the security of current state of art in CHF by adding one NP-hard problem to the public key generation in pairing based cryptography. This adds additional layer of security for our Mobile Health system mHealth application. We describe details of our novel contribution and analyzing the security of MAP-ABCHC protocol.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-16-9967-2_22,en,Machine Learning-Based Multi-temporal Image Classification Using Object-Based Image Analysis and Supervised Classification,OriginalPaper,"During last decade, there has been tremendous research related to the image-based technique in remote sensing; object-based classification is one of the popular techniques due to its capacity of promising results. This paper presents a novel approach where a hybrid method of object-based image analysis and supervised classification is used. The data used in this study is high-resolution multispectral 4-band images from 2017 to 2019 provided by the PlanetScope satellite of region Chandigarh, India. First, the data has been pre-processed through passing it in a pipeline of steps followed by a multi-resolution segmentation algorithm and classifying the image into seven classes based on the spectral signature using algorithms like maximum likelihood (ML), support vector machine (SVM), Mahalanobis distance (MD). Comparing the three algorithms, it was observed that SVM and ML have given the highest overall accuracy of 95.21% and kappa coefficient = 0.9159. Also, the overall accuracy 91.91% and kappa coefficient = 0.8860 were achieved.","['Computer Science', 'Computer Systems Organization and Communication Networks', 'Computational Intelligence', 'Artificial Intelligence', 'Wireless and Mobile Communication', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-8222-4_13,en,A Spiking Neural Network for Brain-Computer Interface of Four Classes Motor Imagery,OriginalPaper,"Spiking neural networks (SNN) has the advantages of low power consumption and high efficiency in processing temporal information. However, due to the difficulty of network training, there exist few studies about the applications of SNN in brain-computer interface (BCI), especially in the four-classification task of motor imagery (MI). In this study, we develop a four-layer SNN structure to solve the MI four-classification problem. Firstly, an improved optimization algorithm for Ben’s spiker algorithm (BSA) is presented to convert EEG signals into spike signals, which obtains about 50 times higher efficiency than the commonly used optimizing algorithms. Secondly, a SNN combined with spike long-short-time-memory (LSTM) module is proposed to perform four-classification tasks in MI. Finally, we introduce the channel-wise normalization strategy to facilitate the training of deeper layers. Our experiment on the publicly released dataset achieves the accuracy that is comparable to the previous work of one-Dimension convolution neural network (1D-CNN). Meanwhile, the number of parameters of proposed network is about 1/10 of that in 1D-CNN. This study reveals the great potential of the SNN in developing a low-power and wearable BCI system.","['Computer Science', 'Artificial Intelligence', 'Computer Applications', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Mathematics of Computing']"
doi:10.1007/978-3-031-03880-8_6,en,Application of UAV for a Disaster-Resilient System,OriginalPaper,"Unmanned aerial vehicles (UAVs) commonly known as drones have several emerging applications with the continuous development of their various features. It highly suits for disaster resilient applications considering ease of deployment, low implementation cost, and flexibility. UAVs and wireless communication can be discussed from two different angles: wireless communication for UAV-assisted application and UAV-assisted wireless communication. Both of them help to understand how it assists disaster-resilient applications. In this chapter, we discuss both the topics and a detailed analysis of UAV-assisted wireless communication for disaster-resilient applications. Initially, we discuss how the UAV and wireless communication assist each other for emerging future applications. Next, we present the various applications of UAV-assisted communication and the respective challenges to overcome. Finally, we have discussed a sample scenario to methodologically realize the problems related to the application of UAVs in disaster-resilient systems. The problem studies the placement and the user association of UAV aerial base station to temporarily enable the coverage in a region where the terrestrial communication infrastructure is destroyed due to a disaster. The objective of the problem is identified as maximizing the achievable rate while increasing fairness among the users. The problem is analyzed by dividing it into three subproblems. Those are user association and clustering subproblem, intra-cluster positioning subproblem, and the altitude selection subproblem. User association and clustering problems are addressed through k-means clustering and the Gale–Shapley algorithm. The intra-cluster placement subproblem is addressed via a modified pattern search algorithm. The altitude selection subproblem is solved by understanding the impact on the achievable rate with the elevation angle between the user and the UAV. The performance of our proposed approach is compared through numerical simulation with one of the benchmark approaches provided in the current literature. Simulation results witness that our proposed approach gives at least a 43% gain compared to the benchmark approach.","['Engineering', 'Cyber-physical systems, IoT', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Transportation Technology and Traffic Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16038-7_31,en,Initialization and Plasticity of CEFYDRA: Cluster-first Explainable FuzzY-based Deep self-Reorganizing Algorithm,OriginalPaper,"The CEFYDRA is a network of units whose outputs are obtained using a fuzzy Takagi-Sugeno-Kang approach. At each unit, the information is clustered in fuzzy sets and then mapped using logistic functions and Cauchy membership functions. There are two primary contributions in this paper. The first is a set of suggestions for the initialization criteria of the parameters of a CEFYDRA. The second is a proposal for the self-reorganizing algorithm that modifies the location of the clusters of each unit as the algorithm is trained with gradient descent.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Engineering']"
doi:10.1007/978-981-19-3391-2_45,en,Identifying Top-N Influential Nodes in Large Complex Networks Using Network Structure,OriginalPaper,"Online social networks are popular for various activities like spreading information, creativity, and ideas, especially for viral marketing. The main focus in the social influence analysis, known as the influence maximization problem (IMP), aims to select top-N nodes to maximize the expected number of nodes activated by the top-N nodes (a.k.a seed nodes). This issue has gotten a lot of attention and has been looking into the issue of IMP, and these studies are usually too time-consuming to be useful in a complex social media network. The problem of seed selection is NP-hard. Due to the utilization of time-consuming Monte Carlo simulations, which are confined to small networks, a greedy method to the IMP issue is insufficient. The greedy approach, on the other hand, offers a good approximation assurance. In this paper, we present an algorithm for identifying communities and computing the ranking scores of nodes in the identified communities to solve the IMP with a focus on time efficiency.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Statistics, general', 'Cyber-physical systems, IoT', 'Professional Computing', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-0098-3_1,en,Efficient Prediction of Fake News Using Novel Ensemble Technique Based on Machine Learning Algorithm,OriginalPaper,"It improves the detection rate of fake news from Twitter, Facebook, and other social media. We are using a novel machine learning algorithm to detect fake news. We proposed a novel algorithm for classifying phony information and actual news. This study deals with logistic regression, SVM, and novel ensemble approach based on machine learning algorithms. It is divided into sample size values of 620 per group. The experiment uses a dataset of 10,000 records with binary classes (fake news, real news). The result demonstrated that the proposed novel ensemble approach obtains a better accuracy value of 95% and a loss value of 05% compared with other algorithms. Thus, the obtained results prove that the proposed algorithm is an ensemble approach that combines decision tree techniques with AdaBoost by varying parameters and can get a significantly higher accuracy value.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Statistics, general', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16075-2_40,en,Weak Supervision Can Help Detecting Corruption in Public Procurement,OriginalPaper,"Corruption in public procurement in the European Union is estimated to cost more than 120 billion Euros per year. Detecting corruption in public procurement is challenging because of imperfect corruption reg flags and vast number of tenders. Authorities need potent and scalable tools to identify corrupt public procurement practices. This paper shows that weak supervision machine learning algorithm provides a proficient method that can easily be implemented. Authorities can effectively calculate corruption probabilities of millions of public procurement tenders using the weak supervision algorithm. Weak supervision combines information contents of imperfect corruption red flags with unknown accuracies. Additionally, it can handle measurement errors. I analyze potential corruption in 25,859,734 European Union (EU) public procurement contracts in years 2009–2020 using the Snorkel weak supervision algorithm. These contracts are awarded by 1,212,533 authorities in 33 EU and affiliated countries. The analysis suggests that 40% of contracts and 22% of EU authorities are susceptible to corruption. Experimental results show that training machine learning models with weak supervision labeled data produces superior prediction results.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-3-031-09719-5_11,en,Central Nervous System Near-Infrared Spectroscopic Monitoring: Technique and Clinical Application,OriginalPaper,"Near-infrared spectroscopy (NIRS) non-invasively measures regional oxygen saturation (rScO 2 ) in the tissue beds of the cerebral cortex. NIRS provides an assessment of the adequacy of oxygen supply relative to demand in vascular beds, and is the technology used in cerebral oximetry. NIRS has been widely adopted as a monitor of the adequacy of brain tissue oxygenation in anesthesiology and critical care medicine and is also used intraoperatively to monitor the perfusion of the spinal cord and some other somatic vascular beds. Measurements of rScO 2 are affected by patient factors, disease states, physiologic alterations, and the variable technology and algorithms incorporated in the design of commercial monitors. It is essential that clinicians understand the technology that underlies NIRS-based cerebral oximetry so that monitoring data can be interpreted correctly. Cerebral oximetry is influenced by a variety of physiologic inputs that can alert clinicians to dysfunction of the central nervous system (CNS) and other vital organs. Specifically, cerebral NIRS monitoring integrates the cumulative input of (a) cardiac output, (b) arterial blood pressure, (c) arterial oxygen content, (d) pH and partial pressure of arterial carbon dioxide (PaCO 2 ), (e) patency of the CNS vasculature, (f) cerebral metabolic rate of oxygen (CMRO 2 ), (g) intracranial pressure (ICP), and (h) cerebral autoregulation. Cerebral oximetry is widely used in neonatology, vascular surgery, cardiac surgery, neurologic critical care, and pediatric and adult anesthesia practice. In this chapter, we review (a) the current state of NIRS monitoring technology and its limitations, (b) the physiologic variables that alter tissue oxygen balance, (c) the rationale for the use of cerebral oximetry in critical care medicine and anesthesia practice, (d) the evidence that supports its use in specific patient populations and surgical procedures, and (e) future directions for the development of NIRS technology and clinical applications .","['Medicine & Public Health', 'Anesthesiology', 'Neurosurgery', 'Pain Medicine']"
doi:10.1007/978-981-19-2225-1_2,en,A Deep Learning-Based Model for Arrhythmia Detection Using Feature Selection and Machine Learning Methods,OriginalPaper,"Arrhythmia is one of the diseases that affects many people around the world. Deep learning provides an efficient tool to detect arrhythmia disease. A convolutional neural network (CNN) is an emerging technique used often for feature extraction in the medical domain. In this paper, AlexNet, VGG-16, VGG-19 models are used as the feature extraction method, and the selected feature is supplied as input to four well-known classifiers such as decision tree, kNN, LDA, and SVM for arrhythmia detection. Furthermore, an experiment is conducted with the combination of proposed CNN model where mRMR is used as feature selection method. Finally, the result of experiment is compared with different machine learning algorithms where LDA shows the efficiency in term of classification accuracy. The classification accuracy of the proposed model is recorded as 99.46%. The performance of the proposed model is higher in terms of classification accuracy compared to previous work on arrhythmia detection.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Statistics, general', 'Mobile and Network Security']"
doi:10.1007/978-3-031-15226-9_27,en,CPG-Based Gait Generator for a Quadruped Robot with Sidewalk and Turning Operations,OriginalPaper,"This article describes the quadruped robot gait generator algorithm based on the central pattern generator (CPG). The proposed architecture uses CPG as a phase signal generator for each leg, and a mapping function that builds the desired trajectory for the robot feet. The algorithm is able to change the gait type smoothly in real time, and also do the same with movement direction, frequency, height and length of the stride. In order to test the performance of the algorithm, experiments were carried out both in the simulation and on the real robot. The results show the efficiency of the algorithm and its ease of implementation.","['Engineering', 'Control, Robotics, Mechatronics', 'Robotics', 'Computational Intelligence']"
doi:10.1007/978-981-19-3571-8_24,en,Text-Based Prediction of Heart Disease Doctor Chatbot Using Machine Learning,OriginalPaper,"Health care is important to live a happy and healthy life [ 1 ]. So Chatbots can be helpful in monitoring current health status before visiting the doctors physically. Doctor Chatbot is a means to communicate with man and machines. A Doctor Chatbot allows a user to ask queries about a health issue in a manner that they would consult a doctor. Doctor Chatbot interprets human input and responds back using Artificial Intelligence [ 2 ] and Natural Language Processing. Therapeutic, Educational, Agricultural areas are important domains to consider. Chatbots can now be utilized everywhere and at any time. Every day, a large number of people, both young and elderly, suffer as a result of a heart attack. In the proposed study the main objective is to predict whether a person has heart related issues using Deep Learning Techniques of Machine Learning. As a result accuracy of the prediction is measured. Comparative analysis of SVM, Naive Bayes, KNN algorithm is carried out and SVM outperforms other two algorithms.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-1610-6_31,en,Industrial Pumps Anomaly Detection and Semi-supervised Anomalies Labeling Through a Cascaded Clustering Approach,OriginalPaper,"Automation technology has brought significant changes to agriculture, industry, commerce and other fields, among which the machine learning algorithms are the important applications of predictive maintenance of industrial equipment. In general, anomalous trends should be detected timely before failure occurs so that unscheduled downtime can be avoided. In addition, predictive maintenance can avoid unnecessary maintenance and make good use of component remaining life by setting appropriate maintenance periods for worn parts. In this paper, based on the real case in which data collected by the various sensors on coal mine pumping system, we propose a cascaded unsupervised clustering method that consists of DBSCAN and spectral clustering to identify uncommon abnormal data and classify the common abnormal data. As equipment continuously operating, the proposed cascaded clustering method can gradually utilize the obtained uncommon abnormal data to enlarge the common abnormal data. This process implemented through periodic manually labeling is regarded as a semi-supervised manner. The results show that DBSCAN has good discriminative power for uncommon abnormal data, and the spectral clustering can properly classify working condition of water pumps with 93% accuracy on test data.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1610-6_3,en,Android Malware Classification Addressing Repackaged Entities by the Evaluation of Static Features and Multiple Machine Learning Algorithms,OriginalPaper,"Expanded usage and prevalence of android apps allows developers of malware to create new ways in various applications to unleash malware in various packaged types. This malware causes various leakage of information and a loss of revenue. In addition, the discovered software is repeatedly launched by unethical developers after classifying the program as malware. Unluckily, the program still remains undetected even after being repackaged. In this research, the topic of repackaging was discussed, emphasizing the implementation based on source code using the bag-of-words algorithm and testing the findings through machine learning. The findings of the assessment demonstrate comparatively improved result in this aspect than the existing implantation based on source code by adapting the bag-of-words strategy and implementing some supplementary dataset preprocessing. A vocabulary for identifying the malicious code has been developed in this study. Bag-of-words was used to classify malware trends using custom implementation. The findings were instantiated using various algorithms of machine learning. The concept was eventually implemented in a practical application too. The suggested method sets out a fairly new methodology for examining source code for android malware to tackle repackaging of malware.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-11170-9_4,en,Healthcare Support Using Data Mining: A Case Study on Stroke Prediction,OriginalPaper,"Data and information have become a valuable asset for small and big organizations in the past few decades. Data is the main ingredient for strategic decision-making, which could give businesses a significant advantage over their competitors, by providing customized services or overall experience to their customers and attracting new ones. For this purpose, data mining techniques are being utilized so that valuable information can be discovered and exploited. There is a vast amount of data generated in the field of healthcare that is not getting fully exploited by traditional methods, for reasons, such as their complexity, velocity, and volume. Therefore, there is a demand for the development of powerful automated data mining tools for the complete utilization of these data, and the uncovering of patterns and precious knowledge about patients, medical claims, treatment costs, hospitals, etc. This work focuses on exploiting the best-known data mining techniques: classification, clustering, and association rule mining, which are utilized extensively in the healthcare industry for incident prediction and general medical knowledge acquisition. The data mining process comprises several steps, such as data selection, pre-processing, transformation, interpretation, and evaluation. The section of the experimentation includes a stroke incidents dataset fetched from the Kaggle dataset provider. This chapter also provides a literature survey on data mining applications in the healthcare sector, while discussing the abovementioned machine learning concepts.","['Computer Science', 'Health Informatics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1142-2_1,en,Enhancement of Energy Efficiency in Wireless Sensor Network with Mobile Sink: A Survey,OriginalPaper,"The energy consumed by any activity taking place in WSN should be controlled such that limited energy in terms of battery backup remains focus throughout. In the case of dying nodes, battery discharge may cause the network to get disconnected. WSN design issues, e.g., location of sensor nodes, scheduling activities, routes of data flow, mobile sink route, should be dealt with keeping energy limitation in mind. The sensor nodes sense the data from the area of concern and communicate the same to the sink for processing. Sensor nodes deployed in various application areas have limited memory, computational power, and battery backup. There is no defined topology of such network and frequently changing environment, very less amount of battery, and limited storage capability of the nodes. It is essential that each node in the network has knowledge about the routing path to the sink which is energy efficient. Since random placement of the nodes restrains coders from presuming routing table data at the sensor nodes, numerous methods have been suggested to create a dynamic path up to sink. Numerous researches are performed for WSN using the mobile sink. Most of the research activities focused on energy conservation in the background while proposing approaches for clustering, data flow paths, trajectory design, etc. In the WSN with a mobile sink, the trajectory of the sink node plays a vital role. Designing of trajectory is an NP-hard problem. With the use of nature-inspired techniques, e.g., particle swarm optimization (PSO), genetic algorithm (GA), etc., can be used for generating a nearly optimal paths for the mobile sink. In this current article, the authors make attempt to present the summary of various strategies for energy-efficient data collection methodology and energy-efficient path planning of mobile sink in wireless sensor networks.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Mobile and Network Security', 'Artificial Intelligence']"
doi:10.1007/978-3-031-06829-4_9,en,Deep Learning to Detect and Classify Highway Distresses Based on Optimised CNN Model,OriginalPaper,"Testing the capabilities/accuracies of four deep learning pre-trained CNN models to detect and classify types of highway cracks and developing a new CNN model to maximise the accuracy at different learning rates. a sample of 4,663 images of highway cracks were collected and classified into three categories of cracks, namely, vertical cracks’, ‘horizontal and vertical cracks’ and ‘diagonal cracks’, subsequently, using ‘Matlab’ to classify the sample to training (70%) and testing (30%) to apply the four deep learning CNN models and compute their accuracies and after that, developing a new deep learning CNN model to maximise the accuracy of detecting and classifying highways cracks and testing the accuracy using three optimisation algorithms at different learning rates. The accuracy of the four deep learning pre-trained models is above the averages between top-1 and top-5. The accuracy of classifying and detecting the samples exceeded the top-5 accuracy for the pre-trained AlexNet model around 3% and by 0.2% for the GoogleNet model. The accurate model here is the GoogleNet model, as the accuracy is 89.08%, and it is higher than AlexNet by 1.26%. At the same time, the computed accuracy for the new created deep learning CNN model exceeded all pre-trained models by achieving 97.62% at a learning rate of 0.001 using Adam’s optimisation algorithm. The created deep learning CNN model will enable users (e.g., highways agencies) to scan a long highway and detect types of cracks accurately in a very short time compared to traditional approaches. A new deep learning CNN-based highway cracks detection was developed based on testing four pre-trained CNN models and analysing each model’s capabilities to maximise the accuracy of the proposed CNN.","['Engineering', 'Building Construction and Design', 'Cyber-physical systems, IoT', 'Professional Computing', 'Construction Management']"
doi:10.1007/978-3-031-18645-5_6,en,An Approach to Corporate Credit Rating Prediction Using Computational Intelligence-Based Methods,OriginalPaper,"Credit ratings tend to be very informative for investors and issuers and might serve as a powerful tool. The purpose of this paper is to investigate existing credit rating methodologies (e.g. Moody’s, Standard and Poor’s, Fitch) and to introduce improved data model for corporate ratings prediction based on computational intelligence methods. We hope that this study will provide academic researchers and industry practitioners new insights into the aspects of credit rating and its predictions. The research is performed on the selected companies that are constituents of the S&P 500 index. Company data from financial reports over period of 2016 to 2019 are analyzed and numerous financial indicators are included into analysis. The paper focuses on the design of data model, data preparation and working with missing values. Various well-known imputation techniques but also computational intelligence-based ones (e.g. fuzzy C-means) are applied to handle missing values and improve performance. In further research, the corporate credit rating prediction is brought down to a classification problem. Being a successful computational intelligence technique for credit ratings prediction, a typical neural network model is applied and compared to support vector machines as another popular data-based method in this domain. Finally, we have performed both cross-industry and industry-specific analysis. It is shown that industry-specific approach improved prediction results achieved by cross-industry data.","['Engineering', 'Mathematical and Computational Engineering', 'Business and Management, general', 'Data Engineering']"
doi:10.1007/978-3-030-92968-8_1,en,Secure Algorithm for IoT Devices Authentication,OriginalPaper,"Internet of Things (IoT) security is a major concern owing to the sensitive data that flows in these networks. The fifth generation (5G) network provides high bandwidth, endearing it as an ideal underlying network for IoT communication. In addition, 5G can facilitate seamless integration of 2G, 3G, 4G, and WiFi to realize faster services, high capacity, and very short latencies. Although 5G features such as high bandwidth and seamless integration are ideal for IoT implementations, the underlying network is vulnerable to attacks such as eavesdropping, de-synchronization, sink hole, denial of service (DoS) and replay attacks, among others. To address these challenges, a number of protocols based on techniques such as elliptic curve cryptography (ECC), trusted authority, quantum cryptography, public keys, private keys, pseudonymous certificates, group handover authentication, multi-signature, and aggregate message authentication code (AMAC) technology have been proposed. Unfortunately, these protocols either have high computation and communication costs or do not provide robust security required for IoT devices communication. This renders them inefficient and susceptible to attacks such as impersonation, privacy and location sniffing, eavesdropping, session key disclosure attacks, modification, and insider attacks. Consequently, there is need for an efficient and secure key agreement and session authentication protocol for IoT deployments. In this paper, an efficient and secure handover protocol for IoT devices is proposed. The simulation results showed that this protocol exhibited lower computation and turnaround time, high stability, and moderate communications costs. It was also demonstrated to be robust against masquerading, packet replay, eavesdropping, free riding attacks, privacy and location sniffing.","['Engineering', 'Communications Engineering, Networks', 'Industrial and Production Engineering', 'Business and Management, general']"
doi:10.1007/978-3-031-12127-2_4,en,The Novel Characterizing Method of Collective Behavior Pattern in PSO,OriginalPaper,"Although swarm intelligence algorithms have attracted extensive attention, there is little research on the behavior of collective dynamics. Inspired by the moving patterns of fish school, we propose a visualization method of collective behavior patterns based on the velocity field, discover various collective behavior patterns, and propose a discriminate index named swarm trend factor. In addition, this paper proposes a novel swarm states division method, on the basis of swarm trend factor. In the experiments, we demonstrate that swarm trend factor can reflect the performance of PSO. And, we also compare the difference between swarm trend factor and another swarm state division method.","['Engineering', 'Computational Intelligence', 'Information Systems and Communication Service', 'Management of Computing and Information Systems']"
doi:10.1007/978-3-031-20105-9_6,en,Fractional-Order Estimation Using via Locust Search Algorithm,OriginalPaper,"Recently, parameter estimation for fractional-order chaotic systems has attracted the attention of multiple scientific and engineering fields. In the estimation process, the parameters of a given system are formulated into an optimization problem. One of the most interesting estimation problems relies on fractional-order systems. Where functional parameters and fractional orders parameters of the chaotic system are considered as decision variables in an optimization perspective. For this scenario, the complexity of fractional-order chaotic systems tends to construct error functions within a multimodal fashion. Many algorithms based on the principles of evolutionary computation have been developed to be applied to determine the parameters of a given fractional-order chaotic system. Nonetheless, most of them hold a crucial boundary, they repeatedly acquire local optimal values as outcomes, as a consequence of an improper balance among the evolutionary exploration stage and exploitation stage. This chapter introduces an evolutionary approach to estimating the parameter values of fractional-order chaotic systems. To estimate the parameters, the proposed approach employs a newly developed evolutionary technique known as Locust Search (LS) which is based on the conduct of swarms of locusts.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-13588-0_32,en,3D Reconstruction Using Sketch Based on Duchon Energy,OriginalPaper,"3D surface reconstruction plays a vital role in augmented reality, virtual reality, and robotics. Previous work can obtain high-quality mesh when the input data is dense and evenly distributed. Although many reconstruction algorithms that can get high-quality meshes have been proposed, the quality of the obtained meshes will be degraded when encountering some particular circumstances, such as noise and data missing. This article introduces a surface reconstruction method with good performance despite non-uniformly distributed and missing data. We supplement the input with the sketch and estimate the normal of the sketch globally based on Duchon energy which makes the estimated normal accurate and smooth. Then we use the signed distance function, whose zero iso-surface represents the surface, to combine the sketch with the original input and compute the implicit function as the solution of a sparse linear system. The experimental results show that this method can generate a high-quality mesh. The use of smoothness energy allows our approach to be much more resilient to sampling imperfections than existing methods. In addition, the technique can add sketches to existing models to obtain 3D models that are more in line with the creator’s intent.","['Engineering', 'Engineering Mathematics', 'Computational Intelligence']"
doi:10.1007/978-981-19-2535-1_38,en,Brain Tumor Segmentation,OriginalPaper,"DIP for Medicinal examination is considered as a vital topic for artificial intelligent system. We are introducing a hybrid technique combining K-means and Fuzzy C-means clustering algorithms for determining whether a brain MR Imaging scan consists tumor or not. As K-means is a hard clustering algorithm so it is used for initial segmentation via appropriate selection of the image. And after that FCM is used to provide membership to each centroid through the distance between the cluster centroid and cluster data point, prior to obtaining best result. This distance relies upon various factors, i.e., contrast, saturation, structure, brightness, and homogeneity of the image. Based upon the provided memberships by FCM technique and automated cluster selection a sharp segmented image is obtained. This modified hybrid (hard and soft clustering) approach reduces equipment and operator error. The outcome unveils that such an approach is remarkably encouraging.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3387-5_162,en,Fast CU Partition Algorithm for AVS3 Based on DCT Coefficients,OriginalPaper,"Audio Video coding Standard 3 (AVS3), which has been brought in many advanced algorithms and technologies on the basis of previous video coding standard, has already improved the coding efficiency greatly. However, with the performance improvement comes a huge increase in coding time. To facilitate commercialization, algorithms that reduce the time complexity of AVS3 standard must be developed. Based on the new code block (CU) partitioning rules of AVS3 standard, we present a new CU partition algorithm based on the discrete cosine transform (DCT) coefficients. According to the feature that DCT coefficient can reflect image texture, we find the relationship between it and CU partition, The DCT coefficients calculated by the fast DCT algorithm are used to limit and make decisions on CU partitioning in all-intra (AI) mode, so that the ergodic process of CU partitioning is greatly reduced, thus achieving the effect of reducing the time complexity. Experimental results show that the proposed algorithm can reduce the time complexity with a small Bjøntegaard-Delta rate (BD-rate) increase.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Aerospace Technology and Astronautics']"
doi:10.1007/978-3-031-11051-1_163,en,Assessment of Porosity and Fracturing of Rocks Using Digital Photographs of Core Thin Sections,OriginalPaper,"Modern methods of lithological research allow obtaining results in digital form. This increases the objectivity, accuracy, reliability of data on rocks and makes possible their further computer processing and modeling. The article studies the issue of analyzing the composition and properties of rocks using digital photographs of the core sample. Existing techniques shall be considered. A scheme for the automated assessment of porosity and fracture parameters based on photographs of petrographic thin sections shall be proposed: 1) semi-automatic selection of voids by color; 2) automatic selection of cracks based on geometric features; 3) estimation of parameters of absolute porosity, total length and average width of cracks. To highlight voids, color filtering was applied with interactive input of the values of the classification attributes. Allocation of cracks from the general mass of voids was carried out according to the characteristics of the shape and area. The value of the absolute porosity was estimated as the ratio of the area of the selected voids to the total area of the photography. To determine the average width and total length of the cracks, the inscribed rectangle approximation was used. The scheme is implemented using algorithms of the OpenCV library, integrated into a custom software application. Convergence of the results of using the application with the results of a non-automated expert assessment for the parameter of porosity 80%, fracturing 70%. Estimation errors refer to cases of low color contrast of voids and mineral skeleton and segmentation of fracture lines in the original photographs. When using the application, a significant increase in speed and a decrease in the labor intensity of a specialist’s work was obtained. This allows us to recommend the developed application for express analysis of photographs of core thin sections.","['Engineering', 'Control and Systems Theory', 'Control, Robotics, Mechatronics', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-3998-3_28,en,Extended ADMM with Paillier Cryptosystem for Nonsmooth Decentralized Optimization,OriginalPaper,"This article studies a nonsmooth multiagent decentralized optimization problem where the agents aim at minimizing a sum of local strongly-convex smooth components plus a common nonsmooth term. We propose an algorithm based on ADMM framework which introduces a proximal term. We establish linear convergence of the proposed algorithm to the exact optimal solution in the presence of the nonsmooth term. Moreover, Paillier cryptosystem has been combined with our algorithm to ensure the privacy preserving in decentralized optimization in the absence of any third party or aggregator. We further provide a numerical example for a least squares problem equipped with $$L_1$$ L 1 regular term to show the linear convergence rate and how the step size influences the convergence.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-981-19-7648-3_13,en,Energy-Aware Computational Resource Allocation,OriginalPaper,"Mobile edge computing (MEC) with energy harvesting (EH) is becoming an emerging paradigm to improve the computation experience for the Internet of Things (IoT) devices. For a multi-device multi-server MEC system, the frequently varied harvested energy, along with changeable computation task loads and time-varying computation capacities of servers, increase the system’s dynamic. Therefore, each device should learn to make coordinated actions, such as the offloading ratio, local computation capacity and server selection, to achieve a satisfactory computation quality. Thus, the MEC system with EH devices are highly dynamic and face two challenges: continuous-discrete hybrid action spaces, and coordination among devices. To deal with such problem, we propose two deep reinforcement learning (DRL) based algorithms: hybrid decision based actor-critic learning (Hybrid-AC), and multi-device hybrid decision based actor-critic learning (MD-Hybrid-AC) for dynamic computation offloading. Hybrid-AC solves the hybrid action space with an improvement of actor-critic architecture, where the actor outputs continuous actions (offloading ratio and local computation capacity) corresponding to every server, the critic evaluates the continuous actions and outputs the discrete action of server selection. MD-Hybrid-AC adopts the framework of centralized training with decentralized execution. It learns coordinated decisions by constructing a centralized critic to output server selections, which considers the continuous action policies of all devices. Simulation results show that the proposed algorithms achieve a good balance between consumed time and energy, and have a significant performance improvement compared with baseline offloading policies.","['Computer Science', 'Computer Systems Organization and Communication Networks', 'Communications Engineering, Networks', 'Wireless and Mobile Communication']"
doi:10.1007/978-3-031-15951-0_7,en,Intelligence in Machines,OriginalPaper,"The idea of building intelligent machines has been around for a long time. The ancient Egyptian and Chinese had myths about robots and inanimate objects coming to life. Philosophers mulled over the hypothesis that mechanical men, artificial beings, and other automatons had existed or could exist in some fashion. Realizing human behavior through machine imitation and making machines possess human intelligence is a long-term goal of human beings.","['Computer Science', 'Artificial Intelligence', 'Engineering/Technology Education', 'Computer Science, general']"
doi:10.1007/978-981-19-1906-0_3,en,Developed Optimized Routing Based on Modified LEACH and Cuttlefish Optimization Approach for Energy-Efficient Wireless Sensor Networks,OriginalPaper,"The main concern for efficient data transmission in a wireless network is energy dissipation. With the enhancement in the size of the network, there is more demand to aggregate the information which leads to depletion of energy in the nodes. To solve such issues, an efficient data transmission model has to be designed. This paper implements the modified LEACH (MOD-LEACH) concept for node clustering. Along with the efficient cluster head selection, the proposed model is backed with an optimized approach called cuttlefish optimization (CO) which uses two objective functions to optimize the parameters of the network. The proposed novel work is compared with two existing approaches, and the experimental and theoretical results reveal that the proposed model surmounts the two preexisting similar methods in terms of average energy consumption, number of alive nodes, and total packets delivered to the base station. The proposed approach records approx. 75% reduction in the energy consumption of the network.","['Engineering', 'Electronics and Microelectronics, Instrumentation', 'Computer Systems Organization and Communication Networks', 'Artificial Intelligence']"
doi:10.1007/978-3-031-11058-0_42,en,Simulation Modelling of Car Movement on Sorting Tracks,OriginalPaper,"Marshalling yards are nodes in rail freight transport chains. The sorting tracks is the most important part of marshaling yard. There is the largest number of commercial rejects on the sorting tracks. This is due to car collision with unacceptable speed. Today many researches investigate the problems on classification tracks. The goal of this article is to consider factors that affect the stop point of the car and develop a new algorithm for determining the stop point of the car. The object of research is the speed of the car on the track. The subject is the factors affecting on the speed. As a result of the study, the authors created a new simulated model of car movement. This model takes into account the possibility of moving the set of cars off after stopping. The authors consider the differences in the determination of the car stop point according to the old and proposed algorithms. It was concluded, that the proposed algorithm determines the car stop point more accurately.","['Engineering', 'Control and Systems Theory', 'Control, Robotics, Mechatronics', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-3951-8_39,en,Predicting the Completion of a Science Degree Based on the First Year Marks at Higher Education Institutions,OriginalPaper,"Advances in the field of machine learning have led to major improvements to Higher educational institutions attempts to predict student performance. The capacity to predict the performance of students is of utmost significance to any Higher Education Institution aiming to improve the performance of students and increase graduation rates. Students at risk of academic retention can be identified and be provided with the necessary support timeously. We can therefore use machine learning techniques to leverage these marks and predict students’ performance. In this study, taking a conceptual framework proposed by Spady in (Interchange 1(1):64–85 [ 16 ]) as a rationale, we attempt to predict (using first year marks) the completion of a learner’s undergraduate Computer Science degree. For this cause, we employ several machine learning predictive models such as the J48, Naive Bayes, Support Vector Machines, Multilayer Perceptron, Logistic Regression and the K-Star. With the 10-fold cross validation method, we compared the performance of the predictive models using their accuracy, precision, and recall values. The J48 predictive model achieved the highest accuracy value of 70% percent. Comparison was also done using AUC. The J48 algorithm achieved the highest AUC value of 0.75. Using gain ratio, this study also revealed that a students who performed well in Calculus and Algebra is more likely to complete their studies in Computer Science.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-3-031-05516-4_2,en,Using a Functional Voxel Model to Simulate Swarm Motion of a Multi-agent System in a Confined Space,OriginalPaper,"This paper proposes a way to implement potential attraction/repulsion fields. We consider the implementation of a multi-agent system that moves toward a common target in unbounded space, using swarming algorithms based on Reynolds rules. Three swarm modeling approaches are presented, jointly implementing a finite algorithm that ensures collision avoidance with all available barrier types. The algorithms are described in more detail in our previous paper [ 1 ]. We propose the joint application of the investigated swarming algorithm and a predator avoidance model based on reinforcement learning to provide collision avoidance with dynamically occurring barriers. Thus, it is possible to temporarily evade the target to ensure the safety of the agents' movement. The algorithm is based on Q-learning, the result of which is an action function. We consider the behavior of a multi-agent system modeled using the proposed approaches in a bounded space—a polygon or polygon. In this case, in addition to the described interactions, the movement of a group of agents is influenced by repulsive forces from walls. There is a problem of compensation of repulsive and attractive potentials, accompanied by braking of agent or ignoring of walls when moving to the target. This problem is proposed to be solved using function-voxel models. The principle of movement of agents according to the local geometric characteristics stored in the represented graphical M-images of the simulated polygon is described. In the paper, the solution of problems for hazard avoidance using the approach of potential fields, which are expressed by voxel surfaces, is obtained. The advantages of using these models and the need for an algorithm for predator avoidance are highlighted.","['Engineering', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Cities, Countries, Regions', 'Artificial Intelligence', 'Statistics, general']"
doi:10.1007/978-981-19-1906-0_34,en,Motion Correction of MR Images Using Cross-Guided Bilateral Filter,OriginalPaper,"Motion artifact has been the foremost concern in the field of medical imaging (MI). These artifacts compromise image quality and interfere in image interpretation, especially in MRI applications with low signal-to-noise ratio. In motion artifact removal process, the most demanding problem is to protect the data bearing structures such as edges and surfaces to get good visual quality while enhancing peak signal-to-noise ratio (PSNR). Application of filters on these motion artifact affected MRI signals yields better performance in terms of removal of artifact and consequently correct interpretation by the radiologist. The paper presents the analysis on the use of various filters/techniques for motion artifact removal. Motion artifact removal using cross-guided bilateral filter (CGBF) is experimented, and the results are discussed with various evaluation parameters. Motion correction using CGBF is compared with the existing techniques, and the performance of CGBF is found to be superior.","['Engineering', 'Electronics and Microelectronics, Instrumentation', 'Computer Systems Organization and Communication Networks', 'Artificial Intelligence']"
doi:10.1007/978-981-19-6004-8_7,en,Convolutional Neural Network Based Intrusion Detection System and Predicting the DDoS Attack,OriginalPaper,"In today’s world, cybersecurity is important as it secures data against damage and unauthorized access. In recent years, machine learning studies have made remarkable developments in cybersecurity and helped in deriving the pattern of user activities, checking for malicious activities in the network, and identifying the cyberattacks. This research intends to predict the DDoS attack that impedes network access by flooding a large amount of traffic, saturating the bandwidth of the network. The proposed work uses convolutional neural network (CNN) to train the machine learning model to anticipate the DDoS attack before it happens. The CNN model is trained using live data, where the data packets are captured using Wireshark and the KDD CUP 1999 dataset. The packet’s information is converted into a two-dimensional image and is trained using the CNN algorithm. The proposed system’s performance is evaluated and compared with the existing IDS systems, which attains a maximum accuracy of 95.8%.","['Engineering', 'Computational Intelligence', 'Cognitive Psychology', 'Personality and Social Psychology', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-1484-3_13,en,"Design of Hybrid Soft Computing Techniques for Estimation of Suspended Sediment Yield in Krishna River, India",OriginalPaper,"This paper explores the soft-computing approaches for estimating suspended sediment yield (SSY). In the management of water resources, the SSY estimation is an important issue. The SSY estimation is essential for getting the information about mass balancing between the land and ocean.  The traditional methods for measuring the SSY require larger magnitudes of time and significant financial investments. Also, the SSY depends on numerous variables and their internal relationship which are extremely nonlinear and complex in nature. Thus, traditional methods are not capable to handle the complex nonlinear sedimentation behaviors and unable to accurate estimation of SSY. The multilayer perceptron (MLP) artificial neural network (ANN)-based genetic algorithm (GA) model is used for SSY prediction which resolves complex sedimentations problems. In this proposed model, the GA optimized all ANN’s model parameters simultaneously. The input functional parameters that impact the SSY in the Krishna River are water discharge and water level. This paper presents artificial intelligence-based sediment yield estimation algorithms at Waddepally gauge station in Krishna River, India. The GA is used for the optimization of the performance of ANN in accurately estimating the SSY. The hybrid GA-based ANN (GA-ANN) has produced most accurate and efficient results for estimation of SSY in Krishna River.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Machine Learning', 'Data Structures and Information Theory', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-981-19-4863-3_32,en,Application of Adaptive Neuro-Fuzzy Inference System and Salp Swarm Algorithm for Suspended Sediment Load Prediction,OriginalPaper,"Due to the sheer importance of suspended sediment load (SSL) in watershed management and design of engineering structures and considering the impact of rainfall, temperature, and runoff parameters in quantifying and understanding nonlinear interdependence, it has been a crucial task to predict suspended sediment load based on these parameters. For this purpose of prediction, a soft computing model (adaptive neuro-fuzzy inference system (ANFIS)) is optimized with Salp swarm algorithm (SSA), and the results were validated against a well-established classical ANFIS model. Data from Jaraikela catchment area in Jharkhand with some part of it in Sundergarh district of Odisha were used in the analysis. The performance of the models was evaluated based on MSE and WI performance indicators. In comparing the results of the models used, it is evident that ANFIS-SSA model proved its ascendancy over ANFIS.","['Engineering', 'Computational Intelligence', 'Engineering Design', 'Machine Learning', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-3035-5_28,en,Hybrid Malicious Encrypted Network Traffic Flow Detection Model,OriginalPaper,"Encrypted communication technology has evolved as the network, and Internet applications have advanced. Malicious communication, on the other hand, employs encryption to bypass standard detection and security protection. The existing security prevention and detection technologies are unable to identify harmful communication that is encrypted. The growth of artificial intelligence (AI) in these days has enabled to employ machine learning (ML) as well as deep learning approaches to identify encrypted malicious communications without decryption, with remarkably precise detection outcomes. At this moment, research on detecting harmful encrypted traffic is mostly focused on analyzing the features of encrypted data and selecting neural network (NN) techniques. Hybrid ML is proposed in this study by merging two well-performing data mining algorithms with natural language processing tasks. Here, a new traffic flow detection method is performed by the hybrid ML technique. At first, the benchmark data is collected from public sources. The features are extracted using the convolutional layer of deep convolutional neural network (DCNN). Then, the weighted feature extraction is performed by grasshopper optimization algorithm (GOA). Employed the hybrid machine learning-based malicious detection with the “support vector machine (SVM) and neural network (NN)” is utilized in this model to detect the traffic affected by malicious activities, where the hidden neuron count of NN and kernel of SVM are tuning by the same GOA for increasing the accuracy and precision. This research provides findings from experiment, encouraging various researchers to develop the research as future work.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Statistics, general']"
doi:10.1007/978-3-031-18050-7_62,en,A Comparison of Two Speech Emotion Recognition Algorithms: Pepper Humanoid Versus Bag of Models,OriginalPaper,"Some of the most exciting applications of Speech Emotion Recognition (SER) focus on gathering emotions in daily life contexts, such as social robotics, voice assistants, entertainment industries, and health support systems. Among the most popular social humanoids launched in the last years, Softbank Pepper ® can be remarked. This humanoid sports an exciting multi-modal emotional module, including face gesture recognition and Speech Emotion Recognition. On the other hand, a competitive SER algorithm for embedded systems [ 2 ] based on a bag of models (BoM) method was presented in previous works. As Pepper is an exciting and extensible platform, current work represents the first step to a series of future social robotics projects. Specifically, this paper systematically compared Pepper’s SER module (SER-Pepper) against a new release of our SER algorithm based on a BoM of XTraTress and CatBoost (SER-BoM). A complete workbench to achieve a fair comparison has been deployed, including other issues: selecting two well-known SER datasets, SAVEE and RAVNESS, and a standardised playing and recording environment for the files of the former datasets. The SER-BoM algorithm has shown better results in all the validation contexts.","['Engineering', 'Computational Intelligence', 'Industrial and Production Engineering']"
doi:10.1007/978-981-19-3387-5_157,en,An Overview on Digital Content Watermarking,OriginalPaper,"With the rapid development of multimedia technology, balancing multimedia visual enjoyment and information security has become one of the hot spots of current research. Due to the complexity and the cost of video content production, the corresponding video services face many security challenges, and higher requirements for the protection of video content copyright are also been put forward. Among them, digital watermarking technology is a typical information hiding method, which covers text, image and video. In the case of copyright disputes, watermark has become an important way to confirm the copyright and identity information. Digital watermarking technology uses the redundancy and randomness of media content data to embed the cipher text of copyright identification into the protected data. Except for data processing, the rest is invisible to ensure high security. This paper summarizes the current research progress of digital watermarking technology and digital watermarking algorithms, and then puts forward possible research directions in the future.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Aerospace Technology and Astronautics']"
doi:10.1007/978-981-19-5224-1_30,en,Security Techniques Implementation on Big Data Using Steganography and Cryptography,OriginalPaper,"The COVID-19 pandemic has increased everyone’s exposure to the Internet thus there has been an addition of new people who now access the Internet and its applications. Hence, the quantity of big data has grown tremendously in the era of smart city life. Thus concern for security of big data has risen. The attacks currently faced by big databases such as misuse, misrepresentation, modification, and unauthorized users and such attacks have increased in number. To ensure the security of big data stores to prevent misuse, misrepresentation, modification, and unauthorized users issues related to insecurity in storage units and not rendering it vulnerable to attackers, it is needed to enhance the secrecy, privacy, and increase the capacity for hiding secret cover. While cryptography guarantees authentication, integrity, non-repudiation, etc. In this paper, the author has studied popular data hiding techniques, especially steganography and cryptography used for provides security to big databases.","['Engineering', 'Communications Engineering, Networks', 'Statistics, general', 'Cyber-physical systems, IoT', 'Sociology, general', 'Professional Computing']"
doi:10.1007/978-981-19-3387-5_164,en,Fast Intra Prediction Algorithm for AVS3,OriginalPaper,"With the development of 5G and multimedia technologies, applications such as ultra-high-definition video, VR and High dynamic range video have become more popular. This has led to an increasing amount of video data, which has brought great challenges to the storage and transmission of video data. Therefore, a video encoder with better compression performance is needed to remove the time redundancy, spatial redundancy and statistical redundancy in the image sequence of video, and greatly compress the raw video data under the premise of ensuring image quality. The Audio Video Coding Standard Workgroup of China has formulated the AVS video coding standard, and the latest AVS3 standard is currently under research and formulation. In order to improve the compression performance of the encoder, AVS3 introduced a large number of new technologies on the basis of AVS2 standard, resulting in a 266% increase in encoding complexity compared to AVS2. This paper optimizes the coding unit partition process and intra mode decision process of AVS3 Results show that the proposed algorithms reduce about 46.82% and 4.49% intra encoding time on average, with only 1.22% and 0.01% increases in terms of BDBR.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Aerospace Technology and Astronautics']"
doi:10.1007/s00256-022-04160-z,en,A deep learning algorithm for detecting lytic bone lesions of multiple myeloma on CT,"['OriginalPaper', 'Scientific Article']","Background Whole-body low-dose CT is the recommended initial imaging modality to evaluate bone destruction as a result of multiple myeloma. Accurate interpretation of these scans to detect small lytic bone lesions is time intensive. A functional deep learning) algorithm to detect lytic lesions on CTs could improve the value of these CTs for myeloma imaging. Our objectives were to develop a DL algorithm and determine its performance at detecting lytic lesions of multiple myeloma. Methods Axial slices (2-mm section thickness) from whole-body low-dose CT scans of subjects with biochemically confirmed plasma cell dyscrasias were included in the study. Data were split into train and test sets at the patient level targeting a 90%/10% split. Two musculoskeletal radiologists annotated lytic lesions on the images with bounding boxes. Subsequently, we developed a two-step deep learning model comprising bone segmentation followed by lesion detection. Unet and “You Look Only Once” (YOLO) models were used as bone segmentation and lesion detection algorithms, respectively. Diagnostic performance was determined using the area under the receiver operating characteristic curve (AUROC). Results Forty whole-body low-dose CTs from 40 subjects yielded 2193 image slices. A total of 5640 lytic lesions were annotated. The two-step model achieved a sensitivity of 91.6% and a specificity of 84.6%. Lesion detection AUROC was 90.4%. Conclusion We developed a deep learning model that detects lytic bone lesions of multiple myeloma on whole-body low-dose CTs with high performance. External validation is required prior to widespread adoption in clinical practice.","['Medicine & Public Health', 'Imaging / Radiology', 'Orthopedics', 'Pathology', 'Nuclear Medicine']"
doi:10.1007/978-981-19-2538-2_3,en,"Security Attacks, Requirements and Simulative Analysis of QoS in WSN",OriginalPaper,"The objective of a routing protocol for wireless sensor network is to ensure availability of messages, authentication and integrity. Most of the existing secure routing algorithms for Wireless Sensor Networks are based on symmetric analysis of transmission and packet analysis. Security is always a concerning area in the field of Wireless Sensor Network and it is necessary to understand the security requirements. This paper explored the Wireless Sensor Network basic with existing secure routing algorithms along with the clustering-based Genetic Algorithm and test over the Wireless Sensor Network. Genetic algorithms are components of random algorithms. In order to construct the answer, this approach requires a precious volume of determinism embedded to genetic variables. The simulation covers most concerning areas of energy and packet transmission analysis. This paper covers to comprehend the security attacks, security requirements and the proposed algorithm that performs better result in terms of energy dissipation, dead nodes and throughput as compare to other protocols after certain comparisons at MATLAB-2013 platform.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory', 'Mobile and Network Security']"
doi:10.1007/978-3-031-11058-0_57,en,Mathematical Modeling the H2SO4-Catalyzed Alkylation of Isobutane with Olefins,OriginalPaper,"The purpose of this work is to develop a mathematical model of sulfuric acid alkylation of isobutane by olefins, taking into account the physical and chemical laws of the process. Due to the increased environmental requirements for fuel, the relevance of sulfuric acid alkylation of isobutane with olefins, as it allows us to achieve good results in this matter. Significant features of the technology that need to be taken into account when modeling are identified. The main schemes of transformations of sulfuric acid alkylation of isobutane by olefins are considered. The probability of all reactions is estimated from the Gibbs energy value. The model is a system of ordinary nonlinear differential equations. The direct problem was solved by Radau IIA method. During the simulation, heuristic optimization methods were used, the Electromagnetism like Algorithm and the Harmony Search algorithm were considered to minimize the deviation of experimental data from theoretical ones. The rate constants of the reaction under consideration are found. The foundations for further modeling of the entire chemical-technological process are laid.","['Engineering', 'Control and Systems Theory', 'Control, Robotics, Mechatronics', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-3505-3_23,en,Departure Time Planner for Multimodal Public Transport Network Using Dynamic Programming,OriginalPaper,"In developing countries like India, number of people using public transport for everyday commute is large. Trip planner is a tool which helps commuters to plan their travel beforehand. In case of public transportation systems, trip with the minimum travel time is often of interest. A trip planner solves the time dependent shortest path problem (TDSPP) in a multimodal transport network to optimize one or more criteria like travel time, the number of transfers, etc. One subclass of this is the departure time planner. It suggests the optimal departure time from origin such that travel time to reach the destination will be minimum. This paper presents development of multimodal departure time planner using General Transit Feed Specification (GTFS) data. A citywide public transportation network is constructed with bus, metro and walking as modes of transport. Nodes represent transit stops and edges represent transportation services available in between nodes. The schedule corresponding to every mode is incorporated in the network. Origin, destination, and the latest arrival time at the destination for the trip are inputs from the user. A schedule-based algorithm is implemented which runs backward in time to calculate optimal labels at every node of the network. The results produced by the trip planner are found to be promising in terms of accuracy and feasibility.","['Engineering', 'Transportation Technology and Traffic Engineering', 'Construction Management', 'Sustainable Development']"
doi:10.1007/978-981-16-7487-7_8,en,Neuromorphic Data Converters Using Memristors,OriginalPaper,"Data converters are ubiquitous in data-abundant mixed-signal systems, where they are heterogeneously distributed across the analog–digital interface. Unfortunately, conventional CMOS data converters trade off speed, power, and accuracy. Therefore, they are exhaustively customized for special purpose applications. Furthermore, intrinsic real-time and post-silicon variations dramatically degrade their performance along with the technology downscaling. Using machine learning techniques and neuromorphic computing, these issues can be overcome. This chapter presents four-bit neuromorphic analog-to-digital (ADC) and digital-to-analog (DAC) converters using memristors that are trained using the stochastic gradient descent algorithm in real-time to autonomously adapt to different design and application specifications, including multiple full-scale voltages, sampling frequencies, number of resolution bits, and quantization scale. Theoretical analysis, as well as simulation results, show the collective resilient properties of our converters in application reconfiguration, logarithmic quantization, mismatches calibration, noise tolerance, and power optimization. Furthermore, large-scale challenges are discussed and solved by leveraging mixed-signal architectures, such as pipelined ADC. These ADC and DAC designs break through the tremendous speed-power-accuracy tradeoff in conventional data converters and enable a general-purpose application architecture with valuable results for neuromorphic computing.","['Engineering', 'Circuits and Systems', 'Electronic Circuits and Devices', 'Processor Architectures', 'Nanotechnology', 'Electronics and Microelectronics, Instrumentation']"
doi:10.1007/978-3-031-16237-4_5,en,Unsupervised Anomaly Detection for MIL-STD-1553 Avionic Platforms Using CUSUM,OriginalPaper,"MIL-STD-1553 is a military standard developed by the US department of defense for communication among military avionic platforms (e.g., F-35 and F-16). It has been widely accepted worldwide for more than five decades and is used in many applications other than military avionics. It follows a strict and deterministic procedure for communication among its components. However, research has suggested that it has many vulnerabilities associated with it that can be exploited to carry a range of attacks on it. And since numerous applications make use of this standard, it is crucial to protect MIL-STD-1553 networks. This chapter presents an unsupervised anomaly detection scheme using the CUSUM algorithm for the MIL-STD-1553 protocol. A dataset was collected in the ISOT lab by executing six attack vectors on a simulated MIL-STD-1553 network. We leverage the time-based properties of the communication bus to extract a set of relevant features that are fed to the CUSUM algorithm for detection. The experimental evaluation of the proposed detector using the dataset yielded promising results, which are very encouraging considering the unsupervised nature of the underlying algorithm.","['Engineering', 'Cyber-physical systems, IoT', 'Data Engineering', 'Computational Intelligence', 'Big Data', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4208-2_1,en,Application of Jaya Algorithm for Minimizing Surface Finish in MQL-Based Green Machining of Titanium Alloy,OriginalPaper,"“Sustainable Manufacturing” is a recent concept to obtain efficiency in the manufacturing process in terms of economy and environmental friendliness with social aspects. Green manufacturing (GM) is a sub-set of sustainable manufacturing and aims to obtain environmentally friendly machining. Dry machining, minimum quantity lubrication (MQL) machining, and nanofluid machining are different approaches employed for minimizing the use of cutting fluid during machining, aiming toward the achievement of the green machining concept. Also, the use of cutting fluids causes several health hazards for human operators during the machining and handling processes. Machining of hard aero-space materials like titanium and nickel-based alloys with better surface finish requires a flood coolant system. This work aims to minimize the surface finish and cutting temperature and obtain optimum machining parameters during nanofluid-based MQL machining of titanium alloy Ti6Al4V. Turning experiments, conducted by Zaman et al. (Adv Mater Process Technol 1–21, 2020), are used for optimizing the process. A Box Behnken design of experiments with four factors at three levels is used, with 27 experimental runs. Model for Ra and T is developed with response surface methodology (RSM) as a function of four process variables (i.e., v , f , d, and C ). The process is optimized using the Jaya algorithm, a popular parameter-free method. The results are compared with the conventional desirability function (DF) approach and found to be closer; the source codes developed were run in MATLAB and obtained optimum parameters with a fewer iterations.","['Engineering', 'Industrial and Production Engineering', 'Robotics and Automation', 'Manufacturing, Machines, Tools, Processes']"
doi:10.1007/978-3-030-92989-3_10,en,Direct Iterative Basis Image Reconstruction Based on MAP-EM Algorithm for Spectral CT,OriginalPaper,"Spectral CT has been attracting great research interest in the last decades. The spectral CT imaging, especially photon-counting multi-energy spectral CT imaging, can effectively improve the reconstructed image quality and has the distinctive ability of material decomposition and identification, which has important theoretical and application value in the fields of medical diagnosis, non-destructive testing and security inspection, etc. However, the presence of non-ideal effects in spectral CT imaging systems limits the accuracy of basis images. To achieve high accuracy of material decomposition and high quality of basis images, a novel and robust direct iterative basis material image reconstruction method based on maximum a posteriori expectation–maximization algorithm (MAP-EM-DD) is proposed. Furthermore, by incorporating polar coordinate transformation into MAP-EM-DD, MAP-EM-PT-DD method is proposed. The iterative formulas of MAP-EM-DD and MAP-EM-PT-DD methods are derived. To evaluate the proposed methods, a simulated cylinder phantom with inserts that contain polyethylene, hydroxyapatite, salt water, air, and aluminum is established. The proposed methods are quantitatively evaluated for comparative studies. Simulated experimental results show that the proposed methods can remarkably reduce the noise of basis images and error of material decomposition and improve the contrast-to-noise ratios (CNRs) of each material-specific region. Compared with the image domain material decomposition based on FBP algorithm (FBP-IDD), MAP-EM-DD method can reduce the noise levels of basis images up to 63.6% and the error levels of each material-specific region up to 62.1%. Simultaneously, the CNRs of each material-specific region are improved up to 237.3%. Compared with MAP-EM-DD method, MAP-EM-PT-DD method can reduce the noise levels of basis images up to 23.6%, the error levels of each material-specific region up to 36.3%, and the reconstruction time of basis images by 14.1%.","['Engineering', 'Circuits and Systems', 'Biomedical Engineering and Bioengineering', 'Microwaves, RF and Optical Engineering']"
doi:10.1007/978-3-031-22200-9_79,en,Obstacle Avoidance Algorithm for Autonomous Mobile Robots in the Indoor Environment,OriginalPaper,"Autonomous mobile robots (AMR) are commonly used in intelligent manufacturing systems. For these robots to operate autonomously in the working environment, in addition to being equipped with a sensor system, algorithms are required to process information collected from the working environment and make control decisions to control the robot's movement in different situations. In this paper, the authors present an algorithm to avoid static, dynamic obstacles and generate local guidance trajectories for the robot to overcome the barriers on its way based on information from the sensor network equipped with the robot. In this, dynamic obstacles are understood as objects moving in the same direction opposite to the direction of the robot or crossing the motion of the robot. The proposed algorithm has been experimentally verified on a differential drive mobile robot combined with a mecanum wheel mobile robot. The results of this research have practical implications for motion control of AMR in industries.","['Engineering', 'Mathematical and Computational Engineering', 'Mechanical Engineering', 'Electrical Engineering']"
doi:10.1007/978-981-19-7210-2_4,en,Sequential Multi-fidelity Surrogate Modeling,OriginalPaper,"Under a limited computational budget, the quality of a multi-fidelity (MF) surrogate depends on the distributions of the sample points and sample size ratio between the low-fidelity (LF) and high-fidelity (HF) simulations, i.e., the allocation of the computational budget.","['Engineering', 'Engineering Design', 'Optimization', 'Engineering Mathematics', 'Mathematical Modeling and Industrial Mathematics']"
doi:10.1007/978-3-031-17576-3_3,en,Mango Varieties Classification-Based Optimization with Transfer Learning and Deep Learning Approaches,OriginalPaper,"Mango is one of the well known tropical fruits native to south asia and currently there are over 500 varieties of mangoes known. Depending on the variety, mango fruit can be varied in size, skin color, shape, sweetness, and flesh color which may be pale yellow, gold, or orange. However, sometimes it is difficult for us to differentiate what type of mango it is. Thus, in this paper, four types of mango classification approach is presented. Thus, we are going to use convolutional neural network (CNN) algorithm and transfer learning methods (VGG16 and Xception) to train on the 1000 mango images collected and obtain a deep learning model which is able to classify four types of mango (Alampur Baneshan, Alphonso, Harum Manis and Keitt) automatically. In summary, the objective in this paper is to develop a deep learning algorithm to automatically classify four types of mango cultivar.","['Engineering', 'Computational Intelligence', 'Machine Learning', 'Big Data']"
doi:10.1007/978-3-030-99075-6_62,en,Review on Simulation and Optimization of Vehicle Ride Comfort Based on Suspension Model,OriginalPaper,"At present, commercial software of the multi-body dynamics is widely used in the research of vehicle ride comfort simulation and optimization. This paper reviews some literatures on vehicle ride comfort optimization based on ADAMS, and focuses on the research based on suspension models. The suspension rigid-flexible coupling models and the simulation research about optimizing suspension model parameters to achieve multi-objective optimization are the main areas of concern. Finally, the paper is summarized and the future trend of ADAMS applied to the simulation and optimization of vehicle ride comfort is prospected.","['Engineering', 'Industrial and Production Engineering', 'Mechanical Engineering', 'Machinery and Machine Elements']"
doi:10.1007/978-981-19-2126-1_29,en,Empirical Analysis of Novel Differential Evolution for Molecular Potential Energy Problem,OriginalPaper,"In bio-chemistry, molecular potential energy problem is a highly complex problem which is multi-model in nature as well. In the present study, a novel differential evolution algorithm (NDE) is applied to handle this problem and to efficiently minimize the molecular potential energy function. The NDE algorithm with its efficient nature provides enhanced search capability with reduced space and time complexities. This variant of DE made use of adaptive control parameter settings along with unit population structure which amplifies the execution of simple DE algorithm without compromising the standards of the solution. The performance of NDE is analysed on eight unconstrained benchmark functions and molecular potential energy function as well in terms of mean fitness and standard deviation. The numerical outcomes showed that NDE achieved good results for all the benchmark cases and maintained a trade-off between convergence rate and efficiency.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Machine Learning', 'Big Data', 'Computer Systems Organization and Communication Networks']"
doi:10.1007/978-3-031-20601-6_1,en,Anti-electricity Stealing Detection Based on Recurrent Neural Network,OriginalPaper,"With the continuous development of the power system, technologies such as power distribution and power collection have become more and more convenient, and the electric meter has ushered in the era of intelligence. Through the remote wireless meter reading technology of the smart meter, the electricity consumption data can be quickly “taken from the air”, and then the collected user electricity consumption information can be analyzed. This paper studies a cyclic neural network algorithm based on electricity consumption data collection to detect anti-electricity stealing behavior, trains and tests the network according to the characteristics of user electricity consumption data, judges whether the user is suspected of electricity stealing, and compares it with clustering Algorithms and BP neural network algorithms are compared for detection accuracy. The comparison results show that the cyclic neural network algorithm can efficiently and accurately detect electricity stealing users, effectively combating electricity stealing events and reducing the loss of power resources.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-1-4842-8005-8_4,en,Unsupervised Learning: Clustering,OriginalPaper,"In Chapter 3 we discussed how training data can be used to categorize customer comments according to sentiment (positive, negative, neutral), as well as according to context. For example, in the airline domain, the context can be punctuality, food, comfort, entertainment, and so on. Using this analysis, a business owner can determine the areas that his business needs to concentrate on. For instance, if he observes that the highest percentage of negative comments has been about food, then his priority will be the quality of food being served to customers. However, there are scenarios where business owners are not sure about the context. There are also cases where training data is not available. Moreover, the frame of reference can change with time. Classification algorithms cannot be applied where target classes are unknown. A clustering algorithm is used in these kinds of situations. A conventional application of clustering is found in the wine-making industry where each cluster represents a brand of wine, and wines are clustered according to their component ratio in wine. In Chapter 3 , you learned that classification can be used to recognize a type of image, but there are scenarios where one image has multiple shapes and an algorithm is needed to separate the figures. Clustering algorithms are used in this kind of use case.","['Computer Science', 'Data Structures and Information Theory', 'Artificial Intelligence', 'Machine Learning', 'Python']"
doi:10.1007/978-981-19-5845-8_8,en,Secure Wireless Smart Car Door Unlocking System,OriginalPaper,"Security is the most essential factor in software as well as internet environment. In the current era, software and hardware security is the most important thing to secure our digital and physical assets. In many cases, tangible entities like smart homes, smart car etc. having some IoT base support enhance the supervision. This paper proposes a secure alternative for the car unlocking system by dynamically generating disposable encryption keys that cater to the future demands of smart cars powered by Internet  of Things while employing ultra-modern communications techniques like MAC-then-encrypt. Encryption keys are used to facilitate locking and unlocking functionality of car via the internet to ensure security. The paper compares the proposed methodology with existing algorithms like Digital Signature Authentication to verify its effectiveness in real world scenarios.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-0095-2_30,en,Energy and Memory-Efficient Routing (E&MERP) for Wireless Sensor Networks,OriginalPaper,"Wireless sensor networks (WSNs) comprised of sensor nodes use the capabilities of sensing, computing, then communicating. But, sensors have limited energy and memory capacity to perform the above operations. Therefore, using the available energy and memory efficiently is perplexing problems in WSNs. Clusters-based routing protocols are situated to exploit network lifetime. In this work, we recommend an advanced combination of clustering and replacement algorithm to decrease energy consumption, prolong network lifetime and improve throughput during frequent transmission. The recommended protocol reduces energy depletion by finding the cluster head (CH) node with maximum residual energy, thereby preventing energy hole, thus, improving network lifetime, and manages memory by using replacement algorithm in case of buffer overflow. The simulation shows that the recommended protocol has extended network lifetime, increased data delivery than protocols like LEACH, LEACH-C, SEP and EEEHR protocols.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Systems and Data Security', 'Artificial Intelligence', 'Computational Intelligence']"
doi:10.1007/978-3-031-19958-5_93,en,Hybrid Particle Swarm Optimization for a Feature Selection Problem with Stability Analysis,OriginalPaper,"In this paper a hybrid Particle Swarm Optimization (HPSO) method is developed and applied to a Hybrid Feature Selection problem. The objective of applying the HPSO method to the Hybrid Feature Selection problem is to increase the classification accuracy and decrease the number of features. In the proposed HPSO method we have introduced the concepts of mutation and crossover taken from Genetic algorithm and then introduced into Particle Swarm Optimization (PSO) method. It helps in order to increase the exploration opportunity. Using Von Neumann stability criterion and the concepts of Fourier series, the mathematical explanation of stability of the proposed HPSO method has been explained with proof. Convergence of the proposed HPSO algorithm is explained using the Markov chain concept. Then results are compared graphically and statistically with other meta-heuristic algorithms. Friedman test and Mann-Whitney U test are used to check the statistical significance of the proposed algorithm against other meta-heuristic algorithms.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-07823-1_6,en,"Planar Convexity Theory-Based Approaches for Heterogeneous, On-Demand, and Stochastic Connected k-Coverage",OriginalPaper,"This chapter introduces our solution to the problem of connected k -coverage in heterogeneous planar wireless sensor networks, where the sensors do not necessarily have the same capabilities.","['Engineering', 'Communications Engineering, Networks', 'Wireless and Mobile Communication', 'Computational Intelligence', 'Artificial Intelligence', 'Data Engineering', 'Computer Systems Organization and Communication Networks']"
doi:10.1007/978-981-19-5292-0_51,en,Effective Security Algorithms for Big Data Clouds,OriginalPaper,"Big data cloud provides high capacity and added imaginative types of informatics to enhance discovery, decision-making, and process improvement. A cloud computing system uses encryption and decryption from a data bank to access and store data. As part of this system, authentication is done using the consumer name and verification code, authorization is provided by the cloud security service provider, the data is encrypted when uploaded, and OTP is used to decrypt the data when accessed. Different cryptographic schemes used for encryption are hybridized ABE and AES as Scheme 1 and the proposed novel algorithm named secure dynamic bit standard (SDBS) as Scheme 2 which offers high security for the data stored by the end user.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-981-19-2538-2_4,en,Breast Cancer Prediction Using Greedy Optimization and Enlarge C4.5,OriginalPaper,"Detecting Breast Cancer in the early step is significant to minimize the death rate by enhancing the available treatments. As there exists no definitive treatment for Breast Cancer detection, early detection is significant. Hence, this study employs Machine Learning (ML) methods for expecting Breast Cancer effectively with efficiently. In this study, novelty is given in the feature selection and classification process. This study intends to perform relevant feature selection through the proposed Greedy Optimization (GO) method. In addition, it aims to perform a classification of the relevant features by the use of the newly introduced Enlarge C4.5 algorithm (Ext.-C4.5). At first, Breast Cancer dataset is loaded. Then, pre-processing is performed. The pre-processed data is obtained through data reduction and dimensionality reduction. Here, data reduction is performed using the Block Level Deduplication, dimensionality reduction is performed using C-Isomap. This pre-processed data is considered for feature selection. This feature selection is given for train and test split. This is followed by classification. Lastly, the prediction is performed by the trained model. The experimental implementation and performance analysis of the planned system is undertaken. It is performed by comparing the proposed system with the existing systems (Naïve Bayes (NB), Decision Tree (DT), Nearest Neighbour (NN), Multilayer Perceptron (MLP), Artificial Neural Network (ANN), Extreme Learning Machine, K-Nearest Neighbour (KNN) and Support Vector Machine (SVM)) in terms of correctness, accuracy, specificity, sensitivity, f1-score and Completing Time. The results revealed that the proposed GO and E-C4.5 performs efficiently than the existing methodology.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory', 'Mobile and Network Security']"
doi:10.1007/978-981-19-3998-3_104,en,Research on Target and Firepower Allocation of Multi-platform Anti-ship Missiles Under Constraints,OriginalPaper,"According to the possible new situation in the future sea battlefield, under the cooperative operation of multi-platform anti-ship missiles. A route planning method based on geometric method is used for route planning, and a firepower distribution scheme that can maximize firepower as much as possible is put forward, and a model of firepower distribution optimization problem is established. Aiming at this model. An improved genetic algorithm is adopted to solve the problem that genetic algorithm is easy to fall into local optimal solution. Simulation results verify the effectiveness of this method.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-981-19-4676-9_2,en,A Performance Evaluation of Genetic Algorithm and Simulated Annealing for the Solution of TSP with Profit Using Python,OriginalPaper,"The Traveling Salesman Problem with profit (TSPP) is defined on an graph G  = ( V , E ). Traveling salesman problems with profit (TSPP) is a generalization of the traveling salesman problem (TSP), with one condition that it is not required for a sales person to travel all cities of the network. Our main purpose is to optimize the total profit and cost of the traveling. Here we are focusing on that in the case of TSPs; in real world scenario it is not always relevant for the salesman to visit each and every customer or city. To solve the problem, a GA with special mutation operators has been presented. Here we have utilized and compared different heuristic techniques genetic algorithm (GA) and simulated annealing (SA). Numbers of tours plots are generated for the comparison of performance of both the algorithm implemented for the solution of TSPP. These plots are beneficial for route planner and for those who want to apply this concept of TSPP. It has been observed that SA performs better than GA, as the response consumed less time than GA.","['Engineering', 'Computational Intelligence', 'Systems and Data Security', 'Artificial Intelligence', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-981-19-4971-5_24,en,Combined Economic Emission Dispatch of a Hybrid Energy System Using Quantum-Inspired Tidal Firefly Algorithm,OriginalPaper,"Population-based optimization algorithms are very efficient in handling the optimization problem, their integration with quantum mechanics principle greatly enhances its capability. In this manuscript, quantum-inspired tidal firefly algorithm (QITFA) is applied to resolve the combined economic emission dispatch (CEED) problem of a hybrid power system. The QITFA is applied to solve the CEED of an IEEE-30 bus system considering transmission line losses. Price penalty factor (PPF) approach is utilized to transform the many objective functions into singly objective functions. The results are collated with three other optimization techniques to prove the superiority of the quantum-inspired algorithm. The effect of increased renewable penetration on the operating cost and emission of power systems is also studied. From the analysis, it is seen that for every 10% increase in the renewable penetration in power system, the fuel cost reduces by 12% and emission is reduced by up to 25%.","['Engineering', 'Power Electronics, Electrical Machines and Networks', 'Energy Policy, Economics and Management', 'Energy Systems']"
doi:10.1007/978-981-19-8202-6_35,en,PolSAR Image Classification Based on Deep Features,OriginalPaper,"The interpretation of polarimetric synthetic aperture radar (PolSAR) images has wide and important applications in target identification, disaster survey, urban planning, road detection and image classification. In PolSAR image classification tasks, some algorithms often obtain different polarimetric scattering features by different target decomposition methods which can generate feature redundant. To solve the problems of complex processing and excessive time consumption caused by multiple dimensional features, a deep feature-based PolSAR image classification algorithm is given in this paper. The algorithm first extracts the original feature set from the PolSAR image which is used to pre-train the Restricted Boltzmann Machine (RBM) model. The redundant features in the original feature set are rejected according to the error which is calculated by the reconstruction error of the input features. The RBM network is initialized by the remaining features and corresponding weights, then train the Deep Boltzmann Machine (DBM). Finally, the softmax classifier is trained with the training samples containing the deep features to achieve image classification. The experimental results show that the proposed algorithm has good feature selection timeliness and the deep features obtained from the algorithm can improve the image classification accuracy.","['Engineering', 'Signal, Image and Speech Processing', 'Computer Applications', 'Geography, general', 'Earth System Sciences']"
doi:10.1007/978-3-031-21203-1_29,en,DITURIA: A Framework for Decision Coordination Among Multiple Agents,OriginalPaper,"Decision making in multi-agent settings is a complex exercise where agents have to handle incomplete knowledge of the complete problem. Agents are interdependent in multi-agent decision making, being subject to the decisions of other agents who bring to bear other qualitative and quantitative criteria. Some aspects of this problem have been addressed in the Distributed Constraint Optimisation Problems (DCOP) and Markov Decision Processes literature. Taking inspiration from a medical example, our objective in this paper is to provide a framework to support multi-agent decision coordination. This method can be applied in scenarios where we seek to combine qualitative preferences on projected final states with assessment made using utility/objective functions, while accounting for partial agent knowledge.","['Computer Science', 'Artificial Intelligence']"
doi:10.1007/978-3-031-13588-0_38,en,Recognition of Archimedean Spiral Voronoi Diagrams from Linear Parastichies Patterns,OriginalPaper,This paper investigates the properties of Voronoi diagrams in which the generators are on an Archimedean spiral curve with various divergence angles. We apply geometrical properties to construct algorithms to recognize whether the given Voronoi diagram is the Archimedean Voronoi diagram from linear parastichy patterns.,"['Engineering', 'Engineering Mathematics', 'Computational Intelligence']"
doi:10.1007/978-981-19-2538-2_18,en,Sentimental Analysis on E-learning Videos for Learner’s Opinion Using Machine Learning Methodology - Support Vector Machine,OriginalPaper,"E-learning is today’s most popular self-learning form for students and educators. There is a problem and concern in e-learning. This is the emphasis of this undeniable demand for complexities and personalization learning opportunities that increase student knowledge. In the text mining company, sentimental analysis is one of the most critical regions. The vector thoughts of several customers in each of them as a single data set are compiled and are analysed. E-learning is generally referred to as educational attempts to convey knowledge through the use of computers. In the setting of a non-traditional classroom. It’s unlikely for customers to inquire if the e-courses are relaxed. Sentiment analysis helps users to easily classify using e-learning portals. The recorded emotional inputs information’s are used by the e-learning methods. Of the entity, and it can be used. Analyses the actions of the customer every time. Students’ anti-course feelings will serve feedback on online e-learning sites. The automatic emotional analysis allows students in the planned e-learning method to evaluate the pages on the e-portal and other input from the professors. Here for the Automated Emotional Study of Support Vector Machine.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory', 'Mobile and Network Security']"
doi:10.1007/978-981-19-3842-9_38,en,Research on Air Supply System Control of PEMFC Based on LQR Control,OriginalPaper,"Proton exchange membrane fuel cell (PEMFC) is composed of several coupled components with complex nonlinear characteristics. Coordinating the work of each component and effectively controlling the air supply system are key measures to improve the efficiency of the system. In order to control the air supply system of PEMFC, this paper explores the influence of different input parameters on the energy consumption efficiency of the system, quantifies the relationship between the variables, and studies the change law of power consumption efficiency and peroxide ratio of the system. After that, separate feed-forward, feed-forward + feedback and LQR control algorithms are used to control the optimal peroxide ratio respectively, and the algorithms are verified by Matlab/Simulink simulation. The results show that the LQR algorithm has the best dynamic response speed, which is shortened by 17.0% and 47.1% compared with the feed-forward + feedback control and separate feed-forward control systems. At the same time, the maximum control error of LQR algorithm is the smallest, which is 52.6% and 84.6% lower than that of feed-forward + feedback control and separate feed-forward control.","['Engineering', 'Mechanical Engineering', 'Automotive Engineering', 'Transportation Technology and Traffic Engineering']"
doi:10.1007/978-981-19-4147-4_45,en,Parametric Investigation of Injection Moulding for LDPE using Capuchin Search Algorithm and Honey Badger Algorithm,OriginalPaper,"In our rapidly expanding world, there is a rising demand for low-cost, long-lasting, and less dangerous medicinal products. Medical items ranging from intravenous fluid containers to medical syringes are created to satisfy their demands using a range of thermoplastics and Plastic Injection Moulding (PIM). However, even advanced profile mouldings can suffer from dimensional inaccuracies. The current study advances our understanding of thermoplastics, specifically Low-Density Polyethylene (LDPE) material moulding for medical syringe plungers using injection moulding equipment. Eight injection moulding input factors were investigated in order to decrease the depth sink marks and weight created during the injection moulding of thermoplastic LDPE material. The 27 trials were piloted in accord with Taguchi's Design of Experiment, and the variables were optimised using the newly developed Honey Badger and Capuchin Search Algorithms, as well as analysis of variance, for determining the most dominating parameter. The cooling time and melt temperature of the plastic injection moulded part are the most significant factors influencing the sink-mark depth and weight of the part, respectively, according to the Analysis of Variance (ANOVA) test.","['Engineering', 'Materials Engineering', 'Robotics and Automation', 'Structural Materials', 'Biomaterials']"
doi:10.1007/978-3-031-16281-7_9,en,Embedded Implementation of an Algorithm for Online Inertia Estimation in Power Grids,OriginalPaper,"The energy transition is an issue of major importance worldwide and entails the gradual replacement of fossil fuels technologies with renewable energy sources (RES) for electric power production. However, integrating photovoltaic and wind power plants in traditional power grids threatens the stability of the system if no additional synthetic inertia is provided by control systems. Due to the intermittent nature of RES, the inertia of the power plants and of the entire grid is time-varying, calling the need for online monitoring methods. In this paper, we implement on a microcontroller an algorithm for online estimation of the inertia constant and damping coefficient of individual energy sources. The behavior of this embedded implementation is analyzed with respect to some key parameters and tested on the IEEE 14-bus power system.","['Engineering', 'Cyber-physical systems, IoT', 'Machine Learning', 'Robotics and Automation']"
doi:10.1007/978-3-031-22200-9_20,en,An Optimal Cascade Reservoir Operation Based on Multi-objective Water Cycle Algorithm,OriginalPaper,"Optimal cascade reservoir scheduling is a complex problem related to the broad interests of society, economy, and environment. This study proposes a solution for dispatching cascade reservoir operation optimization based on the multi-objective water cycle algorithm (MWCA). Search strategies for confluence, diversion, seepage, evaporation, and rainfall are established in the MWCA by simulating the natural water cycle process. A relative gravity mechanism under multi-objective is constructed to achieve an adequate search for optimal solutions. In the simulation section, the calculation results of the proposed approach are compared with the other methods in the literature, e.g., particle swarm optimization (MOPSO) and the genetic algorithm (NSGA-II). Compared results show that MWCA is superior to other algorithms in calculation diversity and an effective solution to the multi-objective optimal scheduling problem of cascade reservoir groups.","['Engineering', 'Mathematical and Computational Engineering', 'Mechanical Engineering', 'Electrical Engineering']"
doi:10.1007/978-981-19-1645-8_22,en,Enabling Real-Time Vehicle-to-Vehicle (V2V) Communication for Intelligent Transportation System (ITS),OriginalPaper,"The rapid advancement in the automobile industry and the ease with which vehicles can be acquired has resulted in a significant rise in the number of vehicles on the road. Vehicles have been upgraded from time to time to provide all kind of facilities to the commuters. Security features of the vehicle have also been enhanced, with the addition of airbags, seatbelts and so on. Still, however, there are many situations in which security has not been provided in complete sense, like prevention of accidents from occurring. There are also many other areas, where vehicles of present age cause problems to the commuters like traffic jams, human proximity detection, and so on. All these have led to the need of emergence of an Intelligent Transportation System, which embodies intelligence and provides innovative solutions such as traffic monitoring, blind crossing, preventing two or more vehicles from colliding, real-time route computation to the destination, and many more. This very idea of Intelligent Transportation System can be realized with the help of a communication paradigm, VANET (Vehicular Ad-Hoc Network), which ensures vehicle-to-vehicle communication.","['Engineering', 'Microwaves, RF and Optical Engineering', 'Wireless and Mobile Communication', 'Optics, Lasers, Photonics, Optical Devices']"
doi:10.1007/978-3-031-16078-3_59,en,Plan Deordering with Conditional Effects,OriginalPaper,"Plan deordering aids several tasks such as plan reuse, modification, and plan decomposition by preserving only the necessary orderings among the actions in a plan. Several previous approaches deorder plans to annotate and find partial orderings. However, these methods do not fully support conditional effects. Conditional effects provide an expressive and convenient way to model complex and intricate scenarios allowing a single action to have context-dependent effects. In comparison with other features of ADL, conditional effects are surprisingly tricky to handle. In this paper, We develop a new algorithm for plan deordering that supports conditional effects. The algorithm also preserves the essence of conditional effects while deordering so that the generated partial orderings can be further used or modified. Our algorithm can successfully deorder plans from the domains of international planning competitions.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5073-5_6,en,Stacked Denoising Sparse Autoencoder-Based Fuzzy Rule Classifiers,OriginalPaper,"With time, machine learning experts are unanimously agreeing that finding good features is one of the most important problems in pattern classification [1]. In fact, if given features are good, even a linear classifier would suffice to give excellent classification results.","['Computer Science', 'Machine Learning', 'Computational Intelligence', 'Pattern Recognition']"
doi:10.1007/978-3-031-18461-1_27,en,Learning to Solve Sequential Planning Problems Without Rewards,OriginalPaper,"In this paper we present an algorithm, the Goal Agnostic Planner (GAP), which combines elements of Reinforcement Learning (RL) and Markov Decision Processes (MDPs) into an elegant, effective system for learning to solve sequential problems. The GAP algorithm does not require the design of either an explicit world model or a reward function to drive policy determination, and is capable of operating on both MDP and RL domain problems. The construction of the GAP lends itself to several analytic guarantees such as policy optimality, exponential goal achievement rates, reciprocal learning rates, measurable robustness to error, and explicit convergence conditions for abstracted states. Empirical results confirm these predictions, demonstrate effectiveness over a wide range of domains, and show that the GAP algorithm performance is an order of magnitude faster than standard reinforcement learning and produces plans of equal quality to MDPs, without requiring design of reward functions.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4204-4_20,en,Platoon and Red Light Violation Detection Using Image Processing,OriginalPaper,"Intersections account for most road accidents and delay in a road network. The intersection's efficiency and safety concerns can be addressed by collecting vehicle platoon size, queue length, and delay data and implementing a red light violation detection technique (RLVDS) to reduce accidents. It is challenging to collect this traffic information in heterogeneous and less lane disciplined traffic, a scenario often observed in developing countries such as India. Traditional sensors such as inductive loop, infrared, radar, or magnetic sensors and image processing solutions do not work well under these conditions. Hence the current work presents a set of robust techniques developed for heterogeneous traffic. First, the platoons were detected using foreground extraction, connected component analysis, and a density-based clustering algorithm. Then, the queue length was extracted using a progressive block processing technique. Separately the RLVD was performed using corner point tracking and user-defined detection zones.","['Engineering', 'Transportation Technology and Traffic Engineering', 'Construction Management', 'Sustainable Development']"
doi:10.1007/978-981-19-7648-3_7,en,Cooperative Beamforming for Secure Satellite-Terrestrial Transmission,OriginalPaper,"In this part, we consider a scenario where the satellite-terrestrial network is overlaid over the legacy cellular network. The established communication system is operated in the millimeter wave (mmWave) frequencies, which enables the massive antennas arrays to be equipped on the satellite and terrestrial base stations (BSs). The secure communication in this coexistence system of the satellite-terrestrial network and cellular network through the physical layer security techniques is studied in this work. To maximize the achievable secrecy rate of the eavesdropped fixed satellite service (FSS), we design a cooperative secure transmission beamforming scheme, which is realized through the satellite’s adaptive beamforming, artificial noise (AN) and BSs’ cooperative beamforming implemented by terrestrial BSs. A non-cooperative beamforming scheme is also designed, according to which BSs implement the maximum ratio transmission (MRT) beamforming strategy. Applying the designed secure beamforming schemes to the coexistence system established, we formulate the secrecy rate maximization problems subjected to the power and transmission quality constraints. To solve the nonconvex optimization problems, we design an approximation and iteration based genetic algorithm, through which the original problems can be transformed into a series of convex quadratic problems. Simulation results show the impact of multiple antenna arrays at the mmWave on improving the secure communication. Our results also indicate that through the cooperative and adaptive beamforming, the secrecy rate can be greatly increased. In addition, the convergence and efficiency of the proposed iteration based approximation algorithm are verified by the simulations.","['Computer Science', 'Computer Systems Organization and Communication Networks', 'Communications Engineering, Networks', 'Wireless and Mobile Communication']"
doi:10.1007/978-981-19-4990-6_27,en,Secured Messaging Using Image and Video Steganography,OriginalPaper,"Protection and security of data is an increasing concern among individuals and organizations. Secure data transmission has a vital application in today’s world. Security has become a priority for every user who uses the Internet. Sensitive data transmission is always a risky task. In-order to address this concern, image and video steganography is quite useful in hiding the secret data inside of an image or a video which makes it harder for the outside world to notice the transmission. Steganography focuses more on high security and capacity. Steganography masks the sensitive data inside any cover media like images, videos, etc. The hidden information will not be perceived by the human eye as the cover looks the same as the encoded one. Thus, only the target user will be able to read the message hidden. This application proposes a secure way for transmitting messages using algorithms like least significant bits, K-least significant bits and key-frame selection for image and video steganography.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Wireless and Mobile Communication']"
doi:10.1007/978-3-031-19958-5_88,en,Modified TANYAKUMU Labelling Method to Solve Equality Generalized Travelling Salesman Problem,OriginalPaper,Equality generalized travelling salesman problem (E-GTSP) is a variant of the travelling salesman problem where the set of cities are partitioned to form clusters. The travelling salesman is required to start from the home city and visit exactly one city in each and every cluster and return home while minimizing travelled distance. In this paper TANYAKUMU labelling method for solving travelling salesman problem is modified to solve E-GTSP. The algorithm terminates after m iterations where m is the number of clusters in the problem and computational complexity reduces as iterations increases. Numerical illustration is used to prove the validity and efficiency of the proposed algorithm.,"['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2704-1_3,en,Grant-Free Massive Access in Cell-Free Massive MIMO Systems,OriginalPaper,"This chapter studies massive access in cell-free massive MIMO-based IoT systems and solves the challenging AUD and CE problems. For the uplink transmission, we propose an advanced frame structure design to reduce the access latency. Moreover, by considering the cooperation of all access points (APs), we investigate two processing paradigms at the receiver for massive access: cloud computing and edge computing. We reveal that the edge computing can achieve the similar massive access performance as the cloud computing, and the edge computing is capable of alleviating the burden on cloud processing unit (CPU), having a faster access response, and supporting more flexible AP cooperation.","['Engineering', 'Wireless and Mobile Communication', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-14537-7_9,en,Automatic PID Tuning Toolkit Using the Multi-Objective Bees Algorithm,OriginalPaper,"In this study, studies were conducted within the scope of the tuning Tuning of PID Proportional-Integral-Derivative (PID) control systems System , which is very popular in the manufacturing and robotics Robotic fields. While optimising the controller parameters Parameters , a multi-objective Bees Algorithm (MOBA) method was used to minimise the settling time Settling time , rise time, overshoot Overshoot , and system System error Error all at once. Simulations have been made on an example for the control Control of robotic Robotic systems used in the manufacturing area. As a result of simulations, low settling and rise times with MOBA were achieved, while overshoot Overshoot was also not allowed. At the same time, the Ziegler-Nichols method and MATLAB PID Proportional-Integral-Derivative (PID) Toolkit were used to compare the parameters Parameters .","['Engineering', 'Robotics and Automation', 'Artificial Intelligence', 'Industrial and Production Engineering', 'Professional Computing', 'Robotics', 'Machine Learning']"
doi:10.1007/978-981-19-3998-3_123,en,An Improved Adaptive Genetic Algorithm Based on Dynamic Bayesian Network,OriginalPaper,"With the prosperous development of information and science technology, the future modern electronic information warfare will have the characteristics of a high degree of equipment informatization and strong game confrontation. Traditional methods rely too much on experts to extract features. Bayesian network (BN), a graph model based on graph theory and probability statistics, uses machine learning as the core to avoid problems such as excessive human subjectivity. Aiming at the unique structure of the transfer network in which the dynamic Bayesian network (DBN) is responsible for time sequence expansion, a genetic learning algorithm with a two-step strategy and an adaptive mechanism is proposed. This paper proposes a genetic algorithm with a two-step strategy and an adaptive mechanism to realize the adaptation of crossover rate and mutation rate, and uses different strategies for different evolution stages in mutation and crossover operations. The improved adaptive genetic algorithm (IAGA) based on DBN is proposed and implemented. The structure learning comparison of search optimization algorithms verifies the accuracy and convergence efficiency of the improved algorithm.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-981-19-3632-6_17,en,Dynamic Equivalence of Power System Based on Artificial Immune Algorithm,OriginalPaper,"The electrical industry is an important part of the energy industry and an important foundation of the national economy. Therefore, its safe power operation plays a very important role in social production and life. However, the current power system faces challenges in the scale and complexity of simulation calculations, so it is very important to study the dynamic equivalence of power systems. Based on the artificial immune algorithm, this paper studies and designs a power system dynamic equivalent system. First, this article explains the concept of artificial immunity, and discusses the application of artificial immune algorithms in depth; then, a system framework for power system dynamic equivalence is designed, and its dynamic equivalence changes are verified. The final results show that the model based on the equivalent of artificial immune algorithm can reflect the dynamic power characteristics of the external system well, and it can also be suitable for the study of static characteristics.","['Engineering', 'Cyber-physical systems, IoT', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing']"
doi:10.1007/978-3-031-07322-9_19,en,Weld Defect Location Method of U-Shaped Crane Boom Based on Helical Guided Waves,OriginalPaper,"The boom is the key load-bearing component of the crane, and its health seriously threatens the service performance of the crane. In order to ensure the safe production of cranes, nondestructive testing (NDT) and structural health monitoring (SHM) of boom become more and more urgent and important. In this paper, the intelligent defect location algorithm based on helical guided waves is applied to the weld defect detection of U-shaped boom. Intelligent defect location algorithm is an imaging algorithm that combines ellipse imaging principle, evolutionary algorithm and K-means clustering algorithm. This paper verifies the effectiveness of this algorithm for weld defect location of U-shaped boom through experimental research. Firstly, the propagation regularity of helical guided waves in the U-shaped boom structure is studied. In addition, the elliptical imaging algorithm is used to image and analyze the weld defects in the U-shaped boom, and the location of the defects is preliminarily determined. The defect location analysis of weld defects is carried out by using the intelligent defect location algorithm. By comparing the imaging results of the two methods, it is found that the intelligent defect location algorithm has higher resolution and can effectively improve the defect location accuracy. This algorithm provides a tool for health monitoring of special-shaped structures based on guided waves.","['Engineering', 'Building Repair and Maintenance', 'Cyber-physical systems, IoT', 'Industrial and Production Engineering']"
doi:10.1007/978-3-031-13702-0_6,en,Utilization of Artificial Intelligence in the Food Industry,OriginalPaper,"The introduction of Artificial Intelligence (AI) in the food industry streamlines the quality assessment of food products. The innovation has brought many advanced applications to make food fabrication more proficient, safe, and gainful. For example, advances in hereditary design are prompting the creation of harvests and food items. The items are more advantageous for the purchasers and more effectively cultivable for the makers. The five artificial intelligence application categories include sorting products and packages, Food safety compliance, Improved cleanliness, product development, and marketing. Artificial Intelligence has directly or indirectly impacted the food industry. The basic food item industry utilizes AI to offer clients focused on offers, oversee stock, and decrease squander. Artificial intelligence applications will impact the food handling organizations and help them build their income and lift client experience. Furthermore, numerous food-centered AI stages are accessible to shoppers. For instance, Softwear like Wellio utilizes AI and conduct science to give customized formula proposals and afterward allows clients to arrange their goods on the web. Habit creates customized nourishment plans dependent on the consequences of a sustenance test. Food processing is a convoluted business and it includes arranging the food or crude materials coming from the homestead, keeping up the hardware and a few kinds of gear, and then some. However, artificial intelligence will be a boon for this industry and will make the work more tranquil and smoother.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Artificial Intelligence', 'Food Science']"
doi:10.1007/978-3-031-06780-8_14,en,Factors Influencing Driver Behavior and Advances in Monitoring Methods,OriginalPaper,"Monitoring driver behavior in real-time is a challenging task as there are several factors that can influence the driver to commit unpredictable mistakes while driving. These factors mainly involve inattentive driver state, absent mind, unreliable cornering, and speeding, resulting in fatal accidents. This chapter identifies the factors that affect driver behavior and performance, and provides an in-depth analysis of various deployed scientific monitoring methods and proposes solutions for early and efficient real-time monitoring of driver behavior. The chapter also reviews real-time smart detection algorithms deployed for the classification of driver state. In addition, the chapter proposes an unsupervised deep learning neural network model that can be deployed in classifying driver states and actions.","['Engineering', 'Automotive Engineering', 'Computational Intelligence', 'Transportation Technology and Traffic Engineering', 'Signal, Image and Speech Processing']"
doi:10.1007/978-981-19-3148-2_57,en,Climate Dependent Crop Field Condition Management Through Data Modeling,OriginalPaper,"Climate and agriculture depend on each other. A small change in climate can highly affect agriculture in a positive or negative manner. Agriculture also affects the climate. Artificial Intelligence (AI) algorithms play a very crucial role in agricultural system maintenance and its enhancement. In this paper, we have briefly summarized research done based on application of artificial intelligence techniques in field condition management of the agricultural system. The motive of this paper is to discuss how machine learning technologies are beneficial for crop field management in order to increase agricultural productivity using minimal natural resources like water and land. The field condition management is mainly categorized into two sub-categories: water management and soil health management.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory']"
doi:10.1007/978-981-19-2840-6_12,en,Automated Intelligent Hematology Classification System Using Image Processing and Neural Networks,OriginalPaper,"In this paper, a method has been proposed which uses an Image Processing and Deep learning-based approach to classify microscopic blood smear images based on 7 classes of blood diseases namely, Leukemia, Anemia, Lymphoma (CLL, FL, MCL), Myeloma and Malaria, from the healthy blood images. Image preprocessing techniques based on Feature Extraction and Ni-black Thresholding were used on image dataset to obtain features for identification and classification of Leukemia and Anemia. Thereafter, a neural network based on VGG16 was implemented to train the model for classification of all the diseases which included pretrained weights from ImageNet. For validation of the model, the scores of Precision, Recall, and F-score were taken into account to calculate the accuracy of the model. Through this methodology, the model was able to achieve an accuracy of 98.6% with minimum loss of 0.47. The proposed system will help hematologists to identify blood diseases more accurately and faster with this automatic analysis system.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-16049-3_7,en,The Structural Evolution of an Organization (a Geometric Approach),OriginalPaper,"In this chapter, the structural evolution of an organization in geometric terms is presented and analysed. The configurational evolutionary phases from a spherical, to an elliptical, to a cylindrical and to a pseudospherical of an organization are presented and analysed: the beginning of the development of an organization (or Phase 1), the formation of the first core processes in an organization (Phase 2)—Inbound Supply Chain and Purchasing—the development of the activities related to operational marketing (Phase 3), the initiation of an organizational formation (Phase 4), Research and Development and Product/Service & Process Development (Phase 5), the development of the Strategic Marketing Process (Phase 6), the initialization of the ellipsoidal configurations (Phase 7), the development of the manufacturing (or Operations) process (Phase 8), the development of Sales or Customer Acquisition Processes (Phase 9), the development of After Sales or Customer Care management (Phase 10), the structural development and growth phases of an organization (Phase 11), the ultimate evolutionary stage of an organization (Phase 12) and the unification of processes. The beginning of the decline of an organization, the final stages in the life of an organization and the death of an organization and the General chapter conclusions are also presented and discussed.","['Business and Management', 'Organization']"
doi:10.1007/978-3-031-21333-5_68,en,Synthetic Generation of Electrical Consumption Traces in Smart Homes,OriginalPaper,"With the introduction of the smart grid, smart meters and smart plugs, it is possible to know the energy consumption of a smart home, either per appliance or aggregate. Some recent works have used energy consumption traces to detect anomalies, either in the behavior of the inhabitants or in the operation of some device in the smart home. To train and test the algorithms that detect these anomalies, it is necessary to have extensive and well-annotated consumption traces. However, this type of traces is difficult to obtain. In this paper we describe a highly configurable synthetic electrical trace generator, with characteristics similar to real traces, that can be used in this type of study. In order to have a more realistic behavior, the traces are generated by adding the consumption of several simulated appliances, which precisely represent the consumption of different typical electrical devices. Following the behavior of the real traces, variations at different scales of time and anomalies are introduced to the aggregated smart home energy consumption.","['Engineering', 'Data Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-08815-5_13,en,Smart School Selection with Supervised Machine Learning,OriginalPaper,"In today’s competitive academic environment, parents and students usually face the school selection problem for a decade. Keeping the question in mind, we proposed to seek the select significant features (academic, social, demographic, etc.) with the help of machine learning algorithms (Support Vector Machine (SVM), Extreme Gradient Boosting (XGB), and Random Forest (RF)). These features will be helpful for guardians/parents, schools, and teachers in deciding the students the best school for their education. We used a statistical approach (one-way ANOVA) to investigate the impact of school selection reasons towards student’s grades. The standard open data set of Portuguese secondary school student was used here for analysis. A Synthetic Minority Over-sampling Technique-Nominal Continuous (SMOTE-NC) technique was used for resampling the imbalanced Reason target class. The proposed automatic school selection recommender might be helpful in every academic community and intelligent education. We found school selection reasons have a statistically significant impact on the final grade. The RF comes out as a strong predictor among all proposed models with an accuracy of 71%. The final grade, going out with friends, parents’ job, and activities are the essential features for Smart School Selection.","['Engineering', 'Computational Intelligence', 'Transportation Technology and Traffic Engineering']"
doi:10.1007/978-981-19-3679-1_55,en,Combination of Oversampling and Undersampling Techniques on Imbalanced Datasets,OriginalPaper,"Many practical classification datasets are unbalanced, meaning that one of the classes is in the majority when compared to the others. In various real-world circumstances, class-imbalanced datasets arise, where the number of data samples in a class is not equal to the other class. To develop good classification models based on present level calculations, using these datasets is difficult, particularly for separating minority classes from the majority class. To address the issue of class imbalance, under/oversampling procedures are used to minimize and enhance the quantities of data examined in minority and majority class. This paper explores the utilization of combination of both undersampling and oversampling techniques mainly synthetic minority oversampling technique (SMOTE) and neighborhood cleaning rule (NCL) to balance the datasets. The performance has been evaluated using two machine learning algorithms. The results are then classified using recall measure and geometric mean which showed improved performance of the algorithms.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4863-3_45,en,Precision Agriculture with Weed Detection Using Deep Learning,OriginalPaper,"Agriculture is the field which needs care and attention. This field remains as the backbone to the Indian Economy. Nowadays, the production or yield decreases due to the increase of variety of crop diseases and weeds. Identification and elimination of weeds are a tedious task. To reduce the stress on the farmers and increase the productivity of the crop, machine learning and deep learning can be used to detect the weeds and the diseases. Various researches have been conducted in this area using machine learning algorithms like Random Forest (RF) and Support Vector Machine (SVM). But for better accuracy in the results, deep learning techniques—InceptionV4 and Xception are used to detect the weeds with higher speed and usage of less computing resources.","['Engineering', 'Computational Intelligence', 'Engineering Design', 'Machine Learning', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-1906-0_48,en,Multiscale Decomposition of HDR Images Using the Edge-Preserving Filters,OriginalPaper,"Tone mapping is very much required to present the high dynamic range (HDR) images on conventional screens. Most popular and efficient way is to perform decomposition of the high dynamic range image into multi-layers. Large-scale intensity variations are assigned to the base layer, and small-scale intensity variations are assigned to the detail layer. Base layer is compressed retaining detail layers, and both the layers are combined; resulted image is displayed on the conventional display devices. In this process, only, contrast is reduced, whereas the details are preserved. In this paper, various base-detail layers decomposition techniques are compared using the metrics such as psnr, mPSNR, and HDRVDP3. Efficiency of edge-preserving filters to preserve the details while smoothing the contrast is analyzed.","['Engineering', 'Electronics and Microelectronics, Instrumentation', 'Computer Systems Organization and Communication Networks', 'Artificial Intelligence']"
doi:10.1007/978-3-031-20141-7_50,en,Investigation of Control Algorithms for Machine Tool Coupled Axes,OriginalPaper,"Modern trends in the development of mechanical engineering and the construction industry include the necessity to create large-sized machine tools, equipment for 3D printing of buildings, and other technological systems with a complex kinematic structures. As a rule, such equipment contains organs driven by several servo drives. The control of this equipment is carried out with applying various coupled-axes control algorithms. An application of CNC-based software and hardware complex for the experimental investigation of such algorithms is proposed. The principles of organizing various schemes to control coupled-axes are considered. The capabilities of the complex for recording a large number of experimental data in the process of controlling such equipment are shown. Examples of experimental investigations of coupled axes control algorithms are presented.","['Engineering', 'Computational Intelligence', 'Transportation Technology and Traffic Engineering', 'Manufacturing, Machines, Tools, Processes']"
doi:10.1007/978-3-031-18100-9_6,en,Humans in the Network,OriginalPaper," The quest for formally modeling risk preferences has come a long way from crudely formulated utility functions to more sophisticated versions that are based on extensive research. The perfect way to model preferences has not yet been reached and each of the many proposals has some shortcomings. However, the practical imperative to understand how human beings perceive risk and act under uncertainty is probably stronger than ever, necessitating the use of even imperfect tools to that end. This chapter aims to present the state of the art in this respect and also some novel experimental results on human behavior in an experimental online environment. It begins with an overview of classical modeling of risk preference as embodied in some popular utility functions, and proceeds by presenting key insights from behavioral and neuro-economics. Decision-making in the digital realm is then investigated with experimental data showing how human subjects’ decisions under risk are affected by changing the level of information exposure and providing mechanisms for peer influence.","['Engineering', 'Computational Intelligence', 'Control and Systems Theory', 'Data Engineering']"
doi:10.1007/978-981-19-2535-1_26,en,An Introductory Note on the Pros and Cons of Using Artificial Intelligence for Cybersecurity,OriginalPaper,"Artificial intelligence is a kind of digital representation of human intellect. Its operations are similar to those of humans in that it can make the computing machines learn, de-learn, and re-learn iteratively over and over again. The roadmap to the application of AI to Cybersecurity has been encountering a lot of issues and challenges. Digital security issues are critical in the creation of methodologies and support measures in any organization to properly prepare for countermeasures to cybersecurity threats and attacks. The role of AI in these countermeasures without a doubt is of paramount importance at present or in future. Some of the worldwide frameworks and standards being used in the context of cybersecurity across the globe may have been advocating for using AI for security. But a lot more effort is needed before the start of the process of integrating AI into these frameworks and standards and bringing the digital transformation thus caused to fruition. This paper presents an account of some of the currently used frameworks and standards for cybersecurity by various organizations around the world followed by a snapshot of using AI in cybersecurity. It also presents a discussion on the pros and cons of integrating AI into cybersecurity countermeasures.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2535-1_34,en,Effectiveness of Machine Learning in Detecting Early-Stage Leukemia,OriginalPaper,"The early identification and diagnosis of leukemia, i.e., the exact distinction of malignant leukocytes at the lowest possible cost in the early stages of the disease, is a key challenge in the domain of disease diagnostics. Considering the large frequency of leukemia, flow cytometry equipment is scarce, and the procedures available at laboratory diagnosis facilities are tedious, complex, and time-consuming. Inspired by the possibilities of machine learning (ML) in illness detection, the current critical search was done to examine the research attempting to find and categorize leukemia using ML algorithms. This research study provides a complete and systematic assessment of the current state of all available ML-based leukemia detection and classification algorithms that analyze PBS pictures. The accuracy rate of the ML techniques used in PBS image analysis to detect leukemia was greater than 93.5%, showing that the application of ML might lead to exceptional results in leukemia diagnosis from PBS pictures.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-0151-5_28,en,Channel-Based Similarity Learning Using 2D Channel-Based Convolutional Neural Network,OriginalPaper,"Object identification is one of the major aspects of computer vision. In recent years, the development the computing as well as the storage capacity has increased drastically. These breakthroughs in the technology have blessed us with various data storage technologies and computational engines. Because of the breakthrough in recent years, we are generating humongous amounts of data of which 80% of data is unstructured data and only 20% of data is structured. Unstructured data are mainly composed of images, video and as well as the natural language, i.e. text. These 80% unstructured data consist of the enormous information, but it is difficult to unravel the information contained in these data. Convolution neural network (CNN) is backbone of computer vision and deals with extracting information from the image and video, before the invention of recurrent neural network (RNN), CNN was also employed for natural language processing (NLP) task such as classification and text generation, but the specialty of CNN lies where the dataset consists of sound signals, images or sequence of frames. On Internet, we can find 60% of the unstructured dataset consists of images or sequence of image or text. Basically, image consists of the features which is the orientation of the pixels in a well-defined pattern which can be extracted by using kernel’s known as the feature maps and Maxpooling layers to extract the underlying feature present in the image to train the neural network. CNN is one of the parts of supervised learning techniques which uses labelled data, but it is difficult to label huge number of images. The similarity-based learning enables us to control the similarity percentage as well as it has minimum labelling procedure, i.e. labelling of the dataset is to be labelled 0 or 1. Similarity learning is used to compute the percentage of the features which are similar in the target image with respect to the input image. Image consists of three channels, i.e. red, green and blue channels, which is basically a 2D vector with pixel values in range of 0–255. These individual channels contribute to the features present in the images, and if we can calculate the similarity between input image and the query image, then we can be able to present the unstructured images in relation to the similarity with respect to the input image by using the channels in channel-based CNN tower.","['Engineering', 'Biomedical Engineering and Bioengineering', 'Artificial Intelligence', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Biological and Medical Physics, Biophysics', 'Information Storage and Retrieval']"
doi:10.1007/978-3-031-11058-0_92,en,Features of Application of Progressive Methods of Predictive Modeling for Solving Transport Tasks,OriginalPaper,"The ultimate effectiveness of the strategic vector of development adopted by the system is completely reducible to the predictions laid down in its foundation; their relevance, accuracy and reliability. Thus, continuous improvement of the quality of predictive analytics is an integral part of the business practice of every successful transport company; an adaptation of promising forecasting algorithms can contribute to a significant increase of the quality of management decisions, resulting in a reduction of economic costs and general optimization of the company’s production processes. A significant amount of advanced scientific research is devoted to the problem; substantial financial resources are mastered annually. The paper analyzes the potential of forecasting approaches based on the progressive methods of predictive modeling in relation to the transport sector. Schemes formalizing the specifics of technologies are formed; features of the commonly utilized algorithms and methods are indicated; the problems of application, and the results of evaluation of the promising models are presented for consideration.","['Engineering', 'Control and Systems Theory', 'Control, Robotics, Mechatronics', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-5221-0_22,en,Identification of Political Hate Speech Using Machine Learning-Based Text Toxicity Analysis,OriginalPaper,"The maintenance of civility during political campaigns has taken a huge blow during recent times with ever increasing toxicity in speeches targeting polarization of people for electoral gains. This is however creating a big divide in the society by the proliferation of cyber-hate speech, which is threatening the integrity and harmony of societies. The term “hate speech” refers to the use of words or phrases that are threatening, derogatory, or insulting to a specific individual or group. Users of social media in India are increasing rapidly, and this is coupled with an increase in the frequency with which cyber-hate speech targets specific segments of society or individuals based on their caste, color, or creed. An online environment free of hostility and bigotry has remained a key focus area of academics’ attention. In the present study, some contemporary political data from the Twitter platform is being used to identify hate speech with the help of machine training and learning methods including the text-based natural language processing (NLP). To achieve the identified goal, several political tweets across different ideologies have been taken into consideration. There are many different ways to collect and organize emotions and personality traits. Analysis of the processed dataset has been done using an ensemble of popular machine learning algorithms, and the results indicate the comparative performance of the methods.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Sociology, general', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-2940-3_18,en,Machine Vision Systems for Smart Cities: Applications and Challenges,OriginalPaper,"A smart city employs information and communication technology (ICT) to boost efficiency and productivity, share data with the public, and promote government service and citizen satisfaction. Smart cities use a combination of low-power sensors, cameras, and AI algorithms to observe the city’s operation. Machine vision has advanced in terms of recognition and tracking thanks to machine learning. It provides efficient capture, image processing, and object recognition for vision applications. Governments benefit greatly from the use of machine vision and other smart applications. This technology allows city administrators to easily integrate and utilize resources. As the “eyes” of the city, computer vision plays an important role in smart city management. The chapter begins with a brief review of machine vision, smart cities, and real-world machine vision applications in smart cities. Lastly, we highlight several smart city difficulties and prospects discovered through a comprehensive literature review.","['Computer Science', 'Artificial Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing', 'Sociology, general', 'Computational Intelligence', 'Machine Learning']"
doi:10.1007/978-981-19-3951-8_35,en,Prediction of Plant Growth Through Nutrient Uptake in the Hydroponics System Using Machine Learning Approach,OriginalPaper,"Agriculture has a significant impact on the nation’s economy. Hydroponic gardening is getting more popular as modern agriculture, which allows plants to be grown without ground using liquid fertilizer. To control the growth of hydroponic plants, some work has been performed using machine learning approaches such as neural network models and Bayesian networks. The Internet of things allows machine to machine interface along with artificially intelligent control of the hydroponic system. The proposed study utilizes ML techniques to predict plant damage, nutrient supply per week and crop yield management under a different scenario. A comparison is presented that uses machine learning methods such as logistic regression, decision trees, support vector machine, and random forest to evaluate the performance of the various methods using the mean square error criterion and % accuracy of the model. Various hyper-parameter tuning is executed on a machine learning model to give the best possible accuracy and performance on a given dataset of hydroponic farming. Toward the end, after performing the comparison of different classification algorithms, it is found that support vector machine classifier had performed the best with an average accuracy of 83.67%. So hence by deploying the support vector classifier model, hydroponic farming can be used for better crop management.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16159-9_28,en,A Model-Based Approach for Testing Automotive Embedded Systems – A Preliminary Study,OriginalPaper,"The automotive embedded systems are experiencing an increasing transformation to automated cyber–physical systems with an extended reliance on software. Guaranteeing the quality, reliability and safety of both single components and the entire vehicle is a tremendous challenge. They should not only comply with functional and performance requirements, interacting reliably with other real-time components, but also with stringent safety and reliability standards. It is distinguished from comparable software well-known from other devices, like mobile phones. In vehicles there are complex real-time interactions between different mechanical systems: braking, drive, suspension, steering. The automotive system is nothing like any other, characterized by rigorous planning, architecture, development, testing, validation and verification processes. This paper discusses a model-based approach to testing automotive embedded systems, particularly in the context of the occurrence of test result flickering, a phenomenon that affects the reliability, reproducibility and validity of embedded software testing. The aim of the research is to verify simplifications used in Hardware-in-the-Loop simulation during testing. The experiments carried out involved comparing test results from a simplified vehicle simulation and a model-based approach in the context of flickering results. A testing bench was designed, and real experiments were performed. The model-based approach is planned to be developed in the future, as the studies have demonstrated that it can be successfully applied to generate aberrations in the test system and to development of a methodology for test case design.","['Engineering', 'Control and Systems Theory', 'Computational Intelligence']"
doi:10.1038/s41386-022-01374-6,en,Adaptive control of synaptic plasticity integrates micro- and macroscopic network function,"['ReviewPaper', 'Review Article']","Synaptic plasticity configures interactions between neurons and is therefore likely to be a primary driver of behavioral learning and development. How this microscopic-macroscopic interaction occurs is poorly understood, as researchers frequently examine models within particular ranges of abstraction and scale. Computational neuroscience and machine learning models offer theoretically powerful analyses of plasticity in neural networks, but results are often siloed and only coarsely linked to biology. In this review, we examine connections between these areas, asking how network computations change as a function of diverse features of plasticity and vice versa. We review how plasticity can be controlled at synapses by calcium dynamics and neuromodulatory signals, the manifestation of these changes in networks, and their impacts in specialized circuits. We conclude that metaplasticity—defined broadly as the adaptive control of plasticity—forges connections across scales by governing what groups of synapses can and can’t learn about, when, and to what ends. The metaplasticity we discuss acts by co-opting Hebbian mechanisms, shifting network properties, and routing activity within and across brain systems. Asking how these operations can go awry should also be useful for understanding pathology, which we address in the context of autism, schizophrenia and Parkinson’s disease.","['Medicine & Public Health', 'Medicine/Public Health, general', 'Psychiatry', 'Neurosciences', 'Behavioral Sciences', 'Pharmacotherapy', 'Biological Psychology']"
doi:10.1007/978-981-19-2065-3_66,en,Health Assistant Using Natural Language Processing,OriginalPaper,"Virtual Assistants take care of patients’ needs as well as maintain their health records. The demand for AI is increasing rapidly in Health factors to maintain the big records. Our Virtual Assistant helps you by a user interface by which you talk it with your disease so that it understands your disease by your symptoms and provide you medicine for a specific disease, maintain your health record and perfect diet by machine learning algorithms also if you want it makes your appointment with the doctor your specific area by which you contact with your doctor. NLP makes an interface by which virtual Assistants work on human data.","['Engineering', 'Communications Engineering, Networks', 'Artificial Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Machine Learning']"
doi:10.1007/978-981-19-2225-1_25,en,Cryptocurrency Price Prediction Using Machine Learning,OriginalPaper,"Globally, the use of cryptocurrencies to purchase goods and services has been rising. They rely on a secure distributed ledger data structure; mining is an integral part of such systems. The rise of cryptocurrencies’ value on the market and the growing popularity around the world open several challenges and concerns for business and industrial economics. Cryptocurrencies have been triggered by the substantial changes in their prices, claims that the market for cryptocurrencies is a bubble without any fundamental value and also concerns about evasion of regulatory and legal oversight. Machine learning is part of artificial intelligence that can make future forecastings based on previous experience. In this paper, methods have been proposed to construct machine learning algorithm-based models such as linear regression, K-nearest neighbour(KNN), and also statistical models like Auto-ARIMA and Facebook’s Prophet (Fbprophet). This paper presents a comparative performance of machine learning and statistical modelling algorithms for cryptocurrency forecasting.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Statistics, general', 'Mobile and Network Security']"
doi:10.1007/978-981-16-9967-2_61,en,An Ensemble Model (Simple Average) for Malaria Cases in North India,OriginalPaper,"Malaria is an infectious disease borne due to mosquitoes that attacks humans and other animals’ bodies. Malaria is a part of the plasmodium group caused by single-celled microorganisms. This study proposes the use of ensemble model using the three regression algorithms that are linear regression, support vector machine (SVM), and auto-Arima techniques and comparing their results. Predictions of plasmodium virus cases are made with the use of linear regression, support vector machine, and auto-Arima algorithms. The accuracy of prediction is measured by calculating the explained variance score, mean squared error rate, and root mean squared error rate. Our aim is to get better prediction results compared to the individual algorithms by combining the results of these individual models. The proposed work determines the accuracy of linear regression, support vector machine, and auto-Arima and ensembles together to find the trend of prediction using simple Average. A comparison of performance among the three regression techniques indicated the SVM model performs the best and has small RMSE and MAE values. But, by introducing the technique of ensemble modeling using simple average, combining the prediction of these three algorithms results in the lowest RMSE and MAE values.","['Computer Science', 'Computer Systems Organization and Communication Networks', 'Computational Intelligence', 'Artificial Intelligence', 'Wireless and Mobile Communication', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-3015-7_20,en,Comparative Analysis of Different Machine Learning Prediction Models for Seasonal Rainfall and Crop Production in Cultivation,OriginalPaper,"Agriculture is one of the strengths of India, from the last few years, gradually the agriculture growth is going downwards in other side the population growth is upwards. Reason for agricultural downward growth depends on so many parameters. The rainfall is one of the main parameters which affects the crop yield. Because of this, the farmers are also facing the loss. If they know this information in prior, the farmers can plan accordingly the type of crop suited for the particular season and it helps the farmer to get good profit out of it. Machine learning scientific and statistical methods are used for predicting the rain fall and crop yield. Kharif and Rabi are two seasons taken for analysis. The regressor predicting models are constructed to predict the seasonal rainfall and crop yield. This study primarily focuses on seasonal crop production prediction, which is dependent on rainfall. The different types of machine learning regression method are used to achieve better results. The performance of comparison models is evaluated using different metrics. Finally, the linear regression and Bayesian linear regression models comparatively produce the best result in terms of accuracy for rainfall prediction. The boosted decision tree regression model is achieving the better result for crop prediction.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Engineering', 'Data Mining and Knowledge Discovery', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-3-031-17752-1_7,en,Emergence of Life,OriginalPaper,"Our sample lineage in the world tree rises from the empty universe to our universe. Along the way, universes emerge in which simpler parts self-organize into more complex wholes. Universes emerge in which self-organization is driven by thermodynamic principles. Self-regenerating systems emerge that contain parts with functional roles. Normativity emerges along with these roles: parts are obligated to perform their functions and prohibited from violating them. Self-regenerating systems evolve into living cells. Later universes contain increasingly complex forms of life that strive to obey increasingly sophisticated axiological laws. These laws are objective and necessary. Beyond our universe, this lineage rises infinitely toward the Good.","['Philosophy', 'Philosophy of Religion', 'History of Philosophy']"
doi:10.1007/978-3-031-18461-1_18,en,Deep Learning and Few-Shot Learning in the Detection of Skin Cancer: An Overview,OriginalPaper,"Skin cancer is a severe condition that should be detected early. The two most prevalent types of skin cancer include melanoma and non-melanoma. Melanoma has been identified as the utmost dangerous skin cancer. Yet, discriminating melanoma lesions from non-melanoma lesions has proven challenging. Several artificial intelligence-based strategies have been introduced in the literature to handle skin cancer detection, including deep learning and few-shot learning strategies. According to the evidence in the literature, deep learning algorithms are reported to perform well when trained on large datasets. However, they are only effective when the target domain has enough labeled samples; they do not ensure adequate network activation variables to adjust to new target regions rapidly when the target domain has insufficient data. Consequently, few-shot learning paradigms have been presented in the literature to promote learning from such limited amounts of labeled data. A search on PubMed from inception to 7 June 2022 for studies investigating the review of the application of deep learning and few-shot learning in the detection of skin cancer was performed via the use of title terms “Deep Learning” AND “Few-Shot Learning” AND “Skin Cancer Detection” AND “Review,” combined with title terms or MeSH terms “Deep Learning” AND “Few-Shot Learning” AND “Skin Cancer Detection” AND “Review,” with no limits on language or date of publication. We found no paper that has reviewed the application of deep learning and few-shot learning in detecting skin cancer. This paper, therefore, presents a brief overview of some of the most critical applications of deep learning and few-shot learning schemes in the detection of skin cancer lesions from skin image data.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3590-9_51,en,Detection of Fake News Using Clustering Algorithms,OriginalPaper,"Due to its potential for causing considerable social and national harm, fake news is a growing problem in today’s media landscape, especially on social media. Previously, it has been the focus of much research. A supervised machine learning method for classifying fake news as genuine or false is developed utilising Python scikit-learn and natural language processing (NLP) for textual analysis, as detailed in this paper’s research on the identification of fake news. Python scikit-learn module contains utilities like Count Vectorizer and Tiff Vectorizer that may help with text data tokenization and feature extraction. Based on the findings from the confusion matrix, we will use feature selection methods to examine and pick the most accurate features to research and select the best features. Internet and social media have made it easier for anyone to get their hands on a wealth of information. While these tools have made communication and information flow simpler and quicker, they have also threatened the authenticity of the news that is being disseminated. Fake news has had such an effect on society that it even influenced the 2016 USA presidential election. In our model, we compare different models to find out which model is providing highest accuracy for detecting fake news. It can be done by using the sklearn module.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security', 'Mobile and Network Security']"
doi:10.1007/978-3-031-21333-5_108,en,Generation and Classification of Illicit Bitcoin Transactions,OriginalPaper,"Financial fraud is an everyday problem that banking institutions have to face. With the disruption of Bitcoin as a new model which relies on decentralisation and anonymity, attackers have taken advantage of this monetary system. It allows them to obtain funds from illegal activities such as ransomware payments and hide them. At the same time, Law Enforcement Agencies use open-source data to apply network forensics to Blockchain data. The analysis is usually performed by using artificial intelligence. Unfortunately, the current situation shows a scarcity of high-quality data sets to train the detection algorithms. This work tries to overcome this barrier with significant contributions. With nearly 25,000 illicit transactions, we have increased the Elliptic Data Set –the most extensive labelled transaction data publicly available in any cryptocurrency. The former data set only contained 4,545 illicit transactions, resulting in a class imbalance of 9.8:90.2 illicit/licit ratio. Our work has changed that to a 41.2:58.8 illicit/licit ratio. Besides, to show that class imbalance datasets can also be beaten with artificial work, we have studied the use of generative adversarial networks (GAN) for creating synthetic samples. Finally, the last part of this work was dedicated to applying deep learning and, more particularly, long short-term memory networks (LSTM) for the binary classification problem. We show ideal results that can help change the current state-of-the-art trend, mainly focused on machine learning algorithms.","['Engineering', 'Data Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2065-3_12,en,Machine Learning Approaches in Mobile Data Forensic: An Overview,OriginalPaper,"This article discusses machine learning’s function in digital forensics to better understand where machine learning stands in today’s cybersecurity arena when it comes to gathering digital evidence. Hear began with discussing the history and development of digital forensics. Following that, the work proposes a short literature study to demonstrate the areas of digital forensics where machine learning techniques have been applied to date. The purpose of this article is to raise awareness about the use of machine learning in digital forensics. I am attempting to examine several machine learning applications in various fields to see how they might use machine learning in other sectors based on their current uses. The concepts described here will pave the way for developing more sophisticated and effective digital forensics tools.","['Engineering', 'Communications Engineering, Networks', 'Artificial Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Machine Learning']"
doi:10.1007/978-3-031-16217-6_13,en,Integration of Machine Learning Algorithms and Time-Series Satellite Images on Land Use/Land Cover Mapping with Google Earth Engine,OriginalPaper,"This study demonstrates the usage of the Google Earth Engine (GEE) cloud service for LULC classification in Nakhon Nayok, Thailand. Herein, multi-temporal Sentinel-2 images are incorporated with supervised machine learning algorithms in order to determine seven land use and land cover (LULC) classes. Pixel-based (PB) and object-based (OB) classification methods are also considered and evaluated. When using the PB approach combined with the random forest algorithms and median composited time-series data, results demonstrated that the highest attainment is achieved: namely, overall accuracy of 85.42% and kappa statistics reaches 0.82. Z-statistics confirm the potential of median composited datasets that provide significant performance (p-value <0.05). GEE reveals many advantages in geospatial analysis from this experiment. GEE is a robust cloud-serviced tool for LULC time-series image classification.","['Computer Science', 'Computer Applications', 'Geography, general', 'Sustainable Development']"
doi:10.1007/978-3-031-17697-5_48,en,Investigation of the Role of the Microbiome in the Development of Alzheimer’s Disease Using Machine Learning Techniques,OriginalPaper,"Data Science and Machine Learning (ML) techniques’ applications to the human microbiome data exhibited a potential to identify biomarkers and participate in the early diagnosis of several medical conditions. In this paper, we explored the application of ML to biological data from Alzheimer’s disease patients. We trained ten classification models that used fecal 16S rRNA sequence data to differentiate between subjects affected by Alzheimer’s disease (AD), pre-onset amnestic mild cognitive impairment patients (aMCI), and healthy controls (HC) (n = 93 patients, 33 AD, 32 aMCI, 28 HC). Before the classification process, bioinformatics analysis was performed using the QIIME2–2021.4 tool which resulted in profiling microbiome communities present in host organisms. Alpha diversity metrics were calculated using three different indexes (Shannon’s diversity index, Faith’s Phylogenetic Diversity, and Observed OTUs) while Kruskal–Wallis test was used to confirm significant difference (p-value < 0.05) between study groups. To achieve binary classification, the dataset was divided into three subsets each containing two groups (AD vs aMCI, AD vs HC, aMCI vs HC) Prior to the classification process, SelectKBest with the f_classif algorithm was used as univariate feature selection to reduce the number of features in each group to top five. 5-fold cross-validation yielded high accuracy results (going over 70%) for a number of classifiers, with the highest accuracy reach of 78.3% (via Logistic Regression) in the case of distinguishing between aMCI and HC subjects. Our results showed that a machine learning algorithm can be developed and achieve high precision (>78%) with relatively few parameters. Such a model can be used to support decision-making in medicine by gathering the data through a non-invasive technique.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-12807-3_7,en,Explainable AI Driven Applications for Patient Care and Treatment,OriginalPaper,"The continuous development of technology has saved countless lives and improved the quality of living. Artificial Intelligence is reshaping the healthcare industry from hospital care to clinical research, drug development, to insurance, and has been able to reduce costs and improve patient outcomes. Most AI system works as a black box with little or no explanation which results in a lack of trust and accountability among patients and doctors. This chapter is written with the intent to share with the audience how exquisitely the health care sector has integrated with the technology. The chapter initiates with a brief description of the use of Artificial intelligence and technology in the health domain, and how computers are helping not only doctors, but patients, health care departments, and Insurance companies. This chapter later focuses on various AI-driven Applications which are used for patient care and treatment. This chapter shed light on the purpose and benefits of XAI along with a few real examples.","['Engineering', 'Computational Intelligence', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5798-7_2,en,Technical Background,OriginalPaper,"This chapter provides the technical background of the collaborative fleet maneuvering problem. The basic knowledge of vehicle model and fleet configuration is introduced. Main approaches on topics related to fleet maneuvering, including collaborative localization, fleet keeping and reconstruction, and collision avoidance, are reviewed.","['Engineering', 'Control, Robotics, Mechatronics', 'Robotics and Automation', 'Control and Systems Theory']"
doi:10.1007/978-981-19-3391-2_10,en,Disease Prediction Based on Symptoms Using Various Machine Learning Techniques,OriginalPaper,"Meticulous and prompt analysis of any health related issues is significant for the anticipation and treatment of the disease. The conventional method of determination may not be adequate on account of a genuine infirmity. Fostering a clinical determination framework dependent on machine learning calculations for forecast of any illness can help in a more exact finding than the regular strategy. We have built a disease predication framework utilizing numerous machine learning techniques from symptoms. The dataset utilized had more than 261 illnesses and 500 symptoms for handling. The Random Forest Classifier gave the best outcomes when contrasted with Multinomial Naïve Bayes Classifier, K-Nearest Neighbors, Logistic Regression, Support Vector Machines, Decision Tree, and Multilayer Perceptron Classifier models. The accuracy of the proposed Random Forest Classifier model on the given dataset was 91.06%. Our prediction model can go about as a specialist for the early finding of disease to guarantee the treatment can happen on schedule and lives can be saved.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Statistics, general', 'Cyber-physical systems, IoT', 'Professional Computing', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-1610-6_46,en,Improving Arabic Hate Speech Identification Using Online Machine Learning and Deep Learning Models,OriginalPaper,"Due to the rising use of social media platforms on a global scale to interact and express thoughts freely, the spread of hate speech has become very noticeable on these platforms. Governments, organizations, and academic institutions have all spent substantially on discovering effective solutions to handle this issue. Numerous researches have been performed in several languages to find automated methods for identifying hate speech, but there has been minimal work done in Arabic. The findings of a performance evaluation of two machine learning models, namely the passive-aggressive classifier (PAC) and the Bidirectional Gated Recurrent Unit (Bi-GRU) augmented with an attention layer, are investigated in this work. Proposed models are developed and evaluated using a multi-platform Arabic hate speech dataset. We employ term frequency-inverse document frequency (TF-IDF) and Arabic word embeddings for feature extraction techniques after running a variety of pre-processing steps. The experimental results reveal that the two proposed models (PAC, Bi-GRU with attention layer) provide an accuracy of 98.4% and 99.1%, respectively, outperforming existing methods reported in the literature.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-15428-7_22,en,Predictive Analytics Applications for Small and Medium-Sized Enterprises (SMEs)—A Mini Survey and Real-World Use Cases,OriginalPaper,"Predictive analytics is becoming more mature and is gaining traction in smart manufacturing around the world. Over the past decade, predictive analytics has hence reached a plateau of productivity while techniques and tools became more robust and accessible. Small- and medium-sized enterprises have to seize these new opportunities in order to optimize and embed analytics in high-value business scenarios and improve their competitiveness. However, getting started with predictive modeling can seem like an insurmountable feat for SMEs, why inspiration and pointers to real-world applications can be valuable. In this paper, we first introduce current trends in predictive analytics followed by a mini survey showcasing interesting real-world use cases in SMEs. Finally, we present common algorithms and models, followed by two recent real-world applications in Danish SMEs.","['Engineering', 'Industrial and Production Engineering']"
doi:10.1007/978-981-19-3148-2_28,en,Research Trends in Image Processing and Defect Detections,OriginalPaper,"In terms of efficiency, quality, and dependability, computer vision dramatically improves defect detection. In visual inspection, high-quality images necessitate excellent optical lighting systems and adequate image acquisition devices. Deep learning is having a huge impact on image analysis. Image processing and analysis are crucial technologies for gathering fault information. This study provides a systematic overview of the history of optical illumination, picture acquisition, image processing, and image analysis in the field of visual inspection. The most recent advances in computer vision-based industrial fault detection are discussed. Deep learning will become increasingly relevant as the field of visual inspection develop. As a result, a comprehensive explanation of deep learning in defect detection following the study of traditional classification, localization, and segmentation is discussed. Finally, the future of visual inspection technology is discussed. In this paper, research trends for the application of defect detection techniques in image processing are analyzed using data from Web of Science and Scopus databases. Data is analyzed globally; cluster analysis of related keywords is computed along with link strength. Various other experiments are also conducted which help analyze research trends in image processing and defect detection.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory']"
doi:10.1007/978-3-031-09659-4_14,en,Typography Design: An Algorithmic Approach,OriginalPaper,"This article explores the theoretical and practical aspects of a new algorithmic approach in the creation of digital typographic drawing. Generative design enabled an application based on a set of rules (algorithms) in a computer, generating unique and random creations. That set of rules is defined by the designer for the computer to execute. In the theoretical scope, generative design explores mathematical programming. Designers thus withdraw from the forefront of creation, determining the rules for creation, but with no control over result. The impact of the project includes the discussion of the concepts of art and generative design, the process and generation of visual elements through code instruction and execution, and the autonomy of software. It also questions the concept of digital typography. Typography has progressed thanks to new technologies and is nowadays more about choices than about limitations. The digital media provide all the resources, following the return of the analogic, complementing them. This project contributes to that wider range of possibilities.","['Architecture / Design', 'Industrial Design', 'Digital/New Media', 'Structural Materials', 'Music']"
doi:10.1007/978-3-031-17697-5_32,en,Prediction of Real Estate Market Prices with Regression Algorithms,OriginalPaper,"The real estate market is one of the most productive businesses in the world. In recent years, many companies are considering switching to a data-driven approach due to many technological advances. In this regard, the field of artificial intelligence stands out the most from other computer science fields. It has the potential to significantly improve buying and selling strategies, as well as to increase investment opportunities in large commercial projects. In this paper, we investigate the possibility of using two machine learning algorithms to predict real estate prices using a real-world dataset of estate listing data. We show how to prepare and analyze this dataset, and then use machine learning algorithms to accurately predict real estate sales prices. Experimental results show very promising results, thus indicating the potential of using machine learning in real-life scenarios.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1618-2_10,en,Classification Methods for Labelled Data in Machine Learning,OriginalPaper,"In the fast-growing web technology and breakthrough techniques of acquiring data from the user without letting them know and using this data to tackle any other problem, data scientist often has to go through a lot of hustles to get the correct and meaningful data. To minimize the efforts and work efficiently there are various ways in machine learning algorithms to do so and one of them is classification. The motive of this paper is to help and enlighten how one can work with labelled data and classification models and make the best use out of them either for study or for working on live projects which can be as sensitive as detecting cancer in a patient.","['Energy', 'Energy Systems', 'Renewable and Green Energy', 'Materials Engineering', 'Mechanical Engineering']"
doi:10.1007/978-981-19-1550-5_54-2,en,Artificial Intelligence,ReviewPaper,"In the fourth industrial revolution (Industry 4.0), Artificial Intelligence (AI) had been a cognitive science that produces actual value needed for relevant data with processing capabilities and algorithms. Manufacturing in the Internet-of-Thing (IoT) era will be more efficient, better quality, easier to manage, and more transparent through integration of physical and cyber technologies in Industry 4.0-based smart factories. Factory automation relies heavily on sensors and AI to make the system intelligent. Sensor technology advancements and developments linked to Industry 4.0 serve as the backbone for the inclusive expansion of industry and the economic success of any country. It is imperative that manufacturing organizations and supply chains have access to the latest low-cost sensor technology for collecting data and putting it to good use. Standard sensor types include position sensors, flow, temperature, flow rate, pressure, and force. A wide range of fields, including motorsport, health care, manufacturing, the armed forces, and agriculture all make use of them on a day-to-day basis. Increasing efficiency through automation is the goal of Industry 4.0. The purpose of this paper is to provide a brief overview and viewpoint on the most recent advancements in AI and the associated problems. Attempts to define the main ideas and tools behind this new era of manufacturing in the early years of the so-called fourth industrial revolution (Industry 4.0) always ended up referring to the concept of smart machines that could communicate with each other and with the environment. When it comes to the new industry 4.0, it’s the defined cyber physical systems connected by the IoT that get all the attention. Nonetheless, several tools and applications will benefit the new industrial environment, complementing the actual formation of a smart, embedded system capable of performing autonomous tasks. And the majority of these revolutionary ideas are based on the same background theory as artificial intelligence, in which the analysis and filtration of massive amounts of incoming data from various types of sensors aids in the interpretation and recommendation of the best course of action. As a result, artificial intelligence science is well suited to the challenges that arise during the fourth industrial revolution’s consolidation. The purpose of this paper is to provide a brief overview and viewpoint on the most recent advancements in AI and the associated problems.","['Physics', 'Measurement Science and Instrumentation', 'Nanotechnology']"
doi:10.1007/978-3-031-14859-0_24,en,Use of YOLOv4 and Yolov4Tiny for Intelligent Vehicle Detection in Smart City Environments,OriginalPaper,"One of the biggest problems in cities today is the significant increase in the number of motor vehicles. Intelligent traffic control is a fundamental part of controlling city travel. To achieve this goal, it is very important to have sensor technologies capable of identifying the number of vehicles traveling on a road. In this paper, we propose the development of a classifier model capable of reliably counting the number of vehicles in urban areas. In this case, it is proposed the construction of a dataset to carry out the training of a model based on YOLOv4 and YOLOv4Tiny systems that can be embedded in intelligent traffic light systems.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16072-1_53,en,Real-World Computer Vision for Real-World Applications: Challenges and Directions,OriginalPaper,"Recent advancements in machine learning, particularly deep learning, have driven the development of next-generation of smart and autonomous applications, especially those that need an in-depth understanding of humans’ behaviors and interactions with the physical world. However, there is a gap between current research in computer vision and the inherent real-world limitations of applications. This paper offers holistic solutions embracing real-world computer vision challenges and bringing computer vision to a broad range of applications. The core significance of this paper is creating a holistic privacy-aware ensemble of novel computer vision algorithms and training principles to understand humans’ behaviors and interactions with the physical world. To this context, this paper presents multiple fundamental contributions intersecting classical computer vision, deep learning research, and information theory principles. The key contributions include novel privacy-aware identity neural person re-identification, domain-invariant training to bridge the gap between the training data-set and real-world data limitation, enhancing visual resiliency, and knowledge amalgamation across multiple concurrent vision tasks to create full situational awareness.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-3-031-21333-5_22,en,"Elderly, Their Emotions and Deep Learning Techniques to Help Their Dignified and Positive Aging",OriginalPaper,"All people in the world age, it is part of the life cycle, the important thing is to understand that it can be done in a dignified and positive way, as proposed by the Ageing Lab Foundation in its EDP model, therefore in the era of the fourth revolution Industrial (4RI), it is essential to have tools that allow us to understand how well older people are at this stage of life, to know if their emotions represent an affable state, or on the contrary indicate symptoms that something is not right. Due to the foregoing, this document presents a first approach to the technologies that have been applied to detect emotions in older people and the way in which tools such as Deep Learning of Artificial Intelligence can help in the process, in order to propose the development of an application that helps in the detection of emotions, but based on an evaluation of some existing algorithms and manual analysis processes, the initial result is a state of the art of technologies applied to the recognition of emotions, mainly in older people, as well such as the evaluation of some algorithms developed and programmed in the Python language and applied to some videos for free use on the Internet, which set the tone and path for the proposal that is being improved in the work with the Fundación Ageing Lab of Spain, the TEC of Costa Rica and the UNAD of Colombia.","['Engineering', 'Data Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-17746-0_14,en,Augmented Press and Robot Journalists Who Determines the Ethics of Journalistic Coverage?!,OriginalPaper,"The focus is on researching the relationship between the journalist and the technician and considering that the current reality has come to refer with complete clarity to the aspiration of journalistic work to rely on algorithms, data processing, and linguistic engineering applications. This shows the importance of examining the symbolic message on which the press is based instead of the cold and direct logic on which digital applications are based. The matter remains dependent on the initiative issued by the press sector, given the responsibility related to the importance of reconsidering the media content industry. And directing attention to the extent of (the world’s vision) for the journalist. The mission and moral responsibility are involved in the entire journalistic work; the journalist’s job is not limited to writing texts or following up and editing the news. Still, the matter goes far beyond this reality. Artificial intelligence and its algorithms may help journalists produce 100 articles in five minutes. But the question remains about the feasibility, meaning, value, and importance of this amount of production. Let us agree that the articles produced based on the existing cooperation between (digital and human) have reached accuracy and skill and rely on a vast amount of data and information. But the question remains, where is the identity, spirit, vision, and intuition that distinguishes this press institution from that one? Where do you see the position of values ​​and ethics, symbolism, unique taste, and press message? What is the point of journalism being automated with a digital mechanism based on algorithms while missing the message of journalistic work and the goal for which it works?","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Business Information Systems']"
doi:10.1007/978-3-031-07254-3_18,en,Machine Learning Techniques for Damage Detection in Wind Turbine Blades,OriginalPaper,"In the wind energy industry, wind turbines are subject to enormous mechanical loads and extreme environmental conditions during operation, which is why damage detection methodologies play a vital role in their operation. In order to reduce costs and guarantee the integrity and longevity of such structures, the use of a reliable Structural Health Monitoring (SHM) methodology, capable of detecting structural defects, is crucial to plan and perform maintenance operations in a way to extend the lifetime of these structures. In this context, Machine Learning (ML) techniques have succeeded in a broad range of applications and can be leveraged to develop accurate and automated SHM procedures. In this work, two different methodologies were successfully implemented to recognize deviating patterns from the healthy state, to detect anomalies in the dynamic response of wind turbine blades. One methodology combines automated modal analysis and the classification of modal parameters with a Multivariate Gaussian anomaly detection technique. The other uses Autoencoders (AEs) to classify frequency-domain data of the structure, i.e., frequency response functions or cross-power spectral densities. The response of the structures was obtained through modal shaker, modal hammer, and pull-and-release testing.","['Engineering', 'Building Repair and Maintenance', 'Cyber-physical systems, IoT', 'Industrial and Production Engineering', 'Monitoring/Environmental Analysis', 'Analytical Chemistry']"
doi:10.1007/978-981-19-1412-6_5,en,IoT-Based Prediction of Chronic Kidney Disease Using Python and R Based on Machine and Deep Learning Algorithms,OriginalPaper,"The machine learning (ML) and Internet of things (IoT) technologies are increasingly focussed on decision tree classification algorithm. Its use is expanding through numerous fields, solving incredibly complex problems. DTCA is also being used in medical health data using computer-aided diagnosis to identify chronic kidney diseases like cancer and diabetes. Deep learning is a class of machine learning that utilizes neural networks to solve problems and learn unsupervised from unstructured or unlabelled data. The DL used to deep stacked auto-encoder and softmax classifier methods is applied for CKD. In this work, based an R Studio and Python Colab software using random forest, SVM, C5.0, decision tree classification algorithm, C4.5, ANN, neuro-fuzzy systems, classification and clustering, CNN, RNN, MLP is used to predict multiple machine and deep learning techniques, discover an early diagnosis of CKD patients. In this work, classify the chronic kidney disease various stages are identified.","['Engineering', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security']"
doi:10.1007/978-3-031-15900-8_6,en,The Flight Dynamics Facility,OriginalPaper,"This chapter describes the main functionalities and architecture of the Flight Dynamics Facility (FDF) and outlines its most relevant interfaces to the other ground segment components. One of the main tasks of the FDF is the regular orbit determination based on the radiometric and meteorological tracking data from the TT&C station network. Based on the computed orbit information, derived products like the pointing files are computed, which are an essential input for the TT&C stations to establish future contacts. The onboard orbit propagator updates are another important product that needs to be derived from the most recent orbit knowledge. Orbit propagation allows to predict the future orbit development and is the basis to calculate upcoming orbit events like eclipses, node crossing, or sensor FoV crossings required by mission planning. Longer term orbit predictions are an important means to detect potential future violations of orbit station keeping requirements which require the manoeuvre planning functionality to provide an adequate orbit correction strategy. Once the necessary orbit change is determined, the satellite platform specific command parameters need to be computed and provided to the spacecraft control facility (SCF) for uplink to the satellite. Manoeuvre planning, execution, and calibration is also an essential task during the LEOP phase in order to bring the satellite from its launcher injection point to its foreseen operational orbit location. Due to the significant increase of the space debris population during the past decades, the regular monitoring of potential orbit collisions and a realistic risk estimation is another important flight dynamics task. In addition to the functional description, this chapter also provides some insight into the underlying mathematical algorithms and techniques. The focus here is given to the areas of orbit propagation, orbit determination, manoeuvre planning, command parameter computation, fuel mass estimation, and collision risk monitoring.","['Engineering', 'Aerospace Technology and Astronautics', 'Astronomy, Astrophysics and Cosmology', 'Communications Engineering, Networks', 'Management of Computing and Information Systems', 'Operations Management', 'Security Science and Technology']"
doi:10.1007/978-1-0716-2663-4_3,en,Numerical Techniques for Applications of Analytical Theories to Sequence-Dependent Phase Separations of Intrinsically Disordered Proteins,OriginalPaper,"Biomolecular condensates, physically underpinned to a significant extent by liquid–liquid phase separation (LLPS), are now widely recognized by numerous experimental studies to be of fundamental biological, biomedical, and biophysical importance. In the face of experimental discoveries, analytical formulations emerged as a powerful yet tractable tool in recent theoretical investigations of the role of LLPS in the assembly and dissociation of these condensates. The pertinent LLPS often involves, though not exclusively, intrinsically disordered proteins engaging in multivalent interactions that are governed by their amino acid sequences. For researchers interested in applying these theoretical methods, here we provide a practical guide to a set of computational techniques devised for extracting sequence-dependent LLPS properties from analytical formulations. The numerical procedures covered include those for the determination of spinodal and binodal phase boundaries from a general free energy function with examples based on the random phase approximation in polymer theory, construction of tie lines for multiple-component LLPS, and field-theoretic simulation of multiple-chain heteropolymeric systems using complex Langevin dynamics. Since a more accurate physical picture often requires comparing analytical theory against explicit-chain model predictions, a commonly utilized methodology for coarse-grained molecular dynamics simulations of sequence-specific LLPS is also briefly outlined.","['Life Sciences', 'Biochemistry, general', 'Bioinformatics']"
doi:10.1007/978-3-031-16203-9_28,en,Computational Intelligence in Medicine,OriginalPaper,"Two paradigms have historically formed in artificial intelligence: neurocybernetics and black box cybernetics. The cybernetics of the “black box” is based on a logical approach. The rapid development of modern medicine is due to the use of technical diagnostic tools, and the use of new information technologies. Technical means of diagnosing allow you to visualize the processes of diagnosing. Intelligent information technologies use the methods and tools of artificial intelligence and can speed up the diagnosis and improve its accuracy. The authors of the work have been working on biomedical images for many years, building CAD systems with elements of artificial intelligence. Biomedical (cytological, histological, and immunohistochemical) images are used for diagnosis in oncology. The problems of classification, generation, segmentation, and clustering of biomedical images are solved in the work. For these purposes, the following means of computational intelligence were used: CNN, GAN, and U-net. CNN is used in the paper to classify images. Several models for the classification of biomedical images are proposed and a comparative analysis with existing analogs is given. The accuracy of classification for cytological images was 86%, for histological was 84%. The authors analyzed the architectures of convolutional neural networks of the U-net type for automatic segmentation of immunohistochemical images. A modified neural network architecture for the segmentation of immunohistochemical images has been developed. Computer experiments were performed on different numbers of stages and iterations. ROC curves are built to assess the quality of segmentation of known and modified network architectures such as U-net.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3951-8_58,en,Perceiving the Danger of “Fake News” via Machine Learning and Deep Learning: GPT-2 and Auto ML,OriginalPaper,"Fake news, usually targeting a person or a group, frequently goes viral as it contains provocative information. Misleading articles have been an issue for a long time, implying that the sentences are so well written that most readers cannot tell that it was generated by machine learning. To resolve this problem in our society, this research focused on how fake news and real news can be classified, and how fake articles can be created through a deep learning model. The first step was collecting data from Kaggle to put in algorithms and sort the data. The algorithms used were LGBM, logistic regression, XGB, KNN, and Gaussian NB for machine learning. Naive Bayes, AdaBoost, SVM-linear model, LDA, and Dummy were used for auto-machine learning models as well as logistic regression and KNN. These machine learning models had an accuracy of around 83 percent average, and most of the auto-machine learning models were close to having 100 percent accuracy. The next step was creating fake news through pretrained and fine-tuned models from GPT-2. Unlike a pretrained model, fine-tuned ones generated longer and more fluent texts that were comparable to the written works of people. The results from the classifiers demonstrate that the spread of fake news can be prevented, while the generated fake news suggests that creating fake information does not require much effort. The society remains vulnerable with countless fake articles, but further research may prevent this issue by introducing simpler and more accessible classifiers to readers.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-3-031-11089-4_1,en,Auditing Advanced Information Systems and Technologies in a Modern Digital World,OriginalPaper,"This chapter provides the introduction to the book auditing advanced information systems and technologies in a modern digital world. First, we provide a brief background on the importance for society of auditing advanced information systems, and the technological developments that has led to the creation of these complex and advanced information systems. Thereafter two basic concepts are described: assurance and complexity. Subsequently, the overall outline of the book is presented and how the chapters are related.","['Business and Management', 'IT in Business', 'Software Management', 'Risk Management', 'Systems and Data Security']"
doi:10.1007/978-981-19-5331-6_4,en,Fall Detection Using Transformer Model,OriginalPaper,"Falls are exceptional activities that put one’s health in danger. To limit the effect of falls, it is necessary to build fall detection and prevention systems. The goal of emerging technology is to create such systems that will improve people’s quality of life, especially for the elderly. To limit the danger of injury, a fall detection system detects the fall and generates an assistance signal. The suggested system detects falls by classifying various behaviors as fall or non-fall activities and alerting those who are affected in the event of an emergency. To calculate characteristics, the dataset SisFall is used, which contains a variety of actions performed by numerous people. The machine learning methods XGBoost and LightGBM are used to identify falls based on calculated characteristics. Using the XGBoost algorithm, the system achieves ROC-AUC scores of up to 97.64%. Our proposed solution is based on a transformer model, which is then tailored to produce the best outcomes, with an accuracy of approximately 95.7%.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-1607-6_45,en,Implementing Butterfly Key Expansion Using Post-Quantum Algorithms,OriginalPaper,"Vehicular ad-hoc networks are important components in intelligent transportation systems which provide a reliable means of communication. Given that a security breach in such networks can result in fatal situation, the security of these networks is as important as their reliability. However, implementing security is not always a straightforward task especially when there are different devices with different capabilities. Additionally, current public-key infrastructure makes use of public-key algorithms that are susceptible to quantum-computation attacks making them not usable if quantum computers become a practical reality. In this paper, we present a public-key infrastructure implementation which makes use of a post-quantum algorithm providing an extra layer of protection to it. We compare the results of our implementation to implement which make the use of classical algorithms and show that they are very comparable in terms of speed, power, and energy consumption.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2273-2_48,en,Accident Prediction Modeling for Collision Types Using Machine Learning Tools,OriginalPaper,"Road accidents are one of the most significant concerns being addressed by developing countries. It is highly imperative to scientifically analyze road accidents to reduce the increasing number of accidents and victims. This study aimed to develop accident prediction models for the predominant collision types on a selected road stretch in Calicut City of a length of 7 km. The main objectives of the project were to identify predominant collision types of accidents and develop prediction models using machine learning algorithms. Rear-end collisions and pedestrian hit collisions were the most predominant types of collision on the study stretch. The developed artificial neural network gave a satisfactory prediction for rear-end collisions, and the major influencing factors were maximum gradient and traffic volume. The random forest model showed promising results for predicting pedestrian hit collisions, and the significant factors that contributed were pedestrian volume, traffic volume, presence of bus stop, and maximum gradient.","['Engineering', 'Transportation Technology and Traffic Engineering', 'Building Construction and Design', 'Mechanical Engineering']"
doi:10.1007/978-981-19-3035-5_54,en,Study of Land Cover Classification from Hyperspectral Images Using Deep Learning Algorithm,OriginalPaper,"As image sensor electronics have progressed, and hyperspectral images have been used in a wide range of applications. In terms of recognizing the classes, a lot of research work has been done to extract useful information from the available unstructured knowledge database. The use of spectral and geographical datatypes in images can improve the classification precision. To improve the accuracy of the energetic-spectral snap analysis, combining dimensional and spectral data is a good idea. This research study examines the history of dimensional facts based on energetic-spectral image classification designs by using prepared and semi-directed classifiers to classify detached sensing images with particularized class labels. Long-term data are removed if the features are protensive. To increase the veracity of classification, the extracted traits are prepared by utilizing multiple classifiers. The preparation and sinking balance towards the loss function have been reused to train the classifiers. To avoid local minima, the preparation is approved by utilizing various tiers for accompanying the extra balancing limits. To overcome the risk of establishing a contradictory validity image, each detached perceiving image is classified throughout the experiment stage. Exploratory discoveries demand higher validity in-class criteria than other advanced directed classifier techniques.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Statistics, general']"
doi:10.1007/978-981-19-2538-2_27,en,Medical Insurance Cost Prediction Using Machine Learning Algorithms,OriginalPaper,"Medical Insurance cost prediction is prime distress. A Medical Insurance company can only make money if it collects quite it spends on the medical aid of its beneficiaries. Medical Insurance companies are troublesome task as determining premiums for his or her customers. Mechanism Knowledge stands a part of Reproduction Intellect and computing which spotlight the consumption of data also controls to imitate the method that persons absorb, increasingly employed on the situation exactness. Prediction means affecting the produce of estimation afterwards the situation consumes be situated arranged on a documented dataset, in addition, original data though computing the likelihood of a particular outcome like whether a customer will mix in thirty days. Comparative analysis of Machine Learning Algorithms. Compare new techniques with existing techniques using various outputs. We will use the dataset for training the model. Which regression gives the best accuracy and who will take less time.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory', 'Mobile and Network Security']"
doi:10.1007/978-981-19-5073-5_2,en,Methods Used to Improve Generalization Performance,OriginalPaper,"Historically, the intuition behind developing classification algorithms was often to identify a hypothesis that minimizes training error. A major problem encountered with this approach is overfitting, which occurs when the hypothesis becomes too complex in comparison to the size of training data. In such cases, it is likely that an algorithm minimizing training error will find a hypothesis that fits the training data very well, but generalizes poorly to previously unseen data. Good generalization here refers to low generalization error which is defined as the difference between the training error and true error.","['Computer Science', 'Machine Learning', 'Computational Intelligence', 'Pattern Recognition']"
doi:10.1007/978-981-19-3391-2_29,en,Hybrid Classification Algorithm for Early Prediction of Alzheimer’s Disease,OriginalPaper,"Alzheimer's disease is the most common type of dementia found. Dementia is actually a syndrome related to an ongoing decline of brain functioning. Alzheimer’s is caused due to increase in age, genes inherited, depression, and factors related to lifestyles. AD at its final stage cannot be treated. The intermediate stages like mild cognitive impairment (MCI), can be treated, so that the risk of developing AD can be decreased. In this work, structural MRI images are used and hybrid approach is introduced to detect MCI with good accuracy. ADNI dataset is used for project work for classification of cognitive normal (CN) and mild cognitive impairment (MCI). ADNI provides MRI data along with demographic information such as age, gender, physical examinations, and other neurobiological data. Initially, the MRI data is subjected to segmentation using K-means clustering in order to extract 2D images and gray matter. These segmented images are preprocessed using discrete wavelet transform (DWT), which is then further classified into MCI and CN classes. Random forest (RF) classifier, artificial neural network (ANN) is discretely implemented and the accuracy of prediction is calculated. Further, these algorithms are hybridized in order to achieve improved accuracy of prediction. By hybridizing the algorithms, an accuracy of 93.47% was achieved.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Statistics, general', 'Cyber-physical systems, IoT', 'Professional Computing', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-3590-9_10,en,A Review on Rice Quality Analysis,OriginalPaper,"Pulses and grains are considered as staple food globally which provides crucial nutrients to the peoples. Emerging problems with the cereals and pulse products are adulteration, fraudulent in combining the species varieties, maintaining the quality in terms of organic, conventional and storage sterilization. Analytical and statistical techniques are employed to tackle the issues. However, some classical and non-destructive techniques still have limitations to eradicate the issues. This review paper analyses the techniques discussed for the detection methods of rice starch content quantitative evaluation, rice physico-chemical functional properties and biochemical properties identification techniques. Machine vision-based internal rice quality evaluation is discussed. Classical methods evolved for quality and safety measurements of grain products were unable to deliver better accuracy than the non-destructive methods. Spectroscopic non-destructive methodologies considered for assessing the adulteration, fungal infection and quality assessment in grain products give better accuracy in delivering the findings. Furthermore, to enhance the identification process, a non-destructive, rapid, real-time analysis needs to be developed for the whole grain or pulses adulteration, fraudulent, quality, quantity and sterilization detection.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security', 'Mobile and Network Security']"
doi:10.1007/978-981-19-4960-9_25,en,"Reinforcement Learning-Based Traffic Engineering in SDN: Problem Formulation, Parameters, and Topology",OriginalPaper,"Traffic engineering solutions in software-defined networks employing reinforcement learning approaches have evolved in recent years due to the rise in interrelated devices and the resulting complexity in the network administration. Network operators can observe the network traffic with efficiency, scalability, and a centralized management in the software-defined networks architecture. Because of separation of control and forwarding planes in software-defined networks, reinforcement learning agents may now be included in networking structure to enforce the traffic pattern modifications during the network congestion. This paper surveys the reinforcement learning methods and the various parameters adopted to improve TE in SDN. We reviewed the usage of reinforcement learning methods and the different parameters used in other policies. We further investigated the recent reinforcement learning-based traffic engineering schemes. The article finally summarizes the various parameters and algorithms used to manage the network performance in SDN efficiently.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Professional Computing']"
doi:10.1007/978-981-19-5845-8_21,en,Deep Learning Based Hand Sign Recognition in the Context of Indian Greetings and Gestures,OriginalPaper,"Communication through sign language can be orchestrated in a variety of ways. There are certain words of the spoken language that can be directly represented and interpreted through simple gestures. Words like (Namaste) (good) (bad) etc. have designated signs or gestures. However, there are certain words that don’t have predefined signs. Prior to the development of deep learning methodologies and algorithms, research in the field of sign language interpretation and translation was few. The most typical method for interpretation is to extract features from coordinated movements using Image Processing Algorithms, then use Convolutional Neural Networks to learn these features and increase utility. Advances in deep learning have led to the creation of Object Detection Algorithms that, when used in conjunction with neural networks, can identify all types of objects. You Only Look Once (YOLO) is one such algorithm that excels in identifying custom objects. It's utilized in conjunction with Darknet, a neural network architecture. People who use sign language frequently need to rely on a translation to get their message across to someone who does not understand sign language. Dependency on a translator can create issues and potentially render the person incapable of acting independently. The creation of a system that can help people use sign language without depending on another person can really help them be independent and ignite the confidence to present themselves to the world without any fear. Thus in a country like India, it is very important that we develop a hand gesture detection system that can identify Indian gestures.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-17544-2_11,en,Early Detection of Chronic Obstructive Pulmonary Disease Using LSTM-Firefly Based Deep Learning Model,OriginalPaper,"Identifying Chronic Obstructive Pulmonary Disease (COPD) is essential for reducing mortality and cost burden. However, the population suffers from an underdiagnosis of chronic obstructive pulmonary disease. This chapter aims to create COPD detection models and assess the relative effectiveness of several modeling paradigms to discover the optimal model for the task on the dataset of 563 hospital or emergency ward visits in China-Japan Friendship Hospital performed between February 2011 and March 2017. We investigated the use of a Long Short Term Memory Network (LSTM), a kind of deep learning, for the automated identification of COPD, with the model hyperparameters modified using the firefly algorithm. Three optimization variations have been used to optimize the hyperparameters of the proposed LSTM Model: random search, hyperband, and firefly algorithm. Firefly algorithm with LSTM obtained superior results than the LSTM-Random Search and LSTM-Hyperband. Therefore, the adoption of LSTM-Firefly is beneficial in terms of COPD detection and diagnosis with clinically acceptable performance compared to LSTM—Random Search, LSTM—Hyperband, LSTM, and other machine learning algorithms such as LR, KNN, NB, DT, and RF.","['Engineering', 'Computational Intelligence', 'Biomedical Engineering and Bioengineering', 'Health Informatics']"
doi:10.1007/978-981-19-2300-5_15,en,Physics Simulation Based Approach to Node Clustering,OriginalPaper,"We present a novel method of node clustering that is based on carrying out a physical simulation. We treat nodes of a graph as point-sized unit mass particles that interact with each other as well as the space (multi-dimensional) that they are present in through certain defined physical forces. As the configuration of the system evolves during the simulation, similar nodes coalesce while the dissimilar nodes separate out, thus allowing node clusters to emerge. We have experimented with this idea on graphs with up to 300 nodes and have found it to work well. Doing so also allowed us to solve problems of network community detection by utilizing existing density based clustering algorithms, which otherwise would not be possible.","['Mathematics', 'Mathematical Applications in Computer Science', 'Engineering Mathematics', 'Operations Research/Decision Theory', 'Mathematical Modeling and Industrial Mathematics', 'Artificial Intelligence', 'Optimization']"
doi:10.1007/978-3-031-14859-0_11,en,Object Detection Through Computer Vision,OriginalPaper,"This research work is focused on the field of object detection through computer vision, focusing on a very popular topic nowadays, smart cities. Therefore, a proposal is presented, after evaluating the different systems that have been used in the literature, based on deep learning techniques together with the use of images to detect traffic density. The developed technique corresponds to a You Only Look Once (YOLO) algorithm, which allows using previously trained weights or training the weights with a personalized dataset, for traffic detection. In relation to the results obtained after the application of these techniques, it can be observed how, depending on the data set used for training, the algorithm obtains different detections.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1457-7_72,en,Research on Operation Data Mining of Pulse Dust Collector,OriginalPaper,"By analyzing the filtering mechanism of the filter bag and the deficiency of static injection method based on fixed pressure difference, three models are selected to predict the pressure difference data. Experimental results show that all three models can predict the change trend of the pressure difference data. The MSE of BP neural network is 0.00994, indicating that the pressure difference data is predictable. The method of dynamic injection with pressure difference as control parameter is feasible. In order to solve the problem of flood of fault alarm information of pulse bag filter, the unsupervised learning method in machine learning was analyzed for the data set of fault type. By comparing the unity of the classification results of the three algorithms, it was found that 67% of the three algorithms have the unity 1, and the unity rate of the three algorithms was greater than 0.998 under different K values. It is proved that this classification algorithm is feasible and has good prediction accuracy.","['Engineering', 'Automotive Engineering', 'Engineering Fluid Dynamics', 'Energy Storage']"
doi:10.1007/978-981-19-2635-8_70,en,Deep Multi Agent Reinforcement Learning Based Decentralized Swarm UAV Control Framework for Persistent Surveillance,OriginalPaper,"In recent years, enhancing intelligence in the development of Unmanned Aerial Vehicles (UAVs) with a decrease in cost for the application of swarm fleets has attracted a variety of interest. Specifically, for urban applications such as public transportation, logistics mobilization, rescue operations, etc., there is a need for a fleet of UAVs to plan and coordinate intelligently without human intervention. A multi-agent reinforcement learning framework that can learn and make policies for such systems is desperately needed. This paper proposes an AI-based Bio-inspired Decentralized Multi-Agent Reinforcement Learning (B-DMARL) framework as a multi-agent actor-critic model for executing an assigned job in an increasingly dynamic environment. The B-DMARL is a distributed control architecture with two levels. For group coordination and collision avoidance, low-level control is developed using an AI-based bio-inspired steering behavior algorithm. Using a Proximal Policy Optimization (PPO) based reinforcement learning method, the agent is trained as a high-level control to correctly execute tasks in more dynamic environments. In a virtual simulation environment, the proposed B-DMARL framework is applied to persistent surveillance tasks that require the cooperation and collaboration of UAVs. Simulation results demonstrate that the proposed methods have an improved learning rate and reward signal.","['Engineering', 'Aerospace Technology and Astronautics', 'Engine Technology', 'Automotive Engineering', 'Mechanical Engineering']"
doi:10.1007/978-981-19-3266-3_50,en,Bearing Fault Identification of Augmented Grayscaled Textured Images Using K-Nearest Neighbor,OriginalPaper,"Bearings are the most commonly used components in rotating machinery, and hence, bearing faults may result in significant breakdowns and even casualties. For this, fault diagnosis is usually done with the help of vibration signals. The current paper uses a publicly available dataset from Case Western Reserve University. The two-dimensional grayscaled textured image is extracted from the vibration signals. Solving the problem of an imbalanced dataset is done by applying geometrical augmentation techniques on these images. A set of statistical features are calculated to form a feature vector. This feature vector is then fed to various machine learning algorithms like decision tree, K-nearest neighbor, support vector machine and ensemble bagged tree to get the classification results.","['Engineering', 'Industrial and Production Engineering', 'Engineering Design', 'Industrial Chemistry/Chemical Engineering']"
doi:10.1007/978-3-031-20141-7_51,en,Technological Equipment and Automation Control of the Three-Dimensional Structures Laser Welding Process in Different Spatial Positions,OriginalPaper,"The problem of automation of the welding process of steel and alloy complex profiles is present in many industries. In this study, the problem of automation of the laser welding process control when welding complex three-dimensional structures in different spatial position was studied. In the first part of the investigation, a centralized hardware-software complex was developed to ensure that the laser welding in different spatial positions is carried out properly. The developed hardware-software complex has the ability to be operated in both manual and automatic modes for the ease of practical preparation of the experiment. In the second part of the study, a set of technological equipment in the form of a laboratory stand was developed. The developed laboratory stand is designed for experimental research of technological features of laser welding of steels and alloys in different spatial positions. In testing, the hardware-software complex, coupled to the laboratory stand have procured control joints, adherent to current quality standards. As a result of this study, the testing of the hypothesis, according to which, the conditions of laser welding in different spatial positions are associated with a stable balance between the forces acting on the free surface of the liquid metal of the melt bath, became possible.","['Engineering', 'Computational Intelligence', 'Transportation Technology and Traffic Engineering', 'Manufacturing, Machines, Tools, Processes']"
doi:10.1007/978-3-031-05491-4_26,en,Study of Contribution Verifiability for Privacy-preserving Federated Learning,OriginalPaper,"Base on the computing device revolution and big data, deep learning has been widely applied to solve any problem. However, originally neural network is not applicable to decentralized collaborative systems when data owners do not like to expose their own data. Nowadays, federated learning, which can train models decentralized, has brought attention since it only releases gradients. Nevertheless, to solve the problem that the shared gradient still retains some sensitive information of real data, privacy-preserving federated learning (PPFL) can aggregate the gradients submitted from collaborators without exposing any knowledge of these gradients. However, in the procedure of PPFL, some gradients may be dropped intentionally or unintentionally, such that collaborators cannot contribute effective gradients. In addition, checking for model tampering has become impossible in PPFL. This paper provides contribution verification that allows users to confirm that their own gradients are aggregated to the global model in PPFL. The proposed method is compatible with any gradient-descent-based federated learning.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Engineering', 'Big Data', 'Mathematical and Computational Engineering']"
doi:10.1007/978-3-030-99112-8_28,en,Comparison and Evaluation of Models for Predicting Immunogenicity of Viral Antigens of the pMHC Complex from Murine Models,OriginalPaper,"Due to the growing importance of immunotherapy, especially in the treatment of cancer or designing personalized vaccines, there is a need to understand the mechanisms of the adaptive immune response. Based on the available data on the immunogenic response of T cells (CD8 +) to viral peptides presented on the molecules of the major histocompatibility complex (MHC) class I, models of predicting immunogenicity were developed using methods such as: Decision Tree, Support Vector Machine and Extreme Gradient Boosting. Models were compared and validated to choose the best method of predicting immunogenicity.","['Engineering', 'Biomedical Engineering and Bioengineering', 'Computational Intelligence']"
doi:10.1007/978-981-19-2535-1_41,en,Comparative Analysis of Machine Learning-Based Approaches for Astrological Prediction of Profession,OriginalPaper,"Astrology is an ancient concept. Each person’s astrological chart is unique and independent, which can be influenced by different factors. In the current world, there are no standard rules or guidelines for astrological prediction. Many applications can be used to predict and analyze data, thanks to advances in artificial intelligence. These applications make use of computers to analyze unknown, large, noisy, and complex data sets and to predict and classify them. This paper aims to establish universal rules and validate astrology by using various scientific methods. This research uses the positions of stars and planets at birth to determine the profession of a person. Logistic Regression, Naive Bayes Algorithm, and Catboost Algorithm use this information to predict a person’s profession. The learning classification dataset consisted of 6248 records covering 14 different professions.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-3-031-18326-3_10,en,Classification and Detection of Malicious Attacks in Industrial IoT Devices via Machine Learning,OriginalPaper,"The term “the Industrial Internet of Things” has become increasingly more pervasive in the context of manufacturing as digitization has become a business priority for many manufacturers. IIoT refers to a network of interconnected industrial devices, resulting in systems that can monitor, collect, exchange, analyze, and deliver valuable data and new insights. These insights can then help drive smarter, and faster business decisions for manufacturers. However, these benefits have come at the cost of creating a new attack vector for the malicious agents that aim at stealing manufacturing trade secrets, blueprints, or designs. As a result, cybersecurity concerns have become more relevant across the field of manufacturing. One of the main tracks of research in this field deals with developing effective cyber-security mechanisms and frameworks that can identify, classify, and detect malicious attacks in industrial IoT devices. In this paper, we have developed and implemented a classification and detection framework for addressing cyber-security concerns in industrial IoT which takes advantage of various machine learning algorithms. The results prove the satisfactory performance and robustness of the approach in classifying and detecting the attacks.","['Engineering', 'Robotics and Automation', 'Industrial Chemistry/Chemical Engineering', 'Computer-Aided Engineering (CAD, CAE) and Design']"
doi:10.1007/978-981-19-1844-5_19,en,Spam Message Filtering Based on Machine Learning Algorithms and BERT,OriginalPaper,"The constant traffic of messages keeps increasing whether be it email or SMS. This leads to a direct increase of attacks from spammers. Mobile spams are particularly threatening as spam messages are often disguised as messages from banks, which cause immense harm. Due to this, having a method to identify if the messages are spam or not becomes pivotal. Several techniques exist where deep learning tasks show higher accuracy compared to classic machine learning tasks. Hence, this paper compares the BERT with traditional machine learning techniques which are used in this paper are logistic regression, multinomial Naive Bayes, SVM, and random forest. This paper uses an open-source dataset from Kaggle of labelled spam and not spam messages. It has a total of 5585 messages of which 4825 are labelled as spam and 760 as spam. This paper uses various machine learning algorithms and an algorithm with BERT. In comparison with the other machine learning techniques, it was discovered that the BERT algorithm delivered the highest testing accuracy of 98%. BERT has an encoding layer which generates encodings such that they are not biased and are then fine-tuned for spam detection. With this attribute, the algorithm obtains a higher accuracy.","['Engineering', 'Communications Engineering, Networks', 'Mobile and Network Security', 'Artificial Intelligence', 'Big Data']"
doi:10.1007/978-981-19-0095-2_39,en,Sentiment Analysis: Twitter Tweets Classification Using Machine Learning Approaches,OriginalPaper,"Analyzing public data from social media could give fascinating results and insights into the realm of public opinion on almost any product, service, or person. Sentiment analysis is a method for analyzing and interpreting Twitter data in order to determine public opinion. Creating sentiment analysis software is a method for measuring Twitter tweet perceptions programmatically. Results classify user’s perspective via tweets into positive and negative, which is represented in result, may include polarity of the tweets. In this paper, we evaluate various machine learning algorithms performance to determine suitable algorithm for twitter datasets classification.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Systems and Data Security', 'Artificial Intelligence', 'Computational Intelligence']"
doi:10.1007/978-981-19-4815-2_7,en,Summarization and Future Work,OriginalPaper,"NFV enables to replace dedicated hardware implementations with software instances and it provides more possibilities for large cost savings, high flexibility and scalability, short deployment cycles, etc. These advantages of NFV makes it very promising to become network provisioning service paradigm in the next generation. This book focuses on a dedicated but important aspect of NFV, that is, resource allocation problem in NFV. More specifically, we first summarize and generalize four fundamental resource allocation problems in NFV, namely (1) the VNF Placement and Traffic Routing (VPTR) problem, (2) the VNF Placement (VNFP) problem, (3) the TRaffic Routing (TRR) problem, and (4) the VNF Redeployment and Consolidation (VRC) problem.","['Engineering', 'Communications Engineering, Networks', 'Graph Theory', 'Operations Research, Management Science', 'Theory of Computation', 'Algorithm Analysis and Problem Complexity']"
doi:10.1007/978-981-19-0108-9_45,en,An Analytical Approach of Crime Prediction Using Machine Learning,OriginalPaper,"Crime is considered regarded as our society’s maximum critical and serious and growing problem, and stopping it would be an essential duty. On a daily basis, a great number of crimes are perpetrated. This necessitates maintaining note of all crimes and retaining a database for them to be referenced in the destiny. The gift issue is maintaining a dependable crime dataset and analyzing these statistics to aid inside the prediction and backbone of destiny crimes. The goal of this task is to observe a collection including a selection of crimes and forecast the type of crime that could arise within the future based on a diffusion of factors. The science of creating computer systems that make judgments without human intervention is called device getting to know. Machine gaining knowledge has currently been used within the improvement of self-driving vehicles, speech identity, web website seek, and a higher understanding of the human genome. It has also made it feasible to perceive crime using referenced data. This research appears into crime prediction the use of gadget studying. This look examines crime data from India over the last 15 years using critical information-processing methodologies. When predicting crime in India, gadget-mastering predictive models including K-nearest-neighbor and boosted choice tree are used, and crime prediction accuracy levels from thirty-nine % to forty-four%.","['Engineering', 'Manufacturing, Machines, Tools, Processes', 'Renewable and Green Energy', 'Materials Science, general', 'Nanotechnology']"
doi:10.1007/978-981-19-1610-6_6,en,Peak Shaving in Microgrids Using Hybrid Storage,OriginalPaper,"In this contribution, we focus on technical and economic aspects of using hybrid storage in microgrids for peak shaving. We perform feasibility analysis of hybrid storage consisting of conventional supercapacitors and chemical batteries. We use multiple real-life consumption profiles from various industry-oriented microgrids. The primary purpose is to construct digital twin model for reserved capacity simulation and prediction. The main objective is to find the equilibrium between technical innovations, acquisition costs, and energy cost savings.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4162-7_29,en,AI-Based Mental Fatigue Recognition and Responsive Recommendation System,OriginalPaper,"Complete comfort is considered the definite one among all the foremost concerns in the present scenario. The organization has been proceeding with more contemplation in upgrading their work comfort. The workers also proceed with many perspectives to enhance their ongoing comfort status. However, comfort is generally related to their everyday activity and conduct, mainly in the worksites where it influences both the levels of stress and mood, resulting in mental fatigue. Specifically, the characteristic of the person’s comfort will be affected by the conduct in a worksite. We suggested a mental fatigue identification system that embraced deep learning techniques for supplying non-intrusive observing systems. The comfort level has been classified based on surveys: pressure and mood. This preparatory study instructs the model to generalized and personalized models of classifications. The model as personalized perspective has been taken as one of the steps to supply a personalized health resolution support system that helps in elevating the awareness in customers and motivates them to upgrade their conduct and eventually put up to the best comfort system. We have attained an accuracy of 87% on the model generic and 94% on the model personalized.","['Engineering', 'Computational Intelligence', 'Data Mining and Knowledge Discovery', 'Systems and Data Security', 'Mobile and Network Security', 'Information Systems Applications (incl. Internet)']"
doi:10.1007/978-981-19-2126-1_35,en,Simplified TOPSIS for MLN-MODM Problems,OriginalPaper,"Multilevel nonlinear multiobjective decision-making problems (MLN-MODM) are a class of complex hierarchical multilevel programming problem with several nonlinear antithetical objectives. The present paper addresses new simplified TOPSIS approach for the solution of generalized multilevel nonlinear multiobjective decision-making problems (MLN-MODM) incorporating major modifications in the interactive TOPSIS approach given by Baky (Appl Math Model 38:1417–1433, 2014) for MLN-MODM problems. In this work, we propose a simplified formulation model for membership functions of distance functions and for membership functions of decision variables. This avoids decision deadlock situations and repeated rejection of the solution in decision-making process for MLN-MODM problems due to the solution preference by the decision-makers. Finally, the same numerical example as taken by Baky (Appl Math Model 38:1417–1433, 2014) is illustrated with proposed simplified technique to show applicability of proposed method and similarity of results of both the approaches. Further, algorithmic comparison between suggested simplified TOPSIS approach and interactive TOPSIS approach by Baky (Appl Math Model 38:1417–1433, 2014) is also carried out to prove the simplicity of new simplified approach. The proposed simplified approach is presented as a simpler, efficient and less calculative than the earlier TOPSIS method in context of finding satisfactory solution of the problem.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Machine Learning', 'Big Data', 'Computer Systems Organization and Communication Networks']"
doi:10.1007/978-981-19-5347-7_29,en,The Influence of Machine Learning in Additive Manufacturing,OriginalPaper,Additive manufacturing gives possibilities to fabricate complex parts up to its near final net shape through layer-by-layer deposition on top. The process involves proper understanding of the underpinning physics involved in the selection of processing parameters as well as materials used. It elucidates the implementation of artificial intelligence technique in additive manufacturing concepts. Machine learning is one among the artificial intelligence technique and can be synchronized with additive manufacturing to have a control over automatic decision-making processes. The manufacturing of constituent structures can be defect-free as machine learning algorithms have a greater influence in optimizing the additive manufacturing process parameters as well as control over defect monitoring system. The present article mainly discusses about such perspective of machine learning in the additive manufacturing concept. The findings from various researchers are used to illustrate some interesting features of machine learning synchronized additive manufacturing.,"['Materials Science', 'Structural Materials']"
doi:10.1007/978-981-19-3490-2_6,en,SOH Estimation,OriginalPaper,"The battery energy and power capacities will decrease with ageing. The ageing indicator, state of health (SOH), is of great significance to the battery safety, the EV’s performance and the user’s driving experience. Once the SOH drops below a threshold value, the battery needs to retired from EV to prevent safety hazards.","['Engineering', 'Automotive Engineering', 'Transportation Technology and Traffic Engineering', 'Energy Systems', 'Energy Materials']"
doi:10.1007/978-981-19-2821-5_15,en,A Review on Community Detection Using Deep Neural Networks with Enhanced Learning,OriginalPaper,"Community detection has become pervasive in understanding complex network structures and detecting similar patterns. The main motivation behind using deep learning methods for community detection comes from the brilliant performance results shown by deep neural networks in various fields. Using unsupervised learning models, the problem of community detection can be solved. The high-dimensional feature space representation of the network data leads to a complex neural network architecture that requires a high number of trainable parameters. Deep learning-based models can transform the high-dimensional graph data of complex networks into simple, low-dimensional space or latent representation. The transformation of network representation to latent representation consists of meaningful features of the network data. This mapping preserves the structural information of the network later on, which clustering algorithms can be applied to the converted latent representation. This survey paper provides an overview of the traditional and deep learning-based methods of community detection, followed by a discussion on the challenges and future directions of community detection.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2188-9_45,en,Implementation of Robotics and Autonomous Systems in Agriculture,OriginalPaper,"Robotics and Autonomous systems are not only useful in the industry, but they are also equally useful for agriculture. It improves working condition across the agriculture domain and helps farmers and labourers to work in a field with ease at higher efficiency. In this paper, the implementation of technology systems toward sustained and better yielding agriculture is discussed. Robotics and autonomous systems change the way of doing the agriculture and help in going toward sustainable farming. With the help of these technology, sustainable farming results in increasing productivity with less dependency on human resources. This paper also critically examines the autonomous system architecture and its implementation in the agriculture. Robots are the next generation bulls of the farm, and early adaptation of automation will result in assured and better yields from the fields.","['Engineering', 'Industrial and Production Engineering', 'Mechatronics', 'Engineering Thermodynamics, Heat and Mass Transfer', 'Energy Storage', 'Materials Engineering']"
doi:10.1007/978-3-031-15191-0_23,en,Explainable Machine Learning Model for Performance Prediction MAC Layer in WSNs,OriginalPaper,"Wireless Sensor Networks (WSNs) are used to gather data in a variety of sectors, including smart factories, smart buildings, and so on, to monitor surroundings. Different medium access control (MAC) protocols are accessible to sensor nodes for wireless communications in such contexts, and they are critical to improving network performance. The proposed MAC layer protocols for WSNs are all geared on achieving high packet reception rates. The MAC protocol is adopted and utilized throughout the lifespan of the network, even if its performance degrades over time. Based on the packet reception rate, we use supervised machine learning approaches to forecast the performance of the CSMA/CA MAC protocol in this study. Our method consists of three steps: data gathering trials, offline modeling, and performance assessment. According to our findings, the XGBoost (eXtreme Gradient Boosting) prediction model is the most effective supervised machine learning approach for improving network performance at the MAC layer. In addition, we explain predictions using the SHAP (SHapley Additive exPlanations) approach.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Mobile and Network Security']"
doi:10.1007/978-981-19-1607-6_13,en,Transfer Learning in Deep Reinforcement Learning,OriginalPaper,"Reinforcement learning has quickly risen in popularity because of its simple, intuitive nature, and its powerful results. In this paper, we study a number of reinforcement learning algorithms, ranging from asynchronous q-learning to deep reinforcement learning. We focus on the improvements they provide over standard reinforcement learning algorithms, as well as the impact of initial starting conditions on the performance of a reinforcement learning agent.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-11847-0_4,en,Numerical Quadrature with Deep Learning,OriginalPaper,"It is well known that the element stiffness matrix of a distorted element calculated using numerical quadrature has a relatively large error. In this chapter, a method to improve the efficiency of the element integration without degrading accuracy is studied by employing deep learning.","['Engineering', 'Mechanical Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-18326-3_22,en,Cost-Minimal Selection of Material Supply Strategies in Matrix Production Systems,OriginalPaper,"Companies are facing changing market demands, high variance, and volatile quantities. Resilient production systems are needed to meet these challenges. The matrix production is such a system. It offers degrees of freedom in terms of operation sequence flexibility and work distribution flexibility through redundantly used resources. For the material supply this is a challenge in planning. The material must be supplied in a cost-efficient manner and without shortages. To increase planning quality, a method for selecting the least expensive material supply strategy is developed. Depending on consumption, constraints of space, and supply framework conditions, different strategies are advantageous for each material. The developed method requires three steps. First, required data for step 2 and step 3 is collected. In step 2, standardized process blocks combine to describe a company-specific material supply strategy. The approach is company-independent and added by cost functions to the process blocks. Through the cost functions applied to the process blocks the costs of a supply strategy is achieved. As material can be supplied in alternative ways, multiple expected costs for supplying arise. As only one supply strategy needs to be selected, step 3 is necessary. It uses the branch-and-cut algorithm on the mathematical description of the logistic selection problem to find the cost-minimal configuration of supply strategies. As the problem is in the context of matrix production, several conditions and requirements need to be included in the selection process. The result is the assignment of a material supply strategy to each material while minimizing the costs.","['Engineering', 'Robotics and Automation', 'Industrial Chemistry/Chemical Engineering', 'Computer-Aided Engineering (CAD, CAE) and Design']"
doi:10.1007/978-981-19-5331-6_61,en,Specific Wavelet Family Selection for Wavelet Domain-Based Super-Resolution Application,OriginalPaper,"The prime need of image quality for accurate analysis with precise decisions is the key attraction for researchers in image processing field. The increasing need is due to degradation of image signals whilst capturing, transmission, compression, etc. The accuracy in super-resolution process for quality improvement of images or videos is achieved at the cost of time and complexity. This limitation is motivation for researcher to contribute themselves in the same field by developing conventional algorithms and methods specially categorised in spatial and frequency domain. In the recent decades, wavelet domain processing has remarkable results in super-resolution field. The results of wavelet domain processing are depending upon wavelet functions or families considered whilst analysis, as these families possess unique properties which gives different results according to application area. Unfortunately, there is no such theory or analysis available which shows specific wavelet family selection for particular super-resolution process. The author has tried to explore the concept behind selection of appropriate wavelet function with analysis on different video frames containing variety of scenes. The process is simple, i.e. decomposition and reconstruction of video frames using different wavelet families and comparative analysis of original and reconstructed image/frames with different quality measurement metrices. The exact reconstruction shows lossless wavelet domain process. The winner wavelet function is Haar which is simplest amongst all wavelets, despite the literature provided in wavelet processing preferred db2/db7/9 families. The assessment provided is beneficial for beginners to select appropriate wavelet function in super-resolution application.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-11051-1_51,en,Interval Estimation of Magnetotelluric Response Function and Quality Control During Registration of Data,OriginalPaper,"In this paper, we consider algorithms for calculating impedance in the magnetotelluric sounding method. Most of the existing algorithms are based on the least-squares method, supplementing it with various robust approaches. Usage of them mutually with a remote reference can reduce the effect of noise and interference in the signals on the final result. The problem is that the confidence intervals of the estimates of impedance have a blurry essence since it is impossible to completely guarantee that the signals are free of interference that introduces bias in the estimates. Confidence intervals are in some cases ignored by geophysicists during further data processing. We propose to move away from traditional probabilistic statistics and use interval analysis methods. In addition, we propose to evaluate the adequacy of the obtained intervals, using physical limitations, which must necessarily obey the impedance and apparent resistance. In the process of accumulating a sufficient amount of data, there is a tendency to increase the compliance of calculated estimates with physical limitations. This fact can be used to roughly control the information content of the recorded signals and the quality of the data. To demonstrate the propositions, we present a number of numerical tests using natural magnetotelluric data.","['Engineering', 'Control and Systems Theory', 'Control, Robotics, Mechatronics', 'Communications Engineering, Networks']"
doi:10.1007/978-3-031-16075-2_46,en,Tantrum-Track: Context and Ontological Representation Model for Recommendation and Tracking Services for People with Autism,OriginalPaper,"The prevalence of autism spectrum disorder (ASD) has recently risen; people are frequently confronted with patients who have been diagnosed with autism spectrum disorder, which is a lifelong neurodevelopmental condition that affects many areas of behavior and cognition. It is frequently difficult for family members, providers, around an ASD patient to interact and communicate with them, necessitating professional assistance. A problem has arisen regarding the lack of automated systems designed especially for people with ASD as well as a lack of experience for neuro-typical people and engaging with these individuals. Existing solutions are restricted, rarely address ASD communities, and use cases. Therefore, we propose and validate an intelligent system called Tantrum-Track to assist in maintaining contact and improving communication with people with ASD and facilitating their integration into their environments and society. This approach can monitor desired outcomes and help in the decision-making process e.g. the system makes a decision about how to handle a certain scenario. For that purpose, we fully detail a comprehensive recommendation system to support people with ASD and support their communication with those in their environment (design phase). This recommendation system model makes two contributions: (1) modelling the autistic person’s context, and (2) representing this context as an ontological knowledge organization system. After assessing the (dis)similarities between two gathered settings, we incorporate these data into our recommendation system. This system suggests actions that are likely to help and calm the autistic person and control a situation before it escalates, and/or prevent a potential tantrum from occurring.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3035-5_31,en,Various Diseases’ Prediction Based on Symptom by Using Machine Learning,OriginalPaper,"An overwhelming number of disease surveys capture patient records of the severity of their illness indications that enable differentiation of patient ailment from typical indication. This paper aims to forecast illnesses in users based on their symptoms. To achieve our aim, we use the XGBoost Classifier, which aids in regulating the victim’s health condition then acquiring the symptoms to predict the condition. The data carries 250 variables and 140 corporal evaluation instances (diseases). In addition, we provide medicine for illness and gather the corresponding victim EH to summarize the diagnostic described by the NLTK.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Statistics, general']"
doi:10.1007/978-981-19-6004-8_15,en,Applied Deep Learning for Safety in Construction Industry,OriginalPaper,"The construction industry in India is the second-largest employer and contributor, but it accounts for 24.2% of occupational deaths. On average, 38 people die in accidents every day. Making it a matter of concern, this paper explains Convolutional Neural Networks, a deep learning approach used for detecting workers on-site and recognizing the safety equipment worn by handling images and videos with a dataset size of approximately 2000 annotated images tailored into over approximately 9000 classified images. Which will be utilized to categorize and recognize workers in the construction industry wearing their relevant safety equipment. In addition to providing a comparison of the output, with the accuracy gained after applying a pre-trained model (i.e. VGG16) to perform classification and model prediction improvisation, along with the classification of the workers who are wearing their equipment this paper also supports future scalability to represent it in an analytical format. In the first approach, the model implements the CNN model and, in the second approach, implements the VGG16 model, eventually comparing the accuracy of the result for further using the best model to deploy on real-time videos/images. Therefore, the Safety Manager will find it more convenient to manage and instruct workers on the site.","['Engineering', 'Computational Intelligence', 'Cognitive Psychology', 'Personality and Social Psychology', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-08693-9_7,en,OFDM,OriginalPaper,"Wideband channels are necessary for high throughput radios, but they are also usually very frequency selective. Equalization of wideband channels can become very complicated very quickly. OFDM is an efficient way to break down wideband equalization into multiple parallel flat equalizations. The scaling of the complexity of OFDM is excellent due to the logarithmic complexity of FFT as an implementation of the discrete Fourier transform. In this chapter, we consider how OFDM is implemented in 802.11n and the options it opens up for communication as well as the mathematical foundations upon which it relies.","['Engineering', 'Circuits and Systems', 'Microwaves, RF and Optical Engineering']"
doi:10.1007/978-981-19-2600-6_13,en,Support Vector Machines and Random Forest Classification Models for Identification of Stability in Extrusion Film Casting Process,OriginalPaper,Extrusion film casting (EFC) is a very important industrial process employed for producing large amounts of thin films for multiple uses. It is important to identify input process parameters for maintaining stable and continuous trouble-free operation. A priori modelling and solution of governing phenomenological equations to achieve this requires tedious computational efforts. As an alternative in this work we have employed Machine learning to build data driven EFC classification models to predict stability of any given set of operating conditions. We have used accurate input data for certain combinations of parameters along with their respective output classes to build robust classification models. We used Support Vector Machines (SVM) and Random Forest classifiers for this purpose. We created four different data sets with different process parameter combinations and number of relaxation modes. We also used the Synthetic Minority Oversampling Technique (SMOTE) to handle data imbalance. Our simulation results indicate that prediction of stability/instability classes for different process parameters can be achieved with high degree of confidence with robust machine learning models.,"['Engineering', 'Data Engineering', 'Statistics, general', 'Machine Learning', 'Artificial Intelligence', 'Data Storage Representation', 'Data Structures and Information Theory']"
doi:10.1007/978-3-031-18344-7_28,en,Identifying Severity Clusters in SLE Patients,OriginalPaper,"Machine learning (ML) has a successful impact in healthcare data mining. We use unsupervised ML methods to extract features and identify subgroups of Systemic Lupus Erythematosus (SLE) patients related to the disease severity. We analyze the similarity between SLE patients within these clusters. Finally, we evaluate the clustering results, using two types of cluster validation, internal cluster validation, and external cluster validation. The clustering analysis results show two separate patients clusters which are mild and severe subgroups. Patients in the severe subgroup have a higher prevalence of the renal disorder, hemolytic anemia, anti-dsDNA anti- body, and low complements (C3, C4). The severe subgroup of patients suffer from malar rash and proteinuria with higher use of cyclophosphamide, mycophenolate mofetil, and azathioprine. The second cluster is mild disease activity, and it is associated with joint pain, low complements (C3, C4), and a positive anti-dsDNA antibody.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4193-1_23,en,Early Parkinson Disease Detection Using Audio Signal Processing,OriginalPaper,"Parkinson disease is a long terms degenerative disorder and it has been found in the studies that a person diagnosed with PD suffers several speech impairments and this problem in patients can be used to differentiate them from a healthy person. In this paper different machine learning algorithms have been used such as, Random Forest Classifier, Xgb Classifier, Naive-Bayes, K-NN, Decision Tree Classifier. The data set used in this paper was divided in the ratio of 70:30, 70 for training dataset and 30 for testing dataset and then hyperparameter tuning was done to select the best of the hyperparameters to be used for the models and to get good accuracies from implemented algorithms and for the evaluation of model accuracies and f1-score has been used to evaluate the models. The XgbClassifier gave the best accuracy of 96.61% and f-1 score of 98.00.","['Engineering', 'Computational Intelligence', 'Information Storage and Retrieval', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Data Structures and Information Theory', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5090-2_3,en,SVM-based Pre- and Post-treatment Cancer Segmentation from Lung and Abdominal CT Images via Neighborhood-Influenced Features,OriginalPaper,"Chakraborty, Tiyasa Bhadra, Ashok Kumar Nandi, Debashis In real medical applications, proper measurement of cancer disease area is very important, particularly so, if we want to compare the disease region between pre-treatment and post-treatment CT images for the same patient. The segmentation of a specific region can be defined as the grouping of image pixels corresponding to specific features. Several supervised approaches are there to solve the region segmentation problem. In our problem, we want to find the cancer area from the pre-treatment and post-treatment CT images which are in the state of raw medical data. In this study, we are using the SVM to measure the cancer area from the raw images where new features are taken into the study including neighboring pixels’ influence. Finally, our proposed approach is compared with the state-of-the-art methods which subsequently proves that our method performs more efficiently than other concerned procedures.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Artificial Intelligence', 'Data Structures and Information Theory']"
doi:10.1007/978-981-19-3632-6_50,en,Technology of Radial Fluid Enhanced Diffusion Based on Machine Learning,OriginalPaper,"In the 1990s, it became easier for people to obtain digital information and to spread the information through the Internet. Against this background, machine learning has begun to develop vigorously, focusing more on solving practical problems. The phenomenon of radial fluid enhanced diffusion has always been the focus of attention in the field of fluid mechanics. However, due to the limitations of various actual physical conditions, convection dominates the radial fluid enhanced diffusion problem. The classic solution method will cause serious non-physical oscillations when solving the problem, and no more accurate numerical results can be obtained. Based on this, this paper proposes a radial fluid-enhanced diffusion technology based on machine learning. The logarithmic increment method is proposed to improve the non-parametric estimation of the drift coefficient. Experiments show that in the two typical models, the mean value of the logarithmic increment method fluctuates between 0.4–0.6, which is closer to the actual value of 0.495, indicating that the mean value of the logarithmic increment method is closer to the true value and the variance is smaller. The effect is better than that of the direct incremental method.","['Engineering', 'Cyber-physical systems, IoT', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing']"
doi:10.1007/978-981-19-2821-5_35,en,TLDC: Tomato Leaf Disease Classification Using Deep Learning and Image Segmentation,OriginalPaper,"Deep learning (DL) has made significant progress in identifying and classifying plant diseases. The convolutional neural network (CNN) model was utilized to classify diseased and healthy tomato plant leaves for this study. Seven predominant DL models, namely LeNet 5, AlexNet, VGG19, Inception Net V3, ResNet50, DenseNet 121, and Efficient Net B0 have been used for tomato leaves disease classification. Deep feature extraction and fine-tuning strategies were utilized to adapt these DL models to the specific task of classification. The obtained features using deep feature extraction were then classified by fully connected layers of the CNNs. The experiments were carried out using the image data acquired from the Indian Agricultural Research Institute, India. The dataset consists of diseased and healthy tomato leaf images with a total count of 155 images. Data augmentation was used to increase the dataset size. Furthermore, three segmentation algorithms were also applied to remove the background and highlight the deep features. In this study, a comparison of the above-mentioned CNNs has been carried out to show the accuracy results achieved on the collected dataset. The evaluation results show that deep feature extraction with image segmentation techniques produced better results (up to 100% classification accuracy) than without segmentation. The outcome of this research will have a substantial impact on tomato disease prediction and early prevention.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2600-6_6,en,Review on Android Malware Detection System,OriginalPaper,"Modern mobile devices have become important part of day to day life as they offer various tools and services which are very useful. Mobile devices handle lot of sensitive information hence malware writers try to exploit vulnerabilities to gain access. Android is one of the most popular OS for mobile device. The open source nature of Android Operating System has attracted users because of open source nature and large number of users it has become lucrative for malware writers to target android devices. With time there is continuous evolution in variety, volume and sophistication of malwares. Researchers are continuously working to develop better malware detection methods which can deal with sophisticated malwares. This paper presents comprehensive overview of latest malware detection methods. The rapid increase of mobile devices and android operating system has led to security issues with android operating system. Malware writers attracted with the increasing use of smart phones and android OS. Hence there is a need to study existing malware detection system for android OS. This paper gives the detailed review on android malware detection system.","['Engineering', 'Data Engineering', 'Statistics, general', 'Machine Learning', 'Artificial Intelligence', 'Data Storage Representation', 'Data Structures and Information Theory']"
doi:10.1007/978-981-19-0095-2_22,en,Learning-Based Framework for Resource Allocation for Varying Traffic,OriginalPaper,"Network function virtualization (NFV) presents a model to remove physical middle-boxes and replace them with virtual network functions (VNFs) that are more resilient. Adjusting resource allocation in response to the varying demands of traffic, there is a need for instantiating the VNFs and also balancing the resource allocation based on demand. Current optimization methods frequently expect the amount of resources required by every VNFs instance is fixed, resulting in either resource wastage or poor quality of service. To resolve this issue, machine learning (ML) models are used on real-time data of VNF, which contains performance indicators and requirement of resources. Evaluating the result, using ML models along with the VNF placement algorithms shows the reduced amount of resource consumption, thereby improving the quality of service and reducing the delay.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Systems and Data Security', 'Artificial Intelligence', 'Computational Intelligence']"
doi:10.1007/978-3-031-15030-2_6,en,Offensive Machine Learning Methods and the Cyber Kill Chain,OriginalPaper,"Cyberattacks are the “new normal” in the hyper-connected and all-digitized modern world, as breaches, denial-of-service, ransomware, and a myriad of other attacks occur every single day. As the attacks and breaches increase in complexity, diversity, and frequency, cybersecurity actors (both ethical and cybercrime) turn to automating these attacks in various ways and for a variety of reasons, including the development of effective and superior cybersecurity defenses. In this chapter, we address innovations in machine learning, deep learning, and artificial intelligence within the offensive cybersecurity fields. We structure this chapter inline with the Lockheed Martin’s Cyber Kill Chain taxonomy in order to cover adequate grounds on this broad topic, and occasionally refer to the more granular MITRE ATT&CK taxonomy whenever relevant.","['Computer Science', 'Artificial Intelligence', 'Privacy', 'Cryptology', 'Mobile and Network Security']"
doi:10.1007/978-981-19-5438-2_18,en,"Extended 
            
              
            
            $$H_{-}/H_\infty $$
            
              
                
                  H
                  -
                
                /
                
                  H
                  ∞
                
              
            
          -Optimal Fault Detection for a Class of Nonlinear Systems",OriginalPaper,"The objective of this chapter is to extend $$H_{-}/H_\infty $$ H - / H ∞ -optimal FD approach to a class of discrete-time nonlinear systems subject to unknown inputs. To this end, an extended $$H_{-}/H_\infty $$ H - / H ∞ optimization problem is formulated to the design of an FDF-based residual generator and a solution is derived by recursive computation that is feasible both for the case with stochastic disturbances and $$l_{2, [0,N]}$$ l 2 , [ 0 , N ] -norm bounded unknown input. It is further shown that the local optimal solution is not unique and, for an arbitrary feasible filter gain matrix, a dynamic post-filter is also presented.","['Engineering', 'Control and Systems Theory', 'Mathematical and Computational Engineering', 'Systems Theory, Control']"
doi:10.1007/978-3-031-19620-1_31,en,Reconstruction of 3D Semantic Map and Its Quality Estimation,OriginalPaper,"Algorithms for reconstruction of three-dimensional semantic maps are an important element of on-board vehicle computer vision systems. Such maps can be used in simulation environments and to generate the so-called HD maps needed for path planning and vehicle navigation. The paper presents an analysis of modern methods for semantic map reconstruction based on sequences of 3D point clouds, including noisy ones. The Kimera Semantics method, modified approaches VDB Fusion, Puma and ALeGO-LOAM with Interactive SLAM are compared. We have developed a novel approach for quantitatively estimation the quality of 3D maps and successfully applied it using the open dataset SemanticKITTI. It allows us to take into account the features of generated 3D map mesh and semantic labels in order to obtain a more informative metric.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-18311-9_5,en,Analysis and Improvement of Two Low-Cost Air Quality Sensor Measurements’ Uncertainty,OriginalPaper,"Measurements resulting from the operation of two different low-cost air quality monitoring devices (LCAQMD) are used as a basis for a data analytics and modelling procedure towards the improvement of the uncertainty of sensor readings. Α data processing method for missing value and outliers handling, followed by the implementation of computational intelligence-oriented algorithms aimed to the PM 10 modelling. Descriptive statistics and correlation coefficients are used for a primary evaluation of data analytics results, while modelling outcomes are compared with the aid of the relative expanded uncertainty, as well as via the model performance evaluation metrics, to determine the most efficient model. Results suggest that the advanced artificial neural network oriented computational intelligence algorithms, may lead to significant improvement of the performance of the two LCAQMD, this being applicable for a certain concentration range (18–65 μg/m 3 ), indicating that additional future work and more advanced computational techniques are required for further improvement of their performance.","['Business and Management', 'IT in Business', 'Environmental Management', 'Geotechnical Engineering & Applied Earth Sciences', 'Energy Policy, Economics and Management', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2600-6_28,en,Literature Survey: Indoor Navigation Using Augmented Reality,OriginalPaper,"Location-based services are an important aspect of living, as these not only provide time benefits but also save a lot of energy. With the increase in complex building structures, people of different ages may find it difficult to navigate within such structures. When we say different age groups, it includes the age groups from little ones who don’t understand directions to the older ones who are in an urge to find places early due to getting drained out easily. Indoor navigation is not only an asset to sighted people but for the impaired ones too. Indoor navigation when integrated with voice assistants allows the impaired people to navigate hassle-free. For this, an Indoor navigation system is required which localizes the user, takes the account of their current location, and then corresponding to the destination point, guides the user through the path. The literature survey takes into account the different localization approaches considered by different researchers in indoor localization and the necessary positioning algorithms to reach the destination for the paths. This paper also reviews the plus points and limitations of the research work that has been done in Localization and Pathfinding algorithms.","['Engineering', 'Data Engineering', 'Statistics, general', 'Machine Learning', 'Artificial Intelligence', 'Data Storage Representation', 'Data Structures and Information Theory']"
doi:10.1007/978-981-16-8154-7_17,en,A Unified Framework for Joint Moving Object Detection and Tracking in the Sky and Underwater,OriginalPaper,"The ability to detect and locate the moving object in a video is a fundamental procedure in applications of computer vision. However, these tracking methods still face some challenges, and are contradictory among different tasks. In this paper, a unified framework for joint moving object detection and tracking in the sky and underwater is proposed. This framework meets the requirements of two real applications: (i) tracking unmanned aerial vehicle (UAV) in the sky; and (ii) tracking unmanned underwater vehicle (UUV) in water. It consists of three key steps: (i) moving object detection by pixel classification; (ii) data association by blob detection; and (iii) object tracking by efficient convolution operator. Finally, analysis on the accuracy of the proposed framework is provided. Experimental results on real-world datasets and object tracking benchmark (OTB) demonstrate the advantage of the tracking method compared with some state-of-the-art trackers, in terms of accuracy and robustness. In addition, to the best of the authors’ knowledge, there is no previously published work for joint moving target detection and tracking in the sky and underwater.","['Engineering', 'Aerospace Technology and Astronautics', 'Communications Engineering, Networks', 'Space Sciences (including Extraterrestrial Physics, Space Exploration and Astronautics)', 'Control and Systems Theory']"
doi:10.1007/978-981-19-3035-5_18,en,Degraded Factors Analysis in Multimedia Data Using Deep Learning Algorithm,OriginalPaper,"Because artificial illumination is created in an indoor environment, multimedia data is recorded in an optimal atmosphere. On the other hand, in an outdoor setting, it is critical to eliminate the weather influence. Outdoor vision devices are used to capture scenes in surveillance. Due to the enormous size of the drips, the items will get motion blurred in changing weather conditions. Several computer vision techniques that employ feature information, such as object identification, tracking, segmentation, and recognition, will be harmed by these disturbances. Even if only a little portion of the object is obscured, the object cannot be accurately tracked. Rainfall features that pixel image is not entirely surrounded by rain in all data. The dynamic adverse weather model is researched for restoration resolution. Rainfall is a very important part of a bad weather system. Rain-fed energy has a strong local structure and is strongly influenced by backlight. When light passes, it is repeated and visible, shining in the surrounding area. The movement fades, when it falls at a high rate. The vehemence of the rain line is therefore, determined by the light of the descent, the radiation of the backdrop, and the unification time of the camera. Particles of rain and ice are very difficult to analyze. Rain-like spatial and temporal occurrences can be produced by some scene dynamics. In this work, we will look into ambient light estimation for submitted multimedia material using image processing algorithms. With in-depth reading techniques, we improved light measurement and used the histogram measurement method.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Statistics, general']"
doi:10.1007/978-3-031-20141-7_3,en,Relaxed Containment in Circular Packing Problems,OriginalPaper,"One of the most important challenges in modeling structures of materials is development and application of new intelligent technologies. To study mechanical properties, e.g., density, a small cuboidal core of the material is extracted from a large volume for further analyses. Due to the cutting edges, material particles may not belong completely to the core volume. This gives rice to a new class of packing problems where the standard containment conditions (all particles are entirely in the container) are substituted by a relaxed containment (all centers of the particles are in the container). A 2D version of this non-standard problem is presented and formulated as a nonlinear programming problem considering non-overlapping and relaxed containment constraints. A new solution technique is proposed combining a fast algorithm for generating feasible starting points and a local optimization procedure based on nonlinear programming. Computational results are provided and illustrated with several examples.","['Engineering', 'Computational Intelligence', 'Transportation Technology and Traffic Engineering', 'Manufacturing, Machines, Tools, Processes']"
doi:10.1007/978-981-19-4052-1_33,en,Enhancement of Low-Resolution Images Using Deep Convolutional GAN,OriginalPaper,"Neural networks have expanded the scope of machine learning to unlock new opportunities across industrial dimensions. Convolutional GAN is a recent technique which has achieved promising results in the areas of image enhancement and classification. In this paper, deep convolutional GAN (DCGAN) is implemented, and the network is trained on the fashion-MNIST dataset. The implementation of DCGAN is done using leaky ReLU activation functions and sequential modeling. The proposed implementation has resulted in successful data retrieval from grayscale images for relevant apparel categories. The collective PSNR and SSIM results achieved in this work are better when compared with the other contemporary image enhancement techniques available in literature.","['Engineering', 'Computational Intelligence', 'Information Storage and Retrieval', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Data Structures and Information Theory', 'Artificial Intelligence']"
doi:10.1007/978-981-19-0108-9_20,en,Enhancing Data Quality by Detecting and Repairing Inconsistencies in Big Data,OriginalPaper,"In several industries in established countries, a phase of Big Data examination has begun. Big data entails huge amounts of data that are challenging to analyze using standard database and software approaches. When using big data applications, a technological hurdle arises when transferring data across several locations, which is highly expensive and necessitates a huge primary memory for storing data for computation. Big data refers to the transaction and interaction of datasets whose size and complexity transcend the ordinary technical capabilities of gathering, organizing, and processing data in a cloud environment. Expanding data metrics are overflowing into contemporary associations with growing developments in Internet technology. Because of a relentless era of data, data from various devices and channels, such as cellular phones, PCs, government documents, medical reports and web-based media, are increasingly misunderstood. In this article, we explored the anomalies in the banking sector attributable to big data technologies, credit card discrepancies and the manner in which the toolkit is used to assess the incongruity of a specific WAP (Wireless Application Protocol) instrument.","['Engineering', 'Manufacturing, Machines, Tools, Processes', 'Renewable and Green Energy', 'Materials Science, general', 'Nanotechnology']"
doi:10.1007/978-981-19-1610-6_63,en,Fake Review Detection with Concept Drift in the Data: A Survey,OriginalPaper,"Online reviews have a great impact on the e-commerce industry. Online users are free to post their perspective on products, which might not always be unbiased or accurate. Such unbiased reviews from the customers can affect both buyers and sellers in the industry. The details of this paper focus on a fake review detection system. This paper examines different techniques used in fake review detection which involves data pre-processing to pre-process and extract features from raw data, classification to classify review as fake or real. Also, our study deals with drift in data, its detection methods, as well as drift adaptation strategies.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-21203-1_27,en,Task Selection Algorithm for Multi-Agent Pickup and Delivery with Time Synchronization,OriginalPaper,"In this paper, we formulate the material transportation problem as a multi-agent pickup and delivery with time synchronization (MAPD-TS) problem, which is an extension of the well-known multi-agent pickup and delivery (MAPD) problem. In MAPD-TS, we consider the synchronization of the movement of transportation agents with that of external agents, such as trucks arriving and departing from time to time in a warehouse and elevators that transfer materials to and from different floors in a construction site. We then propose methods via which agents autonomously select the tasks for improving overall efficiency by reducing unnecessary waiting times. MAPD is an abstract formation of material transportation tasks, and a number of methods have been proposed only for efficiency and collision-free movement in closed systems. However, as warehouses and construction sites are not isolated closed systems, transportation agents must sometimes synchronize with external agents to achieve real efficiency, and our MAPD-TS is the abstract form of this situation. In our proposed methods for MAPD-TS, agents approximately estimate their arrival time at the carry-in/out port connected with external agents and autonomously select the task to perform next for improved synchronization. Thereafter, we evaluate the performance of our methods by comparing them with the baseline algorithms. We demonstrate that our proposed algorithms reduce the waiting times of both agents and external agents and thus could improve overall efficiency.","['Computer Science', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5403-0_12,en,Biometric Assisted Multi-modal Encryption Key for Secured FHSS Communication,OriginalPaper,"Biometrics is one of the ways for identifying person’s identity based on his/her natural traits and characteristics. Identification is unique with very almost zero probability of error. With the advent of digital era most of the transactions have gone digital ranging from product purchase to investment banking. Concepts like Bitcoin are emerging which have completely transformed the way in which the organizations are investing. Number of techniques and algorithms have been designed to enhance the security aspects of these transactions and algorithms usually employ unique keys for secure transaction. Biometric encryption keys offer one such solution, multi-modal biometric encryption is an advanced multiplexed version of the same. These algorithms are presently finding extensive use in the judicial authorization, economical exchanges, data security, and many other sectors. FHSS technique has a unique way of securing data transmission, the data encoded is transmitted a different frequency hop, with frequency of hops employed known only to sender and receiver. Frequency hops are generated using Pseudo-noise sequence generator with binary logic. Uniqueness of the Pseudo-noise sequence generator determines the security of the data. Algorithm proposed employs unique identity of biometric data for generation of the encryption key, encryption key is employed for generation of unique sequences for FHSS mechanism, the process involves multi-modal fusion of two binary data, PN sequence, and biometric fingerprint data in generation encryption key. Algorithm enhances the security of the transaction multifold as compared to existing solutions, comparison with similar multi-modal algorithms establishes increase in security, further almost a zero averaged correlation is obtained between PN sequence and biometric fingerprint data, which establishes the uniqueness of the sequence generated.","['Engineering', 'Computational Intelligence', 'User Interfaces and Human Computer Interaction', 'Data Structures and Information Theory', 'Artificial Intelligence', 'Data Mining and Knowledge Discovery']"
doi:10.1007/978-981-19-1142-2_30,en,A Comparative Analysis of Edge Detection Using Soft Computing Techniques,OriginalPaper,"Detecting edges is one of the most significant aspects of computer vision. Typical methods for edge detection like Sobel and Canny are robust and fast, but they are sensitive to noise. Soft computing techniques such as particle swarm optimization (PSO), ant colony optimization (ACO), genetic algorithms (GA) and fuzzy logic system (FLS) have extensive application in edge detection of images because of their adaptive behavior. Edge detection is identifying the discontinuities in intensity of the pixel and grouping the contour of edges. The quality of edges in ACO-based edge detection majorly depends on the choice of constants, pheromone evaporation rate, number of iterations etc. In PSO-based edge detection, the quality of images depends on the values of acceleration coefficients and inertia weight. However, thresholding is major stakeholder in determining the fitness of the chromosomes. The population contains 2-D chromosomes. Fuzzy systems are most suitable for designing edge detection hardware. This paper presents a thorough comparative study of soft-computing-based edge detection techniques and highlights their key features. The factors affecting quality of edges are compared, and the actual outcomes of the approaches are systematically arranged for better understanding.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Mobile and Network Security', 'Artificial Intelligence']"
doi:10.1007/978-3-031-13150-9_7,en,Technology Aspects of Artificial Intelligence: Industry 5.0 for Organization Decision Making,OriginalPaper,"In today’s time, with the digital revolution and the advent of technologies both customers and organizations are getting exposed to a larger amount of information than ever before, making organizational decision making challenging. Industrial Revolution 4.0 led to the emergence of smart factories with the development of technologies such as Internet of Things (IoT), Sensors, Industrial Internet of Things (IIoT), Cyber-Physical Systems, Cloud Computing, Big Data, and Artificial Intelligence (AI). Their prime focus was to increase productivity and mass production through automation and somewhere superseded humans over technology-enabled machines. With the uprising of Industry 5.0, the vision for this industrial revolution is perceived as supporting not superseding humans. Humans and AI may have multiple roles to play in an organization, but organizations in which both humans and AI act as decision agents need to emphasize managing the impact of technological involvement on human performance and vice-versa, to work in collaboration. This study aims to understand the role of human and AI-enabled machines in organizational decision-making. Different strategies related to human-machine collaboration existing in research are also discussed to enable the organizations, as well as the researchers, to identify the most suitable strategy for organizational decision making in industry 5.0, where human-machine collaboration is the primary goal.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Management']"
doi:10.1007/978-981-19-3035-5_35,en,K-Nearest Neighbor and Collaborative Filtering-Based Movie Recommendation System,OriginalPaper,"Over the past several years, the recommendation system has become one of the important aspects in our day to day life. Recommendation systems are used in various areas like YouTube, Amazon, etc. Collaborative filtering algorithms have been used in recommendation systems for a long time. They have been effective in resolving a number of issues with commercially available systems. Methods based on a user’s neighborhood have showed potential in forecasting user ratings. The aim of this paper is to design and evaluate ‘KNN algorithm and Collaborative Filtering algorithm’ for producing movie recommendations. The dataset used in this paper is ‘Movielens dataset’ which is downloaded from Kaggle. The system was implemented using ‘Python programming language’. Initially, compared different distance measures and then performed correlation. Based on the correlation value, developed system will recommend similar movies/users. Performances of both the developed algorithms were analyzed in terms of accuracy. Finally the result shows that the accuracy of the recommendations is very good and we will get more accurate movie recommendations based on the combination of “KNN algorithm and collaborative filtering algorithms”.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Statistics, general']"
doi:10.1007/978-3-031-09835-2_14,en,Estimation Models for Optimum Design of Structural Engineering Problems via Swarm-Intelligence Based Algorithms and Artificial Neural Networks,OriginalPaper,"In structural engineering, iterative optimization processes may take a long time and several cases of the same problem need the process of the same optimization run. For that reason, machine learning can be used to generate artificial intelligence estimation models. This process includes the steps of generating data including optimum results of several cases, machine learning via using the generated data, and providing an estimation model via artificial intelligence methods. Artificial Neural Networks (ANNs) have been successfully used in developing estimation models for solving and optimization of structural engineering problems. In optimization, swarm intelligence-based algorithms have been generally used to provide machine learning data. In this chapter, a review of ANNs applications in civil engineering is presented. Then, examples of structural optimization that propose an estimation model are presented. The problems include benchmark structural optimization problems, tuned mass dampers, and reinforced concrete retaining walls.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-11686-5_4,en,Feature Location in Models (FLiM): Design Time and Runtime,OriginalPaper,"In this chapter, we apply feature location to automate the identification and extraction of the features existing among a family of product models and re-engineering them into a model-based SPL. To address the feature location in software models (FLiM) challenge, we present two approaches: at design time (FLiMEA) and at runtime (FLiMRT). Both FLiMEA and FLiMRT approaches are different but complementary. FLiMEA takes information from design time models while FLiMRT takes information from runtime models. The FLiMEA approach combines Genetic Operations and Information Retrieval. Given a model and a description of a possible feature, model fragments extracted from the model are generated using genetic operation and are assessed using an information retrieval technique to rank the candidates based on the similarity with the feature description. The FLiMRT approach leverages the use of software architecture models at runtime. The information is collected in the software architecture model at runtime and each model element is assessed based on its similarity to the feature description. We evaluated our approaches in two real-world industrial case studies: BSH and CAF. The application of FLiMEA shows that the mean values of recall and precision are 72.99 per cent for BSH and 68.34 per cent for CAF while FLiMRT ranks the relevant elements in the top ten positions of the ranking in 84 per cent of the cases.","['Computer Science', 'Software Engineering/Programming and Operating Systems', 'Software Management', 'Computer System Implementation']"
doi:10.1007/978-981-19-4990-6_50,en,"Review on Load Balancing Techniques, Resource Scheduling, Sidechannel Attacks in Cloud Environment",OriginalPaper,"Cloud computing is an inventive innovation that has acquired a progressive changes in computing administrations. It has empowered to drive the concentration from neighborhood/individual calculation to datacenter-driven algorithm by giving resources powerfully in a virtualized way by means of Internet. The aim of load adjusting is to clearly comprehend the client prerequisites, the information and data which can be sent and obtained without taking additional time. In this paper, we have focused on cloud computing, load balancing techniques, cloud resource scheduling process. Review on load balancing techniques and resource scheduling, sidechannel attack is also presented in this paper.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Wireless and Mobile Communication']"
doi:10.1007/978-3-031-15758-5_84,en,Study of Machine Learning Techniques for Damage Identification in a Beam,OriginalPaper,"Damage is defined as any change to the material, geometry or boundary condition that can modify the structure’s properties or response. In the past, damage identification was performed through periodical inspection, non-destructive testing/non-destructive evaluation, or visual observation. Structural health monitoring (SHM) has emerged to transition from offline damage identification to near real-time and online damage assessment. Hence, SHM is a damage detection strategy to monitor a structure for a period using a series of continuous measurement devices, which then collect the system’s characteristics and subsequently perform statistical analysis to assess the current circumstances and health of the structure. One of the first steps for the study of SHM is damage detection followed by monitoring. Machine Learning (ML) techniques can be used to develop viable algorithms to make potential predictions. ML algorithms are therefore providing the tools needed to enhance the capabilities of SHM systems and provide intelligent solutions to past challenges. Preliminary studies have reviewed that the extension of ML into SHM has dramatically increased the system’s capabilities, providing innovative solutions to different research challenges. This work conducts a study of the use of ML to identify damage in a beam and discuss the challenge of usage, performance and implementation of each technique.","['Engineering', 'Vibration, Dynamical Systems, Control', 'Robotics and Automation', 'Computational Mathematics and Numerical Analysis']"
doi:10.1007/978-981-19-3590-9_55,en,Predictıng the Loan Using Machine Learning,OriginalPaper,"The implementation of recent technological advancements in banking sector will simplify the loan approval process. It is a well-known fact that the banks benefit more from loans. However, taking a loan from banking sector will highly depend on a crucial parameter, loan status, resulting with the outputs of either YES or NO (approval or rejection). However, it is not always possible to select the true applicant, who will return the loan. It is also difficult to manually select a real client, since banks have different methods for selecting a genuine client. So, in this case, a machine learning approach can be utilized to predict whether the selected applicant is a good choice for loan payback. The machine learning algorithm will evaluate the loan applicant based on the previous data. Here, the algorithm will reduce the chance of opting out the candidates by selecting genuine clients. This research study incorporated the machine learning [ML] algorithms like logistic regression and random forest for performing loan prediction.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security', 'Mobile and Network Security']"
doi:10.1007/978-981-19-1844-5_9,en,Tourist Spot Recognition Using Machine Learning Algorithms,OriginalPaper,"Tourism plays significant role for enhancing economic potential worldwide. The natural beauty and historical interests of Bangladesh remarked as a major tourist destination for the international tourists. In this study, we target to propose a deep learning-based application to recognize historical interests and tourist spots from an images. Making use of on-device neural engine comes with modern devices makes the application robust and Internet-free user experience. One of the difficult tasks is to collect real images from tourist sites. Our collected images were in different sizes because of using different smartphones. We used following deep learning algorithms—convolution neural network (CNN), support vector machine (SVM), long short-term memory (LSTM), K-nearest neighbor (KNN) and recurrent neural network (RNN). In this proposed framework, tourists can effortlessly detect their targeted places that can boost the tourism sector of Bangladesh. For this regard, convolutional neural network (CNN) achieved best accuracy of 97%.","['Engineering', 'Communications Engineering, Networks', 'Mobile and Network Security', 'Artificial Intelligence', 'Big Data']"
doi:10.1007/978-981-19-4052-1_73,en,Ensemble Method of Feature Selection Using Filter and Wrapper Techniques with Evolutionary Learning,OriginalPaper,"The improvement in data collection and mining methods has expanded the range of dimensionality or features in the data, which brings about an obstacle to many existing feature selection methodologies. This paper brings forth a fresh feature selection methodology rooted in particle swarm optimization (PSO) as wrapper method and an ensemble method to merge the results of the different filter techniques (chi-square, F-regression, and mutual information) to find an optimal feature set that covers most of the key variables of the dataset. The local search is executed on the global best and makes use of a filter-based method, which then intends to take the advantage of the filter and wrapper methods. Our results exhibit that the proposed methodology can be successfully used to select fewer features and, at the same time, increase the classification efficiency over using all features. The proposed methodology also shows how well an evolutionary learning algorithm like the particle swarm optimizer can be used for search optimization of optimum features in the dataset.","['Engineering', 'Computational Intelligence', 'Information Storage and Retrieval', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Data Structures and Information Theory', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3575-6_42,en,A Nobel Approach to Identify the Rainfall Prediction Using Deep Convolutional Neural Networks Algorithm,OriginalPaper,"It is unlikely to have a big impact on a country's economic progress. It also helps to reduce the loss of life and property caused by natural disasters. The study of rainfall prediction using machine learning techniques, with a special emphasis on India. In India, about 70% of the population is dependent on agriculture and related activities. Rainfall forecasting has been an issue of major technical and economic importance in the agricultural sector. This rain prediction model is still mostly based on artificial neural networks, and it has only been used in India so far. In the present study, a comparative analysis of the two rainfall forecasting techniques, and is more accurate. In today’s technology, the ability to predict the rainfall is not very well-informed about the complexity of the data. The methods used are the methods of statistical and mathematical methods that don’t work if there is a situation of a nonlinear pattern. An existing installation may fail when the level of complexity of the information contained in it, increase it in the past. Now, this is the best way to get to the waiting; in the rain, it is a study of deep learning and neural networks, and genetic algorithms, is that it gives you more precise, it is used to predict the future. In order to come up with a good rain is a joint, an appraisal is not required. The simplest and easiest approach to get on a larger scale is to use weather forecasting. In the present study, it can be used in all types of weather stations, and the forecast will give access to some parts of the country. A technique for predicting month-to-month rain for a specific area in India using a deep CNN learning method as a replacement fortuning technique. The CNN was compared against an ANN.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-5090-2_2,en,Cardial Disease Prediction in Multi-variant Systems Using MT-MrSBC Model,OriginalPaper,"Heart disease has been a major threat that costs human lives. There are many reasons behind heart disease including smoking, heredity, and diabetes. Day to day, people face various common symptoms of heart disease which are unconsidered in a lethargic manner. This leads to serious and life-threatening complications. To predict these diseases in prior, several methods are existing which take in a certain number of parameters for prognosis. The system proposed here is an ensemble approach that combines the idea of the MT-MrSBC algorithm along with bagging and boosting. The algorithm mentioned here overcomes the issues faced by other algorithms in handling the multi-variant environment. The algorithm deploys iterative techniques indulging bagging and boosting concepts that enhance the system. The system trained is thus capable of predicting the disease of the patient. This helps in taking precautionary measures by the patient which are life saving.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Artificial Intelligence', 'Data Structures and Information Theory']"
doi:10.1007/978-3-031-14615-2_30,en,Effective Implementation of CPPS Self-reconfiguration Functionality: Research Review,OriginalPaper,"From one period to another period, reconfiguration is highly desired especially for manufacturing systems to cope with the increasing frequency of manufacturing system environment changings. Cyber-Physical Production Systems, which will dominate future industries, offer many promising functionalities, in particular the ability to adapt to internal and external changes. To implement this functionality, we have proposed in a previous work the Q-Holonic-based Architecture, a concrete architecture providing all the necessary information for a self-reconfiguration algorithm. It ensures the overall system performance and reactivity to hazards. This architecture is based on the idea of a Q-Holon, an enriched Holon with four dimensions (physical, cyber, human, energy), which is used to represent each of the entities and actors that compose the value chain. Hence, the validation of this proposal using a reconfiguration algorithm is required. For this purpose, this research work provides an overview on the algorithms and methodologies of reconfiguration presented in the literature by analyzing them with regard to different criteria.","['Engineering', 'Vibration, Dynamical Systems, Control', 'Control, Robotics, Mechatronics', 'Materials Engineering', 'Classical and Continuum Physics']"
doi:10.1007/978-3-031-04354-3_4,en,Time-dependent and Time-independent Models of Cyclic Plasticity for Low-cycle and Thermomechanical Fatigue Life Assessment,OriginalPaper,"In this work, time-independent and time-dependent plasticity models are presented that are well suited for the calculation of stresses and strains with the finite-element method to assess the low-cycle and thermomechanical fatigue life of engineering components. The focus are plasticity models that are available in finite-element programs nowadays as standard material models and describe isotropic and kinematic hardening, strain-rate dependency as well as static recovery of hardening. For the presented models, aspects relevant for the application of the models are addressed as the determination of the material properties and the numerical implementation. Nevertheless, the plasticity models are also embedded in the thermodynamic framework used for the derivation of thermodynamically consistent plasticity models. Only uniaxial formulations are used to achieve a good readability and preventing the use of tensors.","['Engineering', 'Mechanical Engineering', 'Structural Materials', 'Classical and Continuum Physics']"
doi:10.1007/978-981-19-4208-2_33,en,A Novel Modeling Approach for Dent Identification and Sizing for Oil and Gas Pipeline,OriginalPaper,"This paper presents a novel mathematical modeling approach for the identification of anomalies like dent sizing, ovality sizing, weld sizing through diameter reconstruction for oil and gas pipelines. A novel mathematical model that integrates the best-fit circle (BFC), smallest covering circle (SCC) and largest empty circle (LEC) algorithms are proposed so that the prediction of pipeline features (diameter and dent) becomes very accurate. In the experimental setup, the in-line inspection (ILI) tool was used to obtain the input parameters of algorithms. These ILI tools recorded the data (through arms) systematically and the fundamental structure of the inner side of the pipeline is reconstructed using the data obtained from the ILI tool calipers through a proposed integrated mathematical model. A real-life practical pipeline case study with numerical experimentation for 18-inch pipeline geometry tool data is carried out to highlight the efficacy of proposed algorithms. The algorithm successfully identified all pre-marked 51 dents in a liquid medium, while in gas medium, the total identification was 49 dents.","['Engineering', 'Industrial and Production Engineering', 'Robotics and Automation', 'Manufacturing, Machines, Tools, Processes']"
doi:10.1007/978-3-031-20029-8_1,en,A Comparison Study of UNDX and UNDX-m Methods for LDVM and RDVM Router Replacement Methods by WMN-PSODGA Hybrid Intelligent System Considering Stadium Distribution,OriginalPaper,"Wireless Mesh Networks (WMNs) are gaining a lot of attention from researchers due to their advantages such as easy maintenance, low upfront cost, and high robustness. However, designing a robust WMN at low cost requires the use of the least possible mesh routers but still interconnected and able to offer full coverage. Therefore, the placement of mesh routers over the area of interest is a problem that entails thorough planning. In our previous work, we implemented a simulation system that deals with this problem considering Particle Swarm Optimization (PSO) and Distributed Genetic Algorithm (DGA), called WMN-PSODGA. In this paper, we compare the results of Stadium distribution of mesh clients for Unimodal Normal Distribution Crossover (UNDX) and Multi-parental UNDX (UNDX-m) methods for two router replacement methods: Linearly Decreasing Vmax Method (LDVM) and Rational Decrement of Vmax Method (RDVM). The simulation results show that the use of UNDX with RDVM achieves full client coverage, better connectivity and improved load balance.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence']"
doi:10.1007/978-981-19-5751-2_7,en,AI-Based GEVs Mobility Estimation and Battery Aging Quantification Method,OriginalPaper,"The bi-directional link between the electrical system and electric vehicles allows vehicle batteries to provide balancing services for the system in a flexible, low-cost, and quick-response manner. However, two critical issues should be solved in realising the benefits of vehicles to grid (V2G) services. Firstly, grid-connected electric vehicle (GEV) mobility may cause uncertainties in the grid’s energy storage capacity, which may further impact the power quality and stability of the power grid. Thus, in V2G scheduling, it is necessary to access electric vehicle (EV) mobility and estimate its schedulable capacity and charging requirements (SC&CR) information in advance. Furthermore, the key factor that keeps GEVs owners from becoming the prosumers of the grid is the battery life loss caused by additional operating cycles in V2G service, as well as the concern about expensive battery deterioration costs. To promote the adoption of V2G services, battery life loss should be evaluated and mitigated through a behaviour management algorithm. This chapter investigates and compares the performance of existing V2G capacity prediction methods, including statistical model, learning-based model, and rolling prediction model. Thereafter, it introduces a life loss quantification model to analyse battery aging characteristics when providing V2G services. With the predicted GEVs mobility information and battery aging cost analysis model, V2G resources can be better utilized by producing more efficient strategies.","['Engineering', 'Control, Robotics, Mechatronics', 'Mechanical Engineering', 'Automotive Engineering', 'Cyber-physical systems, IoT', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-7780-0_31,en,Algorithms and Software for Evaluation of Plant Height in Vertical Farm Using UAVs,OriginalPaper,"Currently, the number of vertical farms is rapidly increasing, and in the process of their work, all new technologies are used. Automation of plant development monitoring is one of the significant tasks in this direction. With the use of unmanned aerial vehicles (UAVs) it is possible to obtain images of plants for further analysis. The paper proposes a new approach to assessing the dynamics of plant development in vertical farm containers, based on obtaining photographs of vertical farm racks using UAVs to further determine plant growth. Using optical flow and navigation data based on ArUco markers, the UAV moves between the vertical truss racks and takes pictures of objects of interest. The resulting photographs are processed to detect plants and evaluate their development dynamics. After processing, we get photos of individual containers with plants, after which the average height of the plants in each container is calculated. All calculated parameters are stored in the database. In order to evaluate the dynamics of plant growth in each container, the current measured height values are compared with the previous ones. The developed approach was tested in the Gazebo simulator; the maximum relative error in determining plant height was 4%.","['Engineering', 'Control, Robotics, Mechatronics', 'Agriculture', 'Artificial Intelligence', 'Mechanical Engineering']"
doi:10.1007/978-981-19-1844-5_50,en,Extraction and Summarization of Disease Details Using Text Summarization Techniques,OriginalPaper,"The application of machine learning (ML) and natural language processing (NLP) is being extensively used for research in the area of healthcare and biomedicine. This pattern goes especially in accordance with the course, and the healthcare system is headed in the highly networked world which includes the World Wide Web where the regular users and health experts conduct discourses on health issues. To glean knowledge from medical texts and discourses which are mostly in text in natural language, many text analysis frameworks and techniques have been designed. Those techniques do not produce a comprehensive summary about the content related to a disease from content available online. So in our work, we propose text summarization based on natural language processing algorithms combined with machine learning algorithms for extracting all information pertaining to a disease from online healthcare forums.","['Engineering', 'Communications Engineering, Networks', 'Mobile and Network Security', 'Artificial Intelligence', 'Big Data']"
doi:10.1007/978-981-19-5751-2_1,en,Energy Efficient Control of Vehicles,OriginalPaper,"Electric vehicles (EVs) have the advantages of energy saving and environmental protection, which are favoured by major vehicle companies nowadays. However, the problem of how to effectively improve the economy has been a hot spot and difficult research point of the vehicle control strategy. Therefore, this chapter introduced the mainstream algorithms currently used as energy management strategies, and analysed the advantages of each method. This chapter begins with an introduction to energy integrated control for electric vehicles. Since the control scheme is related to architecture, this chapter then introduces the common architectures of EVs. Finally, the rule-based energy management strategy and the optimization-based energy management strategy are highlighted, and the vehicle architectures to which the different strategies are adapted are analyzed. Finally, the development and characteristics of the strategies are summarized.","['Engineering', 'Control, Robotics, Mechatronics', 'Mechanical Engineering', 'Automotive Engineering', 'Cyber-physical systems, IoT', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-2768-3_24,en,Development of Personalized Recommendation System for Ideological and Political Education,OriginalPaper,"In the rapid development of network technology, digital education has become the focus of educational innovation and exploration. Teaching resources, as the core content of digital teaching guidance, with the increase of the number of network reserve learning resources, it is difficult for learners to find appropriate resources, which shows that the current educational guidance resources are lack of individualization. Therefore, on the basis of understanding the selection of the resource recommendation system for ideological and political education, this paper analyzes how to build a personalized resource recommendation system for ideological and political education in combination with the personalized needs of practical education.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory', 'Operations Research/Decision Theory', 'Business and Management, general']"
doi:10.1007/978-981-19-3035-5_3,en,Hybrid Approach to Predict the Death Rate of COVID-19 Patients,OriginalPaper,"From closedown of December 2019, coronavirus has directly exhibited a lofty rate of transmission, coercing the World Health Organization to contend in the month of March 2020 that this unbeknownst coronavirus can be depicted as a pandemic. COVID-19 epidemic has guided to an operatic misplacement of deathly life over the public and presents an unbeknownst complaint to public fitness. It also affects the food systems of the person and the world of work. Once the person is infected by COVID, the metabolic exertion of vulnerable cells in his or her body is enhanced, similar as the one driven by COVID-19. The country’s dietary habits are analyzed to predict the particular person’s death rate. By using KNN algorithm, the performance metrics such as accuracy, precision, recall, and F1 score are evaluated for the country’s dietary habits. In this research, both clustering and classification are combined to increase the accuracy of the prediction of death rate of the person. K-means is used for the clustering of the countries, and KNN is used for classifying the countries. The 170 countries are clustered based on the country’s dietary habits, and other disease affected rate using K-means clustering algorithm. Countries are clustered into high and normal death rate countries based on the country’s dietary habits and another cluster into high and normal death rate based on the other disease affected rate rather than COVID-19. Using the country’s dietary habits and other disease affected clusters, the death rate of the person is predicted. After clustering the data based on the country’s dietary habits and other disease affected rate, the KNN algorithm is used to classify and identify the person’s death rate. Using clustering and classification algorithms in a combined way, an accuracy of 79% is achieved.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Statistics, general']"
doi:10.1007/978-3-031-12011-4_60,en,Optimisation of Artificial Neural Network Using Cuckoo Search Algorithm for Damage Detection,OriginalPaper,"Artificial Neural Network is a tool of Structural Health Monitoring based on non-destructive methods for finding damage detection. ANN is a parallel distributed network inspired by the biological nervous system and has the potential to learn and identify from experience to improve its performance. Therefore, a trained network can be utilised to classify and examine new data sets that show similar characteristics as that of trained data sets. By virtue of the potential capability of ANN, it can be used to solve both simple linear and complex nonlinear functions. But due to the gradient descent nature of the backpropagation algorithm, the problem of local minima arises and which acts as a great hindrance to the best solution. To overcome this, various evolutionary algorithms based on global minima were used in conjunction with ANN such as Particle Swarm Optimisation, Genetic Algorithm, Cuckoo Search (CS), etc. Cuckoo Search is a powerful meta-heuristic search algorithm derived from the reproduction strategy of the Cuckoo bird. The lesser number of parameters in CS makes it simple and potentially more genetic. This paper presents a method for damage detection in structures by amalgamating a flexible combination of Artificial Neural Network and Cuckoo Search algorithm. CS is employed with ANN to improve the training parameters (weight and bias) by minimising the difference between the real and desired output and these parameters were used for generating the network. For the study, a lattice structure is used to assess the robustness of the created network and this will be compared with efficiency in damage location and identification of the network created using ANN alone. The Study proved that ANN-CS outperforms ANN alone in damage identification, localisation, and quantification.","['Engineering', 'Construction Management', 'Building Construction and Design', 'Geotechnical Engineering & Applied Earth Sciences']"
doi:10.1007/978-3-031-18516-8_23,en,Communities Detection in Epidemiology: Evolutionary Algorithms Based Approaches Visualization,OriginalPaper,"Complex networks are large scale networks with complicated topologies that have attracted the attention of research scientists, many systems can be represented as complex networks, a fundamental field for studying the structural properties of a large number of dynamic systems. Those networks are modeled by graphs that can be visualized with a dynamic aspect showing their changes over time. The visualization of those networks has increasingly became important in many fields because identifying and understanding the changing are complex tasks in demand. In this article, we will focus on the dynamic graph visualization of community detection in epidemiological diseases. Many studies have been carried out to analyze the spread of the epidemics and how to proceed to the immunization phase. Including a work that relies on a temporal RDF graph and the application of genetic algorithm and bee colony algorithm as an immunization strategy to a community detection problem. Dynamic graph visualization focuses on the challenge of representing the evolution of relationships between entities in readable, scalable, and effective diagrams which will allow us to extract the characteristics of the different nodes and edges as well as to understand the dynamism that occurs when such events occur in a population.","['Engineering', 'Complexity', 'Computational Intelligence', 'Control and Systems Theory']"
doi:10.1007/978-981-19-5845-8_32,en,PDF Steganography Using Hybrid Crypto Encryption Technique,OriginalPaper,"Recently, for all script and content writing, and transferring purposes, the Portable Document Format (PDF) has been widely used. This article presents PDF steganography based on a hybrid crypto encryption technique. The proposed method does not modify the portable document structure or content while concealing the secret data at any stage. Before the stego operation is performed, the confidential data undergo hybrid crypto encryption. Encryption consists of an advanced encryption standard 256-bit key and RSA encryption algorithm. As the document structure is not modified throughout this technique, it is not suspicious to technocrats during communication. Only the size of the PDF document increases as the size of the secret data increases. The human vision system cannot differentiate between the stego and a standard document, as the content and structure are unaltered.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4514-4_9,en,Automatic Balance of Rotating Machinery and Wholeness Dynamic Balance of Aeroengine,OriginalPaper,"On the basis of studying the mechanism of same-frequency vibration failure, the causes of same-frequency vibration of rotating machinery are summarized into 26 kinds of 10 categories. The essence of automatic balance is that the automatic balance system traces the source, through the actuator to timely and appropriately adjust the mass distribution or directly to generate the rotation vector self-recovery force. The electromagnetic automatic balance system for supergravity machine and high-end machine tools are briefly introduced. The principle of a pneumatic liquid automatic balance is put forward. The principle and method of aero-engine wholeness balance are proposed and the automatic balance system for aeronautical propeller unbalanced coupled vibration is introduced.","['Engineering', 'Manufacturing, Machines, Tools, Processes', 'Vibration, Dynamical Systems, Control', 'Mechatronics']"
doi:10.1007/978-981-19-0105-8_18,en,Model Structure from Laser Scanner Point Clouds,OriginalPaper,"The essential target of this research work is generating a three-dimensional (3D) design of cloud point laser scanner structure that performs computer vision system (CVS) processes intentionally fully capabilities of invest to estimate model structure resulting from laser scanner point clouds and recognizing main areas for further studies and development. This study is significant processes were displayed, begins from collecting the clouds of laser point in static mode, and then analyzing the existing data, an iterative closest point algorithm (ICP) used in point cloud registration and matching, noise reduction, synthesis scheme in laser scanner point clouds uses a random sample consensus algorithm (RANSAC), data generating 3D laser scanner, importing a structure model from laser scanner point clouds and fit in using CVS programs. The Poisson surface algorithm is utilized to pick up point clouds and mesh surfacing. The results displaced some of the structural troubles such as deformation and cracks over two places of the wall. The results of the proposed algorithm matched the original point clouds very well. This differential proved that the algorithm advanced in this research work is efficient and more workable for visualization, monitoring, and future data processing.","['Engineering', 'Communications Engineering, Networks', 'Artificial Intelligence', 'Computational Intelligence', 'Bioinformatics']"
doi:10.1007/978-981-19-3998-3_24,en,MADDPG: Multi-agent Deep Deterministic Policy Gradient Algorithm for Formation Elliptical Encirclement and Collision Avoidance,OriginalPaper,"This paper considers the formation encirclement problem of multi-agent systems with collision avoidance, where the enclosing orbit is an ellipse, the target and the formation are dynamic. The novel rewards, that is the elliptical encirclement reward, the formation reward, the angular velocity reward and collision avoidance reward are designed and a reinforcement learning (RL) algorithm, that is multi-agent deep deterministic policy gradient (MADDPG), is designed based on the novel setting of rewards. Simulation results are given to show the validity of the proposed method.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-3-030-92989-3_9,en,X-Ray Multispectral CT Imaging by Projection Sequences Blind Separation Based on Basis-Effect or Basis-Material Decomposition,OriginalPaper,"Multispectral CT is a promising method in material characterization, nondestructive evaluation, and other applications. For multispectral CT, the method of projection domain separation can make multispectral CT reconstruction less complex, easier to implement. But X-ray spectrum should be known. By blind separation of projection sequences with the different X-ray energy, though the ray spectrum is not known in advance, the narrow-spectrum projections can be captured too. The linear reconstruction of narrow-spectrum projections can suppress hardening artifacts and improve the component identification and quantitative analysis capabilities of multispectral CT. In this chapter, two projection blind separation methods of multispectral CT are proposed for obtaining narrow-spectrum projections under unknown spectra by using linear attenuation coefficient decomposition models, namely basis-effect decomposition or basis-material decomposition. The separation results of the two methods not only have a clear energy orientation, but also have superior narrow-spectrum characteristics, which can improve the component characterization accuracy of multispectral CT.","['Engineering', 'Circuits and Systems', 'Biomedical Engineering and Bioengineering', 'Microwaves, RF and Optical Engineering']"
doi:10.1007/978-981-19-6347-6_2,en,Classification of Electrooculography Signals Using Convolutional Neural Networks for Interaction with a Manipulator Robot,OriginalPaper,"Electrooculography (EOG) has been widely applied in human–machine interfaces (HMI) because it provides a reliable communication channel to assist people with disabilities. However, signal behavior under different conditions hinders eye movement classification when algorithms based on voltage threshold detection are used. Therefore, recalibration of the system is required for the classification algorithm to work correctly. Based on the above, a classification algorithm was developed to analyze the data vector corresponding to the entire EOG waveform, instead of just one characteristic value of the signal, thus avoiding the system recalibration process. A convolutional neural network (CNN) was implemented to classify six targets corresponding to different eye movements. The proposed model was compared with a feedforward neural network (FNN) to evaluate its performance. The results were implemented in an HMI for interaction with a manipulator robot.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Health Informatics', 'Statistics, general']"
doi:10.1007/978-981-19-3035-5_14,en,Exclusive Item Recommendation to the Online Shopping Customers Based on Category Using Clickstream and UID Matrix,OriginalPaper,"Online shopping becomes indispensable among the people worldwide. Clickstream, collaborative filtering and machine learning algorithms play a considerable role to analyze the browsing behavior and predict the next click of the customers. In this research, k -nearest neighbor is applied to classify the customers into three groups: Regular, Special and Exceptional. User-Item-Detail matrix is constructed to identify the similarity among the online customers. Exclusive recommendation is provided to the customers based on user classification. The accuracy of the research is evaluated with the parameters precision, recall, and f-scores.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Statistics, general']"
doi:10.1007/978-981-19-5403-0_1,en,Breast MRI Registration Using Gorilla Troops Optimization,OriginalPaper,"Metaheuristics assume a significant part in enhancing issues, and most of them are enlivened by the aggregate knowledge of living peculiarities in nature. In excess of 10% of ladies are experiencing bosom disease in their lives in the entire world. Registration of breast magnetic resonance imaging is a method to align pre- and post-contrast images to analysis and classifying of cancer category. In this research, breast magnetic resonance imaging registration using gorilla troops algorithm is proposed. GTO is a metaheuristics-based optimizations algorithms that tested to registering the image of breast magnetic resonance. After that, images are successfully registered using GTO algorithm. The result of GTO-based registration method is compared with registration based on PSO method. The results implicates, in case of registration of breast magnetic resonance images, the GTO-based registration methods beat the PSO-based registration method.","['Engineering', 'Computational Intelligence', 'User Interfaces and Human Computer Interaction', 'Data Structures and Information Theory', 'Artificial Intelligence', 'Data Mining and Knowledge Discovery']"
doi:10.1007/978-3-030-26050-7_187-2,en,Loss Function,ReviewPaper,,"['Earth Sciences', 'Quantitative Geology', 'Mathematical Applications in the Physical Sciences', 'Remote Sensing/Photogrammetry', 'Statistics for Engineering, Physics, Computer Science, Chemistry and Earth Sciences', 'Statistics and Computing/Statistics Programs']"
doi:10.1007/978-981-19-3387-5_117,en,Continuous Evolution for Efficient Neural Architecture Search Based on Improved NSGA-III Algorithm,OriginalPaper,"Improved Continuous Evolution for Efficient Neural Architecture Search method (I-CARS) is proposed to solve multi-objective optimization problems (MOPs). Seeking to improve the convergence and search accuracy, two modifications of the non-dominated sorting genetic algorithm based on reference-point strategy (NSGA-III) were made to replace pNSGA-III in CARS, including the penalty-based boundary intersection distance (PBI distance) and the selection-and-elimination operators. First, the perpendicular distance from solutions to reference lines was replaced by the PBI distance in the offspring selection stage phase, which can add the convergence information. Second, individuals in the population were selected or eliminated by niche count and PBI distance. Better performing individuals were selected to become the next generation, while poorly performing individuals were eliminated. The convergence and diversity of the population can be balanced by adding the selection-and-elimination operator. Experiments were conducted on Vega pipeline, and I-CARS achieves 3.41% test error on CIFAR10, the results indicated that the accuracy and convergence of I-CARS are enhanced compared to CARS.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Aerospace Technology and Astronautics']"
doi:10.1007/978-981-19-2840-6_6,en,Study of Vulnerabilities in the Cryptography Algorithms,OriginalPaper,"The authors demonstrate the vulnerability of particular algorithms using the principles of timing attacks. RSA and Diffie-Hellman are the algorithms used and comparative study was done on them. In each approach, the private keys are extracted by analysing time differences in various scenarios while modifying specific parameters of the private key. The authors have identified crucial points of difference that can be exploited to decipher the private keys. The authors also attempt to exploit the Elliptical Curve Cryptography technique through a timing attack.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-2225-1_14,en,Random Connected Graph Generation for Wireless Sensor Networks,OriginalPaper,"For analysing networks like social media networks, wireless sensor networks, etc. in many applications, generating random connected graph is very important. As it is time consuming to generate the random connected graph consisting of large nodes it is necessary to generate it in minimum time. Characteristics like dependent edges and non-binomial degree distribution that are absent in many classical random graph models such as the Erdos-Renyi graph model can be captured by random graphs with a given degree range. The problem of random connected graph generation having a prescribed degree range has been addressed here. Random graphs are used to model wireless sensor networks (WSNs) or IoT comprising of sensor nodes with limited power resources. A fast and light-weight algorithm has been proposed in this paper to produce a random connected graph for a real-time multi-hop wireless sensor networks (WSNs). Results show that our method has better performance than other existing methods.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Statistics, general', 'Mobile and Network Security']"
doi:10.1007/978-3-031-15211-5_62,en,Advanced Methods to Solve Multi-project Scheduling Problems Taking into Account Multiple Objective Functions,OriginalPaper,"Project-based planning and execution have an important role in the product lifecycle. Medium and large-sized companies are executing more than one project simultaneously, usually sharing common resources. Each project has its individual goals to achieve. Creating a company-wide optimal or near-optimal schedule in this complex environment is very difficult. Our paper presents a model to define the problem and a concept of a possible solver. A proof-of-concept of an advanced solver with experimental results is presented.","['Engineering', 'Automotive Engineering']"
doi:10.1007/978-981-19-4293-8_15,en,Research on the Application of Computer Vision in Bridge Health Monitoring,OriginalPaper,"This article starts from the theory of computer vision in bridge health monitoring summarizes how it has been used in bridges by applying data collection, data analysis, and data management of bridge health monitoring systems. All these technologies can be used adeptly in their aspects. In the past, China used manual detection of bridge cracks, relying on large mechanical devices such as bridge trucks to send people under the bridge to monitor the health of the bridge. This method was time-consuming and labor-intensive, and the safety of manual labor could not be guaranteed. It is easy to cause diagnostic errors [ 1 ]. This research introduces the general situation and summarizes the main problems in this field of computer vision.","['Engineering', 'Civil Engineering', 'Arts', 'Building Construction and Design']"
doi:10.1007/978-3-031-20029-8_2,en,Performance Comparison of Roulette Wheel and Random Selection Methods by WMN-PSODGA Simulation System Considering Stadium Distribution and LDIWM,OriginalPaper,"Wireless Mesh Networks (WMNs) are gaining a lot of attention from researchers due to their advantages such as easy maintenance, low upfront cost, and high robustness. However, designing a robust WMN at low cost requires the use of the least possible mesh routers but still interconnected and able to offer full coverage. Therefore, the placement of mesh routers over the area of interest is a problem that entails thorough planning. In our previous work, we implemented a simulation system that deals with this problem considering Particle Swarm Optimization (PSO) and Distributed Genetic Algorithm (DGA), called WMN-PSODGA. In this paper, we compare the results of Stadium distribution of mesh clients for Roulette Wheel and Random Selection methods for Linearly Decreasing Inertia Weight Method (LDIWM). The simulation results show that the use of roulette wheel achieves full client coverage, better connectivity and improved load balance.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence']"
doi:10.1007/978-981-19-2535-1_7,en,Locating Potholes with Internet of Things Technology Using Cloud Computing Analysis,OriginalPaper,"Many times, when people travel on the road, especially through rain-affected cities, it becomes a constant need to monitor road quality to essentially make sure that there are no unforeseen circumstances. Owing to the gravitation of human needs toward a smart city and the decrepit road infrastructure, the aim of this research is to constantly monitor the road surface to improve the quality and ensure that the car journey is safe. A mobile application has been developed which collects data from the in-built sensors of the phone. The collected data is sent to a database built using Google’s cloud platform, using a socket connection. The socket connection enables the data to be sent in real time. Google’s Firebase Database offers a real-time database, which can be deemed appropriate for this purpose. The analysis involves fetching the stored data, the fetched data is further cleaned and converted into a suitable form. The Z-Thresh algorithm was used to accurately determine the location of the potholes as it considers the minimum value of the z-axis accelerometer as a threshold. The analysis is done over a cloud-based tool, which further informs the authorities about the locations of potholes via SMS so that they can fix them.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-3-031-17789-7_8,en,Practical Applications,OriginalPaper,"In this chapter, we consider a practical topic as an application of the topics we covered in the previous chapters. Although students think of many of the signal processing subjects they learn in theoretical courses only as mathematical expressions, almost all of them have application areas. In this chapter, we first consider an example application of the subjects we learned. Secondly, we will describe the development of the fast Fourier transform algorithm as an example for scientific work.","['Engineering', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Coding and Information Theory', 'Algorithms']"
doi:10.1007/978-981-19-3490-2_5,en,SOC Estimation,OriginalPaper,Battery state of charge (SOC) is the ratio between the battery’s remaining charge and the total charge capacity. The SOC is not directly measurable. It can be calculated under a fixed discharge rate according to the ‘Battery Test Procedure for Electric Vehicle’ by the Advanced Battery Consortium of America.,"['Engineering', 'Automotive Engineering', 'Transportation Technology and Traffic Engineering', 'Energy Systems', 'Energy Materials']"
doi:10.1007/978-981-19-2764-5_32,en,Demand-Side Load Management Using Grey Wolf Optimization,OriginalPaper,"Demand-Side Management (DSM) is one of the methods that tries to understand customer behaviour and put it into a strategy that maintains network stability. Recently, a large number of load scheduling algorithms were developed by various experts, however these methods were not providing accurate results because of their high complexity and utilization of static datasets. To overcome these issues, an improved load scheduling method is proposed in this paper, in which loads are optimized by using the meta-heuristic Grey Wolf Optimization (GWO) algorithm. In addition to this, a real-time dataset is used that is collected from the Chandigarh Region. The information about the total demand felt and met initially is extracted from the available dataset. In addition to this, the minimum hour of electricity that must be provided to the six sectors (AP, PAT, RDS, MGJG, urban and industrial) is also defined. The loads are optimized by the proposed GWO model and later on its performance is evaluated in the MATLAB software. The performance outcomes were delineated by observing the total demand felt by the providers for the month of May, June and July and the total demand met by the proposed scheme. The results proved the efficiency of the proposed GWO model as it was able to provide electricity to every sector as per the demand.","['Energy', 'Energy Systems', 'Artificial Intelligence', 'Machine Learning', 'Cyber-physical systems, IoT', 'Professional Computing', 'Power Electronics, Electrical Machines and Networks']"
doi:10.1007/978-981-19-1484-3_20,en,A Review on Stock Market Analysis Using Association Rule Mining,OriginalPaper,"Association rules mining on stock market in the analysis of the way toward finding substantial, valuable, and reasonable information in data. Because of the large size of databases, significance of data consumes, and profitable data acquired, finding concealed in data has turned out to be progressively noteworthy. A period arrangement dataset comprises groupings of qualities or occasions that change with time. Time arrangement data is well known in numerous applications, for example, the everyday shutting prices of an offer in a stock market. Stock data mining assumes an imperative part to picture the conduct of the financial market. Association rule mining designs can be utilized to find all thing associations (or rules) in a dataset that fulfill client determined requirements, i.e., least help and least certainty. Since just a single least help is utilized for the entire database, it is certainly accepted that all things are of a similar sort or potentially have comparative frequencies in the data. Examples are assessed by methods for producing item sets utilizing predefined support and association rules with a higher certainty level. The example created by the regular item set of size three is observed to be the same as being reflected by methods for acquired association rules. The patterns are created causes investors to assemble their portfolio and utilize these patterns to take in more about investment planning and financial market with methodology and review analysis.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Machine Learning', 'Data Structures and Information Theory', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-981-19-4975-3_37,en,A Particle Swarm Optimization-Based Maximum Power Point Tracking Scheme Employing Dynamic Inertia Weight Strategies,OriginalPaper,"Photovoltaic (PV) systems are one of the most popular forms of Renewable Energy Sources. It is extremely important that these systems be operated at the Maximum Power Point (MPP). Under uniform insolation conditions, we observe a single peak in the P – V characteristics of a PV array. In contrast, under Partial Shading Condition (PSC) the P – V curve is highly non-linear and has multiple peaks that can be classified as Local and Global Peaks. Conventional MPPT Algorithms have failed to deliver satisfactory results under PSC. Hence, nature inspired optimization techniques such as the Particle Swarm Optimization (PSO) algorithm have been applied to MPPT under PSC and have proven to be an effective solution to the problem. In this paper, we employ a set of simple and dynamic Inertia weight strategies which are independent of factors such as maximum number of iterations and can be exploited to increase the speed of tracking of the PSO-based MPPT approach. An inertia weight that is dynamic, simple, and intuitive has also been proposed. The proposed Inertia Weight (IW) is independent of the current iteration number as well as a predetermined value for the maximum number of iterations necessary to converge to the MPP. A significantly lower convergence time and lesser tracking losses are obtained using the proposed IW. The performance of all these techniques has been evaluated using simulations under different shading conditions and validated with hardware implementation.","['Engineering', 'Power Electronics, Electrical Machines and Networks', 'Energy Policy, Economics and Management', 'Energy Systems']"
doi:10.1007/978-3-031-16078-3_5,en,An Intelligent Hybrid Cloud-Based ANP and AI Model for Development Site Selection,OriginalPaper,"Property development site selection decisions typically rely on traditional on-premises information systems that use model-driven multivariate linear regression approaches to predict dwelling prices for a given set of development criteria. However, traditional on-premises structures have limited the flexibility and accessibility of systems. Meanwhile, prediction errors frequently occur in the appraisal model because of noisy data and incomprehensive analysis. This paper proposes a cloud-based integrated property site selection platform that aims to improve the performance of property site selection. This platform integrates an analytical network process (ANP) framework with a data-driven real estate appraisal model to analyse site selection in the Melbourne suburban area. First, data-driven approaches that are solely contingent on predicted price data can alleviate model uncertainties via data mining. A comparative analysis was conducted of data-driven models to select the best predictive algorithm from among linear regression, ridge regression, regression tree, random forest, k-nearest neighbor, support vector regression and artificial neural network approaches. The random forest achieved the best score in the forecast accuracy test, indicating that houses in the southern metropolitan area have the highest potential. Second, ten dwelling candidates were used in the ANP decision model. Following measurement using strategic criteria and Benefit, Cost and Risk merits, the results of the ANP model differed from those of the traditional appraisal model, and non-financial considerations were found to be the primary drivers of selection.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4676-9_39,en,Intensity and Visibility of PSO-Based Waveguide Arrays with an Overview of Existing Schemes and Technologies for Multi-beam Combination,OriginalPaper,"Spectro-interferometry is a sophisticated astronomy technology that produces high-resolution pictures of celestial objects and allows researchers to investigate their morphological characteristics. In this paper, a waveguide array of 2 × 2 waveguides has been investigated with more than one waveguide excited simultaneously. Each and every waveguide available operates as a beam combiner, whose results determine the waveguide intensity, which means, the output intensity is determined by the waveguides used for stimulation. Hence, it is very important to select the appropriate waveguide in order to increase the intensity and visibility of outputs. The primary goal of this study is to determine which metaheuristic technique can fix the issues of waveguide selection. To achieve this, a basic variant of the Particle Swarm Optimization algorithm has been implemented and its software simulation has been done. An analysis is also carried out by calculating the performance matrix concerning magnification, intensity, visibility, and 1/Signal to Noise Ratio. Simulation results are compared with the existing models, which demonstrate an improvement of the proposed system by achieving high intensity and visibility.","['Engineering', 'Computational Intelligence', 'Systems and Data Security', 'Artificial Intelligence', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-3-031-19958-5_11,en,An Implementation of Basic Ant-Colony Optimization Based Routing in Wireless Sensor Networks,OriginalPaper,"This paper demonstrates Ant Colony Optimization in Wireless Sensor Networks (WSNs) while considering limitations such as limited energy, memory, and processing capacity. This network provides a diverse set of applications that may benefit from it. Just a few examples include environmental monitoring, medical care, and military surveillance. Wireless Sensor Networks are based on a large number of computer simulations. In WSNs’ deployment scenarios, this protocol reduces the amount of data sent while increasing the amount of energy used. Many innovations have been developed to overcome the inherent limitations of these networks. There are several experimental solutions explicitly designed for them. WSNs are required for flexible thinker algorithms that consider the most significant limitations of ant-based routing techniques. The goal of these tools is to make the network last longer. We develop a unique routing protocol using Basic Ant-Colony Optimization Based Routing (BABR) at the Ant Colony Optimization heuristic. For this study, we select the Agargoan area in Dhaka, Bangladesh, for the MATLAB simulation.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-6780-1_20,en,A Comprehensive Analysis in Recent Advances in 3D VLSI Floorplan Representations,OriginalPaper,"Floorplan is one of the most critical steps of the physical design of VLSI Design flow. Decreasing size, interconnects, power consumption, and chip leakage are always on the top priority list for consumers and researchers. This article presents the latest advancements in one of the hot research topics in VLSI Physical Design: 3D Floorplanning. A lot of research articles have been studied for this article, and only major research points from some chosen relevant to 3D architecture articles have been incorporated in this paper. The 3D VLSI floorplan field is quite vast than the 2D VLSI floorplan and is comparatively less explored. This article reviews various aspects of floorplanning that cover floorplanning based on volume, tiers, vias, TSVs, and other representations of 3D VLSI Floorplan. These techniques, when applied as algorithms, help in simplifying the problem. These algorithms help optimize results that increase the chip’s overall performance. Some of the central representations have been incorporated in Sect.  5 . Conclusion with research gap and future scope is described in the end.","['Engineering', 'Circuits and Systems', 'Energy Systems', 'Computer-Aided Engineering (CAD, CAE) and Design']"
doi:10.1007/978-3-031-06780-8_3,en,Environmental Perception for Intelligent Vehicles,OriginalPaper,"Environmental Perception for Intelligent Vehicles (EPIV) generally focuses on the awareness and understanding of the driving environment around intelligent vehicles by various vehicle sensors. In recent years, a lot of excellent research has been conducted on developing novel methods and technologies for EPIV. This chapter overviews some of the main research topics in the field of EPIV. First, this chapter reviews various types of vehicle sensors which capture multimodal environmental information around intelligent vehicles and form the foundation for environmental perception. Second, this chapter focuses on data restoration and denoising technologies on camera and LiDAR sensors, which guarantees the quality of the data captured by the vehicle. Third, this chapter deals with methods on semantic segmentation, object detection and tracking with camera and LiDAR data, which play a central role in environmental understanding. Fourth, this chapter introduces technologies on location and mapping with multimodal sensor data, which is essential for the local path planning of intelligent vehicles. Finally, this chapter discusses the research technologies on fusing multimodal environmental data, which represents the frontier of EPIV development.","['Engineering', 'Automotive Engineering', 'Computational Intelligence', 'Transportation Technology and Traffic Engineering', 'Signal, Image and Speech Processing']"
doi:10.1007/978-981-19-2764-5_1,en,Non-traditional Algorithms for Offshore Engineering Systems,OriginalPaper,"Brushlike Direct Current Motors (BLDCM) are the most extensively used machine in a wide range of oceanic applications such as operation of offshore wind turbines, including robotics, food technology, and aviation. PID controllers exceed other linear controllers in terms of performance. This controller is typically utilized for controlling the motor’s speed. In computing, the traditional approach for adjusting PID parameters is indirect. In this paper, two non-traditional algorithms such as genetic algorithm and ant colony optimization are proposed for tuning PID parameters in order to control the speed of BLDC motor. With the goal of constructing a speed regulation controller, these algorithms were applied and assessed on a second-order plant model of a BLDC motor. The GA- and PSO-based control algorithms were implemented using MATLAB-Simulink interfaces. For each technique, the resulting system performance was compared.","['Energy', 'Energy Systems', 'Artificial Intelligence', 'Machine Learning', 'Cyber-physical systems, IoT', 'Professional Computing', 'Power Electronics, Electrical Machines and Networks']"
doi:10.1007/978-981-19-3842-9_60,en,Visual-Inertial Odometry Design Based on Nonlinear Optimization and Its Online Initialization Method for the Autonomous Navigation,OriginalPaper,"There is a recognized complementarity between the vision system and the inertial measurement unit (IMU) in terms of autonomous navigation. Recently, visual inertial system (VINS) has become a hotspot of current research by fusing data of low-cost inertial measurement unit and vision system. However, the lack of direct measurement information makes the estimator’s initialization more difficult. This paper presents a method for online estimator initialization by using robust visual front end. One iterative process is employed to gradually align the vision system with inertial measurement unit. The convergence criterion can be used to determine the end of initialization, which can accurately recover parameters such as speed, scale, and gravity vector. This algorithm is applied to design a tightly coupled visual inertial odometry. In addition, experiments have been performed based on public data sets and equipment. The results show that the average absolute positioning error is less than 0.08 m, the relative positioning error is less than 0.03 m and the system has stable initialization performance with high accuracy positioning performance.","['Engineering', 'Mechanical Engineering', 'Automotive Engineering', 'Transportation Technology and Traffic Engineering']"
doi:10.1007/978-981-19-6004-8_52,en,Autism Detection in Young Children Using Optimized Long Short-Term Memory,OriginalPaper,"One of the neurological diseases distinguished through the lack of social behavior as well as particular interactions, including decreased eye contact and body movements is autism spectrum disorder (ASD). Rapid innovations in hardware and software multimedia technologies enable many techniques for detecting the existence of this disease in children. This work intends to introduce novel ASD detection in young children that pose three stages including (a) preprocessing, (b) feature extraction, and (c) detection. Initially, the input data is processed under modified data normalization. From the normalized data, it extracts the features like statistical features (min, max, mean, standard deviation, and median) and higher-order statistical features (skewness, moment, and kurtosis). Lastly, an optimized LSTM classifier is used to carry out the classification. For enhancing the detection performance, the LSTM weights are optimally tuned by arithmetic crossover insisted shark smell optimization (ACSSO) algorithm. Finally, the outcomes of the presented approach are calculated to the extant approaches with respect to different metrics like F1-measure, specificity, NPV, accuracy, FNR, sensitivity, precision, FPR, and MCC, respectively.","['Engineering', 'Computational Intelligence', 'Cognitive Psychology', 'Personality and Social Psychology', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-05347-4_15,en,Development of an Algorithm Using the Vikor Method to Increase Software Reliability,OriginalPaper,"Software efficiency indicators play a key role in its optimization. Various ways are available to ensure software optimization. One of the key indicators of software is its reliability. Software reliability refers to the program features to perform certain functions and they are kept within certain limits under specified conditions. Software reliability is determined by its non-denial and recoverability. Software reliability is considered an important quality factor. The article uses the VIKOR (VIsekriterijumska optimizacija i KOmpromisno Resenje) method for the development of an algorithm to increase software reliability. The VIKOR method is used for different areas. Some sources provide information on the application of the VIKOR method. It refers to a multi-criteria decision method or multi-criteria decision analysis method. The alternatives here are ranked and the one closest to the ideal so-called compromise is determined. As a result of the author's research, six important criteria for software reliability are identified and alternatives are used. The fuzzy VIKOR method is used for multi-criteria evaluation of software. The work done is considered to be novel, and the advantage is that the selected criteria have not yet been used for this type of task, this positively changes its efficiency. The experiments perform positive results.","['Mathematics', 'Mathematical Modeling and Industrial Mathematics', 'Risk Management', 'Engineering Economics, Organization, Logistics, Marketing']"
doi:10.1007/978-3-031-20601-6_33,en,Research on Cable Surface Quality Inspection System and Method Based on Image Processing Technology,OriginalPaper,"This paper focuses on surface defects in power cables of 6kV and above. An industrial camera with a lens and light source is used to take a 360° picture of the cable under test and to capture the original images of the three main defects: dents, bumps and scratches. The image acquisition system transmits the captured images to the image processing system via wireless or wired transmission, and after the corresponding technical processing, the characteristic information of the cable under test can be obtained and stored for classification, and finally the control system is regulated by the obtained results. A macrological edge segmentation algorithm is proposed for edge detection of the image. After detecting the image edges of power cable defects in different directions, a morphological algorithm is used to enable the computer to clearly identify the three types of defects in the cable surface scratches, by finding a classification line that can classify the data into two categories and constructing this classifier with a linear function, using a linear svm classifier to train the samples for the classification model. The completed classifier model was used to train the sample set to recognise and classify the scratch-like defects with a stable accuracy recognition rate of over 90%.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3590-9_56,en,Cotton Yield Prediction Based on Fertilizers and a Land Using Machine Learning,OriginalPaper,"Agriculture is the economic backbone of every country. Unpredictable variations in climatic circumstances, on the other hand, have had an impact on crop cultivation. Since the farmers are not encouraged to embrace automation in their activities, individuals are losing interest in the topic. It is mainly due to the absence of information technology participation in the agricultural sector. The above issue can be conquered by using a variety of programming techniques to assist farm owners in estimating the turnover of their production and motivating the farmers to stay in their field area. The prediction of cotton yield entails predicting the yield of the cotton from the present chronological information like climate, fertilizers and soil variables. The one technique used for cotton yield prediction with good accuracy is machine learning. Several algorithms have been used to forecast yields based on locality, land area and fertilizer data for several states in the USA. Here we are using gradient boosting algorithm which gives the better results compared to existing algorithms.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security', 'Mobile and Network Security']"
doi:10.1007/978-981-19-3035-5_39,en,An Efficient Text Detection and Recognition Framework for Natural Scene Images,OriginalPaper,"For understanding the content of the image, a vital clue is the superimposed text in images. However, ineffective text extraction might be caused by the poor contrast and complicated background of the image. An effective text detection and recognition framework as of natural scene images utilizing Anopheles search with convolution neural network are proposed to mitigate such complexities. In this work, for detecting and recognizing the exact text from the image, different steps are undergone by the input images from the street view text (SVT) dataset. The precise text is extracted from the images. For comparing the results attained by the proposed AS-CNN with the preceding top-notch algorithms, SVT and publically accessible datasets are utilized in this research. The experimental outcomes denoted that the proposed AS-CNN exhibits promising results, effectively decreasing the overall computation cost and time.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Statistics, general']"
doi:10.1007/978-981-19-4971-5_2,en,Performance Analysis of a Microgrid System Connected to a Grid Using EHO Technique,OriginalPaper,"Distributed energy resources (DERs) have become more appealing to feed local loads under the abstraction of microgrids (MG). The concept of microgrid (MG) is presented for better renewable energy penetration into the utility grid. Renewable sources being highly intermittent in nature, feeder power flow at substation bus bar is required to be controlled and coordinated. One of the foremost elements to amalgamate distributed generation (DG) unit in a MG is battery energy storage system (BESS). A MG embodying single-phase photovoltaic (PV) arrays and wind turbines (WT) that functions as a foremost distributed generation elements and the “battery energy storage system” to augment the spasmodic photovoltaic as well as wind power generation and the demand variation in the microgrid is presented in this work. Although there are many heuristic algorithms for solving this problem, however, we have considered a swarm-based heuristic algorithm elephant herding optimization (EHO). This algorithm has been utilized to eradicate the error in power flow for keeping up the balance of demand and generation by adjusting the attained values of all the PI controllers optimally. Simulink and MATLAB environment has been used to study the achievement of this propound system.","['Engineering', 'Power Electronics, Electrical Machines and Networks', 'Energy Policy, Economics and Management', 'Energy Systems']"
doi:10.1007/978-3-031-11047-4_11,en,QuCTS – single flux Quantum Clock Tree Synthesis,OriginalPaper,"Superconductive Rapid Single Flux Quantum (RSFQ) is an emerging cryogenic technology promising a significant boost in performance and ultra-low power consumption. The operating frequency achieved by RSFQ digital integrated circuits is several orders of magnitude greater than traditional CMOS circuits. The fundamental difference of RSFQ circuits, however, renders traditional clocking techniques appropriate for CMOS unsuitable for RSFQ technology. Most RSFQ logic gates, such as AND and OR, are sequential in nature. The number of pipeline stages is therefore significantly greater in RSFQ as compared to CMOS, complicating the clock distribution network design process. This issue is further exacerbated with the need for splitters to achieve a fanout greater than one and the need for transmission lines rather than ordinary metallic wires as in CMOS. In this work, QuCTS – single flux Quantum Clock Tree Synthesis – is presented. QuCTS utilizes a three stage framework for synthesizing clock networks. In the clock skew scheduling stage, the clock signal arrival time of each gate is chosen to maximize the robustness of the circuit to timing variations. In the clock tree topology stage, a topological graph of a binary clock tree is generated. In the clock tree synthesis stage, the layout of the clock distribution network is generated based on a novel proxy graph technique. QuCTS is the first clock tree synthesis tool for RSFQ circuits to exploit useful clock skew. The synthesized network satisfies the clock arrival time requirements while minimizing the associated overhead, such as the interconnect length and number of delay elements. The tool is validated on a set of benchmark circuits. In a prototypical case study, a clock tree for the AMD2901 with 1,049 clock sinks is generated in 53 minutes while satisfying the clock skew schedule.","['Engineering', 'Circuits and Systems']"
doi:10.1007/978-981-19-3571-8_21,en,Malware Family Categorization Using Genetic Algorithm-CNN-Based Image Classification Technique,OriginalPaper,Malware analysis and classification of malware families using different techniques is a prominent field of research. The presence of malware code in files has continuously increased over time making it tedious for companies to analyze the large number of files manually. We have used a novel machine learning image classification-based technique to classify images of malware files into their respective families. Classifying malware images using neural networks helps to simply the malware detection process. This research studied drawbacks in existing machine learning approaches and has used genetic algorithm built on the backbone of convolutional neural networks to implement a model which has achieved the objective of classifying new malware files into families on its own. This has helped achieve 98.11% classification accuracy on the MalImg dataset.,"['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-17548-0_16,en,A Decision Method for Missile Target Allocation,OriginalPaper,"Aiming at the weapon target allocation problem of multi-type anti-ship missile attacking ship formations, a multi-stage multi-target optimization model is established. The NSGA-II algorithm is used to solve the model. For the results of the multiple weapon target allocation schemes generated by the NSGA-II algorithm, a new method is proposed to select. A Combinative Distance-based Assessment and Gray rational Analysis (CODAS_GRA) method based on the improved expert method is used to select the unique optimal solution from the Pareto optimal solution set generated by the NSGA-II algorithm. Experiments show that the solution selected by this method can simultaneously maximize damage to the enemy and minimize the consumption of ammunition. This method is reasonable and can provide a better choice for the commander.","['Engineering', 'Data Engineering', 'Computational Intelligence']"
doi:10.1007/978-981-19-3679-1_62,en,Food Classification Using Deep Learning Algorithm,OriginalPaper,"Monitoring of food plays a significant role in leading health-related issues and tasks. With its multiple applications and features, image processing emerges to be an interesting field in the process of identifying food items. In this paper, a technique has been presented for classifying the food image using the You Only Look Once (YOLO) algorithm. Unlike the conventional artificial neural networks, the YOLO algorithm has more efficiency, and it has been trained on a loss function that corresponds straight to detection, and the complete model is trained with 6000 epochs. Due to the high variance in the alike domain of food images, food classification becomes a difficult task but it has a significant role in lives at the present time as it can be utilized by numerous sources. In this paper, a comparison of the working of the YOLO algorithm with other techniques that are used in image processing such as ResNet-50, VGG-16, ImageNet, and Inception has been elaborated. In this work, the famous dataset from Kaggle is used for implementation purposes. The dataset consists of 4000 Indian Food Image 80 different categories or classes. The proposed model is giving 99% accuracy for classifying the food.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-7780-0_23,en,Analysis of Technologies for Visual Tracking of Physiological Condition of Cattle,OriginalPaper,"At the moment, devices for monitoring the physiological condition of the animal are beginning to play an increasingly important role. These devices and systems allow for operational control and monitoring of the animal 24 h a day, 7 days a week, which allows specialists and engineers to make effective decisions on cattle management. The purpose of the paper: the development of models, analysis of methods and systems that allow predicting and assessing the physical condition of animals, detecting, and preventing diseases in cattle in real time. As a result of our analysis, we identified 25 promising studies and technologies that tested the accuracy and conditions for improving the accuracy of various monitoring devices for dairy herd animals to measure the duration and number of activities under different conditions, with different frequency, sampling intervals and editing criteria. This paper provides an overview of other popular studies conducted on cattle. The authors define the current state, problems, and possible ways of further development of dairy cattle health monitoring and herd management technologies based on visual feature recognition using artificial neural networks.","['Engineering', 'Control, Robotics, Mechatronics', 'Agriculture', 'Artificial Intelligence', 'Mechanical Engineering']"
doi:10.1007/978-981-19-0448-6_7,en,Energy-Efficient Resource Allocation in Heterogeneous OFDMA Networks,OriginalPaper,"In this chapter, we investigate the energy-efficient resource allocation in heterogeneous orthogonal frequency division multiple access (OFDMA) networks. Section  7.1 introduces the motivation of developing energy-efficient resource allocation for heterogeneous OFDMA networks. Section  7.2 presents the system model. Section  7.3 formulates the energy-efficient resource allocation problem as a mixed-integer nonlinear fractional programing (MINLFP) problem and transforms it into an equivalent concave mixed-integer nonlinear programing (MINLP) problem in a parametric subtractive form. Section  7.4 derives the global optimal solution. Section 7.5 decomposes the resource allocation into two sub-problems, namely resource block (RB) allocation and transmit power control (TPC), and develops the sub-optimal scheme. Section 7.6 presents the simulation results, and Sect. 7.7 concludes this chapter.","['Engineering', 'Wireless and Mobile Communication', 'Energy Systems']"
doi:10.1007/978-981-19-3998-3_172,en,Multi-agent Collaborative Region Exploration and Path Planning Based on Q-Learning Algorithm Under Communication-Limited Condition,OriginalPaper,"This paper addresses multi-agent cooperative region exploration and path planning. For region exploration, a double probability matrix updating rule based on distance weight is proposed and its convergence is proved by us. Compared with traditional Bayes updating rules, this updating rule improves the convergence speed of the exploration probability matrix and is applicable to multiple environments, thus improving the robustness. Secondly, a multi-agent region exploration strategy based on distance weight is proposed. Compared with the traditional coverage control algorithm, this method improves the search efficiency, reduces the variance of the results thus improves the confidence of the data. For path planning, a multi-agent hierarchical Q-learning algorithm is proposed and we use a multi-agent collaborative process of region exploration and path planning to visualize the influence of region exploration’s result on path planning algorithm. The above algorithm is modeled and simulated based on the cooperative search and rescue task at sea, and the simulation results verify the above conclusions.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-981-19-3387-5_95,en,Ka Band Satellite Communication Adaptive Coding and Modulation Technology Based on Artificial Intelligence LDPC Code,OriginalPaper,"Due to the rapid development of broadband satellite communication technology, the previous C band and Ku band can no longer meet the full range of needs in the communication field. Ka frequency band has outstanding performance with large bandwidth and good anti-interference ability, which can make Ka frequency band a commonly used frequency band in the field of satellite communication. However, rain attenuation is a key factor affecting Ka band satellite communication. In order to make the signal stable and accurate transmission in the satellite communication process and overcome the adverse effects caused by rain attenuation, it can be achieved through adaptive technology. In the context of artificial intelligence, this paper studies the adaptive coding and modulation technology based on LDPC codes in Ka band satellite communications. This article first made relevant research on Ka band satellite communication, and then designed an adaptive coding and modulation transmission mode. Finally, the performance of the maximum likelihood algorithm and the second-order-fourth-moment algorithm are analyzed through simulation experiments, and the normalized estimation errors and estimated variances of the two algorithms are compared, and the corresponding results are obtained according to the experimental results.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Aerospace Technology and Astronautics']"
doi:10.1007/978-981-19-2255-8_10,en,Turbo Equalization Technique for Data Link Communication Systems,OriginalPaper,"The development of data link has greatly changed the operation mode of modern war. The complexity of wireless communication channel makes the high rate of data transmission become one of the important research topics in data link communication technology. In order to enhance the reliability of the system, channel equalization technology can be used to eliminate ISI (Inter Symbol Interference). Equalization is similar to “whitening filter”, which is to “smooth” the frequency response of the channel. Different from the traditional equalization method, the equalization and decoding is combined in the Turbo equalization technology. By recycling the soft information, the bit error rate can be reduced. The Turbo equalization technology can make full use of known information. The soft information can be recycled in each iteration. The simulation results show that the performance of data link communication system can be improved by the Turbo equalization technique. This paper mainly studies the Turbo equalization technology for data link communication systems.","['Engineering', 'Communications Engineering, Networks', 'Wireless and Mobile Communication', 'Signal, Image and Speech Processing', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-19620-1_49,en,An Approach to Fusing Strategic Objectives into Agent-Level Decision Making in Load Balancing,OriginalPaper,"Apart from the increased amount of data being transferred, modern networks are characterized by high complexity of their topology. This is one of the reasons why conventional architectural approaches and technologies are now constantly subjected to series of modifications the most crucial of which is caused by the necessity for decentralized operation. There exists a good portion of algorithms which enable handle this problem. However, only a few of those optimize against multiple objectives, much less enable subjecting a network to coordination. In this paper, we propose an approach that enables setting of multiple objectives for load balancing process in a way so it only requires a coordinating entity to operate with strategic-level terms. Decisions made on this level fuse into local-level decision making performed by individual agents (network nodes), thus enabling separation of responsibilities in terms of scope thus allowing to fit the process of load balancing taking states of the network’s particular parts into consideration.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3938-9_45,en,Extension of Particle Swarm Optimization Algorithm for Solving Priority-Based Time Minimization Transportation Problem,OriginalPaper,"The transportation problem is generally intended to minimize the transportation cost while distributing products from sources to destinations. When there is urgent need, like in pandemic situation, of delivery of products to destinations, the time minimization transportation problem is indispensable. In such urgent situations, there may certain destinations whose demands need to be satisfied earlier than the others. This situation is dealt by prioritizing the destinations to minimize the transportation time. This article proposes two new algorithms to be blended within a particle swarm optimization algorithm for solving priority-based time minimization transportation problem. Being a metaheuristic method, PSO has empowered with exploration-exploitation trade-off expertise and converging competence leading toward global optima. The proposed method is examined over different test problems, and it performed well with respect to its efficiency and efficacy. Some statistical measures like mean and standard deviation are also calculated to evaluate the proposed method.","['Engineering', 'Mathematical and Computational Engineering', 'Optimization', 'Machine Learning']"
doi:10.1007/978-3-031-21062-4_19,en,Multi-robot Coordination for a Heterogeneous Fleet of Robots,OriginalPaper,"There is an increasing need for autonomous mobile robots (AMRs) in industrial environments. The capability of autonomous movement and transportation of items in industrial environments provides a significant increase in productivity and efficiency. This need, coupled with the possibility of controlling groups of heterogeneous robots, simultaneously addresses a wide range of tasks with different characteristics in the same environment, further increasing productivity and efficiency. This paper will present an implementation of a system capable of coordinating a fleet of heterogeneous robots with robustness. The implemented system must be able to plan a safe and efficient path for these different robots. To achieve this task, the TEA* (Time Enhanced A*) graph search algorithm will be used to coordinate the paths of the robots, along with a graph decomposition module that will be used to improve the efficiency and safety of this system. The project was implemented using the ROS framework and the Stage simulator. Results validate the proposed approach since the system was able to coordinate a fleet of robots in various different tests efficiently and safely, given the heterogeneity of the robots.","['Computer Science', 'Robotics', 'Robotics and Automation', 'Computational Intelligence']"
doi:10.1007/978-981-19-3998-3_35,en,Dynamic Target Search of UAV Swarm Based on Improved Pigeon-Inspired Optimization,OriginalPaper,"In this paper, an improved pigeon-inspired optimization (IPIO) algorithm based on natural selection and Gauss-Cauchy mutation is proposed for unmanned aerial vehicle (UAV) swarm to rapidly realize cooperative dynamic target search and full coverage of target area under uncertain environment. Firstly, the environment awareness map is established, which includes coverage distribution map, target probability map (TPM), digital pheromone map and their updating mechanism. Meanwhile, in order to improve the possibility of discover targets, the target probability map is integrated into the attraction pheromone updating mechanism. Next, by the helps of the above environment awareness map, a reasonable collaborative search task optimization model is designed. Furthermore, based on the classical PIO algorithm, the integer encoding method, discrete compass operator and discrete landmark operator are designed in detail. Gaussian mutation and Cauchy mutation operators are introduced to guarantee the evolution escaping from local optimum, and natural selection is applied to accelerate the convergence. Finally, the simulation results show the effectiveness and superior of the proposed target search strategy.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-981-19-5615-7_1,en,A Scheduling Plan Model for Metro Crew Incorporating Fatigue and Biological Rhythms,OriginalPaper,"Crew scheduling is one of the critical planning decisions in railway transportation. The existing scheduling and rostering methods usually take the lowest cost as the objective, ignoring the metrzzo crew members’ fatigue and biological rhythms. This paper proposed an optimization approach considering fatigue's impact on solving real-world metro crew scheduling and rostering problems. The shift work characteristics of the metro crew were analyzed firstly. The usability of the Ikeda formula for fatigue evaluation was verified and applied to the metro crew. Then the metro crew scheduling and rostering model were described, and the process of incorporating fatigue factors into the model was demonstrated. Moreover, using the genetic algorithm to solve the problems. Finally, this model was applied to the Beijing Metro Yanfang Line. The results illustrated that the method could significantly reduce the metro crew members’ fatigue value with optimized operating costs.","['Engineering', 'Transportation Technology and Traffic Engineering', 'Computational Intelligence', 'Automotive Engineering', 'Energy Policy, Economics and Management', 'Mechanical Engineering']"
doi:10.1007/978-3-031-18461-1_36,en,Resampling-Free Bootstrap Inference for Quantiles,OriginalPaper,"Bootstrap inference is a powerful tool for obtaining robust inference for quantiles and difference-in-quantiles estimators. The computationally intensive nature of bootstrap inference has made it infeasible in large-scale experiments. In this paper, the theoretical properties of the Poisson bootstrap algorithm and quantile estimators are used to derive alternative resampling-free algorithms for Poisson bootstrap inference that reduce the computational complexity substantially without additional assumptions. These findings are connected to existing literature on analytical confidence intervals for quantiles based on order statistics. The results unlock bootstrap inference for difference-in-quantiles for almost arbitrarily large samples. At Spotify, we can now easily calculate bootstrap confidence intervals for quantiles and difference-in-quantiles in A/B tests with hundreds of millions of observations.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4193-1_67,en,Exoplanet Hunting Using Machine Learning,OriginalPaper,"With the rapid expansion in the field of aeronautical engineering and its technology, the unseen and unknown area is now in our view and vision. The planets which are light years distant from our galaxy are now visible due to such advancement in the field of astronomy. In basic terms, Exoplanets may be defined as gigantic planets revolving around a star in an unknown possibly habitable galaxy. Due to the rise in temp of Earth, it becomes necessary to identify and gather information about another habitable planet. Such critical data is needed to be processed using machine learning and its models. Therefore, the models are trained and implemented from scratch to provide meaningful information from a humongous set of data. This paper illustrates the implementation and functioning of advanced algorithms to categorize whether the mass found is a planet or debris with the help of flux variation of the stars.","['Engineering', 'Computational Intelligence', 'Information Storage and Retrieval', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Data Structures and Information Theory', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5574-7_9,en,Intelligent Virtual Reference Feedback Tuning Based Data Driven Control for Power Plant,OriginalPaper,Pulverizing system is an integral part of the coal-fired power plant. The safe and efficient operation of pulverizing system is very important to improve the economy of the plant.,"['Engineering', 'Control, Robotics, Mechatronics', 'Energy Systems', 'Computational Intelligence']"
doi:10.1007/978-981-19-3250-2_5,en,Pre-Characterization Techniques for the FRW Based Capacitance Extraction and Simulation,OriginalPaper,"Accurate capacitance extraction and simulation considering various multi-dielectric environment in integrated circuits (ICs) or flat panel displays (FPDs) is a challenging task. For the floating random walk (FRW) method, the pre-characterization approaches must be employed to accurately handle multi-dielectric structures. In this chapter, we improve the pre-characterization approach in Yu et al. ( 2013 ) by permitting the cubic transition domains to contain three or four dielectric layers. This results in the techniques of pre-characterizing and utilizing these multi-dielectric-layer transition cubes. Then, a unified pre-characterization scheme is proposed to suit arbitrary multi-layer dielectric profiles. It avoids the pre-characterization dependent on specified dielectric profile, and preserves high accuracy. Experiments on the test cases under actual manufacture technologies show that the improved pre-characterization approach averagely brings 13X speedup over the approach in Yu et al. ( 2013 ), with affordable memory overhead. The experiments also reveal the significant error caused by the dielectric homogenization approach in a commercial FRW solver. With the comparisons to other pre-characterization schemes, we finally show that the unified dielectric pre-characterization scheme exhibits the highest accuracy while costing the least memory usage, for test cases from IC and FPD design.","['Engineering', 'Electronics and Microelectronics, Instrumentation', 'Engineering Mathematics']"
doi:10.1007/978-3-031-18050-7_11,en,An Extremal Optimization Approach to the Pairwise Connectivity Critical Node Detection Problem,OriginalPaper,"The critical node detection is a computational challenging problem with several applications in biology, sociology, etc. Minimizing the pairwise connectivity after removing k critical nodes is one of the most studied problem. In this paper we approach this problem by using a standard Extremal Optimization algorithm, and another variant with incorporated network shifting mechanism. Network centrality measures are used to speed up the search, the variants are analyzed on synthetic and real-world problems. Numerical results indicate the potential of the proposed approach.","['Engineering', 'Computational Intelligence', 'Industrial and Production Engineering']"
doi:10.1007/978-981-19-3035-5_1,en,Cluster Head Selection Based on Mapping-based Cuttlefish Optimization Algorithm for Multipath Routing in MANET,OriginalPaper,"The study develops the mapping-based cuttlefish optimization algorithm (MCFA) to select the cluster head (CH). A local and global search integration is occurred by using this algorithm, and chaos mapping is introduced to solve the issues of trapping in local optimum. NS-2 tools are used and test the efficiency of the MCFA algorithm with ant colony optimization (ACO) in terms of path optimality, delay time, etc. The results prove that the proposed MCFA achieves better performance than the existing ACO algorithm.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Statistics, general']"
doi:10.1007/978-3-031-02097-1_5,en,The Application of Encryption Algorithm in Information Security Reflected,OriginalPaper,"Computer mass data transmission and information security has always been the focus of scientific research scholars and industry economic innovation. The file system is an important part of the operating system to manage and store file information. File access must be performed through the file system. Therefore, encryption technology is integrated during the system running to ensure the physical security of file data. Based on the understanding of network file transfer encryption key technology on the basis of the proposed hybrid encryption based on AES and ECC algorithm, to solve the previous single password encryption algorithm efficiency is too low or loopholes in management, and design system for the function and performance test and analysis, the final result shows that this article research institute to build file encryption system, can meet the demand of practical work.","['Engineering', 'Mechanical Engineering', 'Computational Science and Engineering', 'Theoretical, Mathematical and Computational Physics']"
doi:10.1007/978-981-19-3679-1_38,en,Full Connectivity Driven K-LEACH Algorithm for Efficient Data Forwarding in Wireless Sensor Networks,OriginalPaper,"Due to the usage of Internet in everything in our life, our environment is transformed into digital society, in which everything can be accessed from anywhere. This is the main concept of Internet of Things (IoT), which consists of intelligent devices connected together without location limitation. These devices can be sensors and actuators, which are used in environmental monitoring, home automation, disaster management and more. This is the definition of Wireless Sensor Network (WSN), which is considered a subset from IoT environment. WSN consists of hundreds of nodes spread in different area for monitoring different physical objects, it suffers from highest energy consumption of nodes, which affect network lifetime. Different routing protocols are used to cope with this challenge, Low Energy Adaptive Clustering Hierarchy (LEACH) protocol is the most common used one. LEACH is a cluster-based micro sensor network protocol that offers energy-efficient, and scalable routing for sensor nodes. So, in this paper, we investigate and present a modified algorithm using LEACH in conjunction with K-means clustering approach in order to achieve a Full Connectivity Driven K-LEACH algorithm (FCDK-LEACH). Based on the CH selection, the k-means algorithm aids in decreasing energy usage and therefore extending network lifetime. The CH is chosen based on the remaining energy level and the CH’s position with relation to the sensor node. The evaluation results show that our modified k-means-based hierarchical clustering enhances network lifetime.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1457-7_51,en,"Simulated Performance of an Improved District Cooling System (DCS) in Tronoh, Perak, Malaysia",OriginalPaper,"District cooling system (DCS) is a popular cooling solution for many institutional applications in Malaysia due to the energy-saving advantages as compared to traditional individual on-site cooling production. However, the problem with DCS is that it’s designed on fixed parameters automation prior to its commissioning and system performance is inefficient by the inability to adapt to uncertainties during operation. Objective of this DCS study is to propose a feedback control algorithm to be implemented in a DCS in Malaysia, as well as assess the proposed algorithm for further improvement. A case study of an existing DCS in Tronoh, Perak is performed in MatLab Simulink. The existing algorithm and the proposed algorithm of improved scheduling are implemented, and the simulation results have compared. The motivation of the new algorithm developed is to see further energy-reduction optimization, especially at the TES charging hours at low demand. The simulation results show improvements in the system efficiency of increased 22.6% (weekdays) and 48.2% (weekends) with reduced overall cooling output, and system energy savings of between 18.7% (~17 MWh at weekdays) and 32.1% (~21 MWh at weekends). Simulated model compared with historical data shows that the simulation model cannot replicate the exact conditions and output values of the actual DCS, but the trend of the output data is sufficiently accurate to model the improvements of implementing feedback control.","['Engineering', 'Automotive Engineering', 'Engineering Fluid Dynamics', 'Energy Storage']"
doi:10.1007/978-3-031-12127-2_12,en,Feature Extension for Chinese Short Text Based on Tongyici Cilin,OriginalPaper,"Since the short text has characteristics such as sparse features, calculating its similarity is a considerable challenge. However, there is less research on the method of Chinese short text feature extension in short text similarity calculation. Therefore, to have a deeper understanding of the method on using feature extension in the similarity of Chinese short texts, this paper adopts a feature extension algorithm based on an external thesaurus Tongyici Cilin (extended) for short texts. The purpose is to solve the feature sparseness problem of Chinese short text feature vectors. Firstly, segment words in the short text according to certain rules with high surface similarity and extract the main difference components in the text. Then, calculate the similarity of the major difference components between the two short texts based on Cilin. Finally, perform feature extension according to the similar results in the corresponding short text. In the large-scale Chinese Question Matching Corpus LCQMC, a variety of unsupervised models are used for testing. The experimental results show that the method in this paper has a certain improvement effect on various spatial vector similarity algorithms. It can achieve accuracy rates and F1-score of about 3% improvements.","['Engineering', 'Computational Intelligence', 'Information Systems and Communication Service', 'Management of Computing and Information Systems']"
doi:10.1007/978-3-031-13786-0_10,en,Wide Band THz Antenna Design Using Salp Swarm Algorithm for 6G Communications Systems,OriginalPaper,"The future 6G wireless communications will need the definition of new spectral bands and the employment of novel advanced physical layer solutions. The millimeter-wave (mmWave) frequency bands have been allocated for the fifth generation (5G) of cellular systems, while additional mmWave sub-bands have been assigned as well. The need to support higher data rates than 5G in the order of terabits per second requires more bandwidth. However, the total consecutive available bandwidth in mmWave bands is still less than 10 GHz, so such data rates cannot be supported. In this context, future 6G communication systems require the use of the terahertz communication band (0.1–10 THz). The THz band is envisioned as a critical wireless technology for meeting future demands in 5G and beyond. For several years, there has been a lack of THz transceivers and antennas, so that the THz band has become one of the electromagnetic (EM) spectrum’s least studied frequency ranges in terms of wireless communication. However, the need for 6G communication systems has redefined the requirements for THz antennas. In this book chapter, we provide a complete framework for circular polarized antenna design in the low THz band. This optimization framework is based on a swarm intelligence algorithm, namely, the salp swarm algorithm (SSA). The numerical results show that the SSA has been successfully applied in designing antenna with wide band operation and circular polarization.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Computer Communication Networks']"
doi:10.1007/978-3-031-15928-2_56,en,Numerical Optimization of a Composite Sandwich Panel with a Novel Bi-directional Corrugated Core Using an Animal-Inspired Optimization Algorithm,OriginalPaper,"Composite sandwich panels with honeycomb, corrugated, tetrahedral, trapezoidal, 3D periodic and hybrid lattice cores have long been studied for their use in various industrial fields. In this study, several numerical analyses were conducted in ANSYS APDL environment in order to analyze the effect of a novel bi-directional corrugated core configuration on the flexural performance of a CFRP sandwich panel. In particular, the sandwich core is obtained by repeating a regular unit cell in two different directions to form a three-dimensional lattice structure. In order to determine the optimal values of the geometrical parameters of the core unit cell and to evaluate how the layout of the composite laminate could affect the mechanical performances of the structure, a numerical study was conducted by using the Group Search Optimizer (GSO) algorithm, a metaheuristic animal-inspired optimization algorithm used to solve various real-world problems. The obtained results show that the GSO algorithm is very effective to optimize the main geometrical parameters of the composite sandwich panel with the novel bi-directional corrugated core. More generally, the implemented procedure provides an open framework to solve complex optimization problems that are very difficult to solve using exact methods, making the GSO algorithm particularly attractive for many industrial applications.","['Engineering', 'Engineering Design', 'Industrial and Production Engineering', 'Computer-Aided Engineering (CAD, CAE) and Design']"
doi:10.1007/978-3-031-21062-4_18,en,A Novel Algorithm for Maximization of the Secondary-Task Function for Redundant Serial Manipulators,OriginalPaper,"Redundant manipulators can employ additional degrees to achieve secondary objectives when performing the trajectory tracking, such as avoiding the mechanical limits of the manipulator’s joints through the Jacobian null space properties. This article presents an improvement to the classical kinematic solution for redundant serial manipulators, changing the secondary gains to a variable vector that replaces the constant scalar gain. Also, a method is suggested for the variation of those gains. The application is demonstrated in trajectories for the Movemaster RV-M2 robot to prove the effectiveness of this change. As a result, the path of the manipulator’s joints remains further away from their limits along the path, maintaining the position error profile in the end-effector.","['Computer Science', 'Robotics', 'Robotics and Automation', 'Computational Intelligence']"
doi:10.1007/978-981-19-7648-3_11,en,QoS-Aware Caching Resource Allocation,OriginalPaper,"Recently, wireless streaming of on-demand videos of mobile users (MUs) has become the major form of data traffic over cellular networks. As responding, caching popular videos in the storage of small base stations (SBSs) has been regarded as an efficient approach to reduce the transmission latency and alleviate the data traffic loaded over backhaul channels. This work considers a small-cell based caching market composed of one mobile network operator (MNO) and multiple video service providers (VSPs). In this system, the MNO manages and operates its SBSs, and assigns these SBSs’ storage to different VSPs, who have caching requirements. However, videos have different popularities and MUs present different preferences to these VSPs when they request videos. In addition, the caching service brings different utilities to different VSPs, as well as that providing caching service to different VSPs causes distinct costs to the MNO. Such privacy information cannot be aware of among VSPs and the MNO. Therefore, to elicit this hidden information, this chapter designs a double auction based caching mechanism, which ensures the efficient operation of the market by maximizing the social welfare, i.e., the gap between VSPs’ caching utilities and MNO’s caching costs. Moreover, the chapter demonstrated economic properties of the designed caching mechanism, which are also validated by simulation results.","['Computer Science', 'Computer Systems Organization and Communication Networks', 'Communications Engineering, Networks', 'Wireless and Mobile Communication']"
doi:10.1007/978-3-031-02097-1_9,en,The Application of Adaptive Algorithm in the Maximum Power Tracking of Power Photovoltaic System,OriginalPaper,"Solar energy, as a kind of clean energy, has played a positive role in the development of today’s society. However, the low efficiency of power generation is the main reason for the slow development of this energy. How to accurately track the maximum power of solar energy is the main subject of current research scholars. Therefore, on the basis of understanding the operation of the power photovoltaic system, this paper systematically understands the content of the adaptive algorithm, and conducts experimental exploration and analysis to prove the application performance of the adaptive algorithm in the maximum power tracking of the power photovoltaic system.","['Engineering', 'Mechanical Engineering', 'Computational Science and Engineering', 'Theoretical, Mathematical and Computational Physics']"
doi:10.1007/978-981-19-2273-2_13,en,Delineation of Pavement Stretches into Homogeneous Sections Using Pavement Condition Data: An Optimization Approach,OriginalPaper,"The paper illustrates a dynamic programming-based search algorithm known as the Pruned Exact Linear Time (PELT) algorithm to produce a solution for an optimization problem to identify change-points within the measurement series to delineate a pavement stretch into homogeneous sections. The data used in this paper was measured using a Falling Weight Deflectometer (FWD) in the runway stretch of an international airport with a length of 3220 m. This paper also comprehensively demonstrates two other existing methods, namely Cumulative Difference Approach (CDA) and Bayesian Segmentation Method, for delineating the same pavement stretch into homogeneous sections. Some of the shortcomings of both the methods have been discussed and the algorithms have been modified to overcome few of the drawbacks. This paper also formulated a comparative study between the three methods in terms of their sensitivity toward type of data, profound mathematical definition of homogeneity, computational complexity and ability for post-segmentation analysis for identification of homogeneous sections.","['Engineering', 'Transportation Technology and Traffic Engineering', 'Building Construction and Design', 'Mechanical Engineering']"
doi:10.1007/978-3-031-14859-0_23,en,Population-Based Methods to Reduce the Colors of an Image,OriginalPaper,"The color quantization problem consists of reducing the number of different colors used to represent an image. Although current devices can render images with many different colors, this is not necessary for many image processing applications. On the contrary, many of these processes require as an initial step to reduce the number of colors in the image. This work describes several color quantization methods based on the use of populations of individuals that collaborate in the resolution of a complex problem. These methods mimic the social behavior observed in various types of animals. Each of the individuals is only capable of performing very simple operations, but when a group of individuals is considered they can perform complex tasks. This solution approach is interesting because it has been shown to yield better quality images than many of the classic color reduction methods. This document briefly describes some of the most interesting methods and shows computational results of their application.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-18409-3_6,en,Powerful Biogeography-Based Optimization Algorithm with Local Search Mechanism for Job Shop Scheduling Problem with Additional Constraints,OriginalPaper,"This paper proposes a Hybrid Biogeography-Based Optimization algorithm for solving the Job shop Scheduling Problem with additional constraints of Time Lags and transportation time using a Single Transport Robot to minimize the makespan (Completion time of the last operation executed). Biogeography-Based Optimization (BBO) algorithm is an evolutionary algorithm inspired by the mi-gration of species between habitats. It has successfully solved optimization prob-lems in many different domains and has demonstrated excellent performance. In order to improve the optimization efficiency of BBO algorithm, the Greedy con-structive heuristic is used for population initialization to guarantee the diversity of solutions and the local search metaheuristic is used for the mutation step. The ef-ficiency of the proposed algorithm is demonstrated by using new set of bench-marks for the problem. Numerical results show that the proposed Hybrid BBO algorithm not only significantly improves the performance of the standard BBO algorithm, but also finds competitive results compared with recently developed optimization methods.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Education, general']"
doi:10.1007/978-981-19-6072-7_3,en,Intelligent Sensing and Identification of Train Power System,OriginalPaper,"Each component of the train power system and its operation status cannot be set with traditional contact sensors (devices) to achieve information collection and transmission. In particular, the moving parts cannot use the contact sensing technology at all. Even if the micro-sensor can be “placed” on the moving parts, the wireless transmission method must be used to transmit the sensing signal.","['Engineering', 'Automotive Engineering', 'Artificial Intelligence', 'Transportation Technology and Traffic Engineering']"
doi:10.1007/978-981-19-2635-8_45,en,Trajectory Planning of Tilt-Rotor UAV Based on Hybrid Algorithm,OriginalPaper,"Tilt-rotor UAVs are exceptionally suitable for near-ground unmanned transportation and other fields because of their helicopter mode, transition mode and fixed-wing mode. However, the tilt-rotor transition on trajectory planning presents a challenge, as performance constraints of different modes must be considered and a trajectory planning algorithm is required to optimize a collision-free and short trajectory with low fuel consumption and small cost. To address these challenges, this paper adds performance constraints of the tilt-rotor UAV to the hybrid algorithm by combining the A* algorithm and the artificial potential field method; meanwhile, the rationality of trajectory planning is improved by setting the tilt-rotor transition region separately in the global. Simulation results show that a reasonable trajectory can be planned by setting the tilt-transition region by itself and using a hybrid algorithm.","['Engineering', 'Aerospace Technology and Astronautics', 'Engine Technology', 'Automotive Engineering', 'Mechanical Engineering']"
doi:10.1007/978-981-19-4594-6_5,en,Optimal Control Using Time Series AI Models,OriginalPaper,"This chapter deals with simulated annealing optimal search control using time series AI models such as neural network predictors. The first half of the chapter provides mathematical bases of these modeling, and the latter half shows practical application examples of the optimal search control of building air-conditioner power consumption under real-time electricity pricing.","['Engineering', 'Control, Robotics, Mechatronics', 'Machine Learning', 'Control and Systems Theory', 'Artificial Intelligence', 'Systems Theory, Control']"
doi:10.1007/978-3-031-05491-4_25,en,A Novel Defense Mechanism Against Label-Flipping Attacks for Support Vector Machines,OriginalPaper,"Datasets are important for machine learning for training, and they can be searched on the Internet these days. However, attackers may attack datasets by label flipping attacks. Therefore, a method to defend against the attack is needed. In this paper, we propose an algorithm with two processes, namely sanitizer and defender (SPD), to protect against uncertain datasets and label flipping attacks. We also conduct a series experiments to validate the relabeled dataset and maintain the accuracy of the support vector machine (SVM). Our experiment results show that the proposed SPD algorithm can effectively block the attack by relabeling the dataset and gain high accuracy with relabeled data.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Engineering', 'Big Data', 'Mathematical and Computational Engineering']"
doi:10.1007/978-981-19-3387-5_11,en,LDPC Coding and Decoding Algorithm of Satellite Communication in High Dynamic Environment,OriginalPaper,"In this digital age, modern communication system plays an important role in almost all aspects of life, such as mobile network and satellite communication to the Internet and data transmission. This paper analyzes the concept of high dynamic environment, satellite communication system and LDPC algorithm. The results show that the resource cost of the rate editor of regs is higher than that of LUTS. Look up table LUTS, register regs and two kinds of encoders can be selected.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Aerospace Technology and Astronautics']"
doi:10.1007/978-3-031-09835-2_21,en,An Improved Cuckoo Search Algorithm for the Capacitated Green Vehicle Routing Problem,OriginalPaper,"Vehicle routing is an optimization problem that determines the shortest path to take while delivering products to consumers. Recently, increasing environmental awareness has led scientists and practitioners to find solutions to reduce the emission gases that cause environmental pollution. These environmental concerns are taken into account in the solution of the green vehicle routing problem, a variant of the vehicle routing problem. For this reason, it has become a frequently studied subject in the literature in recent years. The Modified Cuckoo Search Algorithm, a swarm-based optimization approach, was used in this study to provide a solution to the green vehicle routing problem. When the solutions obtained as a result of the experiments with two different solution models were examined, it was concluded that the method could not show the performance it showed in continuous optimization problems despite the changes made on it.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-14630-5_8,en,Riscophrenia: The Risk Fallacy and the Repression of Uncertainty,OriginalPaper,"Contemporary society has elevated the concept of risk to the status of dogma. That this concept may be converted to a mathematical-probabilistic measure supposedly offers security and control over contingencies and random events. Probabilistic risk is part of the current societal obsession with quantification for grasping realities and making forecasts. The disproportionate use of the notion of risk places many different phenomena under the same conceptual umbrella, subjecting them to the reductionist criteria of rule by calculation. I put forward the concept of riscophrenia to describe this tendency. This chapter criticises riscophrenia, that is to say, the inflated use of the notion of risk and the fallacy that chance can be eliminated, knowing that such efforts are inglorious, neglect the prudential principle, and may produce new unpredictabilities and uncertainties. Risk analyses are unable to question the fundamental reasoning embedded in the instrumental vision which permeates modernity. They not only adjust themselves to the model which produces those problems, but also legitimise, justify and ratify it.","['Philosophy', 'Philosophy of Technology', 'Science and Technology Studies', 'History of Technology']"
doi:10.1007/978-981-19-5077-3_32,en,Prediction of Interface Friction Angle Between Landfill Liner and Soil Using Machine Learning,OriginalPaper,"This study employs machine learning (ML) techniques and artificial neural networks (ANN) to predict the interface friction angle between the landfill liner and the soil. The interface behavior is majorly affected by the thickness of landfill liner (t), mass of landfill liner (m), tensile strength of landfill liner (T), cohesion of soil (cu), angle of shearing resistance of soil ( Φ ), shear strength ( τ ), and normal stress ( σ ). As the stability of landfill liner varies significantly from that of the soil due to the non-homogeneity and anisotropic character of the soil, it is critical to comprehend the interface behavior between the landfill liner and the soil. However, no prior research employing machine learning techniques to analyze the interface behavior between landfill liners and soil has been reported; a study using machine learning algorithms and artificial neural networks is carried out on 66 datasets to probe the interface behavior with the help of an ANACONDA navigator. Further, to understand the impact of input variables on the output variable, Pearson’s correlation coefficients were determined. Mean absolute error (MEA) is considered as a loss function, and the best model was chosen based on the r 2 -value. Random forest regressor (RFR) model is determined to be the best model among the available models with an r 2 -score of 0.99 and a minimum mean absolute error of 0.46.","['Environment', 'Environment, general', 'Geoengineering, Foundations, Hydraulics', 'Sustainable Development', 'Environmental Engineering/Biotechnology']"
doi:10.1007/978-981-19-6290-5_9,en,Security Issues in Deep Learning,OriginalPaper,"Deep learning has created substantial improvements for industries and set the tempo for a destiny constructed on artificial intelligence (AI) technology. Nowadays, deep learning is turning into an increasing number of vital in our everyday lifestyles. The appearance of deep learning in many applications in life relates to prediction and classification such as self-driving, product recommendation, classified ads and healthcare. Therefore, if a deep learning model causes false predictions and misclassification, it may do notable harm. This is largely a critical difficulty inside the deep learning model. In addition, deep learning models use big quantities of facts inside the training/learning phases, which in corporate touchy facts can motivate misprediction on the way to compromise its integrity and efficiency. Therefore, while deep learning models are utilized in real-world programs, it's mile required to guard the privateness facts used inside the model. The countless opportunities and technological abilities that system learning has added to the arena have concurrently created new safety dangers that threaten development and organizational development. Understanding system learning safety dangers is one of every of our contemporary technological time's maximum vital undertakings due to the fact the results are extraordinarily high, mainly for industries along with healthcare in which lives are at the line. We talk about the forms of system mastering safety dangers that you may stumble upon so you may be higher organized to stand them head-on.","['Computer Science', 'Systems and Data Security', 'Cyber-physical systems, IoT', 'Professional Computing', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3391-2_2,en,Is Tiny Deep Learning the New Deep Learning?,OriginalPaper,"The computing everywhere paradigm is paving the way for the pervasive diffusion of tiny devices (such as Internet-of-Things or edge computing devices) endowed with intelligent abilities. Achieving this goal requires machine and deep learning solutions to be completely redesigned to fit the severe technological constraints on computation, memory, and power consumption typically characterizing these tiny devices. The aim of this paper is to explore tiny machine learning (TinyML) and introduce tiny deep learning (TinyDL) for the design, development, and deployment of machine and deep learning solutions for (an ecosystem of) tiny devices, hence supporting intelligent and pervasive applications following the computing everywhere paradigm.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Statistics, general', 'Cyber-physical systems, IoT', 'Professional Computing', 'Communications Engineering, Networks']"
doi:10.1007/978-3-031-17024-9_6,en,Multiple Instance Learning Based on Mol2vec Molecular Substructure Embeddings for Discovery of NDM-1 Inhibitors,OriginalPaper,"In this paper, we first present a new dataset of NDM-1 biological activities that is compiled by a cleaned version of the NMDI database. A literature review enriched the former database by 741 new compounds, comprising activities against NDM-1 classified in three classes (inactive, weakly and strongly active compounds) by specifying a unifying procedure for the labeling, which covers a range of different activity properties. Second, we restate the classification problem in the Multiple Instance Learning (MIL) setting by representing the compounds as a collection of Mol2vec vectors, each of them corresponding to a specific substructure (either atom or atom including their firsts neighbors). We observe an amelioration up to 45.7% and 38.47% in respect to balanced accuracy and F1-score, respectively, for the strongly active class in the MIL approach when compared to the classical Machine Learning paradigm. Finally, we present a classification and ranking framework based on classifiers learned by a k-fold CV procedure, which possess different hyper-parameters per fold, learnt by a Bayes optimization procedure. We observe that the top-3 and top-5 ranked accuracies of the strongly active classified compounds yield 100% for the MIL setting.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Bioinformatics']"
doi:10.1007/978-981-19-4863-3_53,en,Predominant Role of Artificial Intelligence in Employee Retention,OriginalPaper,"The present study throws light on the role of artificial intelligence in human recourses. As technology is changing very rapidly so many industries adopted this system to give more satisfaction to the employees. An employee plays a vital role in the organization. New techniques and technologies are used by the organization to maintain their employees. It is important for all organizations that offer more benefits to the employee. The validity and reliability of the questionnaire were validated by Cronbach’s alpha. The present study is based on the previous literature research “Factors” with the help of this literature review, a structured questionnaire was developed. AI technology will continue to grow and at some point in future, AI will be the norm and the old-fashioned recruiting and hiring processes will seem stone-age. There is a positive relationship between the hiring and training for employees with AI and find the factor which employees are required to be done with AI. With the help of SPSS, the study was found that AI showing a positive relationship with the human resource department as well as with employees. With the help of the Radom sampling technique, the data was collected from the different companies’ employees ( N  = 50).","['Engineering', 'Computational Intelligence', 'Engineering Design', 'Machine Learning', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-3026-3_8,en,Cloud Computing Development Trends,OriginalPaper,"Kubernetes is a multi-tenant architecture. When multiple tenants or teams share a Kubernetes system, the system administrator needs to prevent the tenants from occupying resources and define resource allocation strategies. Kubernetes provides the API object ResourceQuota to implement resource quotas. ResourceQuota can not only act on CPU and memory, but also limit the number of Pods created. The computing resource quotas and resources supported by ResourceQuota are shown in Tables 7.4 and 7.5.","['Computer Science', 'Professional Computing']"
doi:10.1007/978-3-031-15218-4_4,en,Brains for Buildings to Achieve Net Zero,OriginalPaper,"Sustainable use of energy sources is one of the most important issues in modern society and therefore of great importance in the built environment. Construction installations account for approximately 36% of total energy consumption and consume on average 25% more energy due to inefficiency. There is a large unused potential of energy management systems, which can potentially achieve 20–30 PJ final savings through application in non-residential construction already in a small country like the Netherlands. A good design is important but also maintaining performance and condition in operation over the years. Most buildings have many problems with comfort and indoor air quality. The maintenance of the installations is more action oriented than performance oriented, which means that the costs are higher and the number of malfunctions and nuisances for the user higher. Therefore, it is important to detect deviations as soon as possible with continuous commissioning, so that there is constant monitoring of all circumstances and error detection in combination with a diagnosis. The European Commission has adopted the revised European Energy Performance of Buildings Directive (EPBD III) with the aim of improving the energy efficiency of buildings, thereby reducing energy consumption. The directive was implemented in Dutch laws and regulations on March 10, 2020. The EPBD III prescribes system requirements for improving the energy performance of technical building systems. The current building management systems cannot comply with this. Data is produced and (sometimes) shown in graphs, but analysis thereof is missing and is not automated; interfaces to inform and support the administrator in his decisions are very limited. The energy transition requires more optimally functioning installations that use less energy. Users want healthier and more productive climate conditions. The complexity of the installations increases sharply and therefore the necessary experience and knowledge to solve problems. There is a growing shortage of experienced people who are able to analyse this data. Therefore, it is becoming increasingly important to develop systems to automate these continuous monitoring, error detection and diagnostic functions. It is important to improve and safeguard the methods for data analysis and control related to GBS and measurement and control systems of installations and to develop suitable algorithms based on big data analytics and machine learning.","['Energy', 'Sustainable Architecture/Green Buildings', 'Renewable and Green Energy', 'Building Construction and Design', 'Energy Policy, Economics and Management']"
doi:10.1007/978-981-19-0108-9_28,en,Role of Artificial Intelligence in Energy and Power Engineering,OriginalPaper,"Over the last decade, the energy issue has been a major source of concern in many countries, and the usage of renewable energy has risen in importance internationally. Wind speed prediction is required to enhance the quantity of energy generated. The wind speed forecast balances the energy required and the energy generated. Voltage stability has recently received a lot of attention from academics due to the fact that it has become a key concern for modern power system operators. Several countries have experienced widespread blackouts as a result of voltage instability issues. Accurate forecasting of power demand and price is considered as one of the most significant research topics in electrical engineering in the present and future, with academics placing a strong focus on demand and price prediction in deregulated markets. The predictive nature of various machine learning algorithms makes them most suitable tool to deal with problems related to energy and power engineering. Machine learning techniques are capable of analyzing past data and on the basis of that analysis, these algorithms are capable of predicting future results. This article provides applications of machine learning in energy and power engineering.","['Engineering', 'Manufacturing, Machines, Tools, Processes', 'Renewable and Green Energy', 'Materials Science, general', 'Nanotechnology']"
doi:10.1007/978-981-19-6004-8_58,en,A Review on Risk Analysis of Cryptocurrency,OriginalPaper,"The subject of the study is cryptocurrencies and the analysis of the types of cryptocurrency risks. Cryptocurrencies significantly affect the technology world of fiat money, which dates back at least 800 years. Cryptocurrency is a digital asset that employs distributed ledger or blockchain technology to enable transactions. Digital currency, on the other hand, is a type of currency in the digital world in the form of digital forms of electronic equipment. A synonym for digital cash, digital money, electronic money, and cyber-money is the terms. Non-Fungible Token (NFTs), Defi tokens, and cryptocurrencies are examples of kinds in the blockchain industry. The paper analyzes the twenty research papers by using PRISMA. As a result of the study, the risk of digital transactions is increasing, and there is no trust. Moreover, the electronic economy is precarious. And it must be handled with extreme caution to avoid or minimize the problems that may arise. Shortly, Private cryptocurrencies will be subjected to a ferocious reconfiguration, and blockchain implementations will spread out at a visible rate as long as payments are made for digital innovation. Again, bitcoin fraud research is fast expanding in volume and breadth but is still at an early stage.","['Engineering', 'Computational Intelligence', 'Cognitive Psychology', 'Personality and Social Psychology', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-11748-0_1,en,An Introduction to Federated and Transfer Learning,OriginalPaper,"In today’s world, we have access to a tremendous amount of data. However, there is not enough high-quality data to obtain the desired results. More importantly, many industries have separate databases, with restricted sharing policies. This prevents the use of centralized storage of all relevant data in many applications for various reasons, such as privacy concerns and the need for fast computational results at the frontier. These problems can be addressed through transfer learning and federated learning. This book contains some chapters to provide background knowledge of transfer learning and federated learning, as well as, novel contributions to improve the performance of distributed learning systems.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Machine Learning']"
doi:10.1007/978-3-031-07422-6_13,en,Belgium,OriginalPaper,"The recent years have seen many new forms of marketing practices from businesses that target consumers, including the increasing use of artificial intelligence (AI) and other computational or profiling technologies. Not only marketing as such is concerned by these practices, but also advertising, promotions, pricing, and also entering into an agreement with the consumer, with the final objective to sell goods or procure a service.","['Law', 'Private International Law, International & Foreign Law, Comparative Law', 'IT Law, Media Law, Intellectual Property', 'Artificial Intelligence', 'Online Marketing/Social Media', 'Big Data', 'International Economic Law, Trade Law']"
doi:10.1007/978-3-031-16049-3_10,en,The Microstructure of Structural Organizations,OriginalPaper,"In this chapter, the microstructure of structural organizations is designed and developed based upon organizational material and symbolic quanta. This implies a series of fundamental considerations regarding the microstructural analysis of an organization: agents do not make the difference but structures do in organizational development, increasing the complexity (but also the completion) by increasing the symmetric capabilities of the microstructural configurations, the systemic delegating Business Management (based on basic Business Knowledge) model, the interdisciplinary (not to be confused with the multidisciplinary) approach for the development of long-term competitive advantages, the multidisciplinary approach for the design of organizational microstructures and the multidisciplinarity as a long-term key competitive advantage on global level. Furthermore, the development and structuring on operational level of the Quantum pairs are designed and realized on a model level as well as the partial Integration of Material and Symbolic Structures and related competencies for the development of Quantum Pairing conditions, the quantitative and qualitative factors in Quantum pairing and the factors that may inhibit and distort the complete overlapping between Material (QM) and Symbolic (QS) Quanta, the Organizational Quanta and their impact on the transformation of Quantitative into Qualitative changes, the inhibiting elements for the development of the microstructure of an organization based on Organizational Quantum Pairs are also created, developed and discussed.","['Business and Management', 'Organization']"
doi:10.1007/978-981-19-6004-8_13,en,An Ensemble Approach to Recognize Activities in Smart Environment Using Motion Sensors and Air Quality Sensors,OriginalPaper,"Smart environments are built to capture Activities of Daily Living (ADL) data using a variety of sensors. Simple and sophisticated sensors sense the minute and intricate movements of an individual within the environment. With the growth in technology, applications of sensor data are extended to activity recognition. Motion sensors are able to detect movements of the person performing daily routine tasks such as cooking, cleaning, and eating. The utility of air quality data extracted from gas sensors for activity recognition is uniquely explored. The proposed model is built to identify activities using motion sensors and air quality forms of data individually. In this paper, the experiment focuses on routine tasks classification using pressure, temperature, and other related sensor data. Feature selection is performed on the air quality data using ANOVA-F Classification. The novel data is applied for activity recognition in a set of scenarios while simultaneously detecting the presence or absence of chemicals in the surrounding area. Machine learning techniques are applied to recognize activities performed by individuals in both smart environments. A comparative study is performed on the models generated for activity recognition. An ensemble form of learning, the Random Forest technique, provides the best prediction accuracy of 86.8% for activity prediction using motion sensor data. In the case of air quality data, the activity classification model produced an accuracy of 96.19% with the least feature set combination. Activity recognition helps in identifying changes in behavioral patterns and can be extended to assisted care benefiting healthcare professionals.","['Engineering', 'Computational Intelligence', 'Cognitive Psychology', 'Personality and Social Psychology', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-13150-9_35,en,Analysis of the Effect of Feature Selection and Class Balancing Methods with Supervised Algorithms in Web Robot Detection Problem,OriginalPaper,"Accurately web robot identification is one of the most challenging problems for web robot activity detection systems. In the last few years, to accurately identify web robots, machine learning classification methods were used. However, it was discovered that the multiclass distribution in the web robot detection system is substantially skewed due to the data set's class imbalance, which causes problems with classification accuracy. The research presented in this paper examines not only the role of feature selection in improving classification accuracy but also addresses the issue of class imbalance using under-sampling of major classes and Synthetic Minority Over-sampling (SMOTE) of minor classes. After that, the classification performance is compared across a number of different classifier types. The results of this study show that oversampling (SMOTE) is more effective than under-sampling at discovering minor classes when employed with the class imbalance data set. Additionally, it was discovered that KNN and XGBoost are more accurately classified than other classifiers throughout this research. However, no single method can be utilized to classify multiclass data. This study proposes that a combination of KNN and XGBoost may be used to classify minor classes in a web robot detection system's unbalanced class data set.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Management']"
doi:10.1007/978-3-031-04021-4_1,en,Sonic Interactions in Virtual Environments: The Egocentric Audio Perspective of the Digital Twin,OriginalPaper,"The relationships between the listener, physical world, and virtual environment (VE) should not only inspire the design of natural multimodal interfaces but should be discovered to make sense of the mediating action of VR technologies. This chapter aims to transform an archipelago of studies related to sonic interactions in virtual environments (SIVE) into a research field equipped with a first theoretical framework with an inclusive vision of the challenges to come: the egocentric perspective of the auditory digital twin. In a VE with immersive audio technologies implemented, the role of VR simulations must be enacted by a participatory exploration of sense-making in a network of human and non-human agents, called actors. The guardian of such locus of agency is the auditory digital twin that fosters intra-actions between humans and technology, dynamically and fluidly redefining all those configurations that are crucial for an immersive and coherent experience. The idea of entanglement theory is here mainly declined in an egocentric spatial perspective related to emerging knowledge of the listener’s perceptual capabilities. This is an actively transformative relation with the digital twin potentials to create movement, transparency, and provocative activities in VEs. The chapter contains an original theoretical perspective complemented by several bibliographical references and links to the other book chapters that have contributed significantly to the proposal presented here.","['Computer Science', 'User Interfaces and Human Computer Interaction', 'Computer Appl. in Arts and Humanities', 'Music', 'Media Design', 'Multimedia Information Systems']"
doi:10.1007/978-981-19-1484-3_2,en,Building Energy Consumption Prediction Model Using Machine Learning,OriginalPaper,"Predicting and scheduling electricity use in smart homes and workplaces is important for installing energy-efficient management systems. Various proposals and requirements for energy usage planning and preparation have been accepted. Occupancy behavior has a major impact on building energy demand. This article describes a method for estimating occupancy using a prediction model of energy usage based on outside temperature. The model is constructed and recorded using statistical analysis using the number of inhabitants as an input. Given the fact that our model demonstrated cost-effective prediction accuracy, we highly advocate it as a platform for researchers who want to use real-world smart building test beds and analyze machine learning as a promising place for energy demand prediction and scheduling. Most notably, this is often a core feature of the promising infrastructure of smart grids, where loads have to be forecasted and ready in real time. For energy demand estimation and scheduling, many methods and models are implemented. The way people behave in buildings has a big impact on how much electricity is used. Due to a lack of understanding of occupancy, there is currently a significant performance gap between anticipated and calculated energy. This study proposes a method for estimating occupancy that is based on a long-term temperature projection model of electricity consumption, which was developed and registered using regression with the number of occupants as an input.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Machine Learning', 'Data Structures and Information Theory', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-3-031-19715-4_7,en,AI in Oral Health and Oral Imaging,OriginalPaper,"This chapter delves deep into the application of Artificial intelligence(AI) in Oral Health and Imaging. It enlightens on the impact of AI in global health and furthermore delineates in detail the role of AI in Public Health Dentistry and Preventive Dentistry. This segment enumerates the possibilities of AI in prevention of dental trauma, periodontal risk assessment, caries prevention, detection of early childhood caries, besides other uses. Numerous case studies are presented to support this claim.","['Engineering', 'Biomedical Engineering and Bioengineering', 'Dentistry', 'Artificial Intelligence', 'Machine Learning']"
doi:10.1007/978-981-19-3951-8_53,en,Evaluating Deep Learning Algorithms for Natural Language Processing,OriginalPaper,"Natural language processing (NLP) is generally referred to as the utilization of natural languages such as text and speech through software. The NLP is studied for more than 50 years approximately. Deep learning (DL) is one of the subdomains of machine learning, which is motivated by functions of the human brain, also known as artificial neural network (ANN). DL is performed well on several problem areas, where the output and inputs are taken as analog. Also, deep learning achieves the best performance in the domain of NLP through the approaches. The approaches need additional data, however, not have as much linguistic expertise for operating and training. There are a large number of hype claims in the region of deep learning techniques. But, away from the hype, the deep learning techniques obtain better outcomes. In this paper, the information linked with the DL algorithm is analyzed based on the NLP approach. The concept behind the network implementation and feature learning is described clearly. Finally, the outline of various DL approaches is made concerning result validation from preceding models and points out the influence of deep learning models on NLP.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-3-031-06870-6_1,en,Responsible Innovation in Technology and Quality of Experience,OriginalPaper,"Quality of experience (QoE) is an assessment of the human experience when interacting with technology and organizations within a specific context (Laghari and Connelly 2012). Arguably, the quality of experience is subjective. It depends on the experience of a given human user, on how they perceive, for example, a service, software, an application, etc. However, the quality of experience is the only criterion that actually counts to a user of a service. Although a perceived experience is subjective, in order for any system to be successful (i.e. the user accepts to use it), it is still imperative to identify, quantify and improve the perception of QoE for the user, throughout the system’s use. QoE is the collective effect of service performance determining a user’s degree of satisfaction – what a user experiences of the service’s accessibility, usability, retainability and integrity (Dillon et al. 2009). Ultimately, QoE is a measurement of the whole performance of a system at the user level, and it is an indication of the level a system satisfies the user’s (perceived) needs and expectations. Moreover, technology is not value-neutral (van de Poel 2012); value-sensitive design (Brey, 2010) is an approach that claims that designed artefacts are not morally neutral but harbour tendencies to promote or violate certain values. For example, web browsers and apps may be either designed to protect the user’s privacy or they may offer no such protection, or may even violate user privacy (Brey 2016).","['Engineering', 'Communications Engineering, Networks', 'User Interfaces and Human Computer Interaction', 'Computer Applications']"
doi:10.1007/978-1-4842-8814-6_2,en,How Leaders Should Think and Talk About AI,OriginalPaper,"When you consider the tremendous range of national security missions, the existing systems in operation, and the global footprint of America’s national security interests, AI leaders will need to make wise choices about the problems on which they will focus resources. This requires a dialogue between AI leaders and their customers. This dialogue should not begin with or revolve around AI models or some framework that seeks to explain AI in a single conceptual graphic. These conversations need to focus on customers’ mission problems and the potential impact of AI. From this central focus, the four types of AI projects—all of which share the same technical DNA—will keep the dialogue practical and accessible to all. AI technology has transformational potential, but only if it is used to fundamentally change and improve the operations that drive mission outcomes. That is the central focus—not algorithms, not tech, but mission outcomes.","['Computer Science', 'Systems and Data Security', 'Artificial Intelligence']"
doi:10.1007/978-3-031-21062-4_28,en,Benchmark on Real-Time Long-Range Aircraft Detection for Safe RPAS Operations,OriginalPaper,"The growing market in Remotely Piloted Aircraft Systems (RPAS) and the need for cost-effective “Detect and Avoid (DAA)” systems are critical issues up to date towards enabling safe beyond visual line of sight (BVLOS) operations. In hopes of promoting earlier threat detection on DAA systems, we benchmark several object detection algorithms on multiple graphical processing units for the concrete DAA use case. Two state-of-the-art “real-time object detection” and “object detection” model sets are trained using our CENTINELA dataset, and their performances are compared for a wide range of configurations. Results demonstrate that one-stage architecture YOLO variants outperform ViT on all tested hardware in terms of mean average precision and inference speed despite their architecture complexity gap. Additional resources are available to the reader at https://github.com/fada-catec/detection-for-safe-rpas-operation .","['Computer Science', 'Robotics', 'Robotics and Automation', 'Computational Intelligence']"
doi:10.1007/978-981-19-3679-1_16,en,Application of NLP and Machine Learning for Mental Health Improvement,OriginalPaper,"Humans’ most powerful tool is their mental wellness. Individuals’ well-being can be impacted by poor mental health. This paper focuses on a smart technical solution to the problem of mental health issues detection related to the stress, sadness, depression, anxiety, etc. which if not handled efficiently may further lead to a severe problem. The paper deals with the designing of an automated smart system using social media posts that will help mental health experts to successfully identify and understand about the mental health condition of social media users. That can be done based on text analysis of rich social media resources such as Reddit, Twitter posts. The implementation of the system is done using Natural Language Processing (NLP) methods, machine learning and deep learning algorithms. The models are trained using a prepared dataset of social media postings. With this automated system the mental health experts can able to detect the stress or some other emotions of social media uses in a very earlier as well as faster way. The proposed system can predict five emotional categories: ‘Happy’, ‘Angry’, ‘Surprise’, ‘Sad’, ‘Fear’ based on machine learning (Logistic Regression, Random Forest, SVM), deep learning Long Short-Term Memory (LSTM) and BERT transfer learning algorithms. All the applied algorithms are evaluated using confusion matrix, the highest accuracy and f1 score achieved is more than 85%, which is better than the existing human emotion detection systems.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3788-0_28,en,Integrated Piloting Skills Training,OriginalPaper,"Operating highly automated aircraft requires transitioning from automatic to manual control and back. In this process, problems can be caused due to information overload, changes in the operation mode and the pilot’s being exposed to forces in excess of 1 G (Kletz and Amyotte in What went wrong? Case histories of process plant disasters and how they could have been avoided. Butterworth-Heinemann, UK, 2019 [ 1 ]; Megson in Aircraft structures for engineering students. Burlington, USA, 2021 [ 2 ]; Guoqing and Wenhao in The principles of integrated technology in avionics systems. Academic Press, Shanghai, 2020 [ 3 ]; Muravyev and Kovalenko in Helicopter pilots safe landing outside the airfield in conditions of uncertainty skills training methods. Nauka, St. Petersburg, 2017 [ 4 ]). The existing method for training pilots using cognitive converters of activity algorithms does not take into account the way how pilots control the dynamic characteristics of the aircraft in flight. The article proposes a new method that allows the pilot to develop an integral skill that takes into account both static and dynamic parameters of the aircraft. The relevance of the study stems from the fact that it is vital for pilots to know how to backup automated systems in modern aircraft.","['Engineering', 'Aerospace Technology and Astronautics', 'Engine Technology', 'Engineering Thermodynamics, Heat and Mass Transfer']"
doi:10.1007/978-3-031-18275-4_3,en,Ethics and Moral,OriginalPaper,"This chapter focuses on ethics and moral based on an AI environment. It sums up that all past societies had ethical standards with the central goal to survive. Ethics itself goes back a long time in history. Already Aristotle was speaking about ethics, and it will be an even more central topic for the future of humanity. Will AGI consider the needs and understandings of the lower-developed humans? How will humans handle “intelligence explosion” and recursive scenarios, where AI or AGI will replicate itself constantly? Humans reshaped the planet earth to gain benefits, will this be done by an AI system as well? This chapter lists an overview of different AI ethics frameworks and lists different viewpoints for the situation that AI systems will have their own moral status. Section 3.1 describes approaches to how to train AI systems in ethics. One major challenge is, if AI systems will get trained with already biased data sets. Overall, it is still unclear how to teach ethics to AI systems. Section 3.2 lists criteria for Product Development of AI systems and describes the importance of testing environments. Next, Sect. 3.3 analyses some ethical and moral challenges. It shows that moral decision-making is not about logic and rationality, instead, it is about psychologically acceptable explanations. Therefore, it requires a deep understanding of humans and their behavior. Other challenges are accountability (who is responsible for a failure?), law adaption, quick reproduction of AI systems, and the not predictable social impact. Section 3.4 dives deeper into existing guidelines. A survey shows the importance of the requirement of transparency and safety for users and consumers. It describes the outcome of the summary of an overview of 47 values and principles that are based on several manifestos. The AIHLEG of the European Commission defines Trustworthy AI by seven key requirements and offers an AI assessment list.","['Business and Management', 'IT in Business', 'Business Ethics', 'Engineering Ethics', 'Organization', 'Artificial Intelligence']"
doi:10.1007/978-3-030-98546-2_4,en,Computerized Facial Emotion Expression Recognition,OriginalPaper,"Facial emotion expressions are an important gateway for studying human emotions. For many decades, this research was limited to human ratings of arousal and valence of emotional expressions. Such ratings are very time-consuming and have limited objectivity due to rater biases. By exploiting improvements in machine learning, the demand for a swifter and more objective method to assess facial emotional expressions was met by a plethora of software. These novel approaches are based on theories of human perception and emotion and their algorithms are often trained with massive and almost-generalizable data bases. However, they still face limitations such as 2D recognition and cultural biases. Nevertheless, the accuracy of computerized emotion recognition software has surpassed human raters in many cases. Consequently, such software has become instrumental in psychological research and has delivered remarkable findings, e.g. on human emotional abilities and dynamic expressions. Furthermore, recent developments for mobile devices have introduced such software into daily life, allowing for the immediate and ambulatory assessment of facial emotion expression. These trends provide intriguing new opportunities for studying human emotions, such as photograph-based experience sampling, incidental or implicit data recording in interventions, and many more.","['Engineering', 'Biomedical Engineering and Bioengineering', 'Health Informatics', 'Health Psychology', 'User Interfaces and Human Computer Interaction']"
doi:10.1007/978-3-031-20650-4_4,en,Multi-stage Bias Mitigation for Individual Fairness in Algorithmic Decisions,OriginalPaper,"The widespread use of machine learning algorithms in data-driven decision-making systems has become increasingly popular. Recent studies have raised concerns that this increasing popularity has exacerbated issues of unfairness and discrimination toward individuals. Researchers in this field have proposed a wide variety of fairness-enhanced classifiers and fairness matrices to address these issues, but very few fairness techniques have been translated into the real-world practice of data-driven decisions. This work focuses on individual fairness, where similar individuals need to be treated similarly based on the similarity of tasks. In this paper, we propose a novel model of individual fairness that transforms features into high-level representations that conform to the individual fairness and accuracy of the learning algorithms. The proposed model produces equally deserving pairs of individuals who are distinguished from other pairs in the records by data-driven similarity measures between each individual in the transformed data. Such a design identifies the bias and mitigates it at the data preprocessing stage of the machine learning pipeline to ensure individual fairness. Our method is evaluated on three real-world datasets to demonstrate its effectiveness: the credit card approval dataset, the adult census dataset, and the recidivism dataset.","['Computer Science', 'Artificial Intelligence', 'Computers and Education', 'Data Mining and Knowledge Discovery', 'Information Systems Applications (incl. Internet)', 'Computer Appl. in Social and Behavioral Sciences', 'Image Processing and Computer Vision']"
doi:10.1007/978-981-19-4162-7_14,en,Detection of COVID-19 Using CNN and ML Algorithms,OriginalPaper,"As we see coronavirus is the very dangerous diseases and to identify this diseases in one’s body is also not as easy. So during identification of diseases there are many false positive cases we see that person does not have corona and still the prediction comes true and also in some cases, it happens that person has corona but it does not get detected (false negative case). So due to this problem, we here come up with the two approaches and make comparison between these two approaches and decide which one is better to analyze the diseases in the body. We are using CNN to scan chest X-ray dataset and ML algorithms for tabular dataset as it contains many text information too. So in this project, we explain in detail, what is CNN, what is ML, how to implement CNN and ML algorithms on particular dataset, what output we will get as a comparison.","['Engineering', 'Computational Intelligence', 'Data Mining and Knowledge Discovery', 'Systems and Data Security', 'Mobile and Network Security', 'Information Systems Applications (incl. Internet)']"
doi:10.1007/11663_2022_21,en,Offline Breath Analysis: Standardization of Breath Sampling and Analysis Using Mass Spectrometry and Innovative Algorithms,OriginalPaper,"Over the last decades, breath analysis has been postulated as a useful tool for the noninvasive diagnosis and monitoring of diseases. Specifically, offline breath analysis is currently the most common method used for biomarker discovery phase in human exhaled breath. In offline breath analysis, exhaled breath samples are collected in containers and stored prior to analysis, which enables to collect samples from patients at different places. This approach is mainly conducted by analytical platforms with high sensitivity, robustness, and reproducibility, such as technologies based on mass spectrometry. This comprehensive review provides an overview of all aspects of offline breath analysis, including sample collection protocols, challenges of breath sampling standardization, analytical techniques, data preprocessing, and the complex algorithms implemented for data analysis.","['Chemistry', 'Analytical Chemistry', 'Mass Spectrometry', 'Materials Science, general', 'Spectroscopy/Spectrometry', 'Medicinal Chemistry']"
doi:10.1007/978-3-031-09687-7_9,en,Learning Career Knowledge: Can AI Simulation and Machine Learning Improve Career Plans and Educational Expectations?,OriginalPaper,"As AI and machine learning permeates every area of life, its use to ameliorate educational inequities becomes of great interest. One important application of machine learning within education is to help students increase their alignment of career choice, educational attainment, and projected salary. Alignment theory has shown that having alignment yields higher educational attainment for students. Using the app, Init2Winit, which has students play a game which gives them points for correct alignment, this chapter explores how machine learning, in particular using a decision tree, can give insights into game use and its relation to educational expectations. This model builds a basis for the improvement of Init2Winit to increase student educational expectations through counselor interventions and how other educational applications could use machine learning for insights to improve educational outcomes. The model can decrease educational inequities by increasing educational attainment for those in underrepresented minorities.","['Psychology', 'Psychology, general', 'Computer Applications', 'Education, general', 'Philosophy of Mind', 'Artificial Intelligence']"
doi:10.1007/978-981-19-0098-3_64,en,Cooperative Multi-Agent Nash Q-Learning (CMNQL) for Decision Building in Retail Shop,OriginalPaper,"Based on the mentioned cooperative Nash Q-learning framework, the study presents a novel cooperative multi-agent Nash Q-learning approach for building decisions for the retail shop. The technique provides three retail stores throughout the market. Dealers can assist one another and profit from cooperative knowledge by building their own strategies that are solely focused on their goals and benefits. Assuming key hypotheses about the dealer’s stock policy, reload duration, and consumer coming method, the technique is created as a Markov decision process model to build the learning algorithms. Furthermore, the research shows the results of three shop agents’ cooperative reinforcement learning algorithms using Nash Q-learning over a one-year sale period. The findings of two methodologies, Nash Q-learning and joint action learning, are compared in the paper. When compared to a single-agent Q-learning approach, agents with Nash Q are to arrive at a joint optimal path. If at least one agent accepts N , the effect of combined agents is superior to single Q-learning.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Statistics, general', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1906-0_37,en,Predicting Breast Cancer Using Changing Parameters of Machine Learning Model,OriginalPaper,"Breast cancer is the most common type of fatal ailment seen in females in the world. There are many types of cancer, one of which is breast cancer. Several types of breast cancer are found in women that affecting their lives across the world. Several types include “lobular carcinoma in situ (LCIS), ductal carcinoma in situ (DCIS), invasive ductal carcinoma (IDC), invasive lobular carcinoma (ILC).” How many people are dying due to cancer today, and one of the main reasons is not known in time. Generally, breast cancer may be a malignant neoplasm that begins within the cell of the breast and eventually spreads to the encompassing tissue. Due to breast cancer, a lot of death is happening. The death rate can be reduced by using machine learning techniques. Mammography is a good and effective modality that is used in the detection of breast cancer in today’s time. In this paper, we used different machine learning algorithms like Naïve Bayes, k -nearest neighbors, logistic regression, support vector machine, decision tree, and convolution neural network. After changing the unique hyperparameter of each model, find the better accuracy within the model and also do the comparison between models. The performance of convolution neural network is found maximum accuracy with minimum loss. The accuracy achieved by convolution neural network is 99.05%.","['Engineering', 'Electronics and Microelectronics, Instrumentation', 'Computer Systems Organization and Communication Networks', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2840-6_58,en,Automatic Eye Disease Detection Using Machine Learning and Deep Learning Models,OriginalPaper,"Glaucoma is a serious eye disease that affects a lot of people around the world. Deep learning architectures have been widely used in recent years for image recognition tasks. In this paper, we aim to detect human eye infections of Glaucoma disease by firstly using different machine learning (ML) classifiers such as Support Vector Machine (SVM), K-Nearest Neighbors (KNN), Naıve Bayes (NB), Multi-layer perceptron (MLP), Decision Tree (DT) and Random Forest (RF), and secondly a Deep Learning (DL) model such as Convolutional Neural Network (CNN) based on Resnet152 model. The evaluation of the proposed approach is performed on the Ocular Disease Intelligent Recognition dataset. The obtained results showed that the RF and MLP classifiers achieved the highest accuracy of 77% in comparison to the other ML classifiers. On the other hand, the deep learning model (CNN model: Resnet152) provides an even better accuracy of 84% for the same task and dataset. Furthermore, we observe our best performing model produce competitive results in comparison to some state-of-the-art approaches.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-2004-2_40,en,Lung Disease Prediction Using Deep Learning,OriginalPaper,"The evolution of deep learning has enhanced the technique of identifying and classifying lung diseases into various categories using medical images. This project aims to build lung disease detection models using deep learning to identify future potential and thus to efficiently observe and visualize the recent and upcoming trends in this domain. Identifying and discovering lung disease at an early stage has become a vital part of the medical domain because this would facilitate patient’s subsequent clinical management. The project primarily focuses on pneumonia as well as considering the breathing problems of patients. Deep learning and machine learning have served the utmost significance in detecting such lung diseases at a prior stage. This enhancement has contributed much to the doctors and medical systems to provide early treatment to patients. In this project, convolutional neural network (CNN) is used to predict lung disease (pneumonia) from chest X-ray images using machine learning and deep learning frameworks.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Artificial Intelligence', 'Materials Science, general']"
doi:10.1007/978-981-19-3571-8_12,en,"Blockchain-driven Smart Healthcare System: Challenges, Technologies and Future Research",OriginalPaper,"Healthcare service is one of the most important pillars of the existence of life on the planet. It requires frequent updates in its existing methodology; it can be in terms of resources, manpower and technology. Many researchers have proposed various types of technologies (i.e., Internet of Healthcare Things (IoHT)) and ways to enhance the capabilities of the healthcare services, which also contributed in the real world scenario. However, IoHT suffers from various security and privacy-related issues. Because of them, the sensitive healthcare data may be disclosed or altered in the unauthorized way. Therefore, we need some security scheme to secure the communication of IoHT. The security issues of IoHT can be resolved by the blockchain-driven mechanisms. In this paper, we discuss the issues and challenges of blockchain-driven smart healthcare system. We also provide the details of the “generic architecture of the blockchain-driven smart healthcare system”. We then provide the practical implementation of the presented system. After that, we provide the details of various tools and technologies of the smart healthcare system. Finally, the work is finished with some concluding remarks and future research directions, which should be handled by the researchers working in the smart healthcare domain.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-16159-9_34,en,A New Version of the On-Line Adaptive Non-standard Identification Procedure for Continuous-Time MISO Physical Processes,OriginalPaper,"Modern diagnostics and control algorithms rely on physical processes models. Such models have often complicated structure and their synthesis is usually difficult. The approaches based on Partial Differential Equations (PDE) work well for simulation purposes, however their usefulness can be limited in case of industrial applications when a full set of processes data is often inaccessible. The aforementioned problem was the main motivation to propose an adaptive identification method available to work on-line based on processes data. It is based on the Modulating Functions Method (MFM) and utilizes the Exact State Observers. The method was applied for real processes data collected from the industrial glass conditioning installation. The experimental results are presented and discussed in the paper.","['Engineering', 'Control and Systems Theory', 'Computational Intelligence']"
doi:10.1007/978-3-662-65216-9_10,en,Clustering Topologically-Optimized Designs Based on Structural Deformation,OriginalPaper,"Topology optimization can be used to generate a large set of lightweight structural solutions either by changing the constraints or the weights for different objectives in multi-objective optimization. Engineers must analyze and review the designs to select solutions according to their preference towards objectives such as structural compliance and crash performance. However, the sheer number of solutions challenge the engineers’ decision-making process. An automated way of summarizing solutions is to cluster groups of similar designs based on a suitable metric. For example, with the Euclidean metric in the objective vector, design groups with similar performance can be identified and only the representative designs from the different clusters may be analyzed. Since the deformation behavior of a structure is an important design feature, in this work, we investigate the use of manifold learning algorithms to identify and group similar designs using the nodal displacement data. The proposed approach can process the volumetric deformation of geometries with completely different topologies. In this study, we couple the manifold learning techniques, t-distributed Stochastic Neighbor Embedding (t-SNE) and Uniform Manifold Approximation and Projection (UMAP), with the clustering algorithms, k -means and Ordering Points To Identify the Clustering Structure (OPTICS), to identify the representative deformation modes. Using Gaussian Random Fields (GRF) to create artificial displacement fields, we generate a labeled dataset with different modes, which enabled us to evaluate our method using classification accuracy, precision, recall, and F1-score. Finally, using our approach, we successfully distinguished between similar and non-similar designs in the results from topology optimization.","['Engineering', 'Engineering Design', 'Materials Engineering', 'Industrial and Production Engineering']"
doi:10.1007/978-981-19-3575-6_36,en,Face Recognition-Based Automatic Attendance System,OriginalPaper,"In today's digital world, in almost every field, the face recognition technology plays a vital role. The attendance marking system has become difficult and interesting. This system of automation is used for surveillance, authentication, recognition of the face of a specific person, and has many more benefits. Everyone is adopting the conventional method of taking attendance these days, this consumes more time, and there could be possibilities for proxy participation. We used several libraries in this automation framework, such as OpenCV, face recognition, and Harr-cascade classifier. Using a Haar-cascade classifier, face detection and recognition are executed. And, in the Excel sheet, the attendance is revised.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-4052-1_26,en,Comprehensive Review of Learnable and Adaptive Recommendation Systems,OriginalPaper,"Due to the dynamic and heterogeneous nature of the Web, it is increasingly difficult for users to choose amongst large amounts of data. For this reason, the modelling of users and access to personalised information becomes essential. Recommendation systems stand out as systems that aim to provide the most appropriate and efficient services by offering personalised recommendations to users. Traditional recommendation systems provide suggestions to their users with static approaches and do not include user preferences that change over time in suggestion strategies. In this study, a comprehensive review and comparison of recommendation systems that can adaptively develop suggestion approaches according to changing user preferences and learn user preferences are presented.","['Engineering', 'Computational Intelligence', 'Information Storage and Retrieval', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Data Structures and Information Theory', 'Artificial Intelligence']"
doi:10.1007/978-3-031-18292-1_7,en,Role of Explainable Edge AI to Resolve Real Time Problem,OriginalPaper,"The growth of information technology (IT) has resulted in physical de-vices being connected to the internet and having the ability to recognize other devices. Artificial Intelligence algorithms are processed on edge or the devices of users. Edge Computing based on the same premise, stores, processes, and manages data directly at Internet of Things (IoT) endpoints. Edge artificial intelligence uses the device's hardware to process data and performs machine learning and deep learning procedures. In the model, you can troubleshoot and improve model performance while also assisting others in understanding the behavior of your models. To make the area more real, explainable edge devices come in a wide range of costs and capabilities. A decade ago, we couldn’t imagine that explainable edge artificial intelligence would be at today’s level. Now it is a part of industries and even devices for customer service. The best example of explainable edge AI is virtual assistants such as Alexa, google assistant. They learn from the user’s world and phrases and can store them directly on the device. These are just a few examples later, and we have possible applications in future works on the explainable edge artificial intelligence. Edge Computing Platform facilitates the development and elastic operation of apps and services. Its benefits the AI assisting in overcoming the technical obstacles that AI-enabled apps experience. Combination of edge and AI is buzzwords within the industry to deliver the performance and reduce the cost compared to state of arts XAI applications. Moreover edge artificial intelligence are reducing the latency, improving user experience, and reducing the necessary bandwidth, consequently reducing the costs of internet services. It surfs this movement since the need for data processing on the device themselves also represents the increasing use of artificial intelligence. Artificial intelligence edge processing focused on model which trained them in central data center using historical datasets. Compression techniques of data that enables squeezing large artificial intelligence models into small hardware form factors could push some training to the edge over time.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-13714-3_3,en,Problem Modeling,OriginalPaper,"This chapter shows how a problem can be modeled so that it can be handled efficiently by a heuristic algorithm. It gives some examples of transformations of data, constraints, and objectives. Finally, it introduces some notions of multi-objective optimization.","['Business and Management', 'Operations Research/Decision Theory', 'Optimization', 'Computational Mathematics and Numerical Analysis', 'Algorithms', 'Computational Science and Engineering', 'Artificial Intelligence']"
doi:10.1007/978-3-031-20601-6_5,en,"Major Role of Artificial Intelligence, Machine Learning, and Deep Learning in Identity and Access Management Field: Challenges and State of the Art",OriginalPaper,"In order to meet the growing needs of organizations and individuals to access services and systems remotely, especially during the period of the covid-19 pandemic, the use of I&AM systems is increasingly widespread and optimized. Henceforth regulated by the GDPR, these systems must meet privacy requirements in order to strengthen citizens’ control over their personal data. Artificial Intelligence has proven its efficiency in offering methods to secure I&AM processes. In this direction, the main contributions of this paper consist in identifying the challenges facing I&AM process that are: identification, authentication, authorization, auditing/monitoring and accountability. Afterward, we study how these extracted challenges have been addressed by conducting a comprehensive survey of ML applications for the enhancement of I&AM’s five processes. Besides, we conduct an analysis of the studied solutions based on Cognitive Project Management for Artificial Intelligence (CPMAI) methodology. Finally, some future research directions are identified.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16598-6_10,en,"Redesign, Smart and Digital Enablement of Sales and Operations Planning Processes: A Study of White Goods Manufacturing",OriginalPaper,"Traditional sales & operations planning (S&OP) processes have lack of speed, accuracy, and availability in today’s digital age and global epidemic environment. In addition, major domestic appliance industry faces the challenge of increasing complexity in channel, customization, product, facility location, component and supplier dimensions, which brings the necessity of effective and timely planning processes. Redesigning and digital enablement of S&OP processes can provide real-time analytical capabilities in the supply chain, thereby helping stakeholders to focus on the most pressing issues. While increasing complexity brings the availability of big data, it has become another challenge for the industry to collect, interpret and use this data in advanced analytics techniques. Manufacturers and distributors in the white goods industry apply various data governance approaches in line with their supply chain capabilities and structure. This chapter discusses the concept of digital transformation related with S&OP and how it can benefit the white goods sector. Having the network structure and inventory strategy as initial inputs, we re-evaluate the S&OP cycle starting at demand planning by revisiting forecasting hierarchies, horizon and frequency and applying artificial intelligence (AI) based algorithms, supply planning process with real time data, and scenario generation with the financial impacts of each alternative.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16213-8_11,en,Automatic Detection of Hydrodynamical and Biological Indicators of the Shoreline Using a Convolutional Neural Network,OriginalPaper,"The launch of satellites equipped with sensors in the optical range of the electromagnetic spectrum has greatly facilitated the mapping and monitoring of coastal areas for risk prediction. Thus, the frequent updating of information for monitoring purposes is possible. It is, therefore, a modern alternative to traditional methods, namely, photogrammetry and in situ investigation. The objective of this work is to define an efficient and validated method for the detection and extraction of shoreline indicators. It is the first indication of validation for a satellite image classification approach, based on a deep learning algorithm, optimized and adapted to the extraction, a hydrodynamic and biological indicator of the shoreline. The convolutional neural network (CNN) architecture was designed and adapted in order to extract the target shoreline indicators. A Pleiades image of very high resolution was used, sliced into sub-regions, and analyzed by a convolution kernel of size 3*3. The classification results have revealed a very high accuracy of 92%. A validation process was undertaken by comparing the results to field surveys (reference) acquired on the same day as the satellite image acquisition. With a run-up (horizontal wave excursion) of 0.6 m, the confidence interval for the deep learning method was estimated to be ± 0.42 m, which is quite small, revealing the good accuracy of the method tested. A large panel of users could reproduce these methods in an automatic and standard way, which should allow the updating of a possible database shared between involved parties in an efficient way.","['Earth Sciences', 'Oceanography', 'Computer Applications', 'Geography, general', 'Water, general', 'Pollution, general', 'Ecology']"
doi:10.1007/978-981-19-2535-1_40,en,Prediction of Age-Related Macular Degeneration (ARMD) Using Deep Learning,OriginalPaper,"The further proliferation of age-related eye diseases, mainly age-related macular degeneration (ARMD), is increasing the load on healthcare providers. Although ARMD does not lead to complete blindness, the disease can make it difficult for people to perform daily activities such as driving, reading, writing, cooking, etc. The unavailability of any cure for ARMD, necessitates timely actions of detecting the first symptoms of eye conditions as well as following appropriate treatment options to minimize further damage. Some of the current techniques used to detect and monitor ARMD include the Amsler’s Grid, Near Vision Chart, Optical Coherence Tomography (OCT), etc. which are generally performed on paper in hospitals or clinics. This proposed solution facilitates prediction of age-related macular degeneration in patients using data collected through a Mobile application. The proposed system includes the digitization of paper-based tests as well as a novel approach for prediction of ARMD through Deep Learning. The system eliminates the need to visit a clinic and can be used by citizens from home at their discretion. The high prediction accuracy obtained while real-time testing and prediction of ARMD validates the effectiveness of the proposed approach.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-1-0716-2609-2_10,en,In Silico Prediction Method for Protein Asparagine Deamidation,OriginalPaper,"In silico prediction methods were developed to predict protein asparagine (Asn) deamidation. The method is based on understanding deamidation mechanism on structural level with machine learning. Our structure-based method is more accurate than the sequence-based method which is still widely used in protein engineering process. In addition, molecular dynamics simulation was applied to study the time occupancy of nucleophilic attack distance, which is hypothesized as the most important step toward the rate-limiting succinimide intermediate formation. A more accurate prediction method for distinguishing potentially liable amino acid residues would allow their elimination or reduction as early as possible in the drug discovery process. It is possible that such quantitative protein structure–property relationship tools can also be applied to other protein hotspot predictions.","['Biomedicine', 'Antibodies', 'Bioinformatics', 'Pharmaceutical Sciences/Technology']"
doi:10.1007/978-981-19-5331-6_24,en,IoT-Enabled Sustainable Solution for Smart Shopping Experience,OriginalPaper,"The Internet of things (IoT) is transforming people’s lives by connecting common objects. Retail marketing sectors are greatly benefited by IoT-enabled technologies in modernizing the billing and cart-filling activities. Customers experience many delays by waiting in the long queues within the marts. This problem is addressed by designing an affordable radio frequency identification (RFID)-based smart shopping cart that can be used in all retail marketing scenarios. When an item is placed in a smart shopping cart, it can be instantly scanned by a cart equipped with an RFID reader. As a result, billing can be done directly from the shopping cart, saving customers from having to wait in a long line at the checkout. Further, the authors enhance the smart shopping cart which includes smart shelving that is equipped with a video sensor that reads the QR code on the item and may monitor stock, possibly also updating a central server. The major advantage of this type of system is that inventory management becomes much easier because all items can be automatically added after scanning the QR code of the item rather than being manually scanned by a laborer.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-20650-4_9,en,Sequence-to-Sequence CNN-BiLSTM Based Glottal Closure Instant Detection from Raw Speech,OriginalPaper,"In this paper, we propose to frame glottal closure instant (GCI) detection from raw speech as a sequence-to-sequence prediction problem and to explore the potential of recurrent neural networks (RNNs) to handle this problem. We compare the RNN architecture to widely used convolutional neural networks (CNNs) and to some other machine learning-based and traditional non-learning algorithms on several publicly available databases. We show that the RNN architecture improves GCI detection. The best results were achieved for a joint CNN-BiLSTM model in which RNN is composed of bidirectional long short-term memory (BiLSTM) units and CNN layers are used to extract relevant features.","['Computer Science', 'Artificial Intelligence', 'Computers and Education', 'Data Mining and Knowledge Discovery', 'Information Systems Applications (incl. Internet)', 'Computer Appl. in Social and Behavioral Sciences', 'Image Processing and Computer Vision']"
doi:10.1007/978-3-031-18409-3_14,en,A Comparative Study of Machine Learning Algorithms for the Detection of Vulnerable Python Libraries,OriginalPaper,"Detecting the existence of vulnerabilities within source code is an important step in improving the overall security of an organisation and reducing the possibility of an attacker breaching the IT system. This has led to the creation of different vulnerability detection tools and, therefore, to devoting efforts to the study of detection techniques to provide the best results. One of the techniques used for this purpose is those that use Machine Learning and Data Mining models, this being a booming field. Under this premise, this paper presents a comparison of the results obtained with Machine Learning models capable of classifying the vulnerability or non-vulnerability of a real-world source code in Python language.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Education, general']"
doi:10.1007/978-981-19-3387-5_158,en,Location-Independent Human Activity Recognition Using WiFi Signal,OriginalPaper,"The WiFi sensor constrains the Human activity recognition scheme to an immovable orientation when providing training samples, drastically reducing practical applications. In addition, the empirical investigation through the ubiquitous experience of participants in environments with wireless signals makes it imperatively challenging to evaluate a location-independent method to recognize human activity. In this research, a 1D CNN-LSTM model was built to comparatively analyze location-independent human activity recognition through WiFi CSI. Thus, the method reduces the impact of human activity recognition on location independent. Nevertheless, the experimental results demonstrate that our method can achieve over 94.9% coverage accuracy for location-independent human activity recognition and 90% coverage accuracy for CNNs using our proposed method. The location-independent model developed can be used possibly for practical applications in any situation, and data from each antenna is processed independently, making it applicable in any location or antenna setup. A variety of input sample lengths has been tested to overcome the measurement sensors’ sampling rate limitations. The results show that human activities can be recognized in real-time through WiFi signaling. Therefore, the CSI WiFi connectivity is potentially enhancive in building an excellent platform to locate human activities in modern age.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Aerospace Technology and Astronautics']"
doi:10.1007/978-3-030-96276-0_4,en,Structural Patterns for Free-Form Surfaces,OriginalPaper,"In the previous chapter, we defined the design process for connective joints in spatial reticular structures with rods made from bamboo culms. The following chapter, on the other hand, analyses a series of themes related to the design and optimisation of a free-form structure. Once the form of an NURBS mathematical surface has been determined, we investigate the main techniques for subdivision of discrete elements with dimensions adapted for manufacturing and assembly (paragraph 4.1 Digital representation techniques, NURBS and Polygon Mesh ; paragraph 4.2 Optimisation of surface tessellation ). The discretisation method of a planar surface based on Voronoi diagrams is detailed further (paragraph 4.3 Natural patterns, the Voronoi diagram Particle-Spring System and definition of the structural grid ) by optimising the distribution of the cells in the pattern with form-finding techniques, in order to satisfy structural requirements (the algorithm used is the Particle-Spring System , by means of the Kangaroo plug-in for Grasshopper, which was developed by Daniel Piker). In the last Sect. 4.4 , Definition of the numerical model and structural optimisation through the Galapagos evolutionary solver , the diagram is applied to any free-form surface by iterating an algorithmic process to develop the best geometric-spatial configuration that satisfies certain threshold values.","['Engineering', 'Building Materials', 'Light Construction, Steel Construction, Timber Construction', 'Sustainable Development']"
doi:10.1007/978-981-19-4676-9_56,en,Study of Spike Glycoprotein Motifs in Coronavirus Infecting Animals and Variants of SARS-CoV-2 Observed in Humans Across Countries,OriginalPaper,"Sha, Akhbar Nair, Manjusha The greatest threat the world currently faces is due to the COVID-19 pandemic and its adverse effects. This in turn has obtained greater support in research and study on this field with the aim of a better tomorrow. Due to the large-scale spread of COVID-19 which in turn caused high possibility of mutations in this virus prompted us to conduct a study on the spike glycoprotein sequence of this highly debated organism. This study is conducted on two aspects: first on the spike glycoprotein sequences of coronaviruses infecting animals based on association with humans and the second on variants of SARS-CoV-2 based on geographic location of the sequences collected. Coronavirus is considered to be originated in bats and reached humans through unknown sources. We extend this possibility by conducting studies on the spike glycoprotein of coronaviruses that infect animals having some association with humans directly or indirectly as well as to provide better insights into the different mutations that had occurred to the SARS-CoV-2 as it spread through countries. The most similar organisms sharing a significant motif “KRSFIEDLLFNKV” of spike glycoprotein in our study are coronaviruses found in bats and cat. From the current study of mutations in the surface glycoprotein domain of SARS-CoV-2 observed in samples collected from 15 different countries, the amino acid present at 613th position was found to have the most stable mutation. The computational study detailed here provides better insights to the possible origins and transmission of SARS-CoV-2 viruses.","['Engineering', 'Computational Intelligence', 'Systems and Data Security', 'Artificial Intelligence', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-3-031-20650-4_3,en,Minimizing Cross Intersections in Graph Drawing via Linear Splines,OriginalPaper,"The generation of aesthetically pleasing graph layouts is the main purpose of Graph Drawing techniques. Recent contributions delved into the usage of Gradient-descent (GD) based schemes to optimize differentiable loss functions, built to measure the graph layout adherence to given layout characteristics. However, some properties cannot be easily expressed via differentiable functions. In this direction, the recently proposed Graph Neural Drawer (GND) framework proposes to exploit the representational capability of neural models in order to be able to express differentiable losses, specifically for edge intersection, that can be subsequently optimized via GD. In this paper, we propose to improve graph layout readability leveraging linear splines. We exploit the principles behind GND and use a neural model both to identify crossing edges and to optimize their relative position. We split crossing edges introducing linear splines, and threat the control points as novel “fake” vertices that can be optimized via the underlying layout optimization process. We provide qualitative and quantitative analysis over multiple graphs and optimizing different aesthetic losses, that show how the proposed method is a viable solution.","['Computer Science', 'Artificial Intelligence', 'Computers and Education', 'Data Mining and Knowledge Discovery', 'Information Systems Applications (incl. Internet)', 'Computer Appl. in Social and Behavioral Sciences', 'Image Processing and Computer Vision']"
doi:10.1007/978-981-19-4960-9_52,en,Multimodal Detection and Analysis of Parkinson’s Disease,OriginalPaper,"Parkinson’s disease (PD) is a central nervous system neurodegenerative condition that causes temporary or permanent loss of motor movements, speech, and mental processes. Parkinson’s disease (PD) is distinguished and characterized by a wide spectrum of movement and non-movement symptoms that can affect function to varying degrees. Unfortunately, PD is difficult to diagnose because there are no conventional diagnostic tests or systems that can be relied upon for accurate results. While the Unified Parkinson’s Disease Rating Scale (UPDRS) is recommended as a first line for monitoring Parkinson’s disease progression, it must be administered by a neurologist, therefore, it is not a good tool for evaluating short-term variations in the disease state. For this reason, neurologists need to use automated diagnostic technologies to aid them. The study focuses on the development of a system for estimating the prevalence of a person’s Parkinson’s disease (PD) symptoms by remotely monitoring numerical interpretations of their regular motor movements as movement disorders escalate. The research has also focused on the identification of the vocal impairments in Parkinson’s disease patients flowing speech or vowel rhythm. Parkinson’s patients with a more severe form of the condition sketch spiral at a slower pace and with less pressure. Hence, the proposed method uses composite feature score (CFS) of motor movements (M), sketching (S), pen pressure (P), and vocal impairments (V) features to evaluate the severity of Parkinson’s disease (PD) with a need to find parameters that have a greater link so that they can be taken into account for an appropriate diagnosis. Diverse multi-feature processing techniques have been utilized in the study to extract and compute valuable features to develop accurate scores for evaluating PD decision-support systems.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Professional Computing']"
doi:10.1007/978-981-19-3575-6_63,en,Study of Fake News Detection Techniques Using Machine Learning,OriginalPaper,"In today’s world, due to the emerging use of social media platforms, fake news spreads like a bonfire in the online world. Social media and various other news media broadcast fake news to increase viewership and readership among people to make the post trending. The people get easily attracted to fake news psychologically. In this paper, we have proposed a new fake news detection method with most frequent 1000 words in a corpus, consisting of the statements of an open freely accessible dataset named Liar (Wang in “Liar, liar pants on fire”: a new benchmark dataset for fake news detection, 2017 [ 18 ]). This paper also aims at studying different standard and basic techniques useful for text classification in the context of fake news detection. We have studied the performance of basic machine learning (ML) algorithms using basic lexicon-based features being implemented over standard fake news detection dataset “Liar” (Wang in “Liar, liar pants on fire”: a new benchmark dataset for fake news detection, 2017 [ 18 ]). We have also studied the effect of the feature–classifier combination for a Bengali fake news detection dataset, “BanFakeNews” (Hossain et al. in BanFakeNews: a dataset for detecting fake news in Bangla, 2020 [ 8 ]) as well.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-18458-1_4,en,Spatial Blockchain: Smart Contract Using Multiple Camera Censuses,OriginalPaper,"With many data breaches and spoofing attacks on our networks, it becomes imperative to provide a reliable method for verifying the integrity of the source. Blockchain location-based proof-of-origin is explored for tracking trucks and vehicles. Blockchain applications that support quick authentication with these non-mutable ledger properties: consensus and implemented as smart contracts at the edge. This Blockchain application will now be known as the POWTracker platform, gathering data from multiple cameras. POWTracker is based on an existing GPS-based blockchain ledger and runs on an edge device that uses AI consensus and multiple cameras. By using GPS algorithms, we present a novel mining algorithm that rewards POW miners, providing a trustworthy, verifiable proof-of-location system.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-16-9967-2_25,en,Sentiment Classification of Higher Education Reviews to Analyze Students’ Engagement and Psychology Interventions Using Deep Learning Techniques,OriginalPaper,"Globally, higher education institutions are closed due to the COVID-19 pandemic. The sudden shift to online education excites most teachers and students. The professors are researching online learning platforms. They are only involved in face-to-face teaching in traditional teaching platforms. There are many concerns about the quality of online education. This paper proposes a framework for comparing online learning with traditional learning using emotions, learner perception, instructors, student engagement, understanding, effectiveness, learning outcome, peer collaboration, constraints, and comparisons. Deep learning algorithms like LSTM, GRU, and RNN classify the reviews. Students are positive during online learning in higher education according to LSTM, GRU, and RNN experimental analysis. Students are becoming more comfortable with online learning environments for higher education, according to detailed survey results.","['Computer Science', 'Computer Systems Organization and Communication Networks', 'Computational Intelligence', 'Artificial Intelligence', 'Wireless and Mobile Communication', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-16368-5_18,en,The Method of Using a Telecommunication Air Platform as a Flying Info-Communication Robots,OriginalPaper,"The paper is devoted to the conducted research of effectiveness of method of improved monitoring data collection which are accumulated in the sensors of the wireless sensor network. Data collection is performed by the so-called info-communication robot under different initial conditions: network dimension, number of clusters, number of nodes in the cluster, options for constructing data collection methods, flight strategy over nodes in the cluster. The results of efficiency comparison of using the improved method with the existing method of direct data collection and the centroid method of data collection by time criteria are given: the duration of data collection and the duration of network operation. Carried out the analysis of four strategies of flight over cluster (only between collection points centers; flight over critical nodes; data transfer in points closer to the flight route; cooperative). The efficiency of the improved method of data collection from the main nodes of the clustered network was evaluated.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks']"
doi:10.1007/978-3-031-14605-3_13,en,Using AI for Justice: Principles and Criteria of the “European Ethical Charter on the Use of AI in Judicial Systems”,OriginalPaper,"The combined use of AI and Big Data makes it possible to apply automatic decision-making in the public administration. The debate is currently focused on the possibility of using algorithmic decisions also in the administration of justice: the use of algorithms which are capable of making choices should help overcome the propensity for eventual human-decision errors, in favour of the theoretically more certain efficiency of algorithmic decisions. The creation of a predictive justice system, however, raises doubts, especially in consideration of certain factors that might alter the algorithmic logic, e.g. the quality of data and the possibility of system error, which could lead to situations of indirect discrimination. With reference to the concerns and risks of the use of AI for justice purposes, in December 2018, the European Commission for the Efficiency of Justice adopted the “Ethical Charter on the use of AI in judicial systems and in related areas” that identifies 5 fundamental principles capable of guaranteeing efficient implementation: 1. respect for fundamental rights, 2. non-discrimination, 3. quality and security, 4. transparency—fairness-impartiality in data processing, 5. possibility of control by the user—‘under user control’. The proposed paper, after a brief survey of the critical aspects of the use of AI systems and an analysis of the contents of the EU Ethical Charter, will focus on the possibility of using AI for forecasting and non-decisional purposes, highlighting how the forecasting method can optimize use, especially in civil law systems.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-15030-2_7,en,Defensive Machine Learning Methods and the Cyber Defence Chain,OriginalPaper,"Cyberattacks are now occurring on a daily basis. As attacks and breaches are so frequent, and the fact that human work hours do not scale infinitely, the cybersecurity industry needs innovative and scalable tools and techniques to automate certain cybersecurity defensive tasks in order to keep up. The variety, the complex nature of the attacks, and the effectiveness of 0-day attacks mean that conventional tools are not adequate for securing complex networks with large numbers of users and endpoints with differing identities, behavior, and needs. Machine learning and artificial intelligence aid the creators of security tools in their tasks by introducing adaptive environment possibilities, customizability, and the ability to learn from past attacks and predict future attack attempts. In this chapter, we address innovations in machine learning, deep learning, and artificial intelligence within the defensive cybersecurity fields. We structure this chapter inline with the OWASP Cyber Defense Matrix in order to cover adequate grounds on this broad topic, and refer occasionally to the more granular MITRE D3FEND taxonomy whenever relevant.","['Computer Science', 'Artificial Intelligence', 'Privacy', 'Cryptology', 'Mobile and Network Security']"
doi:10.1007/978-3-031-10507-4_13,en,A Blockchain-Based Fair and Transparent Homework Grading System for Online Education,OriginalPaper,"In this work, with the aid of multiple Cryptographic algorithms, a blockchain-based homework grading system is presented to establish a transparent and fair platform for teacher–student interactions. Our goal is to ensure the fairness and transparency of the mutual interaction between students and teachers to guarantee that all students are being treated equally in grading. More importantly, post-grade cheating events will be prevented totally by recording grading results and grading activities on chain. We realized the proposed system based on Ethereum source codes to prove its applicability. Additionally, three autonomous smart contracts are also presented to enhance our design to provide more fairness to students and share more workloads from teachers. By combining all the above features, we believe our work helps manage the interaction between teachers and students and encourages all on-chain members to play their roles with accurate attitudes.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Systems and Data Security']"
doi:10.1007/978-981-19-5224-1_44,en,A Survey of Different Approaches for Word Sense Disambiguation,OriginalPaper,"Analysis of textual data helps to understand the perception of people by studying the various senses of words in the text. The sense of a polysemous word varies as per the context in the sentence. The technique for determining the correct interpretation of a polysemous word according to context is called as Word Sense Disambiguation (WSD). Recently, researchers have proposed many algorithms to solve this linguistic ambiguity problem in different languages. In this paper, we give a general summary of current trends in WSD in terms of automation of disambiguation approaches. We also mention the challenges and future directions for research for WSD systems. We also propose a system based on these future directions for research, which may increase the accuracy of WSD system for Indian languages.","['Engineering', 'Communications Engineering, Networks', 'Statistics, general', 'Cyber-physical systems, IoT', 'Sociology, general', 'Professional Computing']"
doi:10.1007/978-981-19-3951-8_26,en,Optimal Sizing of Stand-Alone Hybrid Energy System Using Black Widow Optimization Technique,OriginalPaper,"The renewable energy sources are clean energy sources, and their role and contribution are increasing day by day. In this paper, optimal sizing has been carried out for stand-alone hybrid energy system (HES) with solar PV, wind turbine (WT), diesel generator (DG), and energy storage. Black widow optimization (BWO) is one of the recent and powerful algorithms which is implemented for finding the optimal sizing of HES through energy management based on sample day load data using annualized model. The main goal of this study is to minimize the cost of energy such that all practical constraints are satisfied. A comparison of BWO has also been carried out with differential evolutionary (DE), particle swarm optimization (PSO), and a traditional solver (TS). It is concluded that the BWO performs better than the other optimization technique. Different configurations were tested for finding the best combination of units to be installed.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3938-9_24,en,A Methodology for Multi-objective Design Optimization (MDO) of Automotive Transmission Systems,OriginalPaper,"Automotive product design is very complex and involves arriving at precise decisions and feasible solutions (with respect to subsystem design specifications, vehicle architecture, change content, materials, geometry, etc.) meeting various functional image and regulatory requirements. It is vital to use various subjective and objective optimization methods while finalizing the specifications of various vehicle subsystems (transmission, engine, body systems, etc.). The present work involves development of a multi-objective multi-disciplinary design optimization (MMDO) approach to optimize the gear pair of an automotive system (SUV/Pick-up platform) with an objective of minimizing the cost and maximizing the performance and transmission bandwidth. Using advanced simulation tools and a DoE-based approach, functional forms were derived for the constraints. The functional forms are the predictive models obtained from various regression, response surface, and machine learning-based methods. The objective functions capture the cost and commonality aspects of the available gearbox design. The concept of cosine similarity is used to arrive at the expressions for objective function that define the commonality aspect of the transmission bandwidth. Tradespace exploration is carried out using advanced optimization algorithms and visualization tools to arrive at optimal solution.","['Engineering', 'Mathematical and Computational Engineering', 'Optimization', 'Machine Learning']"
doi:10.1007/978-981-19-2225-1_31,en,A Survey on Chatbot in Devanagari Language,OriginalPaper,"Chatbots is the current trending topic in machine learning. It processes the user's queries and gives appropriate response. Chatbots are kind of virtual assistant where we talk with a computer bot not with a real human being. But it feels like we are taking with a real human being. Chatbots are being used heavily in various sectors like in banking, ticket reservations, customer enquiry desks, etc. Chatbots are helping businesses to give quick responses to the user queries, and most importantly, it is saving both time and resources of the businesses and customer. In future, chatbot will play major role for the communication between business and consumers for sure. Most of the chatbots are developed in English language by using various frameworks. This paper explains various techniques and architectures which can be used for developing a real-time chatbot.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Statistics, general', 'Mobile and Network Security']"
doi:10.1007/978-981-19-3575-6_4,en,Application of Machine Learning in Mineral Mapping Using Remote Sensing,OriginalPaper,"The machine learning is an effective approach toward acquiring patterns on voluminous data popularly termed big data. Remote sensing is one such field that can be employed with the ML concepts to ascertain solutions to several environmental problems. With the raw spatial data captured by the sensors like LANDSAT, meaningful insights can be drawn adhering to the specifics of the arena. The images are captured in the form of electromagnetic waves often termed as spectral signatures based on the reflectance properties of elements on the earth’s surface. The paper intends to showcase the relevance of machine learning concepts pertaining to a specific area of application in geosciences with the identification of potential mineral mapping areas as the key objective. To derive the most appropriate results, the key indicators on the earth’s surface are focused where the dataset is band mapped with multispectral data. The spectral resolution is a key concept that provides an unambiguous picture of mineral spectra across the spectral regions. The image classification provides the classifiers which can be further accurately assessed to determine the several regions including vegetation, soil, and water. The paper intends to delve into the intricacies of remote sensing as an effective tool of data capturing in the form of spectral signatures and the role of machine learning algorithms for effective geospatial analysis to derive regions of exploration interest with extensive scrutiny of work under the study arena.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-3579-4_4,en,A Machine-Learnt Approach to Market Segmentation and Purchase Prediction Using Point-Of-Sale (POS) Data,OriginalPaper,"In recent years, firms have been able to collate large customer data sets, and this has led to both challenges and opportunities when making marketing and sales-related decisions. Large customer data sets can enable an intimate understanding of customers. However, this can pose additional costs to the firm while also requiring new data analysis and management capabilities. To address this problem, we develop a new approach to market segmentation and the identification of relative segment purchase probabilities using a large point-of-sale (POS) customer data set in the Sri Lankan retail context. Stage one of our method involves supervised and unsupervised learning approaches that analyze three purchase characteristics (Recency, Frequency, and Monetary value—RFM) and product attributes to identify segments in the customer data set. Stage two of our method involves market basket analysis (MBA) to determine the probabilities of purchase behaviors for each segment. Our new approach is among the first to establish a relationship between a machine learning-based approach to market segmentation and purchase prediction.","['Engineering', 'Industrial and Production Engineering', 'Computer Communication Networks', 'Electrical Engineering', 'Mathematical Modeling and Industrial Mathematics']"
doi:10.1007/978-981-19-3387-5_88,en,Research on Image Restoration in Remote Sensing Quick-View System,OriginalPaper,"Quick-view system plays an indispensable row in space exploration and earth observation. Currently, the remote sensing quick-view system of our country only has quick display and store abilities. The motion-blurred remote sensing images would not be restored. This paper centers on image restoration in remote sensing quick-view systems. Through calculating the two-level screw target matching image, the ratio of power spectrum density could be estimated quickly. Then Wiener filtering method is implemented to restore blurred images. To restrain the ringing artifact in quick-view system, different weights are introduced on the edge of the target when implementing Wiener filter. Experiments indicate that the optimized image restoration method can obtain relatively gratifying remote sensing data restorative results and treatment period, which might satisfy the requirement of real time display in remote sensing quick-view system.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Aerospace Technology and Astronautics']"
doi:10.1007/978-3-031-16926-7_18,en,Suitable Evaluation Models for Resilient-Sustainable-Inclusive Cities,OriginalPaper,"The sustainability has a central role in the urban policies of cities in Europe and worldwide. The United Nations, Europe and Member States suggest guidelines to make cities and human settlements more inclusive, safe, resilient and sustainable. The European Commission upholds initiatives aimed at improving the city’s resilient status and the migrants’ inclusiveness by means of Eco-Resilient Projects for the economic development, community's well-being and safeguarding of urban ecosystems. To reduce the theoretical-practical gap between ERP planning and design in terms of “Resilient-Sustainable-Inclusive” (RSI) city development, the present contribution outlines a framework to arrange the main scientific contributions concerning the sustainability in its three components, and the evaluation of projects in view of urban resilience and social inclusiveness. The proposed framework is aimed at the identification of the most suitable evaluation models based on RSI principles. Following the systematic review, the main methods and evaluation tools are outlined and discussed with respect to resilience, inclusiveness and sustainability targets.","['Economics', 'Urban Economics', 'Real Estate Management', 'Urban Studies/Sociology']"
doi:10.1007/978-3-031-19067-4_4,en,Synchronous SGD and Straggler-Resilient Variants,OriginalPaper,"For large training datasets, it can be prohibitively slow to conduct sequential SGD training at a single node, as we described in Chap.  1 .","['Mathematics', 'Algorithms', 'Machine Learning', 'Algorithm Analysis and Problem Complexity', 'Artificial Intelligence', 'Probability Theory and Stochastic Processes', 'Computer Science, general']"
doi:10.1007/978-981-19-4703-2_1,en,A Multitask Learning Approach for Chinese National Instruments Recognition and Timbre Space Regression,OriginalPaper,"Musical instrument recognition is an essential task in the domain of music information retrieval. So far, most existing research are focused on western instruments. In this research, we turn to Chinese national instruments recognition. First, a dataset containing 30 Chinese national instruments is created. Then, a well-designed end-to-end Convolutional Recurrent Neural Network is proposed. Moreover, we combine instrument recognition with instrument timbre space regression using a multitask learning approach to improve performances of both tasks. We conduct experiments in instrument recognition and timbre space regression to evaluate our model and multitask learning approach. Experimental results show that our proposed model outperforms previous algorithms, and the multitask approach can further improve the results.","['Engineering', 'Signal, Image and Speech Processing', 'Engineering Acoustics', 'Mathematics in Music', 'Music']"
doi:10.1007/978-981-19-3148-2_15,en,Performance Evaluation of Optimizers in the Classification of Marble Surface Quality Using CNN,OriginalPaper,"The recital of a convolutional neural network (CNN) is dependent on several things (i.e., optimization, weight initialization, network topology, batches and epochs and activation/loss function and learning rate), as well as on the quality of the input data and specific blend of these model characteristics. When dealing with a classification challenge, relying on a single optimizer is deemed insufficient testing or validity, unless the choice of an optimizer is supported by a compelling reason. As a result, optimizer selection techniques are critical for validating the use of a single optimizer to solve various choice issues. The research begins by evaluating the effectiveness of traditional machine learning algorithms on a dataset of defective/good marble surfaces. The classification was then benchmarked against prominent CNN optimizers to determine where it may be improved. We compare four distinct state-of-the-art gradient descent-based optimizers for CNNs, namely stochastic gradient descent (SGD), adaptive max pooling (Adamax), root mean square propagation (RMS Prop), and Nesterov adaptive momentum (Nadam). The RMS Prop optimizer achieved the highest accuracy of 81% in terms of increasing CNN's classification capabilities.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory']"
doi:10.1007/978-3-031-09640-2_10,en,A Machine Learning Framework for Intrusion Detection in VANET Communications,OriginalPaper,"Intelligent transportation system (ITS) is a promising technology to enhance driving safety and efficiency within smart cities. It involves public transportation management, infrastructure control, and road safety. Its main purpose is to avoid risks and accidents, reduce traffic congestion, and ensure safety for road users. Vehicular ad hoc networks (VANETs) are core components of ITS where wireless communications between vehicles, as well as between vehicles and infrastructure, are possible to allow exchanging road, traffic, or infotainment information. VANETs are vulnerable to several security attacks that may compromise the driver’s safety. Using misbehavior detection approaches and information analysis demonstrated promising results in securing VANETs. In this context, machine learning (ML) techniques proved their efficiency in detecting attacks and misbehavior, especially zero-day attacks. The goal of this chapter is two-fold. First, we intend to analyze the security issue in VANET by reviewing the most important vulnerabilities and proposed countermeasures. In a second part, we define a novel framework for designing an intrusion detection system (IDS) for vehicle-to-everything (V2X) communications. Furthermore, we use our framework for analyzing the efficiency of both standalone and ensemble ML approaches in detecting DOS and DDOS VANET attacks by means of extensive simulations conducted using the VDOS-LRS dataset.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Computational Intelligence', 'Security Science and Technology']"
doi:10.1007/978-3-031-11154-9_1,en,An Introduction to Artificial Intelligence in Healthcare,OriginalPaper,"The chapter presents a brief overview of Artificial Intelligence (AI) in healthcare. We start with the why and the how of AI in medicine. The most known and commonly used AI algorithms are presented. We continued the chapter with the pros and cons of AI, highlighting the main advantages and disadvantages it has. The chapter finishes with some of the newest real-life applications of AI in different healthcare sectors from diagnostic, drug development to administrative work.","['Engineering', 'Computational Intelligence', 'Biomedical Engineering and Bioengineering', 'Artificial Intelligence', 'Health Informatics']"
doi:10.1007/978-981-19-3590-9_16,en,A Survey: Secure Cloud Data Storage and Access Control System Using Blockchain,OriginalPaper,"The recent companies are able to get benefits with designing cloud and IoT solutions for security. The security of any system is considered the robust when it is able to avoid unauthorized access of data in cloud and IoT. In this paper, it is discussed various access control methods for cloud and IoT systems. Various papers are studied and presented in literature review. The access control is able to provide secure data storage using blockchain technology. Various access control methods are discussed and compared in this paper. The study is able to derive the pros and cons of access control methods for blockchain technology.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security', 'Mobile and Network Security']"
doi:10.1007/978-3-031-18344-7_26,en,Machine Learning Computational Framework for Alzheimer’s Disease Stages Classification,OriginalPaper,"Alzheimer’s Disease (AD) is a neurodegenerative disorder primarily characterized by deteriorating cognitive functions. In 2016 an estimated 40 million people were diagnosed with AD, and the expectation for 2050 is 131 million. Therefore, healthcare systems require detecting and confirming AD at its different stages to provide adequate and accurate treatments. Recently, Machine Learning (ML) models have been used to classify AD’s stages. It has become a priority to develop a framework for AD’s stages detection based on ML and imputation methods capable of handling datasets with missing values while providing high accuracy. We propose a ML computational framework that integrates data processing, feature selection, imputation methods and 5 different ML models. The performance of the proposed framework has been evaluated using the main metrics for classification problem; accuracy, F1- score, recall, and precision. As a results of the proposed process, our framework classifies the AD’s onsets with an accuracy of 99%.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-3-031-18050-7_55,en,Classification Methods for MOBA Games,OriginalPaper,"The rise of the sports industry, which over time has increased in popularity along with machine learning and the possibilities for improving upon previously known and used methods, can serve many future predictions and benefits. This paper proposes a methodology to feature sorting in the context of supervised machine learning algorithms. A new perspective on machine learning by using it to predict outcomes with a database of the popular moba game Dota2, which consists of a large volume of data that was collected and analyzed. The reported results are concerned with three machine learning models with two significant metrics such as F-measure and Accuracy.","['Engineering', 'Computational Intelligence', 'Industrial and Production Engineering']"
doi:10.1007/978-981-19-0503-2_17,en,Interactive Expert System for Budgeting World Bank Consultancy Projects,OriginalPaper,"Cost estimating is a key component of the budgeting of any project, conventional approaches may result in uncertainty and usually do not utilize the knowledge of past projects. Ideally, performing cost estimation under the best predictions of the relevant future conditions is the best approach of economic analysis to evaluate the optimum value for money. With the rise of Artificial Intelligence techniques, there are several Machine Learning (ML) methods that are being studied to capitalize on accuracy gains with regards to cost estimating techniques during the tendering phase. This research aims at developing an expert system that determines the rough order of magnitude for budgeting with an expected range of 30–35% leeway, to forecast the budget of consultancy services of World Bank projects through regression by classification using the Ensemble method. The expert system utilizes advanced ML methods to be able to generate accurate forecasts based on a rigorous database of past projects. The model was trained to identify the influential factors that affect the cost of the services in accordance with the published data related to the project and contract award. Among the studied variables are; sector, procurement method, environmental category, procurement type, region, and overall project budget. The dataset was used as inputs for over 80,000 consultancy contracts globally over the last 14 years. A web interface was then created where the cost estimates of consultancy services tendered by the World Bank are determined. The model developed showed a 72% acceptance rate in terms of model accuracy.","['Engineering', 'Building Construction and Design', 'Geoengineering, Foundations, Hydraulics', 'Transportation Technology and Traffic Engineering', 'Environment, general']"
doi:10.1007/978-981-19-4182-5_29,en,A Systematic Review on Underwater Image Enhancement and Object Detection Methods,OriginalPaper,"In the last decade, the number of underwater image processing research has increased significantly. This is primarily due to society's dependency on the precious resources found underwater and to protect the underwater environment. Unlike regular imaging in a normal environment, underwater images suffer from low visibility, blurriness, color casts, etc. due to light scattering, turbidity, darkness, and wavelength of light. For effective underwater exploration, excellent approaches are necessary. This review study discusses the survey of “underwater image enhancement and object detection” methods. These methods are outlined briefly with the available dataset and evaluation metrics used for underwater image enhancement. A wide range of domain applications is also highlighted.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Computer Systems Organization and Communication Networks', 'Statistics, general']"
doi:10.1007/978-3-031-12818-9_2,en,"Modular Multilevel Converters: Key Features, Control Strategies and Main Challenges",OriginalPaper,"Voltage source multilevel converters rank among the most popular solution to implement hvdc systems and efficiently integrate usually remote concentrated renewable energy sources. This chapter presents some of the converters that belong to this group. More specifically, a major emphasis is put on the modular multilevel converter ( mmc s) by describing its topology, key features, pros and cons with respect to other converter technologies, as well as the reasons for its increasing popularity in the recent years. Lastly, after explaining a typical mmc control structure, the chapter highlights the challenges posed by mmc s from a simulation perspective. One of these challenges, namely the electromagnetic transient simulation, constitutes the main cornerstone of this book.","['Engineering', 'Circuits and Systems', 'Electronics and Microelectronics, Instrumentation', 'Energy Systems']"
doi:10.1007/978-3-031-13150-9_5,en,Mirai Botnet Attacks on IoT Applications: Challenges and Controls,OriginalPaper,"IoT is rapidly developing technology to enhance the quality of human life with embedded technologies. IoT can control and access daily usable devices and equipment with an internet connection. Smart technology provides a connected infrastructure to heterogeneous devices like IP cameras, cell phones, cars, home appliances, and industrial equipment for autonomous communication and interaction. The great perspective of IoT infrastructure comes with more security challenges. The multiplication of IoT gadgets it can be more easily negotiated than personal computers has led to intensification in the IoT-based botnet attacks. These IoT devices need to ensure the security and privacy of sensitive information and network communication. In the public channel, an adversary can damage the transferred information for unauthorized activities on applications. To moderate this hazard, there is a necessity for new procedures that diagnose the threats dispatched from exchanged IoT appliances and that are dispersed amongst all IoT-based attacks. We discuss the bio-inspired-based attack discovery techniques for IoT botnet attacks and network traffic from hacked IoT gadgets. This paper aims to review the existing attack detection approaches that have been used to address the security issues on IoT applications. In this work, bio-inspired computing models were independently trained to detect and mitigate the Mirai botnet attacks on IoT applications. The bio-inspired computing framework shows the high accuracy and high detection rate over the IoT environment. And also we are exploring details of the bio-inspired models for improving security measures in different scenarios on smart technology.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Management']"
doi:10.1007/978-981-19-1669-4_16,en,Automated Skin Disease Detection Using Machine Learning Techniques,OriginalPaper,"Dermatological problems are among the world’s most prevalent illnesses. Although its frequent diagnosing, its intricacies of physical appearance, existence of hair are very challenging. Identification and observation of skin diseases is a significant issue for the medical sector. Because medical services are not accessible in rural locations, people often overlook initial signs which might deteriorate over time. This is thus an increasing demand for a high-precision automated skin disorder classification method. To detect skin diseases, it is first necessary to remove the skin from the body. Five different machine learning methods were selected and performed on skin infection information to forecast the precise skin illness classification. From a few methods for machine learning, Naïve Bayes, uninformed mountain pastures, logistical regression, SVM and KNN have been developed. A comparable analysis was conducted using graphs based on cross validation values and training accuracy. It has been shown that KNN is best trained to meet the appropriate expectations of all chosen skin disorders.","['Engineering', 'Signal, Image and Speech Processing', 'Circuits and Systems', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-13714-3_8,en,Construction Learning,OriginalPaper,"The first basic ingredient of heuristics is to build a solution. So, a first metaheuristic approach is to improve the process of building solutions. This chapter presents construction learning mechanisms. A typical example is artificial ants systems. Another technique is vocabulary building.","['Business and Management', 'Operations Research/Decision Theory', 'Optimization', 'Computational Mathematics and Numerical Analysis', 'Algorithms', 'Computational Science and Engineering', 'Artificial Intelligence']"
doi:10.1007/978-981-19-6004-8_31,en,Yolov4 in White Blood Cell Classification,OriginalPaper,"White blood cell (WBC) counting is vital for the diagnostic of many diseases. However, the manual counting method operated in hospitals and centers is time-consuming and inefficient. Many automatic processes in classifying WBC types were proposed using deep learning (DL) models. YOLOv4 is an emerging model for detecting objects with promising results in many applications including the medical field. In this paper, YOLOv4’s performance would be tested on classifying four types of WBC: monocyte, lymphocyte, neutrophil, and eosinophil. A mixed database of WBC microscopic images from an online dataset BCCD and a hospital dataset collected from the Vietnamese National Institute of Hematology and Blood Transfusion, comprising of 10,275 images in total after the augmentation, was used for training and testing the model. The results showed that the trained YOLOv4 was able to classify equivalently well all 4 WBC types with the average accuracy of 97.8%, ranking the second-best option when compared to other contemporary studies.","['Engineering', 'Computational Intelligence', 'Cognitive Psychology', 'Personality and Social Psychology', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-4863-3_12,en,Potential Assessment of Wind Power Generation Using Machine Learning Algorithms for Southern Region of India,OriginalPaper,"Now a day, large scale grid interconnected wind power generation systems are increasing day by day, the stable operation of grid highly depends on the amount of wind energy penetrating into the grid. This is not only essential for stable operation but also necessary for generation allocation and load scheduling. In order to achieve this, a precise method for estimating the potential is necessary. In this paper, a modest attempt has been made to estimate the potential of wind power generation for southern region of India. The methodology presented is based on an efficient machine learning algorithm based regression methods viz. linear, support vector, K -nearest neighbour, and decision trees regression models for prediction of number of units’ generated and output power has been presented. To evaluate the efficiency of these algorithms key performance indicators such as mean absolute error, mean square error, root mean square error and R 2 score have been considered. It has been observed that linear regression model performs better than all the other methods considered in this study and the same was summarized in the results.","['Engineering', 'Computational Intelligence', 'Engineering Design', 'Machine Learning', 'Communications Engineering, Networks']"
doi:10.1007/978-3-031-19620-1_8,en,Patterns in Smart Wireless Sensor Network Nodes,OriginalPaper,"The trend in the modern weapon development is to bind individual samples with a certain autonomy degree into a complex typically using wireless sensor networks. The scope of the complexes is indefinite and poorly formalized environments. It is possible to achieve the desired efficiency of such complexes mainly by improving the intellectual component of their control system and a separate unit in particular. However, it should be noted that the vast majority of research in this area remains at the theoretical level. There is a gap between primitive behavior models of artificial entities, for example in swarm robotics, models of their interaction and expectations from practice. The situation is aggravated by the requirements of secrecy, miniaturization, and low power consumption. The work objective is to propose an approach to developing software for intelligent control systems for a separate network node with a given autonomy degree in performing tasks. To propose relatively simple algorithms for giving a network node the intelligent behavior properties under power consumption and speed restrictions; to provide the ability to study the situation and make decisions, both independently taking into account the data received from other network devices and as part of a group. Methods. The paper uses the methods of fuzzy set theory, the theory of building fuzzy models and networks, as well as approaches and algorithms for building on-board intelligent control systems. Results. It is shown that the required algorithms can be developed after identifying typical situation classes and successful action methods in real conditions. This basis makes it possible to develop formal behavior models (patterns) for implementation in the node management system.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2600-6_21,en,Machine Learning Based Automated Process for Predicting the Anomaly in AIS Data,OriginalPaper,"In this paper, we present an automated process for detecting the anomaly in Automatic Identification System (AIS) data. Machine learning approaches have been employed to automatically detect anomalies in the AIS data. The opensource AIS data is been used to evaluate the performance of the proposed approach. Supervised machine learning approaches like K Nearest Neighbor, Random Forest, Support Vector Machine classifier is employed to predict the anomalies in the AIS data. The AIS data does not contain the ground truth labels and supervised learning algorithms need labelling data, to address this issue, we employed an unsupervised approach to label the data based on the prior information and characteristics of the AIS data. The labelled data is then used to train the supervised machine learning models. The proposed approach with support vector machine classifier has classified the AIS data into normal and anomaly with an accuracy of 96.5%.","['Engineering', 'Data Engineering', 'Statistics, general', 'Machine Learning', 'Artificial Intelligence', 'Data Storage Representation', 'Data Structures and Information Theory']"
doi:10.1007/978-981-19-4606-6_25,en,Generic Classification and Automatic Extraction of Mechanical Interlocking Features from CAD Model,OriginalPaper,"This paper presents the classification, representation and extraction of mechanical interlocking features (MIFs) from the CAD model. Mechanical interlocking features (MIFs) are geometric features of two or more parts that when caused to come into contact and fully engage, prevent relative motion in certain directions of translation and/or rotation, including, when features physically interlock, unwanted separation in any or certain directions. The MIFs are represented as a set of faces with a characteristic arrangement among the faces among parts in proximity. This characteristic arrangement of contact faces and their topological relationships help in classification of MIFs. The MIFs are classified into elementary and compound types based on the number of assembly features available at the joint location. Even though CAD assembly models are available to users, it is rather difficult for the user to manually extract the assembly feature information from CAD models. It is therefore a set of algorithms are developed to extract the attributes of MIFs and identify MIFs from CAD model. CAD assembly models from aerospace domain have been used in order to illustrate and validate the proposed approach.","['Engineering', 'Industrial and Production Engineering', 'Machinery and Machine Elements', 'Materials Engineering']"
doi:10.1007/978-3-031-18050-7_12,en,Dimensional Reduction Applied to an Intelligent Model for Boost Converter Switching Operation,OriginalPaper,"The dimensional reduction algorithms are applied to a hybrid intelligent model that distinguishes the switching operating mode of a boost converter. Thus, the boost converter has been analyzed and both operating mode are explained, distinguishing between Hard-switching and Soft-switching modes. Then, the dataset is created out of the data obtained from simulation of the real circuit and the hybrid intelligent classification model is implemented. Finally, the dimensional reduction of the input variables is carried out and the results are compared. As result, the proposed model with the applied dimensional reduced dataset is able to distinguish between the HS and SS operating modes with high accuracy.","['Engineering', 'Computational Intelligence', 'Industrial and Production Engineering']"
doi:10.1007/978-981-19-3148-2_42,en,Learning Techniques for Prediction of Breast Cancer Disease: A Comparative Analysis,OriginalPaper,"Breast cancer and its detection is always one of the trending topics of all time. Many research activities have been done in this field using different technologies to make it effective. In this research, it has taken machine learning and deep learning algorithms to develop an effective breast cancer classifier. It has implemented ten best machines learning and deep learning classification algorithms like logistic regression, decision tree, random forest, support vector machine, K-nearest neighbor, Naïve Bayes, multi-layered perceptron, stochastic gradient descent, AdaBoost, and artificial neural network classifier for prediction of breast cancer disease. These classifiers are successfully able to classify whether the given data are coming under benign cell or malignant cell. It has also got different accuracy for every classifier. At the end, it has successfully implemented all the approaches and has got the good accuracy.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory']"
doi:10.1007/978-981-19-8202-6_10,en,Dominate Tree Species Classification on Large-Scale Mountainous Areas Using Voting Strategy-Based Ensemble Learning Method,OriginalPaper,"Remote sensing technology provides an economical and efficient means for obtaining the distribution of dominant tree species. However, remote sensing mapping of dominant tree species have remained an ongoing challenge, such as massive data and low accuracy of a single machine learning method, especially over large-scale mountainous areas. In this study, the multi-source variables and multi-classifier decision fusion was used to separate the dominant tree species on the Google Earth Engine cloud computing platform. We combined with multi-source data such as Sentinel-2 satellite imagery, bioclimate, topography, and forest inventory data and constructed time series for NDVI and REP to evaluate different variables combinations. At the same time, tree species classification was carried out following two approaches: non-stratified and stratified. Four different Machine learning algorithms, Random Forest (RF), Support Vector Machine (SVM), XGBoost, and Maximum Entropy (MaxEnt) were used as component classifiers to construct two decision fusion models of serial integration and Bayesian parallel integration respectively and completed the spatial distribution of 10 main dominant tree species mapping in the mountainous areas of northwest Yunnan. The nine tree species were classified with an overall accuracy of 74.44% using serial integration of MaxEnt and RF. This study confirmed that combination of multi-source data multi-source variables and the decision fusion method can be used to provide a reference for the classification of dominant tree species in large-scale mountainous areas.","['Engineering', 'Signal, Image and Speech Processing', 'Computer Applications', 'Geography, general', 'Earth System Sciences']"
doi:10.1007/978-3-031-16237-4_7,en,Attack Detection by Using Deep Learning for Cyber-Physical System,OriginalPaper,"With a cyber-physical system (CPS), physical components like industries are handled with an automated system. With the booming of cyber-attacks, detecting these attacks remains challenging. In order to protect the system from being hacked, we need to have CPS security measures implemented. Machine Learning (ML) has an important role to play in the detection of security attacks, which is the first step to protecting the CPS system. Cutting edge Deep Learning (DL) techniques have widely been applied to various domains like image processing and speech recognition. As part of a review of detecting cyber-attacks in CPSs, this chapter outlines the roles of DL and Deep Reinforcement Learning (DRL). Also, we present state-of-the-art solutions without sacrificing technical details. Additionally, we describe common datasets used for DL in CPSs. Finally, we express research opportunities and challenges in the CPSs with respect to DL.","['Engineering', 'Cyber-physical systems, IoT', 'Data Engineering', 'Computational Intelligence', 'Big Data', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5292-0_41,en,Support System for Chronic Kidney Disease Prediction Using Fuzzy Logic and Feature Selection,OriginalPaper,"Chronic kidney disease (CKD) is a global scientific issue marked by extreme gloom and a high death rate, and it causes extraordinary illness. Because there aren't any obvious side effects in the early stages of CKD, patients frequently fail to monitor their condition. A persistent renal problem is difficult to diagnose. Due to their quick and precise acknowledgment execution, machine learning of fashions can successfully assist scientific achieve this. As a result, we recommend using a logistic regression tool to diagnose chronic renal disease. The professional gadget compares the collection of rules, which includes ANN, C4.5, Support vector system set of rules, and KNN, as well as fuzzy policies, and provides an accuracy of 98.75. The feature selection and classification is used, and produce the ultimate result includes accuracy, f-measure, and recall. Our proposed system’s primary objective is to predict the disease provided with a fuzzy rules along with machine learning model and find the accuracy of the disease in an early stages. Results shows that proposed technique withstands data processing and fuzzy sets to evaluate the accuracy. As a result, we speculated that the way of thinking could be appropriate for locating further confusing medical data.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-981-19-2225-1_27,en,Dense SIFT-Based Facial Expression Recognition Using Machine Learning Techniques,OriginalPaper,"Facial analysis is an active research topic in examining the emotional state of humans over the past few decades. It is still a challenging task in computer vision due to its high intra-class variation, head pose, suitable environment conditions like lighting and illumination factors in behaviour prediction and recommendation systems. This paper proposes a novel facial emotion representation approach based on dense descriptors for recognizing facial dynamics on image sequences. Initially, the face is detected using the Haar cascade classifer to extract the temporal information from the facial frame by applying a scale invariant feature transform by combining a bag of visual words. Later, the extracted high-level features are fed to machine learning algorithms to classify the seven emotions from the MUG dataset. The proposed dense SIFT clustering performance was evaluated on four different machine learning algorithms and achieved a high rate of recognition accuracy in all classes. In the experimental results, K-NN exhibits the proposed architecture’s effectiveness with an accuracy rate of 91.8% for the MUG dataset, 89% for SVM, 87.6% for Naive Bayes, and 85.7% decision tree, respectively.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Statistics, general', 'Mobile and Network Security']"
doi:10.1007/978-981-19-0312-0_20,en,"Perfomance Analysis of Text Extraction from Complex Degraded Image Using Fusion of DNN, Steganography, and AGSO",OriginalPaper,"In present time, any complex degraded image consists of very important and confidential information details which is recognized as a non-textual image and textual information. Due to diversity of text style in image, complicated background, and various interference factors makes detection of text (DOT) from complex degraded image as a field of research. The secure and accurate text in a complex degraded image is found useful for the audience to understand the complete situation. So, a fusion of DNN, adaptive galactic swarm optimization (AGSO), and steganography are applied in this proposed technique to securely, efficiently identify information in the form of text and thereafter, to recognize each character from degraded complex images. In general, images are affected by different type of noise such as structured noise, Poisson–Gaussian noise, periodic noise, and impulse valued noise, and to discard it in the initial preprocessing phase, the guided filter (GF) is used. A very important task in the text identification and recognition process is feature extraction, performed by using Gabor and stroke width transform. The extracted features of the image are required during the classification process. Thereafter, text identification and recognition is done by WNBA. Subsequently, performance comparison of various performance parameters such as precision, F1-scores, and recall was tested using the IIIT5K database for proposed algorithm along with other existing techniques.","['Engineering', 'Microwaves, RF and Optical Engineering', 'Wireless and Mobile Communication', 'Computer Communication Networks']"
doi:10.1007/978-981-19-0105-8_2,en,MultiNet: A Diffusion-Based Approach to Assign Directionality in Protein Interactions Using a Consensus of Eight Protein Interaction Datasets,OriginalPaper,"Protein–protein interaction network (PPIN) plays a major role in information processing and decision making in cells. The PPIN works as a skeleton for cell signaling and functionality. Understanding the flow of information in a cell can enhance our understanding of functional outcomes and flow of signals. To utilize the whole potential of PPIN, we need to direct the edges of the networks. In recent years, a deluge of PPIN became available for analysis but to understand the full picture, these PPINs need to be oriented, or directed, as the direction of signal or information flow in human PPIN is still mostly unknown. In this paper, we propose MultiNet, a method based on the well-known diffusion-based approach which assigns directionality to PPIN created from eight different networks to cover the most of the human genome MultiNet achieves the highest AUC score of 0.94 over protein DNA interaction test set and performs better than the current state-of-the-art algorithms using networks from single sources.","['Engineering', 'Communications Engineering, Networks', 'Artificial Intelligence', 'Computational Intelligence', 'Bioinformatics']"
doi:10.1007/978-981-19-4182-5_2,en,Retrospective Review on Object Detection Approaches Using Boundary Information,OriginalPaper,"In computer vision, object detection is an approach for identifying and locating objects from theimages and videos. It can also be used to measure the number of objects present in a scene determining the precise location as well. A technique for detecting boundaries between two objects comes under semantic ontology. The semantic boundary and edge detection is a difficult task as assessment for an edge cannot be purely grounded on low-level features like a gradient. Semantic learning of classifiers involves the knowledge of edge-labels, which is a complex problem in image processing. Here we examine several levels of information in order to adopt a feasible method where all edges required pixels for the continuous detection of the objects. In this paper, we study the application of object detection and several recent approaches developed using boundary information in past decades. The associated drawbacks are also highlighted in this work to provide the scope of improvement in this research field.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Computer Systems Organization and Communication Networks', 'Statistics, general']"
doi:10.1007/978-3-031-11748-0_10,en,Transfer Learning via Representation Learning,OriginalPaper,"The remarkable performance boost of artificial intelligence (AI) algorithms is a result of re-emergence of deep neural networks that have been applied in a diverse set of applications. The success of deep learning stems from relaxing the need for the non-trivial task of feature-engineering. However, this remarkable success is conditioned on manually annotating a large amount of data points to generate suitable training datasets to supervise training of these networks. Since manual data annotation is time-consuming and expensive in many applications, learning in data-scarce regimes has been a major recent area of research focus in machine learning (ML) and AI. Transferring and reusing knowledge from a related learning problem is a core strategy for addressing challenges of learning in data-scarce regimens. Transfer learning is not a new field in ML and several great survey exist on this topic [ 63 , 95 , 98 , 105 , 120 ]. However, these existing survey are meant to be general and extensively survey many works in the area. In this chapter, we survey a very specific subset of works in this area. Our goal is to explore a framework that unifies a broad range of knowledge transfer problems as learning cross-problems relations and similarities using an representation learning . By representation learning, we mean representing the data in the input space in a latent embedding space. The latent embedding space is meant as an intermediate space to explore relationships between several ML problems. We review the recently developed algorithms that use this strategy to address several primary transfer learning settings in five primary area of: (i) online and offline multitask learning, (ii) lifelong learning and continual learning, (iii) low-shot learning, including, few-shot learning and zero-shot learning, (iv) domain adaptation, and (v) collective/distributed learning. We discuss existing challenges and future potential research directions.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Machine Learning']"
doi:10.1007/978-3-031-16072-1_43,en,Vehicle Usage Extraction Using Unsupervised Ensemble Approach,OriginalPaper,"Current heavy vehicles are equipped with hundreds of sensors that are used to continuously collect data in motion. The logged data enables researchers and industries to address three main transportation issues related to performance (e.g. fuel consumption, breakdown), environment (e.g., emission reduction), and safety (e.g. reducing vehicle accidents and incidents during maintenance activities). While according to the American Transportation Research Institute (ATRI), the operational cost of heavy vehicles is around $$59\%$$ 59 % of overall costs, there are limited studies demonstrating the specific impacts of external factors (e.g. weather and road conditions, driver behavior) on vehicle performance. In this work, vehicle usage modeling was studied based on time to determine the different usage styles of vehicles and how they can affect vehicle performance. An ensemble clustering approach was developed to extract vehicle usage patterns and vehicle performance taking into consideration logged vehicle data (LVD) over time. Analysis results showed a strong correlation between driver behavior and vehicle performance that would require further investigation.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2821-5_52,en,Urban Sound Classification Using Adaboost,OriginalPaper,"Classifying environmental sounds such as gunshots and dog barking are gaining popularity. Environmental sound classification(ESC) helps in developing context-aware applications such as security systems and criminal investigation systems. Research in speech and music has been done but environmental sounds are different because of their unstructured nature and attracts extensive attention in the field of research. Researchers have explored various preprocessing techniques, feature extraction and feature selection methods, and classification algorithms for ESC. In this paper, the ensemble technique—Adaboost algorithm— is applied to classify environmental sounds. The accuracy of different base estimators is evaluated on the publicly available dataset UrbanSound8K, and the highest accuracy is obtained in the case of the base estimator as random forest. The results of the Adaboost algorithm are also compared with the benchmark results reported using other machine learning classification algorithms such as support vector machines(SVM), IBK5, random forest 500, J48, and ZeroR.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-3-031-19067-4_3,en,Convergence of SGD and Variance-Reduced Variants,OriginalPaper,In this chapter we will analyze the convergence of gradient descent (GD) and stochastic gradient descent (SGD) to determine the number of iterations required to reach a target error.,"['Mathematics', 'Algorithms', 'Machine Learning', 'Algorithm Analysis and Problem Complexity', 'Artificial Intelligence', 'Probability Theory and Stochastic Processes', 'Computer Science, general']"
doi:10.1007/978-3-031-15211-5_63,en,Combination of GPU Programming and FEM Analysis in Structural Optimisation,OriginalPaper,"GPUs no longer only support graphical applications and gaming. These are becoming cheap and powerful tools for scientific and general-purpose computations. They provide a massively parallel environment with the support of a single instruction multiple data (SIMD) programming model. Making finite element calculations is also a time-consuming process in some cases due to many elements or a large degree of freedom. The FEM simulation is essential to check the analytical or measured mechanical stresses, deformations, etc. In making structural optimisation, one needs several iterations and combining the optimisation with FEM, increasing the calculation time. GPU programming is a good solution for this. In the article, we show the applicability of the combination of GPU, optimisation, and FEM simulation.","['Engineering', 'Automotive Engineering']"
doi:10.1007/978-981-19-2397-5_71,en,An Analysis of Supervised Machine Learning Algorithms for COVID-19 Diagnosis,OriginalPaper,"The global pandemic COVID-19 is infectious disease which produced devasting effect to mankind and entire health community. The disease shown the multiple variants by the time and due to the severity, many people have lost their lives. The predetermination and early prediction based on symptoms can increase the survival rate. Many researchers have proposed the prediction model using conventional machine learning techniques and ensemble model. With this research work, the comparative study of machine learning techniques is shown. The study shows the utilisation and working process of supervised learning in terms of classification of categorical data. The proposed comparative approach predicts the COVID results based on specific features. The algorithm used is random forest, decision tree, K-nearest neighbour, and Naïve Bayes classifier. The model is evaluated based on the performance metrics such as accuracy, precision, recall, and F1 score. With fitting the model on open-source data, it is found the performance is improved, and the proposed model selection is the best choice for time constraint application.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16075-2_58,en,Smart Hardware Trojan Detection System,OriginalPaper,"The IoT has become an indispensable part of human lives at work and home applications. Due to the need for an enormous number of IoT devices manufacturers are least concerned about security vulnerabilities during designing and developing of these devices. Because of this, it becomes easier for adversaries to manipulate the hardware and insert Trojans or Remote File Inclusion to control remotely. In this research, we aim to build a model to identify hardware Trojans in IoT devices using Deep learning. We used different machine learning models to evaluate the performance and accuracy. In addition we choose a distinctive feature that can detect the presence of Trojan in these devices. The proposed model is evaluated using an existing and real-time dataset generated using a smart city testbed, The testbed used was designed to simulate and evaluate the Hardware trojan attacks, and by using the real-time dataset we could measure the power profile and network traffic on the IoT gateway device to analyze the performance and the accuracy.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-3-031-05445-7_16,en,Sub-Band Decomposition Based-Linear Normal Mode Identification,OriginalPaper,"In the past few decades, matrix decomposition methods have been explored as suitable Operational Modal Analysis algorithms. For a given vibratory mechanical system, one looks for its coherent spatial–temporal structures through the assumption of separation of variables. In practical situations, this separation of variables is done by decomposing a sampled scalar field that contains the underlying continuous field of the structure in time. In mechanical vibrations, this sampled scalar field is usually a trajectory matrix, X ∈ ℝ n × m $$X \in \mathbb {R}^{n \times m}$$ , that is composed of n displacement, velocity, or acceleration observations at m distinct spatial points on a structure. Methods such as the Proper Orthogonal Decomposition (POD) and the Smooth Orthogonal Decomposition (SOD) have been used to decompose the trajectory matrix into its modal coordinates and modal matrix. In real-world scenarios, there are practical limitations to these algorithms. First, for the case of POD, the free-response sample covariance matrix must be scaled by the mass matrix to identify the true LNMs of the structure. For complicated structures with nonuniform mass distribution, this is problematic.","['Engineering', 'Building Repair and Maintenance', 'Vibration, Dynamical Systems, Control', 'Fourier Analysis', 'Abstract Harmonic Analysis']"
doi:10.1007/978-981-19-3015-7_16,en,Anomaly Detection Using Feature Selection and Ensemble of Machine Learning Models,OriginalPaper,"Vulnerabilities have increased in cyberspace. This is due to the technology growth and the huge amount of data communicated between various endpoints of a network. Intrusion Detection System (IDS) plays a major role in identifying malicious traffic in the network. Intrusion Detection is much challenging because of the raw network traffic it contains with a large number of attributes that add to the complexity of the model. Several Machine Learning (ML) models have been built to solve these issues. The problem even after the new technologies’ introduction is the lack of datasets, classifiers work best for one problem and serve the least for the other set of problems, decision algorithms are not framed effectively. To overcome these problems, proposed method uses an ensemble approach on classifiers to provide a better solution for feature selection parameters. Our model outperforms the accuracy and detection rates compared to the individual classifiers. Decision Tree (DT), Logistic Regression (LR), and Support Vector Machine (SVM) values are given to the Random Forest (RF) ensemble classifier. Experiments are performed using CICIDS 2017 dataset. The proposed approach has accuracy of 98%, recall 97%, precision 100%, and F-score 98% compared to the individual models.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Engineering', 'Data Mining and Knowledge Discovery', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-981-19-2065-3_15,en,Comparative Analysis of Speech Enhancement Techniques in Perceptive of Hearing Aid Design,OriginalPaper,"Speech is an essential method for communicating with people. Understanding speech in a non-ideal environment is a challenging issue for a hearing disabled. Hearing instruments address this problem and use various algorithms to improve the speech perceptibility for hearing disabled. Compressive sensing (CS) is one such algorithm. This work compares the effectiveness of compressive sensing for speech enhancement with other tradition algorithms like spectral subtraction, Wiener filter, etc. Comparative analysis is done for speech distorted with various types of noises in real world. The effectiveness of the algorithms is measured in terms of speech quality parameters of: Perceptual Evaluation of Speech Quality (PESQ), Mean Opinion Score (MOS), Processing time, and Segmental Signal to noise ratio (seqSNR).","['Engineering', 'Communications Engineering, Networks', 'Artificial Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Machine Learning']"
doi:10.1007/978-3-031-20322-0_5,en,A Software Development Model for Analytical Semantic Similarity Assessment on Spanish and English,OriginalPaper,We propose a software development method for semantic text similarity based on the analysis of structural properties of pairs of snippets of texts. An agile software method focuses on the detection of biases on generated prototypes to enhance the quality of the expected features. A system for the detection of semantic text similarities is designed and implemented using the software method. The system design defines a set of structures for recording and computation of similarities using algorithms with polynomial complexities. The algorithms exploit knowledge bases for information extraction. Two implementations for English and Spanish were produced to test the portability of the system on European languages. The An experiment on Spanish and English text snippet is performed to test the performance of the prototypes. Results show that the degree of accuracy of the proposed algorithms are improved as the knowledge base content increases. The advantages of this methodologies is the elicitation of similarities between texts and the assessment of the similarity degree from scratch without prior knowledge assumptions.,"['Engineering', 'Computational Intelligence', 'Software Engineering/Programming and Operating Systems']"
doi:10.1007/978-1-4842-8954-9_1,en,Introduction to Recommendation Systems,OriginalPaper,"In today’s world, every customer is faced with multiple choices for every decision. Let’s assume that a person is looking for a book to read without any specific idea of what he wants. There’s a wide range of possibilities for how his search might pan out. He might waste a lot of time browsing the Internet and trawling through various sites hoping to strike gold. He might look for recommendations from other people.","['Computer Science', 'Machine Learning', 'Python', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4052-1_14,en,Banana Leaf Diseases and Machine Learning Algorithms Applied to Detect Diseases: A Study,OriginalPaper,"The world is changing continuously, nothing is permanent. What we think is new today becomes obsolete in a few days with better versions. All things have become computerized day by day. People are opting for technical methods to deal with the changes rather than following traditional methods. Agriculture is not an exception. Since in India, 70% of the population is dependent on agriculture and also agriculture has a 20.5% share in India’s GDP, i.e. 17–18% of India’s income comes from agriculture, farmers have started opting for new methods to increase the productivity of crops. Researchers are working on Artificial Intelligence-based technologies to increase the life of crops by which crop diseases can be predicted in their early stages. India is a land of agriculture and there are varieties of crops available. Since there are different climatic conditions, depending on which soil also changes its behaviour. Pests are also a major problem. Image Processing has evolved as an effective thing for the early analysis and detection of plant disease. Several algorithms have used to analyze the diseases at the early stage that results in minimum loss to the farmers and good quality of crops. This paper is presenting a study on the diseases found in banana crop along with their solutions available. This paper is different from other survey papers because it has focused mainly on banana crop whilst study had done on multiple crops earlier in a single paper.","['Engineering', 'Computational Intelligence', 'Information Storage and Retrieval', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Data Structures and Information Theory', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16159-9_31,en,Dynamic Positioning Capability Assessment for Ship Design Purposes,OriginalPaper,"The article focuses on solving a problem of optimal thrust distribution over the actuators in a ship Dynamic Positioning, according to DNV-ST-0111 standard, Level 1 . The classic Quadratic Programming approach is combined with the numerical solusion used to handle the propeller with the rudder constraints in the optimization task and the influence between thrusters and skeg. It is presented as an efficient method of minimizing the power consumption. The resulting tool for performing a Dynamic Positioning capability assessment allows for fast calculations to qualitatively compare different designs. The study has proven that the Quadratic Programming based method gives less optimistic solution in comparison with DNV tool and can be safely applied at an early design stage. Further validation of the tool with the time-domain simulations would contribute to increasing confidence in its application to the daily routine calculations.","['Engineering', 'Control and Systems Theory', 'Computational Intelligence']"
doi:10.1007/978-981-19-3148-2_38,en,An Efficient Way of Identifying Alzheimer’s Disease Using Deep Learning Techniques,OriginalPaper,"Alzheimer’s disease has recently emerged as a big worry. This condition affects around 45 million people. Alzheimer’s disease is a deteriorating brain illness through an unknown etiology and pathophysiology that primarily affects the elderly. Dementia, which gradually kills brain cells, is the primary cause of Alzheimer’s disease. This condition caused people to lose their capacity to think, read, and do various other things. By forecasting the sickness, a machine learning system can help to alleviate this issue. The primary goal is to identify dementia in a variety of patients. This study offers the results and analyses of multiple machine learning models for diagnosing dementia. The Open Access Series of Imaging Studies dataset was utilized in the program’s implementation. Data was evaluated and used in a variety of machine learning models. When the results are compared, it is discovered that Deep Learning Ludwig Classifier produces 95% accuracy while the Random Forest produces about 87% the best outcomes of the models. Among many patients, it had the highest accuracy in identifying dementia. The technology is simple and may quickly assist individuals by diagnosing dementia.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory']"
doi:10.1007/978-981-19-3571-8_10,en,"Survey on Driver Fatigue Detection Using Sensors, Big Data Analytics and Machine Learning Techniques",OriginalPaper,"Fatigue detection in today’s era has become an important asset as the death rate of India is at its peak, and the reason for it is road accidents. It is very important to identify driver’s drowsiness in the early stages, for minimizing the damage and preventing accidents. Drowsiness can be detected considering parameters like facial expressions, human physiological signals and vehicular parameters. It is possible to detect the state of driver’s fatigue with the development of the technology of IoT, machine learning and big data analytics. This paper focuses on all the techniques and processes involved in the fatigue detection, which includes all the sensors that can be used like heartbeat sensor, temperature sensor, eye blink sensor, etc. As the data collected from sensors is huge, so it can be termed as big data, and for processing this data, big data and machine learning techniques are used which are discussed here.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-18292-1_2,en,Explainable Artificial Intelligence (XAI): Understanding and Future Perspectives,OriginalPaper,"Currently, we are seeing a rapid and broad acceptance of artificial intelligence (AI) in our everyday lives, which is contributing to the acceleration of the transition towards a more algorithmic society. The availability of enormous datasets, as well as recent advancements in deep learning methods, are allowing AI systems to perform at or even beyond the level of human performance on an expanding variety of challenging tasks. However, because of their layered non-linear structure, these strong models have traditionally been regarded as “black boxes,” since they provide no information about how they arrive at their predictions and hence cannot be used trustily to generate predictions. They are often opaque, but they are capable of making accurate predictions that cannot be explained in any other way. All of these choices are having an increasing amount of effect on the lives of individuals. The distrust of totally non-human, autonomous artificial intelligence systems is established as the cornerstone of the movement. The root of distrust lies in a lack of knowledge as to why intelligent systems make certain decisions in certain situations. As a result, this problem has sparked a fresh discussion over explainable artificial intelligence (XAI). Several lines of research work have since picked up on the definition, understanding, and implementation of explainability, including expert systems, machine learning, recommender systems, and approaches to neural-symbolic learning and reasoning, all of which have occurred primarily during different periods in the history of artificial intelligence. This chapter serves as an introduction for academics and practitioners who are interested in learning about essential parts of the new and quickly increasing field of research on XAI. The first section, titled “Introduction,” provides an overall summary of the Explainable Artificial Intelligence. Section  2 describes the need of trust and transparency in AI, which is what led to the development of the idea of XAI. Section  3 discusses the many approaches that contribute to the functioning of XAI. The principal applications domain of Explainable Artificial Intelligence is the topic of discussion in Sect.  4 . In Sect.  5 , the upcoming difficulties and potential directions that this developing technology may take are discussed.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2538-2_41,en,Detection of Unauthorized Access Points Based on Machine Learning Techniques,OriginalPaper,"Wireless networks were widely used, but they were actually a threat. Represents Recognized as a wireless AP (access point). In particular, unauthorized APs used by businesses, military installations, and government agencies can be exposed to hacking attacks. Therefore, to protect your information, it is significant to identify unauthorized APs. This paper addresses round-trip time (RTT) values as records to identify allowed and unallowed APs in a wireless integrated atmosphere. Machine learning techniques such as potential Dirichlet mapping, k nearest neighbors, naive bays, support vector machines, bagging, adapter boosting, gradient boosting machines, random forests, additional trees, and gradient descent techniques are employed to resolve these issues. Gradient Boosting algorithm is used for protection and identification. This is developed and tested on data set. Experimental results show that it offers the highest accuracy.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory', 'Mobile and Network Security']"
doi:10.1007/978-3-031-19958-5_46,en,Reason Based Machine Learning Approach to Detect Bangla Abusive Social Media Comments,OriginalPaper,"For the study issue of abusive language detection, English is the most commonly employed language. There are just a few works accessible in low-resource languages such as Bangla. People use these sorts of statements on many social media sites. As a result, detection of this type of language is a demand of time. Our goal is to identify this abusive Bangla language in a novel approach. There are some works that use Bengali corpus and transliterated Bengali corpus to detect abusive language. However, in this research, we utilized annotated translated Bengali corpora, and we added a formal justification in each remark for being classified as abusive or non abusive language. For evaluations, we employed a variety of machine learning classifiers where logistic regression achieves 97% accuracy.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-20241-4_6,en,Prediction of Geological Conditions Ahead of the Tunnel Face: Comparing the Accuracy of Machine Learning Models Trained on Real and Synthetic Data,OriginalPaper,"Risk assessment during the construction of an underground structure (e.g., tunnel) should rely on accurate information of the rock mass that will be excavated. Advances in engineering equipment allowed vast data collection and thus opened a possibility for data-driven prediction of geological conditions. For an accurate prediction, the integration of various data sources is required, which makes the predictions complex and time-consuming for specialists. The application of machine learning (ML) methods provides a shortcut in analyzing complex data to predict geological conditions. In this work, the authors present a new approach for predicting the geological information ahead of the tunnel face by using an ensemble of ML methods combined with an oversampling technique. Implicit dimensionality reduction is introduced to deal with nonlinear coupling between seismic data: unsupervised machine learning methods are used to cluster the seismic data from two underground construction sites. Obtained information on clusters is then integrated with various seismic and geological variables, and a supervised machine learning model is trained to predict the rock mass class and/or the rock type. The data is over-sampled to avoid biased results when the training datasets are imbalanced and a mix of real and synthesized data is used in training, while an accuracy check is performed only on real data. Our results show that the proposed ML ensemble model has high accuracy in predicting geological conditions. Furthermore, the application of the oversampling technique helps to improve the accuracy of the ML predictors further.","['Engineering', 'Building Construction and Design', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence', 'Statistics, general']"
doi:10.1007/978-3-031-15928-2_71,en,Methodology for Image Analysis in Airborne Search and Rescue Operations,OriginalPaper,"Nowadays, Search and Rescue operations can be performed using manned or unmanned Aerial Vehicles. In this latter case, compact cameras are mounted onboard and a bird’s eye view is available to find the missing person. However, the analysis of the video frames can be very challenging and dull for the operators. In this context, the use of graphical methodologies can boost the searching operations and improve the process. In this study, a methodology based on the object detector Yolov5 is introduced: the performances in detecting small objects such as persons in aerial images are evaluated. These algorithms implement shallow layers of the feature extractor to increase the spatial-rich features and help the detector to find small objects. Finally, detection algorithms are tested using a video simulating a scenario for Search and Rescue operations. The filtering of frames containing false positives, is carried out using a classical graphical tool such as the Hamming distance.","['Engineering', 'Engineering Design', 'Industrial and Production Engineering', 'Computer-Aided Engineering (CAD, CAE) and Design']"
doi:10.1007/978-981-19-3951-8_10,en,Robust Strategy for Optical Burst Scheduling in WDM Networks Through Void Filling and Segmentation,OriginalPaper,"The great contributions in optical networks added the optical burst switching (OBS) networks that are outperforming in advance methods referred to as optical circuit switching and optical packet switching networks in the direction of switching and transmitting data through optical fibres. The critical and obligatory factors in OBS are assembling the bursts, routing, resource (such as transmission channels) scheduling, and burst segmenting for optimal transmission. Hence, the current research is focusing on these either of divergent factors of OBS and putting efforts to contribute optimal approaches to assemble, route, schedule or segment. In this paper, the segmentation scheme is investigated through simulation and it is shown that segmentation with void filling can achieve a significantly reduced burst loss rate.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16072-1_38,en,Optimization of the BANK’s Branch Network Using Machine Learning Methods,OriginalPaper,"The pandemic has made many companies move their business processes to online. Financial institutions, especially banks, have been quite active in developing online capabilities of their front offices. Having an extensive branch structure, they were faced with the need to re-assess the current efficiency of their entire networks and take a closer look at their individual front offices. Both new planned branches and the currently active ones require reassessment if they can be competitive with the online channel. New technologies provide new tools to examine the network and make decisions on its optimization. This article offers an operational assessment example of a financial company’s front office network in the city of Moscow. The proposed machine learning model for predicting customer traffic enables to determine the most relevant locations for office rent. As an open source of realty data a leading real estate aggregator cian.ru has been chosen.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2600-6_39,en,Siamese Network-Based System for Criminal Identification,OriginalPaper,"To discourage criminal activities, the large number of CCTV installations throughout the country play a crucial role. Through this paper, we propose an AI-based solution that can leverage these devices to remotely identify and report absconding criminals. Using the one-shot learning approach, we present a face recognition algorithm that yields accurate results even with low training data. The Siamese Network architecture is used to verify if the face embeddings of the image detected is the same as that of the criminal. Two parallel neural networks are designed to take one input each- one being the detected face and the other being an embedding from the dataset. The outputs of the two networks are compared to predict whether the detected face is the same as the input face or not. This algorithm is further integrated with an automated model for updating the information of the recognized criminal into the database along with updating the appropriate law enforcement authorities about the last known whereabouts.","['Engineering', 'Data Engineering', 'Statistics, general', 'Machine Learning', 'Artificial Intelligence', 'Data Storage Representation', 'Data Structures and Information Theory']"
doi:10.1007/978-981-19-2821-5_63,en,A Review on EEG Data Classification Methods for Brain–Computer Interface,OriginalPaper,"Electroencephalography (EEG) is a technique to quantitatively measure brain activity with high temporal resolution. EEG converts brain activity to time series data with amplitude on the y-axis, and this data can then be used to understand brain functions. Mathematical tools can be applied to this data to extract features and to discriminate them in several classes. Once EEG data is recorded, it is needed to make sense of that data. In the past couple of decades, EEG data has revolutionised the healthcare industry and brain–computer interface (BCI) systems. This is made possible by continuous improvements in EEG data classification methods, which includes improvements in feature extraction and classification algorithms. In this study, methods to classify EEG data for various applications such as medical diagnostics, BCI and emotion detection are reviewed.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4052-1_15,en,Covid-19 Prediction Analysis Using Machine Learning Approach,OriginalPaper,"The unforeseen outbreak of Covid-19 which resulted in a global pandemic posed a threat to the human civilization. The entire world is trying their best to combat against the outspread of the disease. The rapid spread of the disease has put governing bodies under pressure and made it difficult to confront the situation. The RT-PCR which is the test confirming if a person has Covid-19 infection, is restricted by the shortfall of reagents, time taking, high cost and need for dedicated labs with trained pathologists. With the sudden rise in daily cases, there were large queues for Covid-19 tests, stressing the medical laboratories with many such laboratories facing shortage of kits for testing. Hence, there is a requirement for cost effective and quick diagnostic model to determine positive and negative cases of Covid-19. This paper aims to predict Covid-19 infection in an individual person from initial symptoms and information like fever, cough, sore throat using machine learning algorithms. The study includes working with six predicting models, MLP, GBC, Decision tree, SVM, Logistic Regression and Random forest with highest accuracy of 92.94% achieved in logical regression. The results can help in the initial diagnosis of Covid-19, especially when there is a shortage of RT-PCR kits, specialized laboratories and to screen large number of patients.","['Engineering', 'Computational Intelligence', 'Information Storage and Retrieval', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Data Structures and Information Theory', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5403-0_23,en,A Comparative Study for Machine Learning Models in Retail Demand Forecasting,OriginalPaper,"Effective and efficient supply chain management is one of the primary factors behind the success of modern-day organizations. The necessity to circumvent the impediments between supply and demand in any organization brings in the need for machine learning techniques. The performance of several machine learning methods, namely, random forest, gradient boosting, and XGBoost have been compared for demand forecasting. Weekly sales data of a multinational retail chain used consists of various attributes affecting the sales, for example, consumer price index and store size in the region. The data represents the sales made in 45 stores over 3 years across the United States of America. The comparison between the methods mentioned to find the most optimal forecasting method among them has been done through various performance metrics, namely, MAE, MSE, and R 2 scores. The XGBoost model outperforms random forest and gradient boosting models producing the most accurate predictions.","['Engineering', 'Computational Intelligence', 'User Interfaces and Human Computer Interaction', 'Data Structures and Information Theory', 'Artificial Intelligence', 'Data Mining and Knowledge Discovery']"
doi:10.1007/978-981-19-4960-9_31,en,Reinforcement Learning for Autonomous Driving Scenarios in Indian Roads,OriginalPaper,"The decision-making process for autonomous vehicles comes with numerous challenges that are not easily solved. With the ever-changing traffic situation of the world and the increasing need for autonomous driving technology, there are constant innovations to deal with the increasing number of problems in the complex environments that autonomous driving agents find themselves in. Developing countries like India face even more numerous challenges with existing autonomous driving solutions not being directly transferable. However, with the maturation and advancement of deep learning technology over the years, more and more novel methods in the field of deep reinforcement learning are being proposed to tackle both new challenges and existing challenges. In this study, we explore the contemporary reinforcement learning techniques for autonomous driving tasks and analyze their applicability for the unstructured road environment and also look at some of the less-common scenarios that occur frequently in the Indian context.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Professional Computing']"
doi:10.1007/978-3-031-17544-2_8,en,An Optimistic Bayesian Optimization Based Extreme Learning Machine for Polycystic Ovary Syndrome Diagnosis,OriginalPaper,"The most prevalent endocrine disorder that exist in 5 to 10% of the women during their fertility period is the polycystic ovarian syndrome (PCOS). Women having PCOS problem are associated with serious consequences of health issues such as heart disease, obesity, infertility, ovarian cancer, type 2 diabetes and so on. To prevent the risks associated with PCOS, there is a need to develop prediction models for the accurate identification of PCOS at early stage. This chapter aims in developing prediction model based on ELM (Extreme learning machine) and Bayesian optimization algorithm for the detection of PCOS at early stage. The class imbalance problem has been overcome using a strategy known as random oversampling. In this approach, Bayesian optimization is employed to choose the best hyperparameters of the models. The proposed architecture has been evaluated using PCOS dataset obtained from Kaggle. Further, the efficacy of the proposed ELM and Bayesian optimization algorithm has been compared with SVM, MLP, ELM and ELM and Genetic algorithm. The experimental results reveal that ELM and Bayesian optimization attained better performance of 99.31% accuracy when compared with other machine learning approaches.","['Engineering', 'Computational Intelligence', 'Biomedical Engineering and Bioengineering', 'Health Informatics']"
doi:10.1007/978-3-031-19032-2_1,en,Tree Inventory with LiDAR Data,OriginalPaper,"At present, the rational use of forest resources requires a constant assessment of the state and the implementation of a forecast of the dynamics of the forest fund. For these purposes, it is necessary to update existing data on forest areas in a timely manner. With the spread of technologies for remote data collection, there is a need to improve methods for measuring the taxation parameters of stands. Thus, the paper proposes a methodology based on various methods for calculating taxation parameters and obtained results, in some cases better than the results of existing solutions. The methods of fitting a circle for further estimation of the diameter of a tree trunk are compared: Least Square fit and HyperLS fit. A comparative analysis of the results of measurements of parameters with the results of measurements made using similar software in relation to the data collected by field measurement methods was carried out.","['Engineering', 'Computational Intelligence', 'Machine Learning', 'Neurosciences']"
doi:10.1007/978-981-19-2768-3_21,en,The Influence of Literature on Medio-translation Studies Based on Artificial Intelligence Algorithms: An Empirical Study of Shaanxi Literature,OriginalPaper,"Internet literary translation, as a brand new translation model, is a product of the fusion and collision of science and technology and humanity in the current social development. In the network technology rapid development era of information explosion, the Internet effectively combined with artificial intelligence technology and the traditional literary translation application advantages of literary translation, not only changed the human translation reading activity form, and enriched the research contents of translation study, at the present stage to translation study have sprung up in the production of spread to accept the changes more. On the basis of understanding the current development status of artificial intelligence algorithms, combined with relevant theories and current political cases, this paper deeply discusses the impact of artificial intelligence algorithms centered on Shaanxi literature on translation and media, so as to clarify the enlightenment of the algorithm.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory', 'Operations Research/Decision Theory', 'Business and Management, general']"
doi:10.1007/978-981-19-2821-5_65,en,"A Brief Review on Protein Classification Based on Functional, Behavioral, and Structural Properties Using Data Mining Techniques",OriginalPaper,"Knowledge retrieval from a large amount of biological database is one of the challenging tasks, nowadays. Numerous types of data mining techniques are applied to execute the same. For a few years, several researchers have established a lot of information retrieval procedures to extract knowledge from a wide-reaching amount of biological informations like protein and genes. In this paper, the authors try to make a brief review regarding these classification techniques along with their accuracy and computational time, which can classify protein into its family. The authors also try to mention the name of databases and procedures which are used to validate these classification approaches. In the end, a comparative analysis between these classification approaches was established alone with limitations and chance of improvement areas. Finally, a brief idea regarding the protein classification concept along with its need is clearly emphasized here.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1906-0_47,en,Genetic Algorithm and Naïve Bayes-Based (GANB) Diabetes Mellitus Prediction System,OriginalPaper,"Today, machine learning plays a significant role in the classification of healthcare conditions. Machine learning is the process of finding, discovering, and modeling massive amounts of data in order to identify unknown relationships and patterns that are useful to the decision makers. Medical data mining has begun to emerge exemplary, with the potential to discover interesting insights from medical domain datasets. These patterns may be used in the making of clinical decisions. In this research work, we proposed genetic algorithm and Naïve Bayes-based (GANB) diabetes mellitus prediction system. In which, genetic algorithm (GA) is used for feature selection and Naïve Bayes is used for prediction. The proposed system is trained using Pima Indian diabetes dataset (PIDD). The dataset is preprocessed using synthetic minority oversampling technique (SMOTE) for solving the issue of class imbalances. The effectiveness of the system is evaluated using classification accuracy (CA) and error. The simulation results show that the proposed GANB system achieves better accuracy as compared to the results of related earlier studies.","['Engineering', 'Electronics and Microelectronics, Instrumentation', 'Computer Systems Organization and Communication Networks', 'Artificial Intelligence']"
doi:10.1007/978-3-031-09835-2_8,en,Application of Swarm Based Approaches for Elastic Modulus Prediction of Recycled Aggregate Concrete,OriginalPaper,"In concrete, the elastic modulus plays a vital role as a design parameter. Most of the empirical formulas used to predict the elastic modulus are limited to natural aggregate concretes (NAC). The formulae developed for recycled aggregate concrete (RAC) are constrained by experimental conditions since there is a considerable variation in recycled aggregate properties from place to place. In the present study, swarm based soft computing technique is used to overcome this issue. Artificial Neural Network (ANN) is trained by both standalone Levenberg-Marquardt back-propagation (LM-BP) technique and a hybrid of LM-BP and elephant herding optimization (EHO). The developed model is trained by 400 datasets obtained from literature which include seven inputs (i.e., water to cement (w/c) ratio, replacement of NA by RA in volume (r), coarse aggregates to cement (CA/C) ratio, fine aggregate to total aggregate (FA/TA) ratio, saturated surface dry specific gravity (SGSSD) of mixed CA(NA + RA), water absorption ( $$W_a$$ ) of mixed CA and cube compressive strength ( $$F_c$$ )) and one output as elastic modulus of RAC. The performances of the developed models are evaluated using standard statistical measures like MSE, r and MAE. The developed hybrid model yields ’r’ of 0.9966 and 0.9935, MSE of 0.4765 and 0.4807, and MAE of 1.1080 and 1.1888 for training and testing respectively which outperformed standalone technique of LM-BP in every aspect for predicting the elastic modulus of RAC. This shows that the hybrid model can be used effectively to predict the elastic modulus of RAC.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-18458-1_53,en,Non-intrusive Drowsiness Detection Techniques and Their Application in Detecting Early Dementia in Older Drivers,OriginalPaper,"Drowsy drivers cause the most car accidents thus, adopting an efficient drowsiness detection system can alert the driver promptly and precisely which will reduce the numbers of accidents and also save a lot of money. This paper discusses many tactics and methods for drowsy driving warning. The non-intrusive nature of most of the strategies mentioned and contrasted means both vehicular and behavioural techniques are examined here. Thus, the latest strategies are studied and discussed for both groups, together with their benefits and drawbacks. The goal of this review was to identify a practical and low-cost approach for analysing elder drivers’ behaviour.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2394-4_9,en,A Food Constraint Satisfaction System-Based on Genetic and Random Walk Algorithms,OriginalPaper,"This paper has presented a novel concept of a food constraint satisfaction system based on the genetic algorithm (GA) and random walk (RW). The system is a part of the food recommendation system under consideration for recommending proper calorie daily food for obese individuals with overweight. The system estimates the values of overweight, daily needed food calorie (DNC), and saturated DNC (DNC sat ) of the individuals from their Body Mass Index (BMI) and Basal Metabolic Rate (BMR) values. The daily food set is the food items for breakfast (BF), lunch (LN), and dinner (DN) selected by an individual. Individuals can choose any food item from the  predefined food variables for their daily food set. The overall daily food calorie (ODC) is the total food calories estimated from the daily food set. The system aims to assign only the DNC sat matching food items for the daily food set of each individual from the food list of the system. The system has  utilized two random-based algorithms such as GA and RW, to find an appropriate daily food set that satisfies the individual's  food choices and DNC sat  values. The fitness ratio (FR) of GA and RW’s node evaluation (ND eval ) are  estimated based on the individuals’ ODC and DNC sat  values. The carried-out simulations show that RW outperforms GA in performance and computational complexity. The presented food constraint satisfaction  system could effectively satisfy individuals with different food habits and tastes.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-18154-2_3,en,“We’re Pregnant!” Artificial Intelligence by Your Side,OriginalPaper,"The aim of this chapter is to present how Artificial Intelligence can be used in order to signal any potential congenital diseases of the fetus during the first trimester ultrasound. Artificial Intelligence can establish possible diseases or syndromes through screening tests. Last, but not least, we shall learn how to predict miscarriage by looking at the data.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Gynecology', 'Obstetrics/Perinatology/Midwifery', 'Machine Learning']"
doi:10.1007/978-981-19-3505-3_14,en,Road Network Analysis of Major Destinations in Guwahati City Using GIS,OriginalPaper,"The transportation system plays a prominent role in the urban spatial structure. It is the main social-economy operation of the city. Transport planning is a complex process requiring meticulous forecasting of potential needs and review of current urban travel trends. Sustainable development is enabled by successful route planning and accessibility. The GIS-based Network Analyst allows users to dynamically model realistic network conditions at various times of the day, including turn restrictions, speed limits, and traffic conditions. A GIS can be used to monitor the transport system, network conditions, the shortest or best route to the destination, and the closest services. The main purpose of this paper is to provide an enhanced road network analysis that uses the capabilities of GIS to identify the fastest as well as the shortest route between the two busiest hubs in Guwahati city. A basemap of the city is downloaded using the QuickMapServices plugin. The network analyses such as routing and nearest facility are carried out in this project using various plugins available in QGIS. The points of origin and destination were chosen to address the network in order to decide the shortest path as well as the fastest path and to serve the purpose of the analysis. The study would raise awareness of the potential for data collection, management, and analysis of geographical information technology. It will allow them to access low-cost technology and freeware solutions to operate in GIS for decision-making purposes. It will highlight the gaps and restrictions impacting the use of GIS in the transport planning field for the responsible offices to deal with.","['Engineering', 'Transportation Technology and Traffic Engineering', 'Construction Management', 'Sustainable Development']"
doi:10.1007/978-3-031-21203-1_32,en,Privacy-Aware Explanations for Team Formation,OriginalPaper,"Over the recent years there is a growing move towards explainable AI (XAI). The widespread use of AI systems in a large variety of applications that support human’s decisions leads to the imperative need for providing explanations regarding the AI system’s functionality. That is, explanations are necessary for earning the user’s trust regarding the AI systems. At the same time, recent legislation such as GDPR regarding data privacy require that any attempt towards explainability shall not disclose private data and information to third-parties. In this work we focus on providing privacy-aware explanations in the realm of team formation scenarios. We propose the means to analyse whether an explanation leads an explainability algorithm to incur in privacy breaches when computing explanation for a user.","['Computer Science', 'Artificial Intelligence']"
doi:10.1007/978-3-031-07707-4_13,en,Context of a Local Congruence Concept Reduction,OriginalPaper,"In formal concept analysis, attribute reductions lead to equivalence relations on concept lattices. Lately, local congruences arose to enhance the structure of the equivalence classes. In this paper, we show a procedure that details the impact of the application of local congruences on concept lattices obtained from attribute reductions.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Computational Mathematics and Numerical Analysis']"
doi:10.1007/978-3-031-17091-1_62,en,Assessment of Psychological Impact Due to the Pandemic in Society and Education in Colombia with Machine Learning,OriginalPaper,"After 20 months of the pandemic, the health situation in the world has evolved favorably with vaccination in most of the countries that have had access to it. However, the impact on society from the point of view of people’s behavior and their relationship with physical health is being evaluated by stakeholders. It helps states and institutions to formulate public policies to achieve social adaptation to new conditions, after pandemic. Sociodemographic conditions interact with the environment produced by the pandemic and can cause physical and psychological affectation that is reflected in the behavior of the person, such as the reaction to a new threatening situation (stress). This response is used to evaluate the degree of mentioned affectation of people. Models based on machine learning are proposed to evaluate and predict this level as well as the consequence in the educational process.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Cyber-physical systems, IoT', 'Industrial and Production Engineering']"
doi:10.1007/978-981-19-3575-6_7,en,A Survey on Crop Rotation Using Machine Learning and IoT,OriginalPaper,"Agriculture plays a significant role in forming the economy in India. Day by day, as the population increases the demand for food also increases. So, we need more efficient ways to increase crop production. These days with the surge of the Internet of Things (IoT) and machine learning technologies, we can get more effective outcomes. We have proposed a system, which collects the soil data like NPK contents, pH level, and temperature from the IoT sensors in real time which is sent to the cloud using the MQTT method by Node MCU firmware. In the cloud architecture, we have applied the k-nearest neighbor algorithm (KNN) model to the collected data to get the best suggestion for crop rotation. KNN is a supervised machine learning algorithm and can predict similar things that exist in closed proximity. In this system, we have taken different crops for the study. Farmers can also check the real-time soil contents of their farms on the dashboard.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-3148-2_30,en,Detection and Classification of Fruit Tree Leaf Disease Using Deep Learning,OriginalPaper,"Plant disease identification is extremely important in agriculture since it is critical for boosting crop output. Visual plant disease analysis is a modern technique to handle this problem, following recent developments in imaging. In this study, we look at the challenge of plant disease detection which is visually done for identification of plant disease. Plant disease images, in comparison with other types of photographic images, are likely to have randomly dispersed lesions, varied symptoms, and complex backgrounds, making discriminative information difficult to capture. To facilitate plant disease recognition research, we had taken the PlantVillage dataset with 13,347 images with 14 classes. Models were trained using the PlantVillage dataset. The performance of EfficientNet architecture for classifying the plant leaf disease was compared against ResNet-50, Inception V3, AlexNet, and Xception deep learning algorithms in this analysis. The outcomes of the test dataset revealed that B3 models of the EfficientNet architecture had the greatest accuracy of 99.90 percent when related to other deep learning algorithm in the dataset.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory']"
doi:10.1007/978-981-19-1607-6_76,en,Banking Credit Risk Analysis using Artificial Neural Network,OriginalPaper,"Banking credit risk analysis is a form of evaluation conducted by financial institutions to determine applicants’ ability to repay their debt obligation. Financial institutions, such as banks, set objectives to offer credit to creditworthy customers, after spending time trying to evaluate their repaying capacity. In this paper, we propose a credit risk analysis system based on an artificial neural network (ANN) to identify customers who will default. A feedforward propagation algorithm is used to train the model consisting of three layers. Data pre-processing is performed to clean the datasets and check for missing variables. The datasets were normalized using min–max normalization to get the correlation among the variables. The datasets are applied to the proposed model and logistic regression models, and the comparison shows the proposed model which has a better performance.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-11047-4_8,en,Placement of on-chip distributed voltage regulators,OriginalPaper,"In traditional power delivery networks, the on-chip supply voltage is provided by board-level converters. Due to the significant distance between the converter and the load, variations in the load current are not effectively managed, producing a significant voltage drop at the point-of-load. To mitigate this issue, modern high performance systems utilize on-chip voltage regulators. Due to the close proximity to the load, these regulators can quickly respond to fluctuations in the input voltage or load current, providing superior power quality. Integrated voltage regulators however require significant area, limiting the number of on-chip regulators. An algorithm for distributing on-chip voltage regulators is presented in this chapter. The algorithm is accelerated using the infinity mirror technique, enabling the analysis of arbitrarily sized power grids. The power quality is maximized with a limited number of regulators. Practical scenarios are supported, such as limited current capacity and restricted placement.","['Engineering', 'Circuits and Systems']"
doi:10.1007/978-981-19-3951-8_42,en,UDP Flooding Attack Detection Using Entropy in Software-Defined Networking,OriginalPaper,"Software-defined networking (SDN) is one of the most emerging technologies in the recent years. It is the physical separation of the network control plane from the data plane in the network architecture which is dynamic, manageable, and cost-effective. Even though it is emerging and effective, there are security problems like flooding, spoofing, and DDoS attacks. DDoS attacks are achieved with TCP and UDP flooding packets. In this paper, we have proposed a solution to detect such flooding attacks based on the entropy method. This methodology helps in providing a better and efficient solution for such attacks. Entropy method is used for detecting UDP flooding packets, and pox controller is used for its implementation.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2840-6_50,en,A Review on Artificial Intelligence Based E-Learning System,OriginalPaper,"Today, the e-learning system is vital to the educational system. Technology integration in the classroom aids in the effective and efficient delivery of content-based education, hence increasing student confidence. Personalized educational systems concentrate on learning behaviour, interest, and course design based on learners' aptitude and fundamental knowledge. It is a versatile teaching style that may be tailored to match the needs of individual pupils. The individualised learning strategy caters to the specific demands of each student. Understanding learners and developing a strategy that meets individual learning requirements and student interests is required for an efficient education system. An smart Tutor system is an expertise way to monitor the performance of the pupils in order to deliver tailored tutoring. Computer-based education, web-based acquiring knowledge, crowdsourcing, and virtual classrooms are examples of e-learning applications. AI may be used to automate learning processes such as building teaching materials, curriculum, training, evaluating student performance, and employing current teaching technique. Artificial intelligence is the most recent e-learning trend in higher education and business. AI aids in the provision of individual decisions through data analytics, which leads to improved education for tailored teaching and the streamlining of the educational process.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-16075-2_37,en,Similarity-Based Résumé Matching via Triplet Loss with BERT Models,OriginalPaper,"Automatic résumé matching for the recruitment engines is an important task because of the vast volume and varying types of applicants. We propose a résumé matching method to be used as a recommendation engine for recruiters. Our approach combines cutting-edge transformer-based natural language processing technology with the triplet loss, a training method originally developed for the computer vision domain. By treating the output embeddings of a transformer model similarly to those of a convolutional neural network, we develop a model for the document retrieval task. The paper also investigates a clustering based pretraining method before fine-tuning with the triplet loss. The method is applied on the data extracted from an online recruitment website, where real users actively create their own résumés. Measured by the precision at k score, the method yields an accuracy boost of %12 compared to a base model.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-3-031-08084-5_3,en,CatBoost: The Case of Bankruptcy Prediction,OriginalPaper,"Prediction of company bankruptcy is a field that develops mainly with the introduction of big data and data mining, and their application into actual business environment. In the field of classification methods, ensemble methods have significant position including various bagging or boosting algorithms. One of the newest algorithms in this field is the CatBoost algorithm developed in 2018. The aim of this manuscript is to apply the CatBoost algorithm to detect company bankruptcy based on financial and categorical data. The prediction model was created on a data sample of 89,447 small and medium-sized enterprises (out of which 295 went bankrupt) from Slovakia from the year 2019. The results indicate that the best CatBoost model achieved area under curve (AUC) value of 98.12%, and this model outperformed other models applying only financial or categorical variables. The contribution of this paper is the finding that application of categorical variables can contribute to better results than application of pure financial variables in CatBoost models. These findings should be taken into account by managers or institutions such as banks when creating their own bankruptcy prediction models.","['Engineering', 'Mathematical and Computational Engineering', 'Business Mathematics', 'Data Engineering']"
doi:10.1007/978-981-19-3571-8_44,en,Agricultural App Development Using Machine Learning and Deep Learning: A Review,OriginalPaper,"Plant diseases pose a threat to farmers, consumers, the environment, and the global economy. In India alone, diseases and pests damage 35% of field crops, resulting in financial losses for farmers. Excessive use of chemicals, many of which are toxic and biomagnified, also poses a significant health risk. Early disease detection, crop monitoring, and targeted treatment all con-tribute to avoiding these unfavorable consequences. Agronomists identify the vast majority of diseases based on their external characteristics. On the other hand, farmers typically have limited or no access to professionals. Agriculture is one of India’s primary sources of revenue and has a big impact. Humanity is undergoing a digital revolution in terms of economic progress. Rural mobile subscribership has constantly increased over the last many years. With the proliferation of cellphones and the Internet, there is a great opportunity for transmitting crucial data via these means. We have compiled a list of agricultural mobile apps available in the Google Play Store for the Android operating system that may be beneficial for farming and related jobs. There are significant opportunities for integrating smartphones with agriculture growth in India. Its use is crucial for rapid expansion and easy access to information for farmers.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-07254-3_57,en,A Self-supervised Classification Algorithm for Sensor Fault Identification for Robust Structural Health Monitoring,OriginalPaper,"A self-supervised classification algorithm is proposed for detecting and isolating sensor faults of health monitoring devices. This is achieved by automatically extracting information from failure investigations. This approach uses (i) failure reports for extracting comprehensive failure labels; (ii) recorded data of a faulty monitoring device and the information of the failure type for selecting fault-sensitive features. The features-label pairs are then used to train a classification algorithm, so that when a new set of measurements becomes available, the algorithm is capable of identifying with a high accuracy one of the possible failure types included in the training data set. The proposed approach is successfully applied to the failure investigations conducted on a low-cost wearable device, displaying similar challenges encountered in SHM.","['Engineering', 'Building Repair and Maintenance', 'Cyber-physical systems, IoT', 'Industrial and Production Engineering', 'Monitoring/Environmental Analysis', 'Analytical Chemistry']"
doi:10.1007/978-981-19-0095-2_75,en,RADAR and Camera Sensor Data Fusion,OriginalPaper,"As demand for vehicle automation has expanded in the last few years, it has become imperative to more precisely recognize the position and speed of surrounding vehicles. Object detection has been recognized as an important feature of the advanced driving assistance system (ADAS). This also ensures the safety of vehicles and prevents accidents caused by the negligence of humans. Object detection with sensor data fusion has proved to be very effective. Obstacles can be detected and labeled with the help of RADAR, LIDAR, and camera. Every sensor has advantages and limitations. Limitations of one sensor can be overcome by another sensor. Sensors such as LIDAR, RADAR, and camera are used together in order to obtain optimum results contributing to better object detection in autonomous systems. The paper describes the fusion of data acquired by the two sensors RADAR (AWR1642BOOST) and a two-dimensional camera (LOGITECH C170). RADAR can achieve better results in distance calculation than camera, whereas camera can achieve better results in angle compared to RADAR. Similarly, RADAR works efficiently in poor weather conditions and lighting, whereas camera may not provide accurate results. The data acquired by both the sensors are fused in order to obtain better object detection and ensure accurate calculation of parameters of the object detected. Region of interest detection and Haar Cascade algorithms are implemented to get satisfactory results and has been implemented in real time.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Systems and Data Security', 'Artificial Intelligence', 'Computational Intelligence']"
doi:10.1007/978-3-031-19958-5_61,en,Developing a Tool to Classify Different Types of Fruits Using Deep Learning and VGG16,OriginalPaper,"In this paper, we present two methods for the classification of fruits of Bangladesh from image processing techniques. We have used deep learning convolutional neural network in our model and VGG16 in another model. From both models, we have found 99% accuracy. Initially, we used only five classes (apple, orange, jackfruit, watermelon, banana) for building these models. Evaluating our model gives us accuracy on the test dataset and by inputting one fruit image our model predicts the fruit what it is. We have checked and experimented with our model several times that it can detect fruit accurately from single fruit images. If our model goes through further improvement, it can be an application that will help shopkeepers or farmers on fixing price calculations on both online and offline platforms.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-04524-0_7,en,A Survey and Challenges: Embedded System on IoT,OriginalPaper,"An embedded system is made up of electronic hardware and software. It contains a sensor to sense the environment and actuators to respond. There are millions of such embedded devices are available in the environment, but interoperability between them is a significant issue. IoT is a technology to provide communication between such embedded devices over the Internet. Therefore, IoT came into existence, and it is an outcome of the fourth industrial revolution of disruptive communication technologies. It is integrated with sensors, embedded systems, computing, and communication technologies. Embedded system is the heart of IoT. IoT computes and communicates the data and store it in the cloud for future data analysis. IoT is mainly to provide seamless data storing and analyzing the environment. This paper addresses the design aspects of a system required for IoT to use in any general application. This paper presents system architectural comparison, interrupts, task execution, scheduling, switching tasks and latency, prioritization of tasks, real-time tasks, real-time operating system, multitasking, sensors, actuators, memory footprints, and communication standards. This paper summarizes the architecture and its processors recommended for IoT.","['Engineering', 'Cyber-physical systems, IoT', 'Communications Engineering, Networks', 'Computer Communication Networks']"
doi:10.1007/978-981-19-2600-6_33,en,"COVID-19 Regulations Check: Social Distancing, People Counting and Mask Wear Check",OriginalPaper,"The life of every human being in this world is hampered by Covid 19 virus. Everyone is familiar with do’s and don'ts in social environment. The main objective to keep away from Covid 19 is to wear the mask and maintain social distancing. Our AI based algorithms highlighted in this research paper are checking the mask unavailability and are measuring social distancing. We estimate social distancing parameters using estimation of actual distance based on perspective distance without using camera calibration. OpenCV libraries are used to detect people in 2D plane while deep learning-based approach is used for mask unavailability check. It uses combination of 3 methods such as mapping of distances, diagonal ratio comparison, overlapping of bounding box drawn around detected human being for social distancing violation. Every method has pros and cons. AI based methodology has been used to assign weightage to above various algorithms depending on the scenarios. Distance between human beings can be calculated and created real time alert in case of violation. This algorithm has tested on various video streams to check the performance and feasibility of it.","['Engineering', 'Data Engineering', 'Statistics, general', 'Machine Learning', 'Artificial Intelligence', 'Data Storage Representation', 'Data Structures and Information Theory']"
doi:10.1007/978-3-031-13588-0_40,en,Le Corbusier’s Modulor and ‘le jeu des panneaux’: A Parametric Approach,OriginalPaper,"Historically, architecture gradually became controlled by modulation, proportion, rhythm, harmony, and orthogonality of regular forms. In his investigation, Le Corbusier renews this fact maintaining the precise orthogonality of the right angle and modulation as a means to achieve his mathematical ‘ vérités réconfortantes ’ . In recent years parametric modelling allows us to combine a great number of parameters, conducting us to explore and discover new possibilities to plan architectural forms. In this paper we study corbusian window panels using PM. The methodological procedures were: i) drawing of the grid of proportions; ii) parametric redrawing of the red and blue series; iii) geometric study of the so-called “ jeu des panneaux ”, with the reconstruction of the 2.26 m square and its golden section; iv) development of algorithms based on the values of the red and blue series; v) generation of combinations among parameters; vi) discussion of results and analysis. Using Grasshopper, the aim of this article is to report the parametric study of the red and blue series of the corbusian Modulor.","['Engineering', 'Engineering Mathematics', 'Computational Intelligence']"
doi:10.1007/978-981-16-8274-2_14,en,Automatic Generation Control of Hydro-Thermal Power System Using 2DOF Fractional Order PID Controller Optimized with Crow Search Algorithm,OriginalPaper,"The unceasing efforts to design an optimal controller in automatic generation control (AGC) of electrical power system motivate the design of a Two-Degree-of-Freedom Fractional Order PID (2DOF-FOPID) controller. Two-area interconnected reheat thermal and hydro including boiler dynamics and dead zone nonlinearity in each area is tested using the designed controller. The performance of the proposed controller is studied with the conventional PID controller and classical Two-Degree-of-Freedom PID (2DOF-PID) controller. The elemental intension of designing supplementary controllers aims to diminish the area control error (ACE). A new crow search algorithm (CSA) is chosen to evaluate the suitable values of controller gain parameters in order to curtail the figure of demerit (ITAE). The transient response of the system is investigated pertaining to 0. 01 p.u. load disturbance in area-1. Investigations reveal that the transient response is superior using the 2DOF-FOPID concerning the stability indices, viz. overshoot ( O sh ), undershoot ( U sh ) and settling time response of the power system.","['Energy', 'Energy Policy, Economics and Management', 'Engineering Thermodynamics, Heat and Mass Transfer', 'Engineering Fluid Dynamics', 'Environmental Policy', 'Sociology, general']"
doi:10.1007/978-981-19-5438-2_5,en,"
            
              
            
            $$H_{2}$$
            
              
                H
                2
              
            
          -Optimization-Based Fault Detection for LDTV Systems",OriginalPaper,"$$H_{2}$$ H 2 -optimization is a prevalent concept in control theory and is adopted, in its initial form, for optimization issues related to $$H_{2}$$ H 2 -norm of transfer functions. Thanks to its optimization interpretation in the context of the well-known linear quadratic Gaussian (LQG) control problem, $$H_{2}$$ H 2 -optimization is widely accepted as an established term for optimal control and filtering of linear systems under a quadratic cost function. In this regard, we will, in this chapter, introduce fault detection schemes for LDTV systems. Apart from presenting the standard algorithms, we will focus on gaining deep insights into optimal estimation, residual generation and optimal fault detection issues behind the optimization, and learning alternative interpretations. To this end, some basic estimation and fault detection problems will be, at first, addressed. Although these problems are formulated in the context of static processes, they are helpful to understand the centerpiece of conceptual solutions of any fault detection problems, independent of the system type under consideration. The subsequent study on fault detection in LDTV systems is in fact a natural extension and applications of these solutions, with the aid of advanced system theoretical handlings.","['Engineering', 'Control and Systems Theory', 'Mathematical and Computational Engineering', 'Systems Theory, Control']"
doi:10.1007/978-3-031-11058-0_6,en,Improving the Efficiency of Electric Rolling Stock Operation Due to the Analysis of Data from Computer Vision Systems,OriginalPaper,"The main goal of the work is to analyze the existing algorithms for processing a streaming image in the process of moving in real time. Various algorithms were considered, indicating their main characteristics, as well as the equipment that implements the computer vision system (radar, lidar). They indicated their functionality and advantages of applications in certain situations. In the conclusions section about the work, an experiment was carried out to determine signal traffic lights installed along the railway track. In the conclusions section about the work, an experiment was carried out to determine signal traffic lights installed along the railway track. Experiments have shown that the use of the algorithm (SimpleCollorDetection) developed in the Matlab environment shows high accuracy in determining objects of a certain color, in this case, a traffic light signal. The disadvantage is the complexity of selecting several objects at a time, the search error increases. In the future, we will improve the existing algorithm to eliminate current shortcomings.","['Engineering', 'Control and Systems Theory', 'Control, Robotics, Mechatronics', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-5615-7_21,en,A Lightweight Fine-Grained VRU Detection Model for Roadside Units,OriginalPaper,"Object detection of vulnerable road users (VRU) under low computing resources of roadside units is one of the key technologies to achieve vehicle-infrastructure cooperative perception. In this paper, a lightweight fine-grained VRU detection model is proposed. Analyzing the existing complex traffic environment, the traditional definition of VRU is no longer applicable. Our work includes two parts: One is to redefine the fine-grained VRU and construct a new dataset. This task makes the perceptual information obtained by detection more comprehensive and accurate. Another is to optimize YOLOv4 by using the channel pruning method in model compression. The optimized model is 60% lighter than the original model. Under the limitation of low computing resources at the roadside units, the real-time detection of VRU is realized while ensuring a certain detection accuracy.","['Engineering', 'Transportation Technology and Traffic Engineering', 'Computational Intelligence', 'Automotive Engineering', 'Energy Policy, Economics and Management', 'Mechanical Engineering']"
doi:10.1007/978-3-031-16360-9_10,en,Approaches for Stochastic Modelling of Toxic Ion Adsorption at Crystal-Water Interfaces: A Case Study of Arsenic,OriginalPaper,"Adsorption and fate of toxic ions in natural environments are complex phenomena involving a multitude of possible reactions at solid–fluid interfaces. Modelling of these reactions at realistic conditions defined by complex chemistry of natural waters can be a non-trivial task. Stochastic modelling approaches, such as Kinetic Monte Carlo (KMC), and the tools of statistical mechanics, can treat issues of system complexity by generation of possible system’s configurations and time-dependent system’s transitions. We present here basic theoretical background for these modelling approaches for beginners in this field. In particular, we show how KMC modelling can be applied to study adsorption of arsenic (V) on iron oxide nanocrystals. We begin this chapter with a description of molecular and microscopic structure of crystal-fluid interfaces as a necessary prerequisite for formulation of stochastic models. Stochastic modelling approach can be greatly beneficial for addressing phenomenon of toxic ion adsorption in natural water-containing systems. The application of this approach is in its embryonic state and requires a thorough and systematic development.","['Environment', 'Environment, general', 'Earth Sciences, general', 'Geography, general']"
doi:10.1007/978-3-031-15160-6_13,en,Human-Centered Reinforcement Learning for Lighting and Blind Control in Cognitive Buildings,OriginalPaper,"In cognitive buildings (CBs), intelligent IoT edge devices do more than gather data. They also aggregate, analyze, and stream data at the edge of the network, where cognitive controllers based on machine learning algorithms enable new levels of control and security while significantly improving the overall user indoor comfort and safety. As a result, these CBs will be more intelligent, self-learning, innovative, and simple to manage. CBs also promise to heighten their dwellers’ comfort (and, as a consequence, their performance) by optimizing, e.g., lighting, temperature, and humidity where needed. The reinforcement learning (RL) method is becoming more and more attractive for the designing of cognitive controllers. This chapter presents a human-centered reinforcement learning control for visual comfort management in cognitive buildings. A satisfaction-based visual comfort model is coupled with RL to adapt the boundaries of the comfort zone in the presence of a group of occupants. Compared with the traditional controls, it is personalized and human-centric since users’ perceptions of the surroundings are exploited as the feedback loop. A case study of an office room and its performance are also presented.","['Engineering', 'Cyber-physical systems, IoT', 'Communications Engineering, Networks', 'Computer Applications']"
doi:10.1007/978-981-19-4025-5_2,en,Multiple Access Towards 5G and Beyond,OriginalPaper,"In this chapter, we discuss the practical deployment of multiple access in 5G and beyond. Section 2.1 introduces the motivation of practically applying multiple access in wireless communication systems and present researches of multiple access technology. Section 2.2 investigates the typical technologies of multiple access in the existing researches. Section 2.3 presents the motivation and procedures of grant-free multiple access technology, including the transmission and reception techniques. Section 2.4 discusses the key issues raised by multiple access technology in the practical implementation process. Section 2.5 gives a conclusion of this chapter.","['Engineering', 'Communications Engineering, Networks', 'Wireless and Mobile Communication']"
doi:10.1007/978-3-030-92968-8_9,en,Drive Health: Road Condition Detection,OriginalPaper,"Roadways play an essential role in today’s society by contributing to economic growth and development, providing access to all members of society and fast routes to travel on efficiently. With increased numbers of vehicles on the roads, the quality of the roads is deteriorating at a faster rate than can be maintained and repaired. This decrease in road health materializes as hazards such as potholes that can cause significant damage to vehicles on the road. Currently, roads’ health is monitored manually and thus done infrequently due to it being both time-consuming and costly for the responsible local transit authorities. Therefore, many road quality issues are repeatedly reported by the people who drive on them before any inspection or repair efforts are undertaken by the transit authorities. This manual process of reporting potholes and other road hazards is an inefficient process requiring filling out forms or making phone calls while remembering the exact location of the pothole or road hazard. This chapter presents Drive Health , an Internet of Things (IoT) system developed to crowdsource the monitoring of the health of roadways by informing transit authorities of pothole locations. Drive Health includes a smart sensor and performs machine learning on accelerometer data to process and analyze the data without using the cloud. If the system determines that the data indicates the existence of a pothole, the location of where the data was collected is recorded and sent to a web server which can then be automatically shared with the transit authorities responsible for that road location.","['Engineering', 'Communications Engineering, Networks', 'Industrial and Production Engineering', 'Business and Management, general']"
doi:10.1007/978-1-0716-2819-5_11,en,Haplotyping-Assisted Diploid Assembly and Variant Detection with Linked Reads,OriginalPaper,"Phasing is essential for determining the origins of each set of alleles in the whole-genome sequencing data of individuals. As such, it provides essential information for the causes of hereditary diseases and the sources of individual variability. Recent technical breakthroughs in linked-read (referred to as co-barcoding in other chapters of the book) and long-read sequencing and downstream analysis have brought the goal of accurate and complete phasing within reach. Here we review recent progress related to the assembly and phasing of personal genomes based on linked-reads and related applications. Motivated by current limitations in generating high-quality diploid assemblies and detecting variants, a new suite of software tools, Aquila, was developed to fully take advantage of linked-read sequencing technology. The overarching goal of Aquila is to exploit the strengths of linked-read technology including long-range connectivity and inherent phasing of variants for reference-assisted local de novo assembly at the whole-genome scale. The diploid nature of the assemblies facilitates detection and phasing of genetic variation, including single nucleotide variations (SNVs), small insertions and deletions (indels), and structural variants (SVs). An extension of Aquila, Aquila_stLFR, focuses on another newly developed linked-reads sequencing technology, single-tube long-fragment read (stLFR). AquilaSV, a region-based diploid assembly approach, is used to characterize structural variants and can achieve diploid assembly in one target region at a time. Lastly, we introduce HAPDeNovo, a program that exploits phasing information from linked-read sequencing to improve detection of de novo mutations. Use of these tools is expected to harness the advantages of linked-reads technology, improve phasing, and advance variant discovery.","['Life Sciences', 'Genetics and Genomics']"
doi:10.1007/978-3-031-07654-1_7,en,A Novel Real-Time 3D Object Detection Network in Autonomous Driving Using Reformed RS-ResNet network,OriginalPaper,"Extending the RS-ResNets architecture for 3D bounding box detection from 2D images to 3D point clouds that have varying degrees of visibility, a regression module with a Euler Region Proposal Network that performs complex angle regression is added to predict the direction of bounding boxes around detected objects. Geometrical overlap of predicted labels and ground truth is identified for every set of Lidar point cloud and the corresponding image data and compared with the state-of-the-art architectures. With the ability to scale to different architectures of GPU/TPU, the RS-ResNet architecture achieves faster frame rates of reaching threshold value of 70 ms/frame and APH/L2 =  66, on a NVIDIA Tesla V100 GPU and capability to scale to new and more powerful GPU/TPU architectures. The predictions are made to two levels of label hierarchy and three levels of Lidar range images with the associated camera images that are considered as single set. The achieved frame rates and detected AP are compared to the latest state-of-the-art architectures such as Complex-YOLOV4 and other leaderboard in the Waymo 2021 3D object detection challenge.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Computer Communication Networks', 'Computational Intelligence']"
doi:10.1007/978-3-031-16203-9_24,en,Processing Technology of Thematic Identification and Classification of Objects in the Multispectral Remote Sensing Imagery,OriginalPaper,"This paper is devoted to an automated processing technology for remote sensing data of high spatial resolution. The developed technology is based on an object-based approach, which allows the classification, analysis and identification of individual objects on the Earth’s surface by taking into account their properties. The proposed processing technology includes the following key steps: pre-processing, segmentation, identification of different types of objects, and classification of the whole image. The multiscale segmentation method was used to obtain objects for analysis. The features of an image that allow one to accurately identify different types of objects were calculated: geometric, spectral, spatial, texture, and statistical features. On the basis of the calculated features, a decision on the object class is made. A model based on fuzzy inference is chosen to decide on the classes of image segments. The general accuracy, which shows the percentage of correctly classified pixels, and the Kappa index were used to evaluate the classification results.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-0588-9_6,en,Model-Based Hardware-in-the-Loop Closed-Loop Control of Brushless Direct Current Motor in Electric Vehicle Applications,OriginalPaper,"Electric vehicles (EVs) widely use brushless direct current (BLDC) motor with trapezoidal commutation due to its high-power efficiency, ability to operate at high speeds, acceleration, and less maintenance. However, load torque ripples due to trapezoidal commutation and load torque variations due to terrain conditions affect the BLDC motor speed and performance significantly. Furthermore, load torque fluctuations reduce the lifetime of driver components and the battery significantly. Therefore, efficient driver design for BLDC motors that can handle load torque variations and maintains a set-speed for BLDC motors are emerging as an urgent need in the EVs. This investigation presents a hardware-in-the-loop (HIL)-based closed-loop control of BLDC motor for electric vehicle applications. The hardware to be tested which is the proportional integral controller that adjusts the pulse-width modulation applied to the BLDC motor. The motor parameters are obtained from experiments, and their values are used in the simulations. Then the electronic control unit is developed with Arduino and is tested with the MATLAB/Simulink model. Our results demonstrate the ability of HIL to provide a controller design that matches the electric vehicle requirements.","['Energy', 'Energy Systems', 'Transportation Technology and Traffic Engineering', 'Electronics and Microelectronics, Instrumentation']"
doi:10.1007/978-3-031-20141-7_12,en,Retaining Wall Surface Optimization,OriginalPaper,"The paper presents the formulation and implementation of the problem of finding a rational external geometry of a retaining wall. The purpose of the research is to formulate and test the mathematical model of the specified problem. In this connection, the working hypothesis is the assumption of accepting the criteria for rationalizing the system in the form of requirements for minimizing the potential strain energy of system (PSE) on the set of allowable values of variable parameters and equalizing the potential strain energy density (PSED) within the designated model. These criteria are an integral structural part of the bioenergetic optimization method, however, this paper considers the problem of improving external (geometric) parameters based on the exploitation of only the 1st criterion. In the framework of the exploitation of the Coulomb theory, the procedure of formation of the geometry of the structure is defined when the pressure of the ground on it is applied. The simplest example is the algorithm for solving the problem of finding rational geometry of the rear face of a subsurface wall with its given horizontal projection. The essence of the proposed approach is the approximation of the curvilinear forming the rear face of the subsurface wall by a broken line. For each section of the divided structure key dependencies are built for the components of the stress-deformed state of the structure. It is shown that for given soil characteristics, the value of the potential energy of deformation of the system can be described through a combination of the slope angles of each of the sections. The problem is reduced to finding a combination of these angles in which the entered criterion takes the minimum (exact lower bound) value. The conclusion about the representativeness of the obtained solution is made on the basis of the compiled alternative information model. The implementation of the approach is illustrated by a numerical example. The results obtained can be applied in the search for a rational geometry of a retaining wall in the process of building design.","['Engineering', 'Computational Intelligence', 'Transportation Technology and Traffic Engineering', 'Manufacturing, Machines, Tools, Processes']"
doi:10.1007/978-3-031-13150-9_47,en,An Approach for Theft Detection and Alerting System,OriginalPaper,"Today there is a high rate of theft everywhere. Detecting the theft earlier is in high demand. The system which exists is popular using only using CCTV. But now a day’s lots of systems are available with many advanced algorithms. It makes the process more efficient. The proposed research work discusses face recognition and also weapon detection if the thieves brought weapons. In this system, a mobile application telegram is used. The image processing system is also used to implement the application. Wi-Fi module is used to send a photo of a person if he stands near the door. If an unknown person image is detected, then a buzzer will be triggered as an alarm, and then the owner can check the camera in the telegram application. The problems of the existing systems are the intruder can be identified after the theft. The human, along with the weapon, is also not detected in the existing approaches. The work carried out in this paper detect the unknown person and design a cost-effective and more efficient system to identify the theft in real-time and send the immediate notification of the theft to the owner for further action.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Management']"
doi:10.1007/978-981-19-3632-6_27,en,Network Communication Signal Tracking Technology Under Cloud Computing Data,OriginalPaper,"With the development of the times, computer technology is booming, and the degree of association between modern society and computer is higher and higher. Therefore, the rapid development of computer technology has led to earth shaking changes in the whole society. However, due to the rapid development of network information technology, there are unstable factors, hiding their identity in the network world, calling the wind and rain, doing whatever they want, which has caused a certain turbulence to the society. Therefore, in order to solve these potential dangers, we hope to use cloud computing technology with various algorithms to develop a set of network communication signal tracking technology to track everyone’s IP address in real time, so as to ensure the security of the network, which is the purpose of this paper. After we reported the project to the school and obtained approval, we borrowed the school’s laboratory, used the school’s internal network data and the concealment of the school’s website, consulted the literature on cloud computing technology and network communication signal tracking technology, and used the improved particle swarm optimization algorithm and K-means algorithm to model and analyze it to determine the data effectiveness of the experiment. The experimental results show that there is a certain correlation between cloud computing technology and network communication signal tracking technology. Because of the complex network, the network communication signal tracking technology needs huge data and computing resources to build an effective network communication signal tracking system. Compared with before, it has increased the speed by about 189% and is more accurate. This experiment is relatively successful.","['Engineering', 'Cyber-physical systems, IoT', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing']"
doi:10.1007/978-981-19-3998-3_146,en,Survey on UAV Coverage Path Planning and Trajectory Optimization,OriginalPaper,"The Unmanned Aerial Vehicles (UAVs) technology has developed rapidly in recent years, and it has been widely used in aerial mapping, disaster search and rescue, smart farms, geographic mapping, environmental monitoring, power line patrol, aerial photography and other fields. Even so, coverage path planning (CPP) and trajectory optimization remains a hot problem, that is, how to find a safe flyable path in line with UAV dynamics constraints in a given area under the premise of ensuring the completion of coverage tasks. The research status of UAV regional coverage and path planning from the aspects of regional decomposition, traversal mode, trajectory optimization were reviewed in this paper and the trend of path planning technology in future was prospected.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-981-19-2016-5_9,en,Applications in AIoT: IoT Security and Secrecy,OriginalPaper,"Besides distributed learning discussed in Chap. 8 , applications and platforms including cloud computing, content delivery network, distributed ledger (Blockchain) are increasingly popular. It is particularly important considering the growing list of constraints and requirements in terms of security, fault tolerance, secrecy, privacy, etc. Then there is a huge need to evaluate the fundamental limits of distributed information systems. In this Chapter, we will focus on the security and secrecy for distributed AIoT systems as examples.","['Engineering', 'Wireless and Mobile Communication', 'Cyber-physical systems, IoT', 'Professional Computing', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-3015-7_3,en,Development of Walking Assistants for Visually Challenged Person,OriginalPaper,"With the development of technology, many inventions have been made which have helped to make the lives of differently abled people easier. Prosthetic arms and legs have been developed, hearing aids are now readily available, glasses and contact lenses are available for people who have myopia or hypermetropia, motor-operated wheelchairs are available for people with impaired legs. Most of the benefits of technology advancement have little consideration for the visually impaired even though they constitute about 3.6% of world’s population. However, with the advent of artificial intelligence, machine learning and the Internet of things, different types of helping aids have been developed to facilitate a visually challenged person to navigate. Unfortunately, these helping aids either have limited scopes and too many constraints or are very expensive. The device intends to assist a visually impaired person to walk around by integrating machine learning algorithms and image processing techniques.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Engineering', 'Data Mining and Knowledge Discovery', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-3-031-16203-9_26,en,Optimization of Data Preprocessing Procedure in the Systems of High Dimensional Data Clustering,OriginalPaper,"In this paper, we propose the technique of the optimal method choice of high dimensional data normalizing at the stage of data preprocessing procedure is performed. As well known, the qualitative carried out of the data preprocessing procedure significantly influences the further step of their processing such as classification, clustering, forecasting, etc. Within the framework of our research, we have used both the Shannon entropy and the relative ratio of Shannon entropy as the main criteria to evaluate the data normalizing quality. Before the apply the cluster analysis, we reduce the data dimensionality by using the principal component analysis. The obtained data clustering was performed using a fuzzy C-means clustering algorithm with an evaluation of the data clustering quality when using various methods of data normalizing. The analysis of the simulation results allows us to conclude that for this type of data (gene expression profiles) the decimal scaling method is optimal since the Shannon entropy of the investigated data achieves the minimal value in comparison with the use of other normalizing methods. Moreover, the relative ratio of Shannon entropy does not exceed the permissible norms during the data dimensionality reduction by applying the principal component analysis technique.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2273-2_35,en,A Review of Real-Time Traffic Data Extraction Based on Spatio-Temporal Inference for Traffic Analysis Using UAV,OriginalPaper,"The growing demand for Unmanned Aerial Vehicles (UAVs) in the field of computer vision applications leads the researcher into UAV video analysis for extracting real-time traffic data. This paper systematically reviews studies that apply vehicle detection and extraction methods of Spatio-temporal traffic parameters from UAVs for efficacious traffic analysis. A synthesis of bibliographic sources clarifies the advantages and limitations of different methods of vehicle detection, Spatio-temporal data extraction, and discovers recent trends in the applications of UAVs in real-time traffic analysis. This paper reviews various studies that analytically handle Spatio-temporal data in traffic flow analysis, and paying special attention to infer the effective application of UAVs to extract microscopic traffic data. Thus, the three main questions for this review are: How to detect vehicles from UAV videos? How is the application of UAV performing to estimate traffic flow parameters in the context of present traffic research? What are recent approaches are available for Spatio-temporal data extraction from UAV video data? This paper concludes that there is a clear need for the development of comprehensive techniques for selecting suitable Spatio-temporal data extraction methods for analyzing non-lane-based heterogeneous traffic conditions.","['Engineering', 'Transportation Technology and Traffic Engineering', 'Building Construction and Design', 'Mechanical Engineering']"
doi:10.1007/978-981-19-8222-4_8,en,Salient Object Detection with Fusion of RGB Image and Eye Tracking Data,OriginalPaper,"Salient object detection (SOD) is one of the fundamental topics in computer vision, but the current SOD algorithm is difficult to accurately find salient regions in scenarios such as multiple objects or small objects. Considering the above problems, this paper proposes a SOD algorithm with the fusion of RGB image and eye tracking data. The specific methods are as follows: (1) The eye tracking data can well simulate the human visual selection attention mechanism and contains high-level semantic information, so the eye fixation points are integrated into the salient object detection algorithm. (2) Considering the different characteristics of high-level features and low-level features, an improved cascade decoder including channel cascaded decoder (CCD) and spatial cascaded decoder (SCD) is designed. Moreover, the cross-modal fusion module (CMFM) is employed to better fuse the eye tracking data and the RGB image features. (3) The comparative experiments on the two datasets show that the performance of the proposed method exceeds that of the mainstream algorithms and can achieve effective SOD.","['Computer Science', 'Artificial Intelligence', 'Computer Applications', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Mathematics of Computing']"
doi:10.1007/978-3-031-18050-7_60,en,Node Location Optimization for Localizing UAVs in Urban Scenarios,OriginalPaper,"Unmanned-Aerial-Vehicles (UAV) widespread use has grown significantly in recent years. Their insertion in the civil sector allows their implementation in the agricultural and industrial sectors, as well as their use for surveillance or delivery applications. However, the efficient development of these applications depends on the drone’s ability to position itself autonomously. Although it is common to find drones with satellite positioning systems (GNSS), these systems are insufficient for autonomous navigation in urban or indoor environments. In these scenarios, the implementation of local positioning systems (LPS) is widely extended due to their adaptability capabilities. Through the optimal distribution of the sensors that constitute this system, they can adapt to almost any environment while also improving its performance. However, the complexity of this problem has been characterized as NP-Hard, which complicates its resolution. In this paper, a genetic algorithm is developed to optimize LPS in different environments. This algorithm, pioneer in the design of LPS for UAV localization, is tested on a generated urban environment. The results obtained denote the effectiveness of the methodology by obtaining location uncertainties significantly lower than GNSS.","['Engineering', 'Computational Intelligence', 'Industrial and Production Engineering']"
doi:10.1007/978-981-19-7842-5_1,en,Multidimensional Signal Processing and Applications—New Approaches,OriginalPaper,"This chapter is a short introduction in the contemporary approaches aimed at the multidimensional processing and analysis of various kinds of signals, investigated in related research works, which were presented at the Third International Workshop “New Approaches for Multidimensional Signal Processing”, (NAMSP), held at the Technical University of Sofia, Bulgaria in July 2022. Some of the works cover various topics, as: moving objects tracking in video sequences, automatic audio classification, representation of color video чpeз 2-level tensor spectrum pyramid, etc., and also introduce multiple applications of the kind: analysis of electromyography signals, diagnostics of COVID based on ECG, etc. Short descriptions are given for the main themes covered by the book, which comprises the following three sections: multidimensional signal processing; applications of multidimensional signal processing, and applications of blockchain and network technologies.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4052-1_71,en,Data Mining Approaches for Healthcare Decision Support Systems,OriginalPaper,"Data mining is a user-friendly approach to locating previously unknown or hidden information in data. The employment of data mining technologies in the healthcare system may result in the finding of relevant data. Data mining is used in healthcare medicine to construct learning models that predict a patient’s condition. Data mining technologies have the potential to benefit all stakeholders in the healthcare industry. For example, data mining may aid health providers in detecting theft and fraud, medical organizations in making customer service management decisions, physicians in discovering effective therapies and best practices, and customers in obtaining suitable and less expensive healthcare. Contemporary systems, due to their complexity and size, are unable to control and analyze the huge amounts of data generated by healthcare operations. Data mining is a technique and mechanism for converting a large amount of data into useful information. The fundamental purpose of this research is to look at what makes clinical data mining unique, to give an overview of existing clinical decision support systems, to identify and select the most common data mining algorithms used in modern Health and Demographic Surveillance System (HDSS), and to compare different data mining algorithms.","['Engineering', 'Computational Intelligence', 'Information Storage and Retrieval', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Data Structures and Information Theory', 'Artificial Intelligence']"
doi:10.1007/978-3-031-19958-5_24,en,Controlling Home Appliances Adopting Chatbot Using Machine Learning Approach,OriginalPaper,"In the last decades, home automation becomes popular and rapidly increased artificial intelligence-based controlling systems. So, many researchers have been interested in the Internet of things so that every appliance should be autonomous. Smart home technology is one of them. It involves certain electrical and electronic systems in a building with some degree of computerized or automated control. It can control elements of our home environments (e.g. light, fans, electrical devices, and safety systems). We propose an approach that fully controlled the home appliances by chatbot technology. In our research, the system can extract the device name such as light, fan, etc. using synonyms. In the device name extraction part, we use Jaro-Winkler string matching algorithms. We have also used the Naive Bayes algorithm to take command for action. Finally, a Firebase-based system connects the users and controls hardware. Our model can control the home appliances from a long distance because we used the wireless fidelity system.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-6149-6_1,en,"In-Process Sensing, Monitoring and Adaptive Control for Intelligent Laser-Aided Additive Manufacturing",OriginalPaper,"As one of the key technologies of Industry 4.0, additive manufacturing (AM) has been gaining rapid momentum in R&D and industry applications. However, achieving high consistency of material properties and dimensional accuracy of the additively manufactured parts remains a challenge. Hence, it is necessary to make the AM process intelligent to address the issues. In this paper, development of advanced laser aided additive manufacturing (LAAM) technology through digitization, sensorization and machine learning was introduced. A sensor-based adaptive dimension correction strategy using 3D point clouds as the feedback data was explored. A laser displacement sensor was integrated into an LAAM system to perform on-machine laser scanning measurement and in-process surface deviation correction of the intermediate layers. Finally, image-based process monitoring and control was investigated. The melt pool width was measured and fed back to a closed-loop controller that adjusts the laser power. The controller was developed with a novel multi-tasking architecture that incorporated an auto-tuning unit that optimises controller parameters automatically to achieve adaptable control of the process to different part shapes, materials, toolpaths, and process parameters. With this monitoring and control system implemented, the process stability and geometric accuracy of the deposited material can be improved.","['Engineering', 'Control, Robotics, Mechatronics', 'Artificial Intelligence', 'Industrial and Production Engineering', 'Control and Systems Theory']"
doi:10.1007/978-981-19-0095-2_17,en,Topic Modelling-Based Approach for Clustering Legal Documents,OriginalPaper,"The justice system has been institutionalized around the world for a long time, increasing the number of resources available for and in this field. The colossal increase in dependency on the World Wide Web is commensurate to the increase of digitization of documents. Along with this growth has come the need for accelerated knowledge management—automated aid in organizing, analysing, retrieving and presenting content in a useful and distributed manner. For a fair, cogent and strong legal case to be built, the individual fighting the case must have access to case documents from not only several years ago but also a few months ago. Any particular part of any of these various cases that received a verdict in the previous years could be beneficial to the individual’s case. Considering all these factors, it is evident to develop a search engine for legal documents which will provide the user with all the relevant documents it requires. Moreover, unlike widely accessible documents on the Internet, where search and categorization services are generally free, the legal profession is still largely a fee-for-service field that makes the quality (in terms of performance metrics used such as precision and recall) a key difference in services provided. This paper proposes a unique approach to cluster these documents using the mini batch k-means algorithm on dimensionally reduced sentence embeddings generated with the use of DistilBERT and UMAP. The proposed approach has been compared to state-of-the-art topic modelling and clustering approaches and has outperformed them.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Systems and Data Security', 'Artificial Intelligence', 'Computational Intelligence']"
doi:10.1007/978-3-031-05875-2_9,en,Intelligent Traffic Monitoring Systems,OriginalPaper,"Traffic management is gaining increasing importance in solving the major problem of traffic congestion present in many countries. Traditional techniques of RADAR, LIDAR and LASAR to address this problem are no longer an efficient solution, as they are time-consuming and expensive. In this modern age of growing technology and population, challenges are being over-come with several new ways to make the traffic system smarter, more reliable and robust, considering the overall interaction of all the traffic components: vehicles, drivers and pedestrians. These systems are largely supported on Intelligent Traffic System (ITS), and their applications are mostly dedicated to traffic monitoring based on video processing, vehicle detection and tracking. Intelligent surveillance systems may also employ computer vision and pattern recognition techniques. This chapter addresses these new solutions that are being used for traffic management, their advantages and disadvantages, the challenges of their implementation, and most important, the ability to support traffic management systems in their pursue of solving critical problems of congested transportation networks.","['Engineering', 'Building Materials', 'Geotechnical Engineering & Applied Earth Sciences', 'Geoengineering, Foundations, Hydraulics', 'Transportation Technology and Traffic Engineering']"
doi:10.1007/978-3-031-18256-3_41,en,PET Image Reconstruction Using a GRU-Convolutional Network,OriginalPaper,"Positron emission tomography is widely used for tumor detection and treatment monitoring in oncology. However, the quality of the images depends, among other factors, on the amount of radiopharmaceutical ingested by the patient. In this sense, the quality suffers degradation because there is a limit on the amount of radiation the patient can tolerate. Because of this, image reconstruction algorithms are required to generate images of adequate quality even if the amount of radiopharmaceutical to produce the image is small. In this study, a reconstruction algorithm is proposed based on deep learning using a GRU recurrent network which is expected to model the series of projections produced by the PET scanner as an input sequence to the recurrent network and is capable of reconstructing an image even with low amounts of the radiopharmaceutical. In comparisons using image quality metrics, our proposal achieves a SIMM of 0.95, outperforming other state-of-the-art methods. Additionally, tests were performed for the evaluation of the task of lesion detection; the proposed method obtained a better contrast of the lesion with a value of 0.54 when using the weber contrast metric, very similar to the ground truth contrast of 0.55.","['Engineering', 'Biomedical Engineering and Bioengineering', 'Regenerative Medicine/Tissue Engineering', 'Bioinformatics']"
doi:10.1007/978-3-031-11748-0_2,en,Federated Learning for Resource-Constrained IoT Devices: Panoramas and State of the Art,OriginalPaper,"Nowadays, devices are equipped with advanced sensors with higher processing and computing capabilities. Besides, widespread Internet availability enables communication among sensing devices that results the generation of vast amounts of data on edge devices to drive Internet-of-Things (IoT), crowdsourcing, and other emerging technologies. The extensive amount of collected data can be preprocessed, scaled, classified, and finally, used for predicting future events with machine learning (ML) methods. In traditional ML approaches, data is sent to and processed in a central server, which encounters communication overhead, processing delay, privacy leakage, and security issues. To overcome these challenges, each client can be trained locally based on its available data and by learning from the global model. This decentralized learning approach is referred to as federated learning (FL). However, in large-scale networks, there may be clients with varying computational resource capabilities. This may lead to implementation and scalability challenges for FL techniques. In this paper, we first introduce some recently implemented real-life applications of FL underlying the applications that are suitable for FL-based resource-constrained IoT environments. We then emphasize the core challenges of implementing the FL algorithms from the perspective of resource limitations (e.g., memory, bandwidth, and energy budget) of client devices. We finally discuss open issues associated with FL for resource-constrained environments and highlight future directions in the FL domain concerning resource-constrained devices.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Machine Learning']"
doi:10.1007/978-981-19-2600-6_19,en,Machine Learning Based Earthquake Early Warning (EEW) System: A Case Study of Himalayan Region,OriginalPaper,"Seismic sensing and generation of earthquake alarm is an important application for society at large. In this paper, we propose the strategy of extracting earthquake event features parameters τ c and P d from fast-arriving P-wave signals. The said features are used to explore the performances of some of the popular machine learning (ML) based classifiers to compare their performances in triggering an alarm for the Earthquake Early Warning (EEW) system. We explored four different ML classifiers namely Support Vector Machine (SVM), Naive Bayes, K-Nearest Neighbors (KNN), and Logistic Regression so that the best can be applied for the EEW alarm generation. We have used publicly available data from the PESMOS platform of IIT-Roorkee in this work.","['Engineering', 'Data Engineering', 'Statistics, general', 'Machine Learning', 'Artificial Intelligence', 'Data Storage Representation', 'Data Structures and Information Theory']"
doi:10.1007/978-3-031-16832-1_10,en,Optimizing a Real Case Assembly Line Balancing Problem Using Various Techniques,OriginalPaper,"In this research, a real-life Line Balancing Problem (LBP) at a metalworking company is considered to find the minimum number of workstations. Tasks are assigned to workstations aiming to minimize the required number of workstations, subject to considering a given production rate and satisfying the precedence relationships between tasks. Besides, line efficiency and smoothness index are considered as the second and the third objectives to select the best solution. The straight and the U-shaped lines have been considered for the layout configuration. Several solution methods, including Ranked Positional Weight (RPW), a modified version of RPW which is called Revised-RPW, and the Revised-COMSOAL, which is a recent-proposed, and one of the most efficient heuristic methods, are used to balance the production line and workstations, assuming deterministic tasks’ processing times.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Engineering']"
doi:10.1007/978-3-031-06780-8_10,en,Energy-Efficient Autonomous Driving Using Cognitive Driver Behavioral Models and Reinforcement Learning,OriginalPaper,"Autonomous driving technologies are expected to not only improve mobility and road safety but also bring energy efficiency benefits. In the foreseeable future, autonomous vehicles (AVs) will operate on roads shared with human-driven vehicles. To maintain safety and liveness while simultaneously minimizing energy consumption, the AV planning and decision-making process should account for interactions between the autonomous ego vehicle and surrounding human-driven vehicles. In this chapter, we describe a framework for developing energy-efficient autonomous driving policies on shared roads by exploiting human-driver behavior modeling based on cognitive hierarchy theory and reinforcement learning.","['Engineering', 'Automotive Engineering', 'Computational Intelligence', 'Transportation Technology and Traffic Engineering', 'Signal, Image and Speech Processing']"
doi:10.1007/978-3-031-20601-6_36,en,Effect of Inertia Weight of PSO Used to Solve the Continuous p-Center Location Problems,OriginalPaper,"Particle swarm optimization (PSO) has several benefits including few parameters, quick convergence, and ease of implementation; however, for NP-hard problems such as p -center location problems, it often falls within local minima. Inertia weight parameter can be used to overcome this problem, since it increases the diversity of particles. To study the effect of inertia weight, and based on different values of inertia weight used in the lectures (0.5, 0.7, 0.9, 1.1, and 1.3). We examined the effect of inertia weight used to solve benchmark continuous p -center location problems/instances. The validity of the results is demonstrated by experiments. 1,050 experiments have been conducted. The results show that inertia weight = 0.9 yield the minimum objective function values. Also, the results show that low value of inertia weight leads to faster convergence, however, it does not guarantee the best minima values.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-11686-5_3,en,Semantic History Slicing,OriginalPaper,"Feature location techniques aim to locate software artifacts that implement a specific program functionality, a.k.a. a feature. In this chapter, we introduce a technique called semantic history slicing , to locate features in software version histories. The key insight is that the information embedded in version histories can be used to establish a connection between features and changes implementing the features. We present the formal definitions as well as the general principles of semantic history slicing and provide details on a specific history slicing algorithm based on change dependency analysis. The identified feature implementing changes are fully functional and guaranteed to preserve the desired behaviors.","['Computer Science', 'Software Engineering/Programming and Operating Systems', 'Software Management', 'Computer System Implementation']"
doi:10.1007/978-3-031-20105-9_1,en,Fundamentals of Metaheuristic Computation,OriginalPaper,This chapter presents the main concepts of metaheuristic schemes. The objective of this chapter is to introduce the characteristics and properties of these approaches. An important purpose of this chapter is also to recognize the importance of metaheuristic methods to solve optimization problems in cases in which traditional techniques are not suitable.,"['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2065-3_2,en,Implementing Client-Side Encryption for Enforcing Data Privacy on the Web Using Symmetric Cryptography: A Research Paper,OriginalPaper,"The Internet provides remote access to resources such as storage and computation available worldwide. The virtual interaction of people on the Internet makes it difficult to recognize the identity of a person. In addition, the open-network structure of the Internet might allow third parties to read and change data in a communication over the network. Hence, every organization must maintain the integrity of data by preventing unauthorized modification. To secure confidential information on the Internet, one must put into practice necessary security measures. Cryptography is a technique that helps to reduce security risks to the confidentiality and integrity of the data on the Internet. Moreover, the encryption of confidential data can be done either at the client machine (Web client) or on the server (Web server). The side (client/server) at which the encryption has to take place is decided based on the confidentiality of data to be protected. The critical data that need highest security in an organization is considered as in Level 1. In Level 2, we have information that is important but not critical as in Level 1. Level 3 comprises of data that are not important in the daily operations of an organization. Among the three levels of confidentiality, data exist at Level 1 and Level 2 need encryption so that they can be kept confidential on the Web. As the data in Level 1 is both confidential and important, it must be encrypted at the client-side itself before their migration onto the Web. Whereas, data in Level 2 can be encrypted after their migration since the criticality of data in Level 2 is less compared to that of Level 1. In this paper, the authors have identified some of the symmetric cryptographic algorithms with the help of which client-side encryption of data can be achieved for enforcing data privacy on the Web. They have also proposed an extended symmetric algorithm using which searchable encryption is possible on the encrypted data stored in a remote server.","['Engineering', 'Communications Engineering, Networks', 'Artificial Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Machine Learning']"
doi:10.1007/978-3-031-09382-1_26,en,Dynamic Sectorization - Conceptualization and Application,OriginalPaper,"Sectorization is the division of a large area, territory or network into smaller parts considering one or more objectives. Dynamic sectorization deals with situations where it is convenient to discretize the time horizon in a certain number of periods. The decisions will not be isolated, and they will consider the past. The application areas are diverse and increasing due to uncertain times. This work proposes a conceptualization of dynamic sectorization and applies it to a distribution problem with variable demand. Furthermore, Genetic Algorithm is used to obtain solutions for the problem since it has several criteria; Analytical Hierarchy Process is used for the weighting procedure.","['Engineering', 'Engineering Design', 'Manufacturing, Machines, Tools, Processes', 'Complexity']"
doi:10.1007/978-981-19-6168-7_1,en,Introduction,OriginalPaper,"Currently, as production resources are desired to be capable of rapidly reacting to variations in the market environment.","['Engineering', 'Control, Robotics, Mechatronics', 'Robotics and Automation', 'Applied and Technical Physics', 'Industrial and Production Engineering', 'Measurement Science and Instrumentation']"
doi:10.1007/978-3-031-19604-1_7,en,Speed-Up Single Shot Detector on GPU with CUDA,OriginalPaper,"Nowadays, most of the current research on object detection is to improve the whole framework, in order to improve the accuracy of detection, but another problem of object detection is the detection speed. The more complex the architecture, the slower the speed. This time, we implemented a Single Shot Multibox Detector(SSD) using GPU with CUDA. We have improved the object detection speed of SSD, which is one of the most regularly used objects detection frameworks. The most time-consuming part, the VGG16 network, is rewritten by using cuDNN, which is made faster by about 9%. The second time-consuming part is post-processing, where non-maximum-suppression (NMS) is performed. We accelerated NMS by implementing our new algorithms that are suitable for GPUs, which is about 52% faster than the original PyTorch version [ 16 ]. We also ported those parts that were originally executed on CPU to GPU. In total, our GPU-accelerated SSD can detect objects 22.5% faster than the original version. We demonstrate that using GPUs to accelerate existing frameworks is a viable approach.","['Engineering', 'Computational Intelligence', 'Software Engineering/Programming and Operating Systems', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3998-3_17,en,Stability Analysis of Distributed Optimization for Multi-agent Systems Under Time-Varying Digraphs,OriginalPaper,"This paper investigates a distributed convex optimization problem for multi-agent systems over time-varying directed communication topologies. To explore this problem, the differential inclusion strategy is used to model the time-varying situation, and the average dwell-time automaton and the time-ratio monitor are utilized to constrain the switching law. Ground on these constraints and using the Lyapunov stability analysis method, our proposed algorithm converges exponentially to the optimal solution over time-varying digraphs. Finally, some simulation results are reported to illustrate the proposed algorithm.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-3-031-16868-0_12,en,Architecture Design for Analyzing Hyperspectral Images,OriginalPaper,"Denoising images is a key part of the process of images. The hyperspectral image (HSI) has three dimensions in addition to the natural 2D image to display spectral and spatial information. In forestry [ 2 , 2 ], agriculture, and urban planning, HSIs are commonly used. However, there are impacts with the multi-detector utilized to create the HSIs because of the harsh space environment, resulting in the noise of HSIs. The accuracy of consequent work, such as classification tasks [ 3 ], will be affected by the corrupted hyperspectral data with noise. As a result, in recent years have been an increase in interest in HSI denoising [ 4 , 5 ]. Numerous methods, for example the Tenser-SVD [ 6 ] as well as the K-singular value decomposition [ 7 ], have been proposed. In general, the HSI denoising techniques may be categorized into three major groups.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3387-5_89,en,An Image Denoising Algorithm Combining Global Clustering and Low-Rank Theory,OriginalPaper,"In recent years, image denoising algorithms based on non-local image prior information have been extensively researched. At present, most similar image blocks are gathered by neighborhood block matching, that is, a fixed number of similar image blocks are matched in the field of image blocks by a similarity measurement method, basing on Euclidean distance. Although this method is more efficient, there are some problems: when searching for similar image blocks locally, some special structures, such as image edges or corners that cannot match similar image patterns and existing similar structures in the global scope, are ignored.To solve the above problems, a global clustering method is proposed in this paper to match image blocks, which improves the flexibility of the algorithm. At the same time, to solve the problem of the loss of detailed information such as edge texture when the similar image block matrix is constrained by low-rank, a low-rank sparse image denoising model combined with global clustering is proposed to effectively filter out noise while preserving image details as much as possible.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Aerospace Technology and Astronautics']"
doi:10.1007/978-981-19-3788-0_23,en,Developing a Virtual Device to Identify Signals for Aviation Communication Monitoring System,OriginalPaper,"Rapid loading of the used-frequency bands inevitably leads to an increase in the number of unintended interferences related to the system operation features. Also, there exists a danger of unapproved access to the professional communication frequency band. This is most critical for the metric-wave band, because it is here, where the main communication between an aircraft and the ground control occurs at the take-off and the landing. Data losses, in this case, may lead to a terrain accident, because the take-off and the landing are the most complex flight stages demanding prompt information exchange. Due to this, it is important to quickly find and identify the preventing effect impeding the radio communication. The goal of this paper is to develop an algorithm for detecting and identifying the signals in the set band, based on analyzing their in-phase (I) and quadrature (Q) components, which enables to essentially increase air safety.","['Engineering', 'Aerospace Technology and Astronautics', 'Engine Technology', 'Engineering Thermodynamics, Heat and Mass Transfer']"
doi:10.1007/978-3-031-19958-5_6,en,Adaptive Metaheuristics for Evaluation-Number Constrained Optimization Problems,OriginalPaper,"This paper is related to an optimization problem constrained by the evaluation number of the objective function. This class of the problem, called the “Evaluation-number Constrained Optimization (ECO)” problem, has pragmatic value when the objective function evaluation is expensive in terms of money or time because such costs are usually limited in any real-world project. This paper first shows a solution framework for this problem, proposed previously by the author, that adapts metaheuristic algorithms to any evaluation-number constraint. Second, the proposed framework is applied to a standard Differential Evolution (DE) algorithm. The expected value of the population state of the DE algorithm is calculated to obtain the adaptive parameter adjusting method in the framework. Finally, a numerical experiment on the proposed adaptive DE algorithm is conducted to confirm its effectiveness for three test functions under different evaluation-number constraints.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2538-2_11,en,Cloud Network Communication Performance Improvement Using a Stochastic Bandwidth Allocation and Swarm Optimization Algorithm,OriginalPaper,"Cloud computing is fulfilling the dream of providing the highest resource utilization in the IT world. Many commercial applications also offer a wide range of shaded services. Owing to rapid increase in the usage of the internet, rapid access has also been the factor to the prosperity of the industry. Different services are built within the virtualized resources of cloud computing that allow us to perform the abstraction of the underlying resources. It offers flexibility, high capacity, and an ecological service-oriented mindset. In this work, algorithm development solves resource utilization, performance degradation, and availability issues. This problem requires an almost unlimited number of tasks assigned to cloud resources that are solved in polynomial time. The proposed Stochastic Bandwidth Allocation with Swam Optimization (SBA-SO) framework for dynamic network-based resource scheduling algorithms provides scalability and reliability by providing better resource utilization and minimum response times during migration. User requests arrive at the data center as bandwidth, response time and throughput quality check different parameters based on the request. Additive-polling load analysis is introduced to estimate each cloud datacenter load to categorize overload server and under load cloud servers. Each cloud resource monitors the usage and updates into the cloud index table. When the cloud suddenly increases the load, it searches other load servers to allocate to the user. The Swam Optimization method using a memetic hyper-heuristic algorithm is used to construct the network topology and establish the communication between servers. Optimization algorithms are also suitable for solving individual problems and can be used for managing cloud computing resources and scheduling resources.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory', 'Mobile and Network Security']"
doi:10.1007/978-981-19-5224-1_49,en,A Survey: Extraction of River Networks from Satellite Images,OriginalPaper,"River network extraction is crucial to keep track of the water resources. Various methods have been implemented in times series to yield profound and incisive outputs and are still being developed and combined with predefined available methods. We have carried out a structured survey on these methods and have presented them with their outputs. There are numerous Web sites available for data set collection. Some generalized methods are available like image processing, using predefined models, or developing user-defined algorithms. For image processing, various segmentation methods are available out of which clustering- and threshold-based segmentations are mostly used. Predefined models such as CNN, ResUNet, YOLO, Faster CNN, and MSCFF are available. These algorithms can be used for the extraction of river networks but might not yield higher accuracies. Hence, this paper concentrates mainly on approaches for the extraction of river networks from satellite images.","['Engineering', 'Communications Engineering, Networks', 'Statistics, general', 'Cyber-physical systems, IoT', 'Sociology, general', 'Professional Computing']"
doi:10.1007/978-981-19-2600-6_15,en,Augmented Feature Generation Using Maximum Mutual Information Minimum Correlation,OriginalPaper,"With size of datasets varying un-uniformly in sample size and feature length, to optimize the feature set usually different methods such as filter, wrapper methods are used. However, with different machine learning techniques though either feature reduction is used, or feature extraction is used, both have its own merits and de-merits. The proposed work proposes a hybrid model that tries to combine the feature extraction and feature reduction techniques thereby using both linear and non-linear techniques to take the best parts of both methods. After the initial ensemble is created still the feature set is further optimized by using the concept of entropy and information gain. Using mutual information, on further analysis the best non-redundant feature sets are selected after considering a specific threshold and using this as a testing tool the datasets are again analyzed to check the working accuracy. The model performance is found to be effective even using reduced feature sub-set. Also, it has been found apart from excelling in classification accuracy, the model has been successful in maintaining the range of the metric irrespective of the input size.","['Engineering', 'Data Engineering', 'Statistics, general', 'Machine Learning', 'Artificial Intelligence', 'Data Storage Representation', 'Data Structures and Information Theory']"
doi:10.1007/978-981-19-3387-5_45,en,A Query Optimization Method for Real-Time Embedded Database Based on Minimum Arborescence,OriginalPaper,"In this paper, a query optimization method based on minimum arborescence for real-time embedded database is proposed to solve the problems of memory limitation and real-time access performance limitation of spaceborne computer system. Based on the characteristics of SQL statements, this method applies the minimum arborescence algorithm to the real-time embedded query processing by relying on the relationship between the attributes of each table during the construction of SQL query. This method can improve the processing speed of multi-table complex query statements, reduce the system memory usage, and optimize query processing in embedded database. The verification on SQLite database shows that this method is an effective query optimization method for embedded database.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Aerospace Technology and Astronautics']"
doi:10.1007/978-981-16-9967-2_48,en,Artificial Intelligence-based Vehicle In-Cabin Occupant Detection and Classification System,OriginalPaper,"Vehicle safety is the primary and necessary aspect of the automobile industry. An airbag is one of the passive safety systems available in an automobile. However, the airbag deployment needs to be controlled to avoid accidents due to it. In low-velocity crashes, the injury caused by airbag deployment is higher than the impact inside the vehicle. Children are more vulnerable to airbags when they sit near airbag housing without proper seatbelts or child seat arrangements. Deployment of the airbag when no occupant is sitting on a seat is unnecessary. So, it is important to detect the occupants’ presence in a seat and their classes such as a child or an adult. The primary aim of the paper is to detect the occupants’ presence and classify them into different classes. The occupant classes used are child and adult. In this project, we developed a technique to identify the occupants’ presence and verify the data from one sensor using another. We collected the image data of the occupants using a camera in a sedan and hatchback vehicles. We analyzed the images using a deep learning algorithm. The output classified the occupants as child and adult. A load cell sensor mounted on the seat was used to measure the weight of the passenger. This data was used to confirm the occupant classification. We evaluated the model detection and classification performances with the parameters such as precision 0.95, recall 0.97, and F1-score 0.96 for image dataset, and we got 0.73 as a classification accuracy for load cell dataset. Finally, we compared both the model performances.","['Computer Science', 'Computer Systems Organization and Communication Networks', 'Computational Intelligence', 'Artificial Intelligence', 'Wireless and Mobile Communication', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-1862-9_68,en,Collection of Municipal Solid Waste by Clustering of Dynamic Nodes for Vehicle Path Optimization,OriginalPaper,"Collection and transportation of municipal solid waste (MSW) is a critical factor that governs the overall cost of the MSW management system. With the help of various technological interventions, optimal usage of available resources could bring about a considerable amount of savings. In this study, an attempt has been made to optimize the MSW collection vehicle route path to reduce the fuel, distance, and overall workload in local municipalities by adopting dynamic graph modeling. The optimization problem is addressed from three different perspectives, namely, (a) analyzing the dynamic nature of the user requests, (b) the influence of the number of waste collection vehicles available in a given area, and (c) determining the optimum number of vehicles for which the overall cost is minimized. Relevant simulation studies are carried out to validate the proposed approach.","['Engineering', 'Building Construction and Design', 'Transportation Technology and Traffic Engineering', 'Building Materials']"
doi:10.1007/978-3-031-08246-7_1,en,A Vertical Fragmentation Method for Multimedia Databases Considering Content-Based Queries,OriginalPaper,"In database systems, response time is paramount, to reduce this, fragmentation techniques have been used that give favorable results. Fragmentation methods have been applied in multimedia databases to reduce the execution cost of content-based queries. A vertical fragmentation method to optimize content-based queries is proposed in this chapter. Also, the design of a Web application is presented using the aforementioned method. Some experiments were performed using a cost model to demonstrate the effectiveness of our approach.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-17697-5_35,en,Serendipity-Oriented Clustering Method for Recommender Systems Based on Collaborative Filtering,OriginalPaper,"Online shopping is becoming more common, and customers need a recommendation from the system for their needs. Providing accurate predictions is of utmost importance for the success of recommender systems. Various factors may affect the quality of the prediction. Besides the quality of prediction, efficiency is also vital for the success of recommender systems. A similarity metric is used to create a neighborhood in a dataset. In this study, we investigated the effects of binary similarity metrics on the accuracy and efficiency of the prediction. Additionally, we compared how the number of neighborhoods impacts the result and the quality of prediction. We conduct various real data-based experiments to determine the optimal number of neighborhoods and the optimal binary similarity measure. Our experimental outcomes show that the Jaccard similarity metric provides the best result when compared to the Ochiai and Kulczynski. These similarity measurements are implemented with a serendipity approach in mind. The Serendipity approach contains novelty, unexpectedness, and relevance components. In this study, we implemented the above-mentioned similarity measurements to calculate the relevance component whereas most of the researchers used cosine and Pearson similarity measurements.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3998-3_75,en,Multi-target Passive Localization Algorithm Based on UAV Clusters,OriginalPaper,"In order to study the problem of multi-target passive localization of UAV clusters, this paper first uses the traditional pseudo-linear estimation (PLE) method for target coarse positioning. Then for multi-target passive localization scenarios, proposes a resource allocation method of UAV clusters based on the greedy algorithm. Finally uses the improved weighted pseudo-linear estimation (WPLE) method or improved maximum likelihood estimation (MLE) method for target fine positioning. Besides, the influence of different passive localization algorithms and related parameters on the positioning performance of the system is analyzed through simulation. The experimental results show that the positioning algorithm proposed in this paper achieves accurate positioning of multiple targets, and has a higher positioning accuracy than the traditional PLE method, which verifies the effectiveness and feasibility of the algorithm.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-981-19-5224-1_18,en,Missing Value Imputation Using Weighted KNN and Genetic Algorithm,OriginalPaper,"Missing data cause many challenges for imputing missing value in real-world datasets. Much research has been done on these challenges, but most existing research focuses on the classification task. Only a few methods can handle the large datasets for imputation of missing value. This paper proposes a new hybrid approach to impute the missing value. This approach is based on a Weighted k-nearest neighbor (WKNN) and genetic programming algorithm. This approach aims to enhance the accuracy of the imputation of missing value in symbolic regression. This paper has used different datasets with a different missing ratio of data and applied the imputation model to the datasets. This approach makes exact imputation compared to other methods like Decision Tree, Genetic programming imputation, Bayesian Regression, logistic regression, WKNN, Multilayer Perceptron, Random Forest, and Support Vector Regression.","['Engineering', 'Communications Engineering, Networks', 'Statistics, general', 'Cyber-physical systems, IoT', 'Sociology, general', 'Professional Computing']"
doi:10.1007/978-981-19-4971-5_49,en,Peak Time Energy Management System for Household Load Devices Under Real-Time Pricing,OriginalPaper,"This paper describes how to schedule the home load types like air conditioner (AC), electric water heater (EWH), clothes dryer (CD) and electric vehicle (EV), taking into account end user’s ease level that is flexibility to choose the operation period of the devices. The real-time pricing (RTP) is accounted so that peak demand will shift to the other time which is having lower pricing hours and due to this user save in the electricity bill. The utility has set a demand threshold level (DL) if user breaks the limit at any time of the billing period, then the supplementary charges will be levied on consumer for drawing more power. This paper examines the comparison study of three different scheduling methods. The scheduling of load devices has been formulated one with home energy management algorithm accompanying load predilections and the other two optimization methods: binary particle swarm optimization (BPSO) and proposed binary salp swarm algorithm (BSSA). The proposed optimization arrived at the conclusion that the solution it has provided surpassed from the rest of the added two methods solution. In comparison with the rest of the methods, the reduction in load factor and the saving from BSSA is very much in consumer’s bill. The convergence is also faster than the BPSO.","['Engineering', 'Power Electronics, Electrical Machines and Networks', 'Energy Policy, Economics and Management', 'Energy Systems']"
doi:10.1007/978-981-19-3951-8_51,en,Optimal Planning of Renewable-Based Microgrid Using Bald Eagle Search Algorithm,OriginalPaper,"In this paper, the operational planning of microgrid consists of different type of distributed generators has planned to meet the load demand. The objective is to minimize the operating cost and output emission, which are mainly dependent on the type of distributed generators used in the microgrid. Therefore, load dispatch has been performed to evaluate the minimum operating cost and output emission, operating under their respective limits. For multi-objective optimization, the bald eagle search algorithm has been used to determine the best-compromised solution between operating cost and output emission. The bald eagle search algorithm is a new metaheuristic approach inspired by the behaviour and foraging methods of bald eagles, to hunt their food.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-981-19-7083-2_4,en,Secure Federated Learning,OriginalPaper,"Although federated learning does not require any participant to share its private data to the central server, local data information still has a potential risk of being revealed taking advantage of the uploaded model parameters or gradients from each client, if the server is honest-but-curious . To address this issue, homomorphic encryption is one of the main stream privacy preservation technologies used in federated learning due to its extraordinary model protection ability. However, most encryption-based federated learning systems are computationally intensive and consume a large number of communication resources. Moreover, a trusted third party is always needed to generate key pairs for both encryption and decryption operations, not only increasing the complexity of the system topology but also causing additional security threats. Therefore, in this chapter, we introduce two secure federated learning frameworks. The first one is for horizontal federated learning, where the global key pairs are jointly generated between the server and connected clients without the help of a trusted third party. In addition, model quantization and approximated model aggregation techniques are adopted to significantly improve the encryption efficiency during the training period. The second framework is tailored for vertical federated learning, where labels are distributed on different local devices. To achieve secure node splitting and construction as well as label aggregation of a XGBoost tree, both homomorphic encryption and differential privacy are adopted.","['Computer Science', 'Machine Learning', 'Privacy', 'Cryptology']"
doi:10.1007/978-981-19-3632-6_24,en,Path Planning of Indoor Mobile Educational Robot Based on Improved Deep Reinforcement Learning,OriginalPaper,"With the maturity of artificial intelligence and Internet of Things technology, the research on robots has also become one of the hotspots of artificial intelligence. Indoor mobile educational robots are an important part of machine intelligence. Research on the path of indoor mobile educational robots has become a key point in machine research. The purpose of this paper is to study the path planning of indoor mobile educational robots to improve deep reinforcement learning. This article first summarizes the research status of mobile educational robots at home and abroad. On this basis, the kinematics model of the indoor mobile educational robot is researched and analyzed. This article systematically elaborates the path planning based on the Actor-Critic algorithm and the deep reinforcement learning training model based on the minimum depth of field information. And use comparative analysis method, observation method and other research methods to carry out experimental research on the theme of this article. Research shows that the Actor-Critic algorithm proposed in this paper is shorter in path planning time and path distance than traditional algorithms.","['Engineering', 'Cyber-physical systems, IoT', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing']"
doi:10.1007/978-981-19-2468-2_32,en,Steering Algorithm for Generation of a Stable Time Scale,OriginalPaper,"An atomic clock drifts from UTC (Coordinated Universal Time) due to factors such as aging and frequency drift. Algorithms are designed to provide a stable timescale by predicting and steering clocks to standard reference time (UTC). Kalman filter is an optimal estimator that can estimate present and future behavior of an atomic clock with respect to a stable reference timescale. A clock in general comprises white phase noise, white frequency noise, random walk frequency noise, random walk frequency aging, and constant frequency aging. Kalman filter is required for removal of noises and improving clock performance. The role of Kalman filter in improving the long- and short-term stability of a free running clock is investigated. A state matrix is formulated using a phase difference and frequency of clock with respect to a reference signal in this algorithm. The estimated state from Kalman is further used in a control algorithm for steering of clocks. Steering removes the drift in atomic clock and generates an accurate clock output with respect to UTC. The level of steering is determined by user-defined parameters. The variation in steering coefficient leading to a change in clock performance is studied.","['Engineering', 'Electronics and Microelectronics, Instrumentation', 'Quantum Physics', 'Measurement Science and Instrumentation']"
doi:10.1007/978-981-19-3998-3_114,en,A Distributed v-GNE Seeking Algorithm for Multi-agent Games over Unbalanced Graphs,OriginalPaper,"In this article, we study distributed generalized Nash equilibrium (GNE) seeking algorithm in multi-agent network games. We focus on networks described by unbalanced digraphs and concentrate on a class of games with coupling constraints, and give the convergence analysis by using and doubly-augmented operator splitting approach and Perron-Frobenius (PF) eigenvector. We extend the algorithm to the case of intermittent communication and give a theoretical analysis. Finally, we validate the convergence by a Nash-Cournot game example.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-981-19-5331-6_56,en,An Improved Static Technique for Placement of Anchor Nodes to Enhance the Localization in IoT,OriginalPaper,"Location-based IoT applications require the exact location of the things, which is unknown if it is not deployed with GPS system. Localization means locating things’ positional coordinates. We require the assistance of anchor nodes that are things too whose location are known. As anchor nodes are not cost effective hence the numbers need to be reduced and set up effectively so as to cover the whole area for finding the location accurately in the network. One algorithm is proposed and implemented through several simulations in Python for placement of anchor nodes. In this paper, we compared with the existing pluck the berry algorithm.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-14537-7_18,en,Collaborative Optimisation of Robotic Disassembly Planning Problems using the Bees Algorithm,OriginalPaper,"Remanufacturing Remanufacturing is an important way to realize environmental protection and resource reutilization by reusing end-of-life products. Disassembly Disassembly is an important process of remanufacturing Remanufacturing . Manual disassembly is a common method used to disassemble end-of-life products; it is expensive and inefficient. Recently, robotic disassembly Robotic disassembly has been proposed to address the shortcomings of manual disassembly Disassembly . Before the robotic disassembly Robotic disassembly execution process, robotic disassembly planning Disassembly planning , which contains robotic disassembly sequence planning and robotic disassembly Robotic disassembly line balancing, could be utilized to improve disassembly efficiency. However, the existing research independently studies robotic Robotic disassembly sequence planning and robotic disassembly line balancing and ignores their interrelationships. In this chapter, the Bees algorithm Bees Algorithm is utilized to collaboratively optimize the robotic disassembly planning Disassembly planning methods. First, every single robotic disassembly Robotic disassembly workstation executes the disassembly Disassembly tasks assigned by using the space interference matrix and robotic Robotic workstation assignment method in the robotic disassembly line. Then, the optimization objectives of the collaborative optimization Collaborative optimization problem are described, and the analytic network process is utilized to assign weights to different objectives. After that, the improved discrete Bees algorithm is used to find the optimal Optimal solution, and case studies are carried out to verify the proposed method. In addition, simulations based on RoboDK under different scenarios are also conducted to show the effectiveness of the proposed method.","['Engineering', 'Robotics and Automation', 'Artificial Intelligence', 'Industrial and Production Engineering', 'Professional Computing', 'Robotics', 'Machine Learning']"
doi:10.1007/978-981-19-0448-6_8,en,Energy-Efficient Power Control for D2D Communications,OriginalPaper,"This chapter investigates the energy-efficient power control for device-to-device (D2D) communications. Section  8.1 introduces the motivation of developing energy-efficient power control schemes for D2D communications. Section  8.2 presents the system model, and Sect.  8.3 formulates the energy-efficient power control problem. Sections  8.4 and 8.5 derive the optimal and sub-optimal solutions, respectively. Section  8.6 presents the simulation results, and Sect.  8.7 concludes this chapter.","['Engineering', 'Wireless and Mobile Communication', 'Energy Systems']"
doi:10.1007/978-981-19-3998-3_49,en,An Improved Distributed Optimization Algorithm over Unbalanced Directed Graph,OriginalPaper,"This paper mainly discusses the common distributed optimization problem over unbalanced directed graph. Assumed that the local objective function of each agent is strongly convex and has a Lipschitz continuous gradient. An improved distributed algorithm is proposed by introducing a momentum term and different local step lengths. Then we prove that all agents would find the optimal value under our algorithm when the maximum step length and the momentum parameter satisfy a certain range and are positive. At last, we illustrate the effectiveness of the obtained results by a numerical experiment.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-981-19-6168-7_4,en,Error-Similarity-Based Positioning Error Compensation,OriginalPaper,"The kinematic error model is described in Chap. 2 , and the robot error compensation using the kinematic calibration is conducted in Chap. 3 .","['Engineering', 'Control, Robotics, Mechatronics', 'Robotics and Automation', 'Applied and Technical Physics', 'Industrial and Production Engineering', 'Measurement Science and Instrumentation']"
doi:10.1007/978-981-19-3951-8_16,en,Low Bandwidth and Side-Channeling Resilient Algorithm for Pervasive Computing Systems,OriginalPaper,"Wearable devices are pervasive computing devices that have been heavily deployed in wireless body area networks for remote patient monitoring. These networks convey sensitive and private data items that are exchanged between the sensors and medical servers over public channels. Some of the transmitted data include heart rate, blood oxygen, body temperature, blood pressure, electromyogram and electrocardiogram. Upon receiving these signals, the medical staff or actuators take some appropriate actions, such as drug injections. Since public channels are deployed during signal transfers, attackers can perform malicious activities to the transmitted data, which may lead to erroneous responses from the medical staff. As such, it is critical that strong security and privacy protection be implemented during these transfers. Although many security protocols have been presented in literature based on methods such as digital signatures, advanced encryption standards and elliptic curve cryptography, their deployment in wireless body area networks is detrimental due to their high computational complexities. As such, the design of an efficient algorithm that offers trust, security and privacy provisioning in these networks is still an open challenge. In this paper, a wireless body area network-based algorithm is developed based on symmetric key cryptography and elliptic curve point multiplications. The security analysis shows that this scheme is resilient against power analysis-based side-channeling attacks. In addition, it offers mutual authentication, anonymity, backward and forward key secrecy and is robust against impersonation and packet replays among other attack vectors. Moreover, performance evaluation shows that it has the lowest computation costs and relatively lower bandwidth requirements compared with similar protocols.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-3-031-14537-7_20,en,Task Optimisation for a Modern Cloud Remanufacturing System Using the Bees Algorithm,OriginalPaper,"Remanufacturing Remanufacturing represents one of the most promising strategies for reaching economic and environmental sustainability Sustainability goals. The implementation of cloud technologies in the classical remanufacturing Remanufacturing process provides an opportunity to define a novel approach called cloud Cloud remanufacturing Remanufacturing . Referring to this context, this chapter proposes the application of the Bees Algorithm (BA) for task assignation optimisation in the cloud remanufacturing Remanufacturing context. Furthermore, a full factorial plan of experiments is proposed to evaluate the influence of different BA parameters on the solutions.","['Engineering', 'Robotics and Automation', 'Artificial Intelligence', 'Industrial and Production Engineering', 'Professional Computing', 'Robotics', 'Machine Learning']"
doi:10.1007/978-981-19-2764-5_8,en,LFC of a Deregulated Power System Using Opposition Based Novel Arithmetic Optimization Algorithm Based Fraction Order Cascade Controller,OriginalPaper,"Several changes have occurred in the electrical power system during the previous decade, owing to continually growing load demand, quick diminution of fossil fuels, rapid industrialization, and newly implemented electrical-deregulation policies. Several reviews of literature on the topic of Load Frequency regulation (LFC), which copes with varied and modern controller techniques for the effective functioning of the power system, have been produced in the last few years. This research article discusses the Novel utilization of opposition-based Airhmetic Optimization Algorithm (OAOA) for twin areas, multiple-source of linked power system considering Thermal and Hydro in one zone and Thermal and Gas in another zone. For a practical approach, non-linear constraints such as boiler agitation (BD) effects, Time-delay, and generation-rate-constraint (GRC) have been included for each unit. A Novel cascade combination of 2-Degree-of Freedom PI controller (2DOF-PI) and Fraction order Proportional-derivative controller considering filter (FOPDN) is used as a proposed controller in the scheme. The gain parameters of the (2DOF-PI) with FOPDN controller have been improved by the opposition-based Arithmetic Optimization Algorithm (OAOA). Later, the supremacy of the suggested algorithm is verified among the other well-known meta-heuristic approaches like particle-swarm-optimization (PSO), Wild-horse-optimization (WHO), and Artificial-bee-colony (ABC) by evaluating under the same test conditions. To ensure the efficiency of the prospective work the progressive response of the suggested controller to load interuption is correlated to the schematics of current controllers.","['Energy', 'Energy Systems', 'Artificial Intelligence', 'Machine Learning', 'Cyber-physical systems, IoT', 'Professional Computing', 'Power Electronics, Electrical Machines and Networks']"
doi:10.1007/978-3-031-07707-4_23,en,The Effects of Knowledge Extraction Approaches on Cryptanalysis Studies and Analysis of the Success of Chaos-Based Countermeasures,OriginalPaper,"Each new approach and scientific progress provides many advantages and innovations from theory to practice yet, its disadvantages should be evaluated comprehensively from different perspectives. In this study, the effects of knowledge extraction approaches on the cryptanalysis process have been evaluated. It is known that the secret key of the encryption algorithm can be obtained by using knowledge extraction approaches, especially with application oriented attacks such as side channel analysis. It is known that chaotic masks can be used as a countermeasure to prevent the success of these attacks. In this study, side-channel analyzes of the chaos-based substitution box structures that have been proposed in recent years have been carried out. The side channel analysis results of the existing studies in the literature have been carried out for the first time in this study. The results obtained showed that the approaches in the field of knowledge extraction should be handled more comprehensively in the cryptanalysis processes, and also pointed out that a new evaluation criterion should be analyzed for future studies for chaos-based design studies.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Computational Mathematics and Numerical Analysis']"
doi:10.1007/978-3-031-16078-3_3,en,A Self-learning Musical Tool to Support the Educational Activity,OriginalPaper,"Computer-assisted musical composition (for the generation of a melody, accompaniment or rhythm) is a topic that has stimulated multiple research projects. However, few of these projects take into account the didactic aspect by paying the right attention to students with Specific Learning Disorders (such as dyslexic students). Several previous works have proposed methods for harmonizing a melody, that is, for creating a succession of chords as an accompaniment to a melody. This paper illustrates a model for the harmonization of music bassline based on a machine learning approach. This model has been designed to support (dyslexic and non-dyslexic) students in studying Theory, Analysis and Composition. It allows students to harmonize a music bassline, giving them advices in case of mistakes in the concatenation of the chords. Future improvements of the method are discussed briefly at the end of the paper.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3998-3_156,en,Cooperative Optimization Method of UAV Swarm for Multi-objective High-Precision Location,OriginalPaper,"In the field of electromagnetic radiation source location, using UAVs to locate the radiation source target has become a new location method. At present, the UAV swarm cooperative optimization method for high-precision location has some challenges, such as insufficient ability of multi-objective high-precision location, poor timeliness and so on. To solve these problems, this paper proposes a cooperative optimization method of UAV swarm for multi-objective location. Firstly, the multi-objective joint location accuracy is derived, which is taken as the objective function of swarm cooperative optimization. Secondly, in order to allocate multiple UAVs to multiple targets efficiently, the initialization strategy based on target isolation and the random allocation method of UAV based on probability are proposed. Finally, by combining the above improved strategies, an optimization method of UAV swarm cooperative location is proposed. Through the analysis of experimental results, the cooperative optimization method in this paper has obvious advantages in global optimization and convergence ability, which can improve the joint location accuracy and optimization speed.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-3-031-14615-2_80,en,A Modified Accelerated Particle Swarm Optimization to Solve Reliability Problems Related to Production Systems,OriginalPaper,"This paper aims to present a new algorithm based on the class of swarm intelligence methods, named the Modified Accelerated Particle Swarm Optimization (MAPSO), for solving production reliability problems. The main objective is to ameliorate the reliability of the production systems based on the number and reliability of redundant components under some constraints such as the cost, volume, the budget, etc. This problem is considered as a constrained nonlinear mixed-integer problem that can be modelled with two different ways: A Redundancy Allocation Problem (RAP) or a Reliability-Redundancy Allocation Problem (RRAP). The developed MAPSO is based on a new updating procedure that allows to adjust the position of particles, without dealing with velocity. Position updating is based on a simple expression using two parameters that help to speed up the convergence of the suggested algorithm and prevent it from being trapped within the local optimum. To assess the efficacity of the suggested method, the MAPSO is applied to solve reliability problems related to a power distribution plant system. Based on a comparative study, simulation results demonstrate that solutions presented by the developed procedure are superior to those given by several methods in literature in term of solution quality and computation time.","['Engineering', 'Vibration, Dynamical Systems, Control', 'Control, Robotics, Mechatronics', 'Materials Engineering', 'Classical and Continuum Physics']"
doi:10.1007/978-981-19-3632-6_26,en,Hilbert R-tree Space Indexing Based on RHCA Clustering,OriginalPaper,"Spatial indexing is an important research in the field of spatial databases, and plays a key role in how to efficiently perform spatial data retrieval and query. In this paper, a new hierarchical clustering algorithm RHCA is proposed, and accordingly, a Hilbert R-tree index based on RHCA clustering algorithm is proposed. This clustering algorithm is improved in the split stage and merge stage of hierarchical clustering. First, the sample distribution is counted in the split stage to find the appropriate split position, and then the merge strategy with label detection is used in the merge stage, which reduces the amount of calculation and overcome the shortcomings of the traditional hierarchical clustering algorithm that the intermediate results cannot be traced back. The experimental results show that the Hilbert R-tree index based on the RHCA clustering algorithm reduces the execution and query time by about 25%, the coverage and overlap area is reduced by 27%, the performance of the index is greatly improved compared with Hilbert R-tree.","['Engineering', 'Cyber-physical systems, IoT', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing']"
doi:10.1007/978-3-031-19945-5_3,en,A Cluster Formation Algorithm for Fog Architectures Based on Mobility Parameters at a Geographically LAN Perspective,OriginalPaper,"As Internet of Things (IoT) becomes popular, different approaches to increasing its quality also so. One of the used paradigms to enhance these applications is fog computing. The fog intends to bring computational power closer to the users (edge). This paradigm is known to mitigate costs and energy consumption and also to benefit location-aware applications. As fog environments can cover small to medium areas, these can be used to increase location awareness. To make it possible, researchers have used cluster computing. However, in new scenarios, cluster formation can be a challenge since when manually set, geographical-location parameters can be biased. In this manner, this paper aimed to promote a cluster formation algorithm based on these geographical parameters. To evaluate our proposal, we compared our approach to the original using the standardized EUA dataset through iFogSim v2. The proposed algorithm was capable of creating clusters based on accepted node range and maximum nodes per cluster, operating similarly to the original dataset.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Computer Applications']"
doi:10.1007/978-981-19-3842-9_52,en,Research on Laster Positioning Algorithm of Unmanned Formula Racing Car,OriginalPaper,"In order to solve the positioning problem of unmanned formula racing cars, a real-time positioning algorithm based on the combination of LiDAR and Inertial Measurement Unit (Inertial Measurement Unit, IMU) is proposed. Firstly, the high-frequency IMU data were used to compensate the motion distortion of the laser point cloud. Secondly, the feature points were divided according to the smoothness features, and the target optimization function was constructed according to the corresponding registration of different feature points to solve the laser odometer. Then, the Normal Distribution Transform (Normal Distribution Transform, NDT) was used to construct the loop constraint. Finally, the graph optimization algorithm is used to solve the real-time position and pose of the racing car and construct the environment map. In this paper, the performance test is carried out based on the data collected from the self-developed unmanned formula racing platform. The test results show that the real-time positioning algorithm proposed in this paper meets the positioning accuracy requirements of college students’ formula race, and can meet the real-time requirements in the actual scene application, which has a certain theoretical reference and engineering application value.","['Engineering', 'Mechanical Engineering', 'Automotive Engineering', 'Transportation Technology and Traffic Engineering']"
doi:10.1007/978-981-19-5574-7_6,en,Process Modeling of Power Plant,OriginalPaper,"Electric power generation plays a vital role in social and economic development. Presently, coal-fired power generation is still dominating the power generation market worldwide.","['Engineering', 'Control, Robotics, Mechatronics', 'Energy Systems', 'Computational Intelligence']"
doi:10.1007/978-981-19-3632-6_55,en,Electric Automation Control System Based on Improved KMP Algorithm,OriginalPaper,"Electrical automation technology is a comprehensive technology that optimizes the production process through computers, information technology and control theory, and realizes the improvement of production efficiency. Hardware automation system and software system are the prerequisites for realizing electrical automation technology. In addition to the hardware part of this platform, electrical automation systems are also used in it. Man-machine interface refers to industrial control computers and operating screens. Touch screens are widely used devices in recent years. They have the characteristics of instant information interaction, easy operation, and high reliability, and are widely used in the field of industrial control. The advantage of this automatic control function is that it is separated from the traditional manual control pendulum, which greatly reduces the cost of supervision and improves the quality of supervision at the same time. From this perspective, the study of electrical automation control systems based on computer algorithms has certain practical significance. The purpose of this paper is to study the electrical automation control system based on the improved KMP algorithm. For electrical automation control systems, the kmp mode distribution algorithm is used on the basis of the bf mode distribution algorithm, and the kmp algorithm is further improved on the basis of the kmp mode distribution algorithm. In practical applications, the feasibility of the improved kmp algorithm is studied. The PID control model algorithm and the improved kmp algorithm control experiment verify the efficiency and practicability of the improved kmp calculation and transmission, and the experimental results are in line with expectations. The experimental results show that the improved algorithm proposed in this paper is based on the kmp algorithm, and the error does not exceed 0.1 in actual experiments compared with the experimental results of the standard control group, which proves that the algorithm is feasible in practical applications.","['Engineering', 'Cyber-physical systems, IoT', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing']"
doi:10.1007/978-981-19-5615-7_51,en,Prediction for Taxi-Hailing Demand—An Adaptive Multi-view Deep Learning Model,OriginalPaper,"The emergence of taxi requesting service have changed the situation of traditional taxis. Nowadays, it has gained great popularity all over the world. As more people use this service, some problems spring up gradually and the imbalance between supply and demand is one of the most serious ones. It is urgent for researchers to solve this problem because it affects greatly the service quality of taxi system. In summary, traditional papers involving the demand prediction of taxi-hailing are mainly divided into two directions. Some researchers tend to use regional attributes (e.g., land use variables) for spatial modeling and analysis (e.g., using geographically weighted regression, GWR) and then interpret the model. The others mainly depend on spatiotemporal correlation to predict the demand (e.g., autoregressive integrated moving average, ARIMA) and then focus on the improvement of prediction. Based on previous researches, this paper proposes an adaptive multi-view deep learning model which comprehensively integrates the focuses of previous studies. The framework of the model includes four views, namely feature views (including various features of zones such as the conditions of weather, transportation, land use and so on), semantic views (division of zones that functionally similar), spatial views (searching for adaptive spatial neighbors), temporal views (searching for adaptive time windows). By embedding these views into our model, the accuracy and extension of prediction are greatly improved. To evaluate the prediction performance of our model, it is respectively compared with models which use different algorithms or have different model frameworks. Validation based on large amounts of data shows the superiority of our proposed model.","['Engineering', 'Transportation Technology and Traffic Engineering', 'Computational Intelligence', 'Automotive Engineering', 'Energy Policy, Economics and Management', 'Mechanical Engineering']"
doi:10.1007/978-3-031-21333-5_37,en,Towards Recognition of Driver Drowsiness States by Using ECG Signals,OriginalPaper,"Drowsy driving is one of the leading causes of car accidents that can result in great loss and tragedy, which could be prevented with early warning. Recent work has used behavioral, physiological, and driving skill traits that are present during drowsiness, such as yawning, closed eyes, decreased heart rate, and sudden steering wheel movements. From these traits, features can be extracted to be used in machine learning (ML) models for the automatic detection of the state of drowsiness. On the other hand, the study of fatigue or sleepiness in real settings leads to risks by exposing test subjects to states of non-alertness. In the present work, it is proposed to use a combination of features extracted from physiological signals, captured with a wearable ECG sensor (Polar H10) during a simulated driving environment, for building and evaluating ML-based models in order to classify different levels of drowsiness. These levels were recorded by self-report using the Karolinska Sleepiness Scale. An accuracy of 76.5% was archived with kNN when classifying drowsiness in 2 levels and 70.5% using Random Forest when classifying drowsiness in 3 levels. The results obtained are promising despite the fact that only physiological type traits were processed.","['Engineering', 'Data Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3035-5_62,en,Identifying Genre of a Book from Its Summary Using Machine Learning Approach,OriginalPaper,"Categorical search and category-wise book recommendation are two common tasks for online booksellers. But for a machine to understand this category from a given text is still challenging work, where machine learning is a widely used tool at present. Though in the English language, with the availability of rich datasets and corpus, machine learning-based categorization and recommendation have reached a standard level, in the Bengali language, to reach the standard, still needs a long way to go. One key reason is the lack of availability of a rich Bengali dataset. The aim of this research was to make a dataset first for the book’s genre identification from its given summary and to explore which supervised classifier performed best on that dataset for classifying the genres. Before that, we performed several essential preprocessing steps essential to prepare our dataset fit for the algorithms. Six machine learning classifiers were applied to the dataset, and it was observed that Naive Bayes performed best with an accuracy of 68% followed by XGB with an accuracy of 67%.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Statistics, general']"
doi:10.1007/978-3-031-13714-3_12,en,Codes,OriginalPaper,This chapter gives utility codes used by various procedures presented in the book. It also gives some programs for testing many of the metaheuristics discussed in the book.,"['Business and Management', 'Operations Research/Decision Theory', 'Optimization', 'Computational Mathematics and Numerical Analysis', 'Algorithms', 'Computational Science and Engineering', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2535-1_9,en,Machine Learning Approaches in Smart Cities,OriginalPaper,"With the advent of urbanization, the introduction of smart cities is taking place at a rapid rate to enable the ever-growing population in the urban cities to give them a chance of having a good lifestyle. Smart cities aim to do so by using and adopting the modern concepts of technology. The objective of this research is to understand and unleash how the smart cities that are coming up depend on technological aspects like sensors and actuators so that large volumes of data can be both stored as well as utilized to extract information that could prove to be beneficial for the growth of the city. The study followed content and document reviews with a systematic literature review to arrive at the observation made. For conducting this study, secondary data has been taken into consideration where the database of reliable sources like EBSCO, Scopus, and Web of Science have been utilized. This study has shown that how the emergence of ML (Machine Learning) tools makes use of algorithms that help in providing personalized services as well as efficient resource management in smart cities.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16281-7_37,en,Optimization of Non-destructive Damage Detection of Hidden Damages in Fiber Metal Laminates Using X-ray Tomography and Machine Learning Algorithms,OriginalPaper,"Detection of hidden damages in Fibre Metal Laminates (FML) is a challenge. Damage detection, classification, and localization is a part of the lower levels of Structural Health Monitoring (SHM) and is critical for damage diagnosis. SHM is an extremely useful tool for ensuring integrity and safety, detecting the evolution. Early damage detection and understanding of damage creation can avoid situations that can be catastrophic. X-ray tomography is a powerful tool for research as well as damage diagnostics. But high-resolution tomography results in high measuring and computational times up to 10 h for one specimen. The paper presents an early method of accessing the sections of the FML for identifying internal damages using X-ray imaging by optimized and adaptive zooming and scanning using automatic Region-of-Interest extraction with Machine Learning methods. The generated knowledge and the image data collected would further accelerate the development in the field of autonomous SHM of the composite and hybrid structures like fibre metal laminates which would further reduce the safety risks and total time associated with structural integrity assessment. A comprehensive image-based data set is collected by means of X-ray CT images containing micro-scale damage mechanisms (fibre breakage, metal cracks etc.) and macro-scale damages like delaminations. Starting point is an image sets were measured with two different X-ray CT devices with a static parameter set (set in advance and a-priori) and posing many limitations and issues that make damage diagnostics difficult. The adaptive and iterative measuring process should increase the quality of the images and decrease the measuring time significantly.","['Engineering', 'Cyber-physical systems, IoT', 'Machine Learning', 'Robotics and Automation']"
doi:10.1007/978-3-031-15030-2_8,en,Differential Privacy: An Umbrella Review,OriginalPaper,"Privacy-preserving analysis of data refers to possibilities of using personal information from individuals in a completely anonymous fashion. In a statistical sense, this means that statistics and models derived and learned from data are insensitive to individual observations. Differential Privacy as defined by Cynthia Dwork in (Dwork 2006) has become a popular approach for ensuring privacy. In contrast to earlier definitions, Dwork defined differential privacy as a relative guarantee that nothing more could be learned from data whether an individual observation is included or excluded from the analysis. This was achieved by adding random noise that is bigger than the effect of a change due to the largest single participant. The approach was referred as 𝜖-differential privacy. Such an actionable definition gave more room for practitioners to define how, for example, machine learning algorithms can ensure differential privacy. In this paper, we present an umbrella review on differential privacy related studies based on a methodology proposed by Aromataris et al. (Int J Evidence-Based Healthcare 13(3):132–140, 2015).","['Computer Science', 'Artificial Intelligence', 'Privacy', 'Cryptology', 'Mobile and Network Security']"
doi:10.1007/978-981-19-0098-3_74,en,Image Matching Techniques: A Review,OriginalPaper,"The motive of this work is to distribute a review of both modern and classic area-based image matching algorithms. In the realm of machine vision, determining three-dimensional data from images is a critical issue (Joglekar and Gedam in Int J Emerg Technol Adv Eng 2(1), 2012, [1]). To match images and identification at the heart of computer, they play very significant role in our daily lives (Feature detection and extraction—MATLAB & Simulink, 2016, [2]). The motive is to behave the cameras like human eye work. In modern era, with cameras, people generate wide number of pictures, there is need to examine those pictures, which can be used for further research and to get useable results particularly for a problem given by user (Jayanthi and Indu in Int J Latest Trends Eng Technol 7:396–401, 2018, [3]). In this paper, we have described some points of which comparison for matching can be done, and along with, some different points of interest for matching are described.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Statistics, general', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-20601-6_28,en,A Survey of Concurrency Control Algorithms in Collaborative Applications,OriginalPaper,"Collaborative applications are becoming more prevalent for a variety of reasons, most important of which is the increased interest in remote work. In addition to adapting the business processes to a remote setting, designers of collaborative software have to decide on how their software can be used collaboratively. This paper discusses the two main technologies used to enable network-based real- or near-real-time collaborative software, namely Operational Transformation and Conflict-free Replicated Data Types. Recent developments in each technology are discussed, as well as a brief overview of their theoretical underpinnings.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-17746-0_18,en,"Meta-analysis of AI Research in Journalism: Challenges, Opportunities and Future Research Agenda for Arab Journalism",OriginalPaper,"The use of artificial intelligence tools in newsrooms is revolutionary and controversial as well. Despite the promising opportunities provided by AI to enhance digital journalism practice, it also raises several legal, professional, and ethical considerations. Research about AI in Arab media is a promising area of interest that increasingly attracts Arab scholars. However, there is a need for systematic and purposive growth in future research about AI and Arab media, that considers the socio-cultural and economic contexts of Arab countries and meets the priorities and needs of Arab media organizations. Accordingly, this paper provides researchers with an overview of the main challenges and debates in the field of AI and journalism studies. This study applies a systematic review of a sample of English and Arabic-written studies from 2014 to 2022 about the implications, challenges and considerations of using AI in newsrooms. Based on the analysis, the study proposed a future research agenda about AI and Arab journalism.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Business Information Systems']"
doi:10.1007/978-981-19-1142-2_10,en,Explainable Artificial Intelligence (XAI): Connecting Artificial Decision-Making and Human Trust in Autonomous Vehicles,OriginalPaper,"Automated navigation technology has established itself as an integral facet of intelligent transportation and smart city systems. Several international technological organizations have realized the immense potential of autonomous vehicular systems and are currently working towards their complete development for mainstream application. From deep learning algorithms for road object detection to intrusion detection systems for CAN bus monitoring, the functioning of a self-driving vehicle is powered by the simultaneous working of multiple inner vehicle module systems that perform proper vehicle navigation while ensuring the physical safety and digital privacy of the user. Transparency of the vehicle’s thought processes can assure the user of its credibility and reliability. This paper introduces explainable artificial intelligence, which aims to converge the decision-making processes of Autonomous Vehicle Systems (AVS). Here, the domain of Explainable AI (XAI) provides clear insights into the role of explainable AI in autonomous vehicles and increase human trust for AI based solutions in the same sector. This paper exhibits the trajectories of transportation advancements and the current scenario of the industry. A comparative quantitative and qualitative analysis is performed to compare the simulations of XAI and vehicular smart systems to showcase the significant developments achieved. Visual explanatory methods and an intrusion detection classifier were created as part of this research and achieved significant results over extant works.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Mobile and Network Security', 'Artificial Intelligence']"
doi:10.1007/978-3-031-12818-9_3,en,Modular Multilevel Converter Models and Simulation Approaches,OriginalPaper,"The electromagnetic transient simulation of modular multilevel converters ( mmc s) in high voltage direct current ( hvdc ) systems is a burdensome task due to their high number of nodes and semiconductor devices. To cope with this issue, scholars proposed over the years several mmc models that implement different trade-offs between simulation speed and accuracy. One of the common traits of these representations is that they simplify the model of the semiconductor devices inside the mmc . Other than providing a thorough review and comparison of the most popular mmc models in the literature, this book proposes a novel mmc simulation approach based on sub-circuit isomorphism. This approach, originally conceived to analyse modular electronic circuits such as random access memories, can be profitably exploited to simulate mmc s, since it exploits the common behaviour of structurally identical sub-modules inside them by clustering them together. As a result, the isomorphism-based approach allows performing detailed, yet efficient simulations of hvdc systems.","['Engineering', 'Circuits and Systems', 'Electronics and Microelectronics, Instrumentation', 'Energy Systems']"
doi:10.1007/978-3-031-07254-3_24,en,An SHM Data-Driven Methodology for the Remaining Useful Life Prognosis of Aeronautical Subcomponents,OriginalPaper,"Prognosis of the Remaining Useful Life (RUL) of a structure from Structural Health Monitoring data is the ultimate level in the SHM hierarchy. Reliable prognostics are key to a Condition Based Maintenance paradigm for aerospace systems and structures. In the present work, we propose a methodology for RUL prognosis of generic aeronautical elements i.e. single stringered composite panels subjected to compression/compression fatigue. Strain measurements are utilized in this direction via FBG sensors bonded to the stiffener feet. The strain data collected during the fatigue life are processed and used for the RUL prognosis. In order to accomplish this task, it is essential to produce Health Indicators (HIs) out of raw strain that can properly capture the degradation process. To create such HIs a new pre/post-processing technique is employed and a variety of different HIs are developed. The quality of the HIs can enhance the performance of the prognostic algorithms, hence a fusion methodology is proposed using genetic algorithms. The resulted fused HI is used for the RUL estimation of the SSCPs. Gaussian processes and Hidden Semi Markov Models are employed for RUL prognosis and their performance is compared. Despite the complexity the raw data we demonstrate the feasibility of successful RUL prognostics in a SHM-data driven approach.","['Engineering', 'Building Repair and Maintenance', 'Cyber-physical systems, IoT', 'Industrial and Production Engineering', 'Monitoring/Environmental Analysis', 'Analytical Chemistry']"
doi:10.1007/978-1-4842-8925-9_1,en,"Introduction to PyTorch, Tensors, and Tensor Operations",OriginalPaper,"PyTorch has been evolving as a larger framework for writing dynamic models. Because of this, it is very popular among data scientists and data engineers for deploying large-scale deep learning frameworks. This book provides a structure for experts in terms of handling activities while working on a practical data science problem. As evident from applications that we use in our day-to-day lives, there are layers of intelligence embedded with the product features. These features are enabled to provide a better experience and better services to the user.","['Computer Science', 'Python', 'Big Data', 'Big Data/Analytics']"
doi:10.1007/978-981-19-5331-6_9,en,White Blood Cells Classification Using Deep Learning Technique,OriginalPaper,"Collaboration with technology is the next revolution in health care, and they must adapt evolving healthcare technologies to be significant in the next years. Digitization in medicine and health care might help transform unsustainable healthcare systems into sustainable ones, enhance interactions between medical specialists and people, and provide inexpensive, speedier, and more effective illness remedies. The objective of this study is to devise a system that distinguishes the types of white blood cells using precise and programmed analysis, which has been considered an effective way of classifying the 4 different types of WBCs—eosinophil, lymphocyte, monocyte, neutrophil. Convolutional neural network (CNN) models had been used for detection and classification, providing an efficient solution with a good accuracy rate when compared to the existing system. The training was done using a publicly available dataset, and visualization methods were used to map the model accuracy and loss. It was discovered that neural networks can record the colors, and textures of lesions that are specific to their type, which resembles human decision-making. The final model is deployed using Django framework for classification, where the image is uploaded and the application displays the result.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-5908-0_12,en,Theory for Invisible Thermal Sensors: Optimization Scheme,OriginalPaper,"Metamaterial-based devices have been extensively explored for their intriguing functions, such as cloaking, concentrating, rotating, and sensing. However, they are usually achieved by employing metamaterials with extreme parameters, critically restricting engineering preparation. In this chapter, we propose an optimization model with particle swarm algorithms to simplify parametric designs to realize bilayer thermal sensors composed of bulk isotropic materials (circular structure). For this purpose, the fitness function is defined to evaluate the difference between the actual and expected temperatures. By choosing suitable materials for different regions and treating the sensor, inner shell, and outer shell radii as design variables, we finally minimize the fitness function via particle swarm optimization. The designed scheme is easy to implement in applications and shows excellent performances in detective accuracy and thermal invisibility, which are confirmed by finite-element simulations and laboratory experiments. The optimization model can also be flexibly extended to a square case. This method can calculate numerical solutions for difficult analytical theories (circular structure) and optimal solutions for problems without analytical theories (such as square structure), providing new inspiration for simplifying the design of metamaterials in various communities.","['Physics', 'Optics, Lasers, Photonics, Optical Devices', 'Thermodynamics', 'Optical and Electronic Materials', 'Materials Science, general', 'Theoretical, Mathematical and Computational Physics', 'Condensed Matter Physics']"
doi:10.1007/978-981-19-1412-6_23,en,"Software Testability (Its Benefits, Limitations, and Facilitation)",OriginalPaper,"Software testing refers to a testability method which has test support to improve and predict the software testability. Various types of method have been adopted by researchers and practitioners to improve the testability mechanism in software testing domain. This paper main objective is to reviewing the body of knowledge in this domain and provides a comprehensive overview to new readers and researchers about the software testability. This review selected eighteen papers as evidence to discuss the benefits, limitations, and proposed methods in the domain of software testing. We believe that this short review will give a quick overview to new researchers and readers in the field of software testability.","['Engineering', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security']"
doi:10.1007/978-981-19-2188-9_33,en,"Global Governance of Artificial Intelligence: Ethical, Legal Challenges and Changes in Economy and Business",OriginalPaper,"Artificial intelligence (AI) and global governance are an inclusive platform to discover the policy challenges worldwide augmented by artificial intelligence. The platform has three predominant subjects: AI and the global order, governance of AI, insights on the platform consider for mapping of AI futures. AI has great impact in revolution of geopolitical order and the reaction of multifaceted organizations which minimize AI risks and unpremeditated significances and its social aids are maximized through governance structures. It focusses on setups, collaborations, and tensions between different actors responsible for plan, deployment, support and governance of AI. AI improves the benefit for human well-being, productivity, social good, and safety with substantial risks for workers, developers, firms, and governments. The actors and organization begin to realize the ethical, legal, and regulatory challenges associated with AI.","['Engineering', 'Industrial and Production Engineering', 'Mechatronics', 'Engineering Thermodynamics, Heat and Mass Transfer', 'Energy Storage', 'Materials Engineering']"
doi:10.1007/978-3-031-19032-2_47,en,Multilevel Separation Pipeline for Similar Structure Data,OriginalPaper,"Text classification model based on multilevel filtering is considered. The features of social network messages that have to be taken into account for language processing are determined. Based on a large dataset of real data, it is shown that in case of high proximity between relevant and irrelevant messages widely spread methods of machine learning, ANN and NLP show unsatisfactory results. The idea of preclassification using context data structuring is proposed. The solution proposed in the article involves a combination of traditional methods, context-structuring and clustering in subsets of records. Their joint use makes it possible both to noticeably improve the quality of classification and to make the assessment of the quality of classification more controlled. We demonstrated that the combined use of a large number of wide filters provides, on average, better classification quality than a smaller number of narrower ones. The proposed solution has been tested on data from social networks, but can be effectively applied to other text data with similar features.","['Engineering', 'Computational Intelligence', 'Machine Learning', 'Neurosciences']"
doi:10.1007/978-3-031-17040-9_6,en,"Right to Life, Liberty and Security of Persons",OriginalPaper,"Artificial intelligence Artificial intelligence (AI) can Right to life, liberty and security of person support individuals Individual ’ enjoyment of life Life , liberty Liberty and security Security , but it can also have adverse effects on them in a variety of ways. This chapter covers three cases affecting human life Life , liberty and security: one in transportation Transport (self-driving cars Self-driving cars ), one in the home (smart security Security systems) and one in healthcare Healthcare services (adversarial attacks Adversarial attack ). The chapter discusses ethical questions and three potential solutions to address AI Artificial intelligence human rights Human rights issues related to life Life , liberty and security Security of persons: defining and strengthening liability Liability regimes, implementing quality management Quality management systems and adversarial robustness Adversarial robustness . AI developers Developers , deployers and users Users must respect the sanctity of human life Life and embed, value and respect this principle in the design, development and use of their products and/or services. Critically, AI Artificial intelligence systems should not be programmed to kill or injure humans.","['Philosophy', 'Engineering Ethics', 'Artificial Intelligence', 'Philosophy of Technology', 'Computers and Society']"
doi:10.1007/978-3-031-16868-0_1,en,Evolutionary Computation,OriginalPaper,"EC is a class of nature-inspired algorithms that maintains a population of candidate solutions (individuals) and evolves toward the best answer(s). It has been frequently used to solve difficult real-world optimization problems since it evolves numerous solutions at the same time, which contribute to the notable characteristic of EC as being frequently insensitiveness to local minimal.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4182-5_9,en,Different Skin Tone Segmentation from an Image Using KNN for Sign Language Recognition,OriginalPaper,"Color as a feature has advantages like it is invariant to scaling, rotation, and partial occlusion changes. Skin color segmentation has many applications like sign language recognition, hand and face gesture recognition, biometric applications, face detection, and analysis of facial expressions. Due to the importance of an effective skin segmentation method, the Machine Learning (ML)-based skin segmentation approaches are studied in this paper. The objective of the work is to segment the different human skin tones for sign language recognition. The skin segmentation dataset from the UCI machine learning repository is used to evaluate the effect of various supervised learning algorithms. Despite the comparison criteria, KNN is found to be the desirable classifier. There are two color spaces RGB and HSV, considered in experiments, and the HSV representation gives better performance in the segmentation of various skin tones than the RGB color space.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Computer Systems Organization and Communication Networks', 'Statistics, general']"
doi:10.1007/978-3-031-15191-0_12,en,"Big Data and Machine Learning in Healthcare: Concepts, Technologies, and Opportunities",OriginalPaper,"Recently, big data and machine learning have become increasingly important in various environments, including health care, industry, government, scientific research, business organizations, social networking, and natural resource management. In particular, they apply to the field of health care and make it possible to process and analyze many data that humans or traditional computer tools cannot do simultaneously. Big data and machine learning are having a significant influence on the health care business, and their analyses may help the whole industry. The opportunities they will create will serve as a springboard for the future of the health care business. This will lead to a paradigm shift, shifting the industry's focus from disease-based diagnosis to patient-based diagnosis. This article will discuss big data technology, including its definition, characteristics, technology, relationship, and influence on the healthcare industry. The concept of machine learning technology, as well as its influence on healthcare, will be also explored.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Mobile and Network Security']"
doi:10.1007/978-981-19-7622-3_15,en,"Future Intelligent Vehicles: Open Issues, Critical Challenges, and Research Opportunities",OriginalPaper,"Intelligent Vehicles (IVs) have become a priority for research because of their significant benefits in enhancing road safety and operational efficiency. Intelligent Vehicles have made enormous progress over the years, but they still face substantial obstacles in gaining widespread acceptance. The authors recommend, in this regard, that Intelligent Vehicles research be advanced anywhere, gradually addressing existing issues. To begin with, the most basic necessity of Intelligent Vehicles is security. The authors outline the essential technologies and problems of Intelligent Vehicles’. It includes fundamental architecture, existing attacks, and defense tactics for information security. Second, comfort is primarily concerned with people’s subjective sensations. Visual perception is the primary, which humans integrate data from the traffic environment. Visual sensors can gather the majority of the information needed to operate a vehicle. Necessitating advanced machine vision and picture interpretation approaches for visual sensing. The functional spectrum covered ranges from sophisticated automated driving to self-driving vehicles. This chapter follows the order of image processing pipelines, which consolidate the rich information and a large quantity of data in video sequences one by one. Specific items in a traffic scene are associated using recognition and classification systems. Although several Intelligent Vehicle prototypes have been constructed to demonstrate the notion of automated vehicles and the viability of enhancing traffic efficiency, there is still a considerable gap until high-level IVs can be mass-produced. The goal of this research is to provide an overview of present technologies. It will be practical in future Intelligent Vehicles, their current condition, and prospects. Reviewing all linked works and predicting their future perspectives is a strenuous endeavor, especially in such a vast and multi-disciplinary field of study.","['Engineering', 'Communications Engineering, Networks', 'Automotive Engineering', 'Transportation Technology and Traffic Engineering', 'Computer Applications']"
doi:10.1007/978-3-031-18326-3_11,en,Implementation of a Novel Fully Convolutional Network Approach to Detect and Classify Cyber-Attacks on IoT Devices in Smart Manufacturing Systems,OriginalPaper,"In recent years, Internet of things (IoT) devices have been widely implemented and industrially improved in manufacturing settings to monitor, collect, analyze, and deliver data. Nevertheless, this evolution has increased the risk of cyberattacks, significantly. Consequently, developing effective intrusion detection systems based on deep learning algorithms has proven to become a dependable intelligence tool to protect Industrial IoT devices against cyber-attacks. In the current study, for the first time, two different classifications and detection long short-term memory (LSTM) architectures were fine-tuned and implemented to investigate cyber-security enhancement on a benchmark Industrial IoT dataset (BoT-IoT) which takes advantage of several deep learning algorithms. Furthermore, the combinations of LSTM with FCN and CNN demonstrated how these two models can be used to accurately detect cyber security threats. A detailed analysis of the performance of the proposed models is provided. Augmenting the LSTM with FCN achieves state-of-the-art performance in detecting cybersecurity threats.","['Engineering', 'Robotics and Automation', 'Industrial Chemistry/Chemical Engineering', 'Computer-Aided Engineering (CAD, CAE) and Design']"
doi:10.1007/978-981-19-1669-4_13,en,Intelligent Traffic Monitoring Systems Using Deep Learning Algorithms,OriginalPaper,"We are proposing an intelligent traffic monitoring system with deep learning (DL) algorithms. Monitoring videos contribute a great deal to unstructured data. Surveillance cameras are deployed everywhere where safety is important. Manual monitoring seems long and tedious. Security can be defined in various contexts such as theft identification, detection of violence, explosion chances. This paper includes an extensive learning method, starting with detecting vehicles and recognizing objects in crowds. The main focus is about image analysis, detecting the number of vehicles involved and the happens are the main focus of this use of deep learning model. Effective time processing is also considered as an important topic to be further examined in this field. The suggested ITM system is implemented, and challenges problems such as parallel training and model sync are addressed. Task and model-level parallel training methods are proposed to speed up the analysis even more. We offer low latency and precise solutions for image frame analysis. Traffic monitoring and analysis can be handled efficiently by the proposed DL model. We implement deep learning model using a neural network algorithms in deep learning.","['Engineering', 'Signal, Image and Speech Processing', 'Circuits and Systems', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2821-5_14,en,Classification of Sentiment Reviews for Indian Railways Using Machine Learning Methods,OriginalPaper,"AI provides the concept of machine learning that helps to automate the decision-making process by analyzing data inputs. It trains machines by providing it sample data and thus makes the system intelligent that is helpful for real-world AI applications. Machine learning algorithms are applied to such social feedback data to excerpt useful information that confers a competitive edge to several enterprises. There are enough machine learning technologies in the existing literature on sentiment analysis. However, it still needs optimizations for a better decision making process for several enterprises. In this paper, we proposed a scheme for Indian Railways for determining sentiments from Facebook. This is a more specific scheme that clouts business intelligence over different classifiers, viz. SVM, NB, RF, and decision tree, K-NN. The proposed scheme is provided with various parameters like F -measure, recall, precision, logarithmic loss, and accuracy. The first section of this paper provides the preface of sentiment analysis, and the next section presents the related work and motivation for sentiment analysis then methodology adopted for better decision making through machine learning to bring out in depth knowledge for future marketing game plans; it then discussed the experimental results, and finally, the paper encapsulates the conclusion and future scope in the area of sentiment analysis.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-3-031-12807-3_5,en,Evaluation Measures and Applications for Explainable AI,OriginalPaper,"Machine learning advances, particularly deep learning, have enabled us to design models that excel at increasingly complicated tasks. Because of the growing size and complexity of these models, it’s becoming more difficult to grasp how they arrive at their forecasts and when they go incorrect or even worse. Now, think of a situation in which we humans could open these black-box learning models and translate the content into a human-understandable format. This is known as Explainable Artificial Intelligence and there has been a lot of research in this field over the last few years mainly focusing on how to explain different types of models. The advancement of this research, raised a very important query: “Why does a model need to be explained?” So, the most accurate answer to this question is “TRUST”. TRUST that the models are making the correct decisions over the correct assumptions. TRUST that we can tell what happened when a model fails. TRUST that we can do on a model implemented on a large scale that the predictions are made in line with expectations. It’s hard to trust a system that’s not transparent about its internal processes. This paper discusses the evaluation measures and application areas of XAI. Some XAI-related concepts were also mentioned.","['Engineering', 'Computational Intelligence', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-3-031-19067-4_7,en,Quantized and Sparsified Distributed SGD,OriginalPaper,"The communication delay in sending and receiving gradients or model updates between the worker nodes and the parameter server can be significantly, especially in networks with limited bandwidth and high latency on the communication links.","['Mathematics', 'Algorithms', 'Machine Learning', 'Algorithm Analysis and Problem Complexity', 'Artificial Intelligence', 'Probability Theory and Stochastic Processes', 'Computer Science, general']"
doi:10.1007/978-981-19-3951-8_18,en,Sentiment Analysis of Emotion Detection Using Natural Language Processing,OriginalPaper,"(NLP) is an acronym for natural language processing. It refers to the branch of computer science—and more specifically, the branch of artificial intelligence concerned with giving computers the ability to understand the text and spoken words in the similar way human beings can do. Emotion detection (ED) is a sentiment analysis branch dedicated to emotional extraction and analysis. Speech, facial expressions, and body language may determine human emotions efficiently. Emotion detection is an emerging field of research in sentiment analysis for effective interaction between humans and computers. Emotion detection and text recognition is a recent study subject that is strongly connected with sentiment analysis. Positive, neutral, or negative sensations are identified in a text, whereas the objective of the emotional analysis is to discover and recognize different kinds of feelings through the use of words such as wrath, disgust, fear, happiness, sorrow, and surprise. A multitude of research in the field of text mining and analysis is being conducted due to the convenience of data acquisition and the enormous benefits offered by it. This article examines the concept of emotion detection (ED) from text, image and outlines the primary approaches taken in the construction of text and image-based emotion detection (ED) systems by researchers. This article further discusses about how we are going to use sentiment analysis in emotion detection to analyze what exactly is the intent of the sender toward the receiver, how we are going to apply emotion detection (ED) to bifurcate the various emotions of the sender. This research paper proposes the discussion related to the handouts, findings, datasets used, and the combined outcome obtained after analyzing the dataset. This research is based on two (ED) emotion detection techniques: I) Text based (ED) II) Image based (ED). Researcher aims to analyze a plain text and images on any platform, be it reviews, comments or image on a blog post or social media applications, etc. It further focuses on detecting the emotion of the sender or receiver by using sentiment analysis. ( Sentiment Analysis: The Go-To Guide monkeylearn.com), Sentiment Analysis.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-981-19-6347-6_14,en,A Tool for the Implementation of an Educational Data Mining Model Applied to Universities,OriginalPaper,"This work proposes a tool for the implementation of an educational data mining model that applies automated machine learning and machine learning interpretability. Starting from the selection between different types of educational problems, the tool: allows semi-automatically building the data set, obtaining an optimized machine learning model using automated machine learning and enabling the explanation of results with machine learning interpretability methods. The proposal allows university institutions to draw conclusions on complex problems, requiring a minimum number of experts in data science and providing a framework for both end users and legal entities to inform themselves about results.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Health Informatics', 'Statistics, general']"
doi:10.1007/978-981-19-1610-6_42,en,A Low-Cost and Energy Autonomous IoT Framework for Environmental Monitoring,OriginalPaper,"The emergence of IoT devices that support sensor technology has gain much attention for their integration into smart city applications to improve citizens’ quality of life. In industrial territories, people that suffer from chronic respiratory diseases, e.g., chronic obstructive pulmonary disease, asthma, occupational lung diseases and pulmonary hypertension require special care, targeted information and efficient treatment, when the environment deteriorates their condition. This article presents the design of an IoT framework that wirelessly connects devices of low-cost, low-power consumption and integrates multi-sensor measurement capabilities (CO 2 concentration, humidity, temperature, particulate matters concentrations) with an open-source IoT platform aiming to alert the aforementioned population, when the combination of aerial pollution and weather conditions severe impact their daily activities. The energy autonomy of the IoT devices that are connected via wireless sensor network is explored and utilized. Finally, we evaluate the functionality and the accuracy of the low-cost sensors and demonstrate how proper filtering can improve their performance and mitigate problems stemming from outage times. For the latter, we have evaluate the effectiveness of forecasting algorithms like ARIMAX, LSTM and PROPHET on the measurement data.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-0095-2_74,en,Smart Classroom: A Step Toward Digitization,OriginalPaper,"The word SMART has already been implemented on a large scale in different fields from smart home to smart industry. Smart classroom service, one of the prominent technologies in the Internet of Things era, will change classrooms into being more intelligent, interconnected, and remotely controllable. The existing manual attendance system kills a tremendous amount of time for both the faculties and the students. Proxy attendance is also a huge challenge. There is a need for digitization of course materials for allowing access to it anytime from anywhere. Considerable amounts of energy can also be saved by switching off the smart board when not in use. Our proposed system aims to create an advancement in education systems by face detection and recognition-based attendance system, speech-to-text transcription for digital course material, and to save energy by automatically switching off the smart board when not in use.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Systems and Data Security', 'Artificial Intelligence', 'Computational Intelligence']"
doi:10.1007/978-981-19-2468-2_14,en,Biomedical Signal Processing: ECG Signal Analysis Using Machine Learning in MATLAB,OriginalPaper,"An arrhythmia is an abnormality in the heart rhythm or heartbeat pattern. ECG beats can be classified into different arrhythmias beat types (bigeminy, trigeminy, ventricular tachycardia (VT)). Early and accurate detection of arrhythmia types is important in detecting heart diseases and choosing appropriate treatment for a patient. We have used MIT-BIH arrhythmia database for data collection and prepared different data sets. Features, such as amplitude, RR interval, heart rate (Speed), gender, age, are used for the analysis. In classification learner application, the extracted features are used as inputs to different classifiers: support vector machines (SVM) and Naïve Bayes. Some other techniques that also have been employed for arrhythmia classification are decision trees and ensemble learning. Results show high classification accuracy of over 99.3% with either of these classifiers. The performance comparison of these classifiers is carried out using accuracy. Each classifier can show the confusion matrix, which summarizes the accuracy for each true label class.","['Engineering', 'Electronics and Microelectronics, Instrumentation', 'Quantum Physics', 'Measurement Science and Instrumentation']"
doi:10.1007/978-1-0716-2617-7_19,en,A Machine Learning-Based Approach Using Multi-omics Data to Predict Metabolic Pathways,OriginalPaper,The integrative method approaches are continuously evolving to provide accurate insights from the data that is received through experimentation on various biological systems. Multi-omics data can be integrated with predictive machine learning algorithms in order to provide results with high accuracy. This protocol chapter defines the steps required for the ML-multi-omics integration methods that are applied on biological datasets for its analysis and the visual interpretation of the results thus obtained.,"['Life Sciences', 'Bioinformatics']"
doi:10.1007/978-3-031-20601-6_7,en,MOOC Video Classification Using Natural Language Processing and Machine Learning Model,OriginalPaper,"MOOC opens up the doors for universal access to education remotely and serves as a constructive approach to acquire formal education informally by negating the traditional practices. In recent years, the number of MOOC video resources has increased exponentially. Therefore, the need is a fully automated system that would be proficient enough to store, analyze and manage such an immensity of videos while sustaining the quality in response. An automatic classification/prediction of videos is a challenging and complex aspect, although supervised machine learning can effectively achieve this task in an effective way. Many applications use text classification to categorize documents like, e.g. spam filtering, email routing, sentiment analysis, etc. In this study, we present a clever and adaptive technique for autonomous classification of MOOC videos transcription using natural language processing and machine learning model. Our approach can predict the category of a targeted video; the data mining algorithms such as SVM, Random Forest, and Naive Bayesian will be engaged to organize the MOOC videos. Experiments reveal that our approach outperformed other approaches in the field of transcription classification and supervised learning.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3679-1_12,en,Machine Learning and Deep Learning-Based Detection and Analysis of COVID-19 in Chest X-Ray Images,OriginalPaper,"Machine learning (ML) is a cutting-edge method with numerous applications in prediction and classification. This technology should be used to identify high-risk patients, their death rates and other irregularities in the COVID-19 pandemic (Taresh et al. in Int J Biomed Imaging, 2021 [ 1 ]). ML can be used to learn more about the virus’s nature and to foresee potential problems. With the goal in mind to help the healthcare sector, we can definitely leverage the advancement of technology (Chowdhury et al. in IEEE Access 8:132665–132676, 2020 [ 2 ]). This paper uses the COVID-19 dataset available on Kaggle. Various machine learning techniques are used to weigh the risk of COVID-19 disease in a patient in the proposed work. VGG19, MobileNetV2, DenseNet201, CapsNet201, COVID-Net, CoroNet and VGG16 are tested for classifying the images of normal human lungs versus lungs affected by viral pneumonia due to COVID-19. The performance of various machine learning algorithms is analysed, and it was determined that VGG16 algorithm achieved the best accuracy (97%) in tests.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2538-2_2,en,Survey of Surveillance of Suspicious Behavior from CCTV Video Recording,OriginalPaper,"Many of crimes that are executed through online-mode are un-identified. Currently, most of crimes are explicitly executed in front of surveillance cameras which are implicitly recorded through CCTV cameras. The surveillance systems recording failed to catch those culprits from recorded videos spontaneously. No doubt, the strategies were developed where the culprit’s photos are captured and criminal department start hunting for those culprits for days, months or years. Unfortunately, in most of cases, searching for culprits is prolonged for short span of time and later the hunting task may be stopped or closed, due to many reasons such as delay in searching process or permission restrictions or insufficient proofs or change of detective officers. Innumerable works exists in the market that monitors the suspicious behavior analysis of persons, but fails to catch them on the spot at the offence location. To resolve this critical issue, we need to make use of these recorded stored videos for catching the culprits on the spot at run-time by implementing an alerting strategy via an automated alarming system at run-time during the crime scenario itself. This survey emphasizes on various video surveillance systems that were developed earlier for catching the culprits. Many of the state-of-art systems lack the ability to surveillance such suspicious videos at run-time. Many of the existing surveillance systems fail to generate an alert or alarms during the execution of crime which are video recorded implicitly.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory', 'Mobile and Network Security']"
doi:10.1007/978-3-031-15160-6_11,en,Structural Health Monitoring in Cognitive Buildings,OriginalPaper,"Structural health monitoring (SHM), together with condition monitoring (CM), nondestructive evaluation (NDE), statistical process control (SPC), and damage prognosis (DP), through the most recent techniques of survey and data processing, allows to identify, evaluate, and monitor with ever-greater clarity the structural characteristics and the level of damage of any building and, therefore, to predict its trend over time. The use of traditional and experimental sensor networks and the processing of the data obtained from them allow to identify anomalies in the behavior of structures in operation, as well as to implement early warning systems. The use of accelerometric sensors is helpful for identifying the representative parameters of the structural behavior; the measurements of the displacements, on the other hand, allow a quick estimate of the magnitude strictly correlated to any damage suffered by the structure during a seismic event or a failure. In this work we try to reach the last three steps of the hierarchical structures proposed by Ritter, which are remembered to be damage location, damage assessment, and prediction. To obtain these levels, it is necessary to combine all the analyzes of the simple SHM that leads to the sending of an alarm, to a cognitive capacity of the building, also achieved with the use of artificial intelligence. In particular, the connection of SHM with AI and with building information modeling (BIM) can make the system cognitive, making it capable of managing (e.g., ensure, predict, assess) the healthiness of a building. The article also presents a case study to highlight how the proposed methodology is applicable to concrete cases.","['Engineering', 'Cyber-physical systems, IoT', 'Communications Engineering, Networks', 'Computer Applications']"
doi:10.1007/978-981-19-2225-1_37,en,Facial Expression Recognition Using Hyper-Complex Wavelet Scattering and Machine Learning Techniques,OriginalPaper,"Human emotion recognition is an active research topic in analysing the emotional state of humans over the past few decades. It is still a challenging task in artificial intelligence and human–computer interaction due to its high intra-class variation. Facial emotion analysis achieved more appreciation in academic and commercial potential challenges mainly in the field of behaviour prediction and recommendation systems. This paper proposes a novel scattering approach for recognizing facial dynamics using image sequences. Initially, we extract the temporal information from the facial frame by applying a saliency map and hyper-complex Fourier transform (HFT). Later the extracted high-level features are fed to the scattering transform method and machine learning algorithms to classify the seven emotions from the MUG dataset. The performance of proposed wavelet scattering network was evaluated on four different machine learning algorithms and achieved a high rate of recognition accuracy in all classes. In the experimental results, K-NN exhibits the proposed architecture’s effectiveness with an accuracy rate of 97% for the MUG dataset, 95.7% for SVM, 93.7% for decision tree and 91.2% naive Bayes, respectively.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Statistics, general', 'Mobile and Network Security']"
doi:10.1007/978-981-19-1610-6_19,en,Verification and Validation for a Project Information Model Based on a Blockchain,OriginalPaper,"Agile project management based on minimum viable products has some benefits against the traditional waterfall method. Agile supports an early return of investment that supports circular reinvesting and makes the product more adaptable to variable social-economical environments. However, agile also presents some intrinsic issues due to its iterative approach. Project information requires an efficient record of the requirements, aims, governance not only for the investors, owners or users but also to keep evidence in future health and safety and other statutory compliance-related issues. In order to address the agile project management issues and address new safety regulations, this paper proposes a project information model (PIM) based on a distributed ledger technology (DLT) with a ranked procedure for the verification and validation (V&V) of data. Each V&V phase inserts a process of authenticity, data abstraction and analytics that adds value to the information founded on artificial intelligence (AI) and natural language processing (NLP). The underlying DLT consists of smart contracts embedded on a private Ethereum blockchain. This approach supports a decentralised approach in which every project stakeholder owns, manages and stores the data. The presented model is validated in a real scenario: University College London—Real Estate—Pearl Project.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-15374-7_4,en,Gamma-Ray Spectroscopy and Imaging with SiPMs Readout of Scintillators: Front-End Electronics and Position Sensitivity Algorithms,OriginalPaper,"This is an introductory article to the topics more widely discussed in the PhD thesis from the same author. Following a short introduction and the motivations for researching innovative gamma-ray detector systems, this article describes a novel 85 dB dynamic range per channel integrated circuit for SiPM charge signal readout, named GAMMA, and the custom FPGA-based readout system. Experimental results presented in this article, obtained using a planar array of NUV-HD SiPMs, encompass the single-photon sensitivity achieved by GAMMA ASIC and the 2.6% resolution at the 137 Cs peak emission energy of 662 keV, when using GAMMA ASIC to collect current signal from a detector array that is coupled to a LaBr 3 scintillation crystal. Pixellation of the detector matrix allows for coarse position of interaction sensitivity in the scintillation crystal using machine learning reconstruction algorithms.","['Engineering', 'Electrical Engineering', 'Biomedical Engineering and Bioengineering', 'Computer Systems Organization and Communication Networks']"
doi:10.1007/978-3-031-21065-5_30,en,RGBD Data Analysis for the Evaluation of Trajectory Planning Algorithms in Human Robot Interaction Environments for Rehabilitation,OriginalPaper,"Robotic platforms are a great solution to ensure assistance and rehabilitation for disabled people using human-robot interaction capabilities. However, safe path planning trajectories are required by the robotic platform to avoid any collision between the human and the robot during the assistance or rehabilitation process. This paper proposes an intelligent robotic system that supervises the environment using 3D data from an RGB-Depth sensor and performs safe trajectories of the collaborative robot manipulator. Human-robot interactions are focused on upper-limb rehabilitation exercises about reaching a point using a collaborative robot UR3. Finally, several planning algorithms from Open Motion Planning Library (OMPL) are evaluated in order to obtain some metrics of the human-robot interaction and to find out the best one.","['Engineering', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Robotics']"
doi:10.1007/978-981-19-3951-8_36,en,Machine Learning Approaches to Stroke Prediction Based on the Framingham Cardiovascular Study Dataset,OriginalPaper,"Stroke is the second biggest cause of death and long-term paralysis globally. It continues to be a significant health burden for both the elderly and national healthcare systems. Hypertension, heart illness, atrial fibrillation, diabetes and other aspects of one’s lifestyle are all potentially modifiable risk factors for a stroke. Then, putting machine learning concepts into practice over an existing health study dataset to effectively and accurately predict the occurrence of stroke will help with early intervention and treatment. In this study, we propose various machine learning methods for stroke prediction and compare them to available methods or approaches from other similar studies. Furthermore, we present a Naive Bayes probabilistic method that combines the concept of data imputation, class imbalance and feature selection for stroke prediction, which achieves a greater area under the ROC curve than the multilayered perceptron neural network, and the SVM is proposed as the baseline methods for stroke prediction. In addition, neurologists can use our work to identify potential risk factors for stroke without any clinical trial methods. Finally, our methods can be applied to the clinical prognosis of other diseases, where data are often lacking and risk factors are poorly understood.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-3-031-13150-9_44,en,Multiclass-Based Support Vector Machine for Parkinson’s Disease Detection on Speech Data,OriginalPaper,"Overview: Parkinson’s disease is a central nervous system neurodegenerative condition that impairs the ability to manage certain bodily activities. Parkinson’s symptoms begin gradually and worsen with time due to dopamine’s supply to the motor system. It is well established that vocal difficulties associated with illnesses may be assessed for early Parkinson’s disease identification. Objective: The primary objective of this project is to develop a categorization system for the typical symptoms of Parkinson’s disease to aid in early identification. Methods: All features were examined and chosen to utilize feature selection algorithms to categorize subjects into four groups based on their UPDRS (Unified Parkinson’s disease Rating Scale) score. SVM, LR, GNB, K-Nearest Neighbor’s (KNN), and Random Forest (RF) were some of the machine learning classifiers that we used to make predictions. Results: SVM had the highest classification accuracy of 89% when combined with PCA for Parkinson’s disease identification.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Management']"
doi:10.1007/978-981-19-3391-2_21,en,MOOC-LSTM: The LSTM Architecture for Sentiment Analysis on MOOCs Forum Posts,OriginalPaper,"The massive open online courses (MOOCs) have been among the foremost energizing improvements in e-learning environment in recent days. As the number of MOOCs resources on each domain growing greatly, there is a necessity of evaluating MOOCs. Discussion forums are the key resources for MOOCS evaluation. Sentiment analysis is the famous mechanism to identify the opinion of the students on every particular MOOC. Long short-term memory architecture is used to avoid the issue of long-term dependencies in the text. In this paper, we propose a sentiment analysis system contains a new LSTM architecture and Ax hyperparameter tuner that can jointly performs well with large text for sequential analysis and sentiment classification. Proposed system is trained on two different datasets from different platforms using optimal hyperparameters. Experimental results shown that the proposed system outperforms other machine learning models in terms of accuracy and working well with different domains.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Statistics, general', 'Cyber-physical systems, IoT', 'Professional Computing', 'Communications Engineering, Networks']"
doi:10.1007/978-3-031-19958-5_41,en,Exploration of Online Fake News Through Machine Learning and Sentiment Analyses,OriginalPaper,"With the progress of technology throughout the world, the rapid adoption of online platforms is rising daily. It is quickly becoming a primary source of information, and we rely on it to get the latest news in the simplest possible way. However, many different forms of news are available online, and it might not be easy to recognize and pick reliable news. This paper uses supervised learning to recognize false news using four machine learning algorithms: Logistic Regression, Decision Tree, Gradient Boosting, and Random Forest, simultaneously on a valid dataset. We conducted a performance study of these prediction models and discovered that Logistic Regression and Gradient Boosting perform well on the dataset. Besides, we evaluate false and real online news sentiments to find the distinctions between these two forms of news in our relative contribution. This paper incorporates all of our unique observations than that of other ones. Furthermore, our outcomes are concrete, precise, and significant.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3679-1_14,en,Evolution of WSN into WSN-IoT: A Study on its Architecture and Integration Challenges,OriginalPaper,"Researchers have contributed a lot to the enhancement of wireless sensor networks (WSN). Various protocols have been designed for these networks to work with limited resources. However, we are leading toward a new era of innovation, and a new network of things (devices), known as Internet-of-Things (IoT), is evolving, where everything will be connected to the Internet. WSNs integration with the Internet will unleash the full potential of sensor networks, and the sensed data will be available to any user on the Internet at any time. However, their integration raises some challenges which need to be tackled. WSN protocols, designed for limited resources, may not be compatible to create a robust connection with the Internet. Also, the connectivity will make WSN accessible to the whole Internet that may influence the working of the sensor networks. In this paper, we have reviewed the evolution of WSN toward WSN-IoT. For this, we have studied the layered architecture of WSN and how various researchers have contributed to its lifetime enhancement. After that, we have compared the architecture of WSN with IoT to find out the architectural dissimilarities between them. Finally, to address the various challenges that emerge with WSN-IoT integration, we have reviewed the different approaches used for their integration, and then some solutions are given to deal with those challenges.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5090-2_24,en,Priority-Based Mitigation in Education Sector using Machine Learning,OriginalPaper,"Education sector is fastest growing as well as major contributing sector in society. Although like every sector in society, education is also facing issues in term of security. Since the pandemic rise and resulting lockdowns, education industry is restricted learning to remote access on virtual platforms and providing the combination of physical classroom as well as virtual training. Whilst this is of enormous help to students and educational institutes, it does come with cyber risks. Education sector has not been exempted from the inevitability of cyber risks and threats that prevail in the dark side of the booming technological developments. Hence, it has become imperative to not only identify these risks but also classify them in order to rectify and understand their consequences. Therefore, in this paper, we will describe the vulnerable areas in educational organisation and predict the attacks according to the impact of the attack which is part of the risk mitigation, so that they can be detected and prevented by using machine learning (ML).","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Artificial Intelligence', 'Data Structures and Information Theory']"
doi:10.1007/978-981-19-2225-1_39,en,Image-Based Plant Seedling Classification Using Ensemble Learning,OriginalPaper,"Agriculture is crucial for human survival and is a major economic engine across the world, particularly in emerging countries. Plant seed classification is a multi-class dataset with 5,539 pictures divided into 12 classes. We investigate various learning classifiers for the image-based multi-class problem in this study. We will start with a simple convolutional neural network (CNN) classifier model and work our way up to more complex options like support vector machines, and K-nearest neighbors. We will create an ensemble of classifiers to increase the current state-of-the-art accuracy. We will also investigate data preprocessing techniques like segmentation, masking, and feature engineering for an improvement in the overall precision. We will compare the performance as well as their impact on the final ensemble. To overcome this challenge, traditional techniques use complex convolution layer-based neural network architectures like Resnet and VGG-19. Though these techniques are effective, there is still scope for increasing accuracy. In this study, we propose a boosting ensemble-based strategy that employs a multilayer CNN model with a deep convolution layer that is boosted using the K-nearest neighbors lazily supervised learning technique. Although the fact that this combination is less complex than previous ways, it has obtained a higher accuracy of 99.90%.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Statistics, general', 'Mobile and Network Security']"
doi:10.1007/978-981-19-2394-4_2,en,Weight-Based Dynamic Hybrid Recommendation System for Web Application Content,OriginalPaper,"This paper presents a prototype for a Web application recommendation system’s content applied to movies’ recommendations. It learns the pattern of user content consumption, predicting what he will consume in future based on similar items to those he has shown interest. It considers similarity with neighbor users, thus creating a user model. Content-based filtering, collaborative filtering, and memory-based on hybrid filtering techniques are used. Content-based filtering allows to extract the fundamental features or attributes of the items and select similar items. Moreover, it proposes predicted classifications for the items of interest not yet classified by the active user. Collaborative filtering allows applying the KNN methodology to identify the similarity between the active user located in the neighborhood and propose predicted classifications for items of interest not yet classified. Hybrid filtering combines the two methodologies to overcome their drawbacks. A weighted approach is applied, allowing a dynamic linear combination of collaborative and content-based filtering. The results obtained were empirically relevant in the experimental evaluation, matching with the results presented in similar studies validated with RMSE metrics.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-658-38316-9_4,en,Examples for the Stationary Retail Trade of the Future,OriginalPaper,"In particular, the major platforms and online retailers, as well as international D2C brands, are leading the reinvention of brick-and-mortar formats. For each of these formats, Machine Learning lends itself to stationary retail. This will be explored in more depth with the ON4OFF project example. However retailers deal with the results of such future projects, one thing is clear: there has been no shortage of digital retail initiatives since the start of the Corona pandemic. But even before the pandemic, there were numerous digital retail projects, the most important of which are briefly presented. This also shows that brick-and-mortar retail and city centres are a community of fate, which is why the topic of Smart City is also relevant for Intelligent Retail. And what the Smart City means for city centres on the one hand, is the intelligent shopping centre on the greenfield site on the other.","['Business and Management', 'Trade']"
doi:10.1007/978-3-031-18461-1_50,en,A Prediction Model for Student Academic Performance Using Machine Learning-Based Analytics,OriginalPaper,"The adoption of digitization in the education sector has led to transformational changes. The academic sector has become more digital, more extensive, and more comprehensive but more complex as well. The topical advancements include the rise of technology-driven learning, the use of digital learning platforms, management systems, and technologies by students; the implementation of artificial intelligence and machine learning approaches for improvising student learning. In recent times, the solicitation of machine learning into academics has led to an upsurge in the education sector embroidering the growth of novel arenas such as Academic Data Mining (ADM) or Education Data Mining (EDM). ADM, based on machine learning techniques, helps in the prediction of students’ academic performance and is the subject of concern to many academic institutions for the classification of its students according to their learning capabilities. Moreover, the enormous amount of data about student academics can be handled, pre-processed, analyzed, and transformed into meaningful results and interesting patterns. The resulting patterns help in analyzing the academic performance of students and further lead to the identification of students who require special counseling. This paper proposes a model that predicts the performance of students based on academic details that helps in the classification of different learners.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3015-7_30,en,Machine Learning Models for Predicting Customer Willingness to Buy Electric Vehicles,OriginalPaper,"Countries across the world have started taking measures to control vehicular pollution, and one great initiative is to implement the Electric Vehicles. In India, where vehicular density is high, it is important to implement Electric Vehicles at a faster pace. Every innovation lacks promotion which will aid its success. This study predicts the customer willingness to purchase an electric vehicle and analyses the significant predictors of the Electric Vehicle purchase willingness. A sample of 371 respondents are considered, and convenience sampling is used to collect data over the Internet. Machine learning models are built with the available data and of all the machine learning algorithms, binary logistic regression, random forest and gradient boosting have the highest accuracy. Prior Experience, Cost Convenience, Aesthetic Convenience, Conventional Vehicle usage, Individual attitude and Gender are the most significant predictors of the purchase willingness. Also, through the sentiment analysis, it is known that people largely consider electric vehicles as good and eco-friendly.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Engineering', 'Data Mining and Knowledge Discovery', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-3-031-15191-0_35,en,Pedagogical Classification Model Based on Machine Learning,OriginalPaper,"The quality assurance of E-Learning systems can be guaranteed by a quality instructional design and by the definition of learning objectives associated with modules and programs. Learning objectives are central to teaching and learning in many higher education institutions. However, teachers have limited tools to help them reflect on the learning objectives of the course they create. Bloom's taxonomy's cognitive levels are widely used as a reference standard for classifying E-Learning Contents. However, many action verbs in Bloom's taxonomy overlap at various levels of the hierarchy, leading to confusion about the cognitive level expected. Some research papers have addressed the cognitive classification of E-Learning content such as assessment questions or forum texts, but none has addressed learning objectives. This study proposes a method for classifying learning objectives automatically, by extracting features based on a modified TF-IDF-POS to assign a suitable weight for essential words in the learning objective based on Part-Of-Speech (POS). Then, we use different classifiers combined with those features. To address the problem of the absence of annotated learning objectives dataset, we create a dataset of 2400 items. The classification results achieved the highest accuracies for the models combined with TF-IDF-POS. According to the findings of this study, the proposed method is effective in classifying learning objectives using Bloom's taxonomy.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Mobile and Network Security']"
doi:10.1007/978-981-19-2821-5_60,en,A Survey on Various Approaches to Examine Cognitive Behavior and Academic Performance of Learner in Virtual Learning,OriginalPaper,"A virtual learning environment (VLE) is the type of environment that can attract more students because it allows them to study anywhere in the world, which means that the student's location is no longer a constraint. In addition, VLE facilitates access to teaching resources, which facilitate the monitoring of teacher activities and interaction between students and teachers. Therefore, the online environment can assess the factors that lead to an increase or decrease in the academic performance of students. Machine Learning approaches are used for the cognitive behavior and academic performance of students in Virtual Learning. There is still no decision on the parameters to be adopted for the evaluation of virtual teaching as each student may submit the same type of assignment and same Practical files, and can have the same attendance. In such a case, evaluation of a student’s academic performance became tough. So we need to adopt some LMS which records various actions of the learners and the teachers like Quiz Submitted On-time/Late, Number of Assignment Submitted On-time/Late, Number of Discussions attended, Number of CA attended, and Practical Submitted On-time/Late, Internet connectivity, etc. So, there is a need for a framework that accounts for all of these parameters’ consideration so that a Predictive model can be designed for Forecasting/estimation performance of students that are recommended system should be framed for enhancing the academic performance of the learner.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-3-031-08093-7_13,en,How Artificial Intelligence Revolutionizing Digital Marketing,OriginalPaper,"In the last decade, the use of Artificial intelligence in the digital marketing has remarkably increased. Although it is a push for digital marketers, in fact, all applications of artificial intelligence affected the complexity of maintaining business competitiveness. The author aim to investigate the new techniques of maintaining competition and insure efficient usage of AI at its full potential. Thus, this qualitative study analyses what strategies could be used to succeed and standout from other digital marketers while considering what AI brought in new insights into the digital marketing field.","['Engineering', 'Mathematical and Computational Engineering', 'Business Mathematics', 'Data Engineering']"
doi:10.1007/978-3-031-18050-7_19,en,First Steps Predicting Execution of Civil Works from Georeferenced Infrastructure Data,OriginalPaper,"Geospatial data treatment is an important task since it is a big part of big data. Nowadays, geospatial data exploitation is lacking in terms of artificial intelligence. In this work, we focus on the usage of an machine learning models to exploit a geospatial data. We will follow a complete workflow from the collection and first descriptive analysis of the data to the preprocess and evaluation of the different machine learning algorithms. From unload dataset we will predict if the unload will lead to civil work, in other words, it is a classification problem. We conclude that combining machine learning and geospatial data we can get a lot out of it.","['Engineering', 'Computational Intelligence', 'Industrial and Production Engineering']"
doi:10.1007/978-3-031-20036-6_11,en,Network Analysis,OriginalPaper,"Proliferation is not a matter of a single transaction, strategic good, duped manufacturer, or bad actor. WMD and weapon system capabilities are complex constructions requiring a wide range of equipment, materials, technical knowledge, willing and unwitting accomplices, and opportunity. Proliferation needs a network. As described in Chap. 5 on scripting, illicit strategic trade is not necessarily hierarchical but is a web of actions that may be repeated across individual criminal acts and involvement of diverse entities from manufacturers, banks, logistics and transport companies, state-run organizations, and governments (Albright et al. 2020). Network analysis shifts the focus from the entities themselves to the relationships between entities. Most of the STA methods thus far have been focused on identifying individual instances of illicit behavior, primarily between the exporter, importer, and possibly some entities involved in transshipment/re-export. Network analysis broadens the scope by","['Political Science and International Relations', 'International Security Studies', 'Military and Defence Studies', 'Political Science']"
doi:10.1007/978-981-19-1610-6_55,en,Scientific Music Therapy Technologies for Psychological Care and Rehabilitation in the COVID-19 Pandemic,OriginalPaper,"This article analyzes the complex challenges of the pandemic and prospects of the scientific music therapy technologies used in psychological care and rehabilitation patients with COVID-19. First, the researchers found that COVID-19 can occur in asymptomatic or mild clinical forms and severe clinical forms with the development of pneumonia and respiratory failure. More recently, another severe problem of the pandemic has appeared, and it is different mental disorders. The achievements of scientific music therapy are so significant that they improve mood and optimize the function of vital systems, even online, which is very actual for patients with COVID-19. That was the reason to present the basics and technologies of SMT, including the concept model of the multifunctional autonomous robot “Helper” for medical services, rehabilitation, and music therapy. The article's conclusive idea is that integration of science, advanced technologies, and art will play an increasingly significant role in modern rehabilitation treatment and hospital services in pandemics.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-0095-2_23,en,Machine Learning Classifiers for Detecting Credit Card Fraudulent Transactions,OriginalPaper,"Credit card usage has increased significantly as a result of the fast development of e-commerce and the Internet. As a consequence of enhanced credit card usage, credit card theft has risen substantially in recent years. Fraud in the financial sector is expected to have far-reaching effects in the near future. As a response, numerous scholars are concerned with financial fraud detection and prevention. In order to prevent bothering innocent consumers while detecting fraud, accuracy has become critical. We used hyperparameter optimization to see if created models utilizing different machine learning approaches are significantly the same or different, and if resampling strategies improve the suggested models’ performance. The hyperparameter is optimized using GridSearchCV techniques. To test the hypotheses of data that has been divided into training and test data, the GridSearchCV and random search methods are used. The maximum accuracy 72.1% was achieved by decision tree classifier on the imbalanced German credit card dataset. The maximum accuracy of 98.6% is achieved by LDA on imbalanced European credit card dataset. Additionally, logistic regression and naïve Bayes were also tested and SMOTE was applied.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Systems and Data Security', 'Artificial Intelligence', 'Computational Intelligence']"
doi:10.1007/978-981-19-3679-1_25,en,A Hybrid Approach to Optimize Handover Margin in UWSN by Integration of ACO with PSO and MVO: A Comparative Analysis,OriginalPaper,"Underwater Wireless Sensor Network (UWSN) in the ocean is becoming more and more popular as a tool for marine monitoring and data collection. Sensor nodes’ mobility models for UWSN vary from WSN devices on the ground. This variation complicates handover prediction in these networks, which is a key difficulty. As a result, the current study focuses on handover optimization. UWSN handover and optimization in UWSN handover have received only sporadic attention. Thus, this paper offers a simulation of sensor nodes’ movement calculated data. The speed and direction of the water flow between the data points are included in this dataset. Sensor nodes and base stations in a UWSN are used to simulate the suggested simulation. For the handover optimization job, all of the handover events that occur throughout the simulation are collected. Handover events are optimized using PSO, MVO, and ACO techniques based on historical data obtained from previous handovers. This paper provides the ideal option to increase reliability in the case of UWSN. Performance analysis of the proposed model indicates the excellent quality in the case of the measured evolution scores.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5221-0_29,en,Exploratory Analysis of AI Automation in Various Horizons,OriginalPaper,"A significant technological advancements concern the automation of knowledge and organization processes as a result of development in artificial intelligence and its various sub-fields. However, in this study AutoAI term is used to describe this phenomenon. This advancement presents organizations with new strategic opportunities to increase its production value. However, prior researches that examine these developments are spread across some areas, namely health care, education, etc. The principal objective of this study is to present analysis of recent papers in three most demanding areas, namely AutoAI in cyber security, digital marketing and expert system. Based on the analysis of the available researches and empirical evidence, the following research questions can be answered: (a) what all sub-categories of above-mentioned areas are touched till now? (b) What are all algorithms used so far? (c) What are the gaps that need to be handled in future?","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Sociology, general', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-2821-5_61,en,Intrusion Detection System Using Machine Learning Approach: A Review,OriginalPaper,"The abundance of technology followed by serious cybercrimes makes way for providing better security. Internetworking applications at a paramount level generate the need of securing host system as well as network system from the user having malicious intent. Several enterprises and organizations become victims of these severe attacks in the aspect of using many applications for providing safety like firewall, data encryption, and user authentication. By taking into account, this causes a detection system with the use of machine learning approaches of artificial intelligence which has been developed, known as an intrusion detection system (IDS). An intrusion is a process of entering into the system having the intent of unsolicited duplication, record alteration, and illegal access to confidential resources. Hence, analyzing the network packets of such cases for possible intrusions in near future is intrusion detection. The intrusion detection system has evolved as a vibrant topic for researchers in the last two decades and hope it will be in the future as well because of rapid advancement in technology day by day. In this study, a survey of various research papers has been depicted and it has been the utmost priority that the display of work shall be comprehensible.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-3-031-17789-7_5,en,Fourier Analysis of Digital Signals,OriginalPaper,"The advances in digital computers after the Second World War led to the appearance of a new engineering branch. Digital signal processing is the name of this engineering branch. Advances in computer technology have led to the design of almost all signal processing methods with digital technology. Analog technology has been almost completely abandoned, and most newly manufactured devices are digitally designed. Signal processing techniques developed for continuous-time signals are adapted to digital signals. Some of these digital signal processing techniques are Fourier series representation of digital signals and digital Fourier transform. The formula for the Fourier series representation of digital signals is obtained using the Fourier series representation formula of continuous-time signals. Despite advances in computer technology, some signal processing algorithms are still time-consuming and need huge computation amount for computers. For this reason, algorithms are modified to run faster by computers. One of the best known of these algorithms is the fast Fourier transform algorithm developed in the 1960s. With the development of this algorithm, there has been an acceleration in the design of systems used for signal processing.","['Engineering', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Coding and Information Theory', 'Algorithms']"
doi:10.1007/978-3-031-06780-8_6,en,Future Technology and Research Trends in Automotive Sensing,OriginalPaper,"We discuss the importance of sensing technology in enabling intelligence of future automotive vehicles. We briefly overview efforts of leading technology companies such as Waymo and Tesla which resulted in impressive progress toward highest levels of driving automation. We then describe our efforts in the areas of future radars and lidars, specifically, those which go beyond 2D and mechanical scanning emphasizing importance of AI in improving sensor performance at marginal added cost. We then discuss trends in optical computing with its promise of substantially reducing energy consumption while enhancing edge computing.","['Engineering', 'Automotive Engineering', 'Computational Intelligence', 'Transportation Technology and Traffic Engineering', 'Signal, Image and Speech Processing']"
doi:10.1007/978-981-19-4971-5_15,en,Analysis of Microgrid and Protection Schemes: A Review,OriginalPaper,"The review paper presents a detailed analysis and review of microgrid and factors on which development of protection algorithms for microgrid-interfaced renewable energy sources depends. The review focuses on every aspect of the microgrid. It includes the factor affecting the protection of microgrid under different conditions. This is done after the investigation and literature review of various protection schemes currently in effect and are being implemented at various stages in a microgrid. To understand the microgrid protection schemes, understanding the recent protection challenges associated with AC microgrids with inverter-interfaced RES should be investigated thoroughly. The research paper includes microgrid classification, advantages of microgrid, characteristics of microgrid, microgrid protection schemes, limitation of microgrid protection schemes, and future scope of the paper. Major concern of the protection is specifically for the situation when microgrid switches from grid connected to island mode of operation. Exploration of the selected protection solutions and algorithms that would alter the regular protection methods are needed to be critically analyzed to achieve effective conclusions and implementable algorithms.","['Engineering', 'Power Electronics, Electrical Machines and Networks', 'Energy Policy, Economics and Management', 'Energy Systems']"
doi:10.1007/978-3-031-16035-6_8,en,Detecting Illicit Ethereum Accounts Based on Their Transaction History and Properties and Using Machine Learning,OriginalPaper,"The Ethereum blockchain has been subject to an increasing fraudulent activity during the recent years that hinders its democratization. To detect fraudulent accounts, previous works have exploited supervised machine learning algorithms. We can identify two main approaches. The first approach consists in representing transaction records as a graph in order to apply node embedding algorithms. The second approach consists in calculating statistics based on the amount and time of transactions realized. The former approach leads to better results at this day. However, transactional data approaches - based on time and data only - are not used to their full potential. This paper adopts a transactional data approach by expanding feature calculation to every transaction properties. We study three classification models: XGBoost, SVM Classifier and Logistic Regression and operate a feature selection protocol to highlight the most significant features. Our model results in a 26 features dataset providing an f-score of 0.9654.","['Engineering', 'Computational Intelligence', 'Data Engineering']"
doi:10.1007/978-981-19-5845-8_57,en,rSense: A Novel Gesture-Based Human Assistive Device,OriginalPaper,"The research paper discloses the implementation of rSense, a novel gesture-based human assistive device. The device comprises a ring and wireless earpiece, wherein the ring has Internet connectivity and is operated via gestures, while the earpiece is connected to the ring via Bluetooth. The proposed device utilizes sensory modalities of vision and hearing to perceive the environment and assist individuals by relaying relevant feeds over the earpiece in real time. It uses gesture-based controls and Internet-assisted intelligence to perform tasks such as reading, object recognition, speech recognition and others. The device is capable of providing high-level assistance to students, researchers, blind people, and people with reading disabilities.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5331-6_74,en,A Comprehensive Framework for Online Job Portals for Job Recommendation Strategies Using Machine Learning Techniques,OriginalPaper,"The employment market in today’s modern society is growing increasingly active, which makes choosing a clear opportunity for yourself a difficult endeavor, particularly for newcomers who are unfamiliar with the numerous possible professions. As a result, the need for employment recommendation systems has been steadily increasing. Many systems employ suggestions to provide consumers with personalized solutions. By examining job recommendation articles, we are taking into account various machine learning algorithms as well as models provided in this study. The information in the student’s résumé is compared to the specifications of the job opportunities. Users’ abilities, knowledge, past previous employment, demographic data, as well as other necessary details are extracted from recommendation apps. The applicant is presented with fresh positions that are unrelated to the one being sought based on the extraction of information. We discovered that by using content-based filtering to unsupervised based on deep learning classification methods such as SVM, KNN, and randomized forest, the random forest approach delivers the highest outcomes for our applications. Python is used to construct the recommendation engine.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-19958-5_37,en,Classifying Sentiments from Movie Reviews Using Deep Neural Networks,OriginalPaper,"Sentiment analysis has become crucial for the building of opinion mining systems due to the daily creation, sharing, and transfer of massive volumes of data and opinions via the Internet and other media. The sentiment analysis for movie recommendation is the main focus of this study. There are too many reviews and comments for movies to be manually processed. Therefore, to effectively process, we utilized user assessments of movies (whether they were favorable or unfavorable) to construct an overall assessment of the movie, which we then used to suggest it to other users. Even the most sophisticated review algorithms have been baffled by the enormous volume of reviews that are currently available. As a result, a strategy for extracting knowledge from the existing reviews and using it more skillfully needs to be created. This study utilized Artificial Neural Network (ANN), Convolutional Neural Network (CNN) and Long short-term memory (LSTM) to perform movie sentiment analysis on a dataset of 50k reviews from IMDB movies. Initially, the data was pre-processed using a GloVe word embedding algorithm. The testing outcomes showed that, with accuracy of 87.11% and an F1-score of 87%, LSTM beats other strategies. However, ANN recorded accuracy of 73.95%, while CNN reported accuracy of 85.17%. In addition, our models performed better than Naive Bayes (NB) and Support Vector Machine (SVM).","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3679-1_34,en,Crypto-Economic Model for Data Security in IoT Network,OriginalPaper,"The Internet of things (IoT) is the future research area in the networking domain. IoT is the Internet of things that connects everyday objects. It is the Internetwork of objects that enables these objects to collect the information from the environment and forward the information to the central server for further processing using several communication technologies. IoT is a new emerging technology that is used in variety of applications such as smart-building, smart-city, artificial intelligence, tracking, remote sensing, online emergency healthcare services. Routing plays a significant role in IoT network. This paper proposes a crypto-economic model for improving the security of data and determining the economic value of records in IoT Network.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-16-8154-7_43,en,Design Methodology Based on the RFLA Approach,OriginalPaper,"Throughout the entire existence of avionics, the role of software in aircraft systems was constantly increasing, and the aircraft systems themselves are becoming more and more complex, while the complexity increases not only in the implementation but also in the integration of systems. This has led to the conclusion that on-board software is to be developed by large teams, and the mutual influence of hardware and software, as well as various subsystems, must be taken into account. Inevitably, the projects began to face the following difficulties: Dependence on bench software, simulators, and physical prototypes; Communication both within the development team and between teams and businesses; Opacity of the relationship between the initial requirements and the result; Avalanche-like increase in the complexity of the source code; High costs for system verification and validation; Problems with the qualification of heterogeneous development tools. The solution to these difficulties is the use of model-based design, which is a modern approach to the development of large, complex, and highly reliable systems. The essence of the method is the systematic application of models at all stages of the product life cycle, from design to implementation. In the course of development, models of systems and subsystems are created at different levels of the hierarchy, including models of both the physical part and the algorithms themselves. Such models are used to evaluate the interaction of the algorithm, the physical part, and the external environment. This allows to validate and verification algorithms at the early stages of the project without the use of physical prototypes. With model-oriented design, the following results are achieved: There is a need to fully convey to the supplier the requirements for the developed aircraft system or component. Distribution of responsibility between the integrator and the supplier. As a result, the correct certification in accordance with P-4754A [ 1 , 2 ]. Reduction of labor costs and time for algorithms implementation on the target microprocessor platform, due to automatic program code generation (for example, using MATLAB, Simulink). Validation of system requirements by creating a system model and performing tests on it. Debugging and testing algorithms at the system model level, which ensures that most development errors are found at the preliminary design stage, rather than at the product prototype testing stage. Traceability of requirements, model, program code, and test scenarios, which is one of the conditions for compliance with industry standards for embedded systems development.","['Engineering', 'Aerospace Technology and Astronautics', 'Communications Engineering, Networks', 'Space Sciences (including Extraterrestrial Physics, Space Exploration and Astronautics)', 'Control and Systems Theory']"
doi:10.1007/978-981-19-4052-1_43,en,Supervised Learning Techniques for Sentiment Analysis,OriginalPaper,"Data mining implies the application of techniques of obtaining useful knowledge from a huge data. Another term for data mining is knowledge discovery from data. For the same, various data mining technologies are available such as statistics (lay the foundation of data mining), artificial intelligence (applying human thoughts like processing of data), and machine learning (union of statistics and artificial intelligence). In this research work, authors employ natural language processing in order to perform sentiment analysis using various feature extraction techniques of NLP. Sentiment analysis is especially important to gain users’ feedback and opinion about products. In this paper, authors perform sentiment analysis of twitter data. Each data point (tweets in considered case) will be classified as “positive tweet” or “negative tweet”. For this classification, six different techniques, i.e., information gain, Gini index (GI), Naive Bayes, K-nearest neighbor, random forest, and gradient boost are used. In the end, classification through all these techniques are analyzed and a comparative analysis is made based upon accuracy, precision, recall, and F1-score. Experimental results suggest that random forest aces the current analysis by yielding an accuracy of 97%.","['Engineering', 'Computational Intelligence', 'Information Storage and Retrieval', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Data Structures and Information Theory', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3571-8_58,en,A Survey of Methods and Techniques in Offline Telugu Character Segmentation and Recognition,OriginalPaper,"Telugu is one of South India’s oldest languages. It has a complicated orthography with various different character shapes. For so many decades, offline character recognition has always been a popular area of study. Handwriting segmentation and recognition are difficult, which has stimulated the interest of industry and academic researchers. Methods for recognizing handwriting have become much more prominent in recent years. Until now, the connected component approach, vertical and horizontal profiles, and other approaches were presented in the literature for the segmentation of printed character's work. The selection of the best discriminative features is an important concern in character recognition. Various statistical and structural features, as well as various combinations of them, are discussed in the research work. Researchers used ANN, SVM, KNN, and CNN to classify offline Telugu characters. The purpose of this article is to closely analyze various feature extraction methods and classification models to understand the problem and challenges encountered by earlier research. This identification is meant to provide numerous recommendations for advancements and scope.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-3015-7_41,en,A Survey on Advancements of Real-Time Analytics Architecture Components,OriginalPaper,"With the evolving technological landscape, Real-Time Analytics has become a de-facto practice and area of attraction for various industrial applications. Real-Time Analytics has proven to be impactful in plenty of critical problem statements, and a wide range of use cases have been raised in the real-time world. Working with streaming data includes various steps and aspects of software development and engineering starting from data collection to movement to processing and building actionable insights. Every such component of streaming analytics architecture needs to be designed and developed keeping in mind that the materialization of insights generated with this kind of dataset needs to be nearly real time. Many industrial organizations and large-scale enterprises have grown by adopting and investing heavily into building their systems using event-based streaming architectures. In this article, we intend to provide insights on primarily three aspects of architectural components in the context of Real-Time Analytics as well as advancements in the field. These aspects include recent research and development with regards to Real-Time Analytics Architecture and its use cases, industrial applications, development of tools and technologies. We also attempt to expose some open challenges and research issues that need further attention from researchers and industrial experts.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Engineering', 'Data Mining and Knowledge Discovery', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-3-031-16281-7_53,en,A Tiny CNN for Embedded Electronic Skin Systems,OriginalPaper,"The quest for efficient Tiny Machine Learning on Microcontroller Units is increasing rapidly due to the vast application spectrum made possible with the advancement of Tiny ML. One application area that could benefit from such advancement is Electronic Skin systems, that are employed in several domains such as: wearable devices, robotics, prosthesis, etc. An e-skin system demands hard constraints including real-time processing, low energy consumption, and low memory footprint. This paper presents a tiny Convolution Neural Network (CNN) architecture suitable for the deployment on an off-the-shelf commercial microcontroller in compliance with the e-skin requirements. The training, optimization, and implementation of the proposed CNN are presented. The CNN implementation is optimized through layer fusion and buffer re-use strategies for efficient inference on edge devices. As a case study, experimental analysis of a touch modality classification task demonstrates that the proposed CNN-based system is capable of processing tactile data in real-time directly near the source while reducing the model size by up to 65% with respect to comparable existing solutions.","['Engineering', 'Cyber-physical systems, IoT', 'Machine Learning', 'Robotics and Automation']"
doi:10.1007/978-981-19-3571-8_7,en,A Review on Societal Application of Data Analytics,OriginalPaper,"A combination of facts having a certain size and value represents data, and information represents the data that should be new, untested, logically correct, potentially useful, and unambiguous in nature. To find out the information which it incorporates in and are logical, novel, useful potentially, and understandable and draw conclusions about the information it comprises of, the discovery of knowledge is required. Analysis of data can be defined as a cognitive operation of scrutinizing, processing, transforming, and visualizing data so that we can identify the pattern and knowledge inside it. Numerous applications of data analytics include various domains like health care, academics, banking and finance, product recommendation, digital marketing, road travel, sports, governance, e-commerce, social life, and many others. Hence, it has a massive payoff in these domains to become eminent. Major applications are profit-oriented with very little societal application. This paper is a comprehensive survey of papers which are published between 2017 and 2021 of various societal applications belonging to different domains. And during the process, we found that the number of reported societal applications is infrequent although it is extremely crucial.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-5403-0_15,en,MATRA: An Automated System for MATernal Risk Assessment,OriginalPaper,"The progress of science and technology in recent times has gifted numerous solutions that have revolutionized our lifestyle. The advent of Internet of Things (IoT) and associated frameworks have ushered in a new era of smart, automated applications that require minimum human intervention to provide effective solutions. However, it is quintessential that some critical, real-time, human health related problems be addressed in a human-centric approach with the aid of the current technological developments. The assessment and early detection of maternal risk is a persisting issue which often results in loss of life and/or trauma in pregnant women. The proposed work addresses this problem with the development of a smart system that is capable of identifying the intensity of maternal risk based on physiological health parameters of the patients. It is observed that the Decision Tree classification algorithm is more effective in developing such a critically important system, than other algorithms like Logistic Regression and Multi-Layer Perceptron. Our system thus provides an efficient solution that can mitigate mis-identification of maternal risk intensity to a large extent whilst ensuring an accuracy of 83.5%.","['Engineering', 'Computational Intelligence', 'User Interfaces and Human Computer Interaction', 'Data Structures and Information Theory', 'Artificial Intelligence', 'Data Mining and Knowledge Discovery']"
doi:10.1007/978-3-031-20650-4_1,en,Graph Augmentation for Neural Networks Using Matching-Graphs,OriginalPaper,"Both data access and data collection have become increasingly easy over the past decade, leading to rapid developments in many areas of intelligent information processing. In some cases, however, the amount of data is still not sufficiently large (e.g. in some machine learning applications). Data augmentation is a widely used mechanism to increase the available data in such cases. Current augmentation methods are mostly developed for statistical data and only a small part of these methods is directly applicable to graphs. In a recent research project, a novel encoding of pairwise graph matchings is introduced. The basic idea of this encoding, termed matching-graph, is to formalize the stable cores of pairs of patterns by means of graphs. In the present paper, we propose to use these matching-graphs to augment training sets of graphs in order to stabilize the training process of state-of-the-art graph neural networks. In an experimental evaluation on five graph data sets, we show that this novel augmentation technique is able to significantly improve the classification accuracy of three different neural network models.","['Computer Science', 'Artificial Intelligence', 'Computers and Education', 'Data Mining and Knowledge Discovery', 'Information Systems Applications (incl. Internet)', 'Computer Appl. in Social and Behavioral Sciences', 'Image Processing and Computer Vision']"
doi:10.1007/978-3-031-13249-0_1,en,A Flexible Reinforcement Learning Framework to Implement Cradle-to-Cradle in Early Design Stages,OriginalPaper,"Reinforcement Learning (RL) is a paradigm in Machine Learning (ML), along with Supervised Learning and Unsupervised Learning, that aims to create Artificial Intelligence (AI) agents that can take decisions in complex and uncertain environments, with the goal of maximizing their long-term benefit. Although it has not gained as much research interest in the AEC industry in recent years as other ML and optimization techniques, RL has been responsible for recent major scientific breakthroughs, such as Deep Mind’s AlphaGo and AlphaFold algorithms. However, due the singularity of the problems and challenges of the AEC industry in contrast to the reduced number of benchmark environments and games in which new RL algorithms are commonly tested, little progress has been noticed so far towards the implementation of RL in this sector. This paper presents the development of the new Grasshopper plugin “Pug” to implement RL in Grasshopper in order to serve as a flexible framework to efficiently tackle diverse optimization problems in architecture with special focus on cradle-to-cradle problems based on material circularity. The components of the plugin are introduced, the workflows and principles to train AI agents in Grasshopper are explained and components related to material circularity are presented too. This new plugin is used to solve two RL problems related to the circularity and re-use of steel, timber and bamboo elements. The results are discussed and compared to traditional computational approaches such as genetic algorithms and heuristic rules.","['Engineering', 'Engineering Design', 'Manufacturing, Machines, Tools, Processes', 'Industrial Design', 'Interaction Design', 'User Interfaces and Human Computer Interaction']"
doi:10.1007/978-981-16-7487-7_11,en,Empowering the Design of Reversible and Quantum Logic with Decision Diagrams,OriginalPaper,"Reversible computation has received significant attention in recent years as an alternative computation paradigm which can be beneficial e.g. for encoder circuits, low power design, adiabatic circuits, verification—just to name a few examples. Aside from those applications in the design of (conventional) integrated circuits, reversible logic components are also a key ingredient in many quantum algorithms, i.e. in the field of quantum computing which by itself emerged as a very promising computing paradigm that, particularly these days, gains more and more relevance. All that led to a steadily increasing demand for methods that allow for an efficient and correct design of corresponding circuits. Decision diagrams play an important role in the design of conventional circuitry. In the recent years, also their benefits for the design of the newly emerging reversible and quantum logic circuits become evident. In this overview paper, we review and illustrate previous and ongoing work on decision diagrams for such circuits and sketch corresponding design methods relying on them. By this, we demonstrate how broadly decision diagrams can be employed in this area and how they empower the design flow for these emerging technologies.","['Engineering', 'Circuits and Systems', 'Electronic Circuits and Devices', 'Processor Architectures', 'Nanotechnology', 'Electronics and Microelectronics, Instrumentation']"
doi:10.1007/978-981-19-0095-2_27,en,Various Diabetes Detection Techniques a Survey,OriginalPaper,"Diabetes Mellitus is one of the most serious illnesses, and it affects a large number of people. Diabetes Mellitus may be caused by age, obesity, lack of exercise, genetic diabetes, lifestyle, poor diet, high blood pressure, and other factors. Diabetics are at a better chance of developing such as heart failure, kidney disease, stroke, eye problems, nerve damage, and so on. The standard hospital procedure is to collect the necessary information for diabetes diagnosis is obtained through a variety of tests, and appropriate medication is prescribed based on the results. Type 1 and 2 diabetes are the maximum not unusual place sorts of the condition, however there also are different kinds, inclusive of gestational diabetes which happens during pregnancy, as well as other forms. The emphasis of this paper is on various prediction techniques that have had a major impact in the field.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Systems and Data Security', 'Artificial Intelligence', 'Computational Intelligence']"
doi:10.1007/978-981-19-1142-2_21,en,Timely Prediction of Diabetes by Means of Machine Learning Practices,OriginalPaper,"In the past few decades, the quality and quantity of medical data generated by digital devices have been significantly improved, which makes data generation cost-effective and simple, thereby increasing its leading position in the field of big data and machine learning. There is a huge application of machine leaning and artificial intelligence in health care sector. The use of machine learning to train the machine to classify the medical cases taking care of the historical data can be a boon in medical studies. In this paper, we have analyzed many machine learning algorithms and classifiers which are used to make prediction on the diabetes based on the chosen features and attributes of the dataset. The implementation of the algorithms and its performance are compared in terms of accuracy. The proposed model uses soft voting ensemble techniques to the standardized Pima diabetes data to best fit the data and high accuracy.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Mobile and Network Security', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1906-0_38,en,Extended Kalman Filter-Based Position Estimation in Autonomous Vehicle Applications,OriginalPaper,"As there is great demand in self-operating driving cars, probabilistic-based model is one of the emerging areas while considering the estimation of position of vehicles. In this paper, two probabilistic models are implemented in application to autonomous ground vehicles. Bayesian-state estimator has been repeatedly used for estimating the position as well as state of the vehicle. In this paper, simulation results are executed for Kalman filter (KF), extended Kalman filter (EKF) for predicting the positions of vehicle. A brief description on improvement of each method is being discussed by drawing comparison table.","['Engineering', 'Electronics and Microelectronics, Instrumentation', 'Computer Systems Organization and Communication Networks', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16237-4_3,en,Machine Learning Assessment: Implications to Cybersecurity,OriginalPaper,"After discussing the construction of machine learning (ML) algorithms in the previous chapter, this chapter is dedicated to their assessment and performance estimation (with an emphasis on classification assessment), a topic that is equally important specially in the context of cyberphysical security design. The literature is full of nonparametric methods to estimate a statistic from just one available dataset through resampling techniques, e.g., jackknife, bootstrap and cross validation (CV). Special statistics of great interest are the error rate and the area under the ROC curve (AUC) of a classification rule. The importance of these resampling methods stems from the fact that they require no knowledge about the probability distribution of the data or the construction details of the ML algorithm. This chapter provides a concise review of this literature to establish a coherent theoretical framework for these methods that can estimate both the error rate (a one-sample statistic) and the AUC (a two-sample statistic). The resampling methods are usually computationally expensive, because they rely on repeating the training and testing of a ML algorithm after each resampling iteration. Therefore, the practical applicability of some of these methods may be limited to the traditional ML algorithms rather than the very computationally demanding approaches of the recent deep neural networks (DNN). In the field of cyberphysical security, many applications generate structured (tabular) data, which can be fed to all traditional ML approaches. This is in contrast to the DNN approaches, which favor unstructured data, e.g., images, text, voice, etc.; hence, the relevance of this chapter to this field.","['Engineering', 'Cyber-physical systems, IoT', 'Data Engineering', 'Computational Intelligence', 'Big Data', 'Artificial Intelligence']"
doi:10.1007/978-3-031-20601-6_23,en,Alzheimer’s Disease Multi-class Classification Model Based on CNN and StackNet Using Brain MRI Data,OriginalPaper,"Alzheimer's Disease (AD) may harm memory cells forever, which results in dementia. The detection and classification of Alzheimer's disease (AD) are critical in patient care. Many studies have applied machine learning and deep learning methods to classify the stages of AD. Consequently, it is used for the grouping of cerebrum images among Non-Demented, Very Mild Dementia, Mild dementia, Moderate Dementia, Alzheimer's Disease (AD) which are the four classes of AD in this manner guaranteeing exact and precise diagnosis. In clinical examination, magnetic resonance imaging (MRI) is utilized to analyze AD. For exact classification of dementia stages, we need profoundly discriminative high-lights acquired from MRI images. In this paper, we proposed a new model based on three convolution neural network architectures, DenseNet196, VGG16 and ResNet50 pre-trained models for features extraction, and the stacking ensemble for multi-class classification of this disease using a brain MRI dataset. This model has achieved an accuracy of 89% using the dataset published on Kaggle.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-0108-9_34,en,Decomposition Makes Better Rain Removal: An Enhanced Attention-Guided Image De-raining Using Deconvolutions Network,OriginalPaper,"Downpour streaks noticeable all around show assorted qualities with various shapes, headings, densities, even the complex covered marvel, causing extraordinary difficulties for the de-pouring assignment. As of late, profound learning-based picture de-pouring techniques have been broadly examined because of their amazing exhibition. In any case, the majority of the current calculations actually have constraints in eliminating precipitation streaks while saving rich textural subtleties under muddled downpour conditions. To this end, we propose to disintegrate downpour streaks into numerous downpour layers and separately gauge every one of them along the organization stages to adapt to the expanding abstracts. To all the more likely portray downpour layers, a further developed non-neighborhood block is intended to abuse the self-similitude of downpour data by learning the all-encompassing spatial element relationships while lessening the estimation intricacy. Also, a blended consideration instrument is applied to direct the combination of downpour layers by zeroing in on the neighborhood and worldwide covers among these downpour layers. Broad tests on both manufactured blustery/downpour cloudiness/raindrop datasets, certifiable examples, the murkiness, and low-light situations show generous enhancements both on quantitative pointers and special visualizations over the present status-of-the-craftsmanship advances.","['Engineering', 'Manufacturing, Machines, Tools, Processes', 'Renewable and Green Energy', 'Materials Science, general', 'Nanotechnology']"
doi:10.1007/978-3-031-04086-3_33,en,Application of Black-Box NIXO to Experimental Measurements,OriginalPaper,"Nonlinear identification methods seek to create a mathematical representation of a mechanical system, which can then be used to: (1) predict the structure’s motion or (2) design, redesign or optimize the structure. In a prior work the Nonlinear Identification through eXtended Outputs (NIXO) algorithm was found to work well if the model form is known a priori. Moreover, the black-box NIXO-based algorithm was successful for the data generated numerically. However, when it comes to actual experimental measurements, the black-box identification procedure has proven more challenging. This work builds on the previous efforts seeking to create a black-box NIXO and to demonstrate it on experimental measurements. The identification attempt is performed on a 3D-printed flat beam, and the results are validated against experimental measurements collected during sweep sine vibration testing.","['Engineering', 'Mechanical Statics and Structures', 'Building Construction and Design', 'Vibration, Dynamical Systems, Control', 'Mechanical Engineering', 'Aerospace Technology and Astronautics', 'Automotive Engineering']"
doi:10.1007/978-981-19-3998-3_92,en,Adaptive Consensus-Based Unscented Information Filter for Distributed Space Target Tracking,OriginalPaper,"The target tracking algorithm plays a key role in space situation awareness. The traditional target tracking filters are usually designed when only the maneuver or outlier is considered. In this paper, an adaptive consensus-based unscented information filter is proposed to deal with the dynamics model error caused by orbital maneuver and the measurement outlier during target tracking. The proposed method can handle the above two unfavorable factors by adopting the innovation anomaly detection for each sensor. Based on the detection result, the probability of outlier and the probability of maneuver under different sum of alarm are compared to determine which situation occurs. If the outlier occurs, it will be replaced by the predicted value of measurement. If the target performs maneuver, the predicted information state and matrix will be shrunken through a fading factor to suppress the impact of dynamics model error. The superiority of the proposed method is verified by simulations that a space target is tracked by a satellite swarm with ranging radars. Simulation results show that the proposed method can provide higher tracking accuracy than the traditional methods.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-981-19-3590-9_59,en,Diagnosis of Skin Cancer with Its Stages Using Multiclass CNN Technique,OriginalPaper,"Skin illnesses are one of the most frequent diseases in humans, and their prevalence is on the rise. Even expert doctors are unable to categorize skin disorders and their causes, necessitating the use of computer-based skin disease detection to make recommendations to non-expert users. Early detection and treatment of skin diseases reduce patient mortality and morbidity, as is widely recognized. Digital dermoscopy is one of the most cost-effective ways for diagnosing and classifying skin conditions. As a result, image processing techniques can be used to identify skin cancer. It can be utilized in the medical field to provide information about a lesion. The main objective is to implement a deep learning algorithm named a convolutional neural network to categorize skin cancer with its stages, severity levels, prescription and with improved accuracy by using a Python framework. The suggested approach employs image segmentation and features extraction. It does not require human interaction.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security', 'Mobile and Network Security']"
doi:10.1007/978-3-031-18256-3_8,en,Artificial Intelligence Applied to Breast Cancer Classification,OriginalPaper,"One in eight women is likely to develop breast cancer at some stage in her life, with a 12.5% average risk rate of developing breast cancer. Early detection and treatment are of vital importance to ensure the patient's survival. Currently, mammography is the main diagnostic study to identify breast cancer. However, since mammography requires a human, medical radiologist, to make a diagnosis, it is prone to errors. Recently, deep learning techniques have proven to be a suitable tool for breast cancer classification and detection. Therefore, this research proposes an algorithm based on convolutional neural networks (CNN) for screening classification of cancer in mammography images. The evaluation results of the proposed algorithm respect state-of-the-art algorithms demonstrate competitive accuracy results of up to 99% and the fastest training time. Therefore, our algorithm is well suitable for automatic breast cancer detection using the public All-MIAS database.","['Engineering', 'Biomedical Engineering and Bioengineering', 'Regenerative Medicine/Tissue Engineering', 'Bioinformatics']"
doi:10.1007/978-981-19-3148-2_7,en,Knowledge Management Using Blockchain Technology for Digital Resources,OriginalPaper,"Blockchain is a shared distributed database and cryptographically ensures that it cannot be tampered with, is unforgeable, decentralized, and trustless shared general ledger, and can safely store simple and self-verifiable data in the system. It is a new decentralized, overall maintained infrastructure and distributed computing paradigm, with the four major characteristics of decentralization, trustlessness, collective maintainability, and reliable database. This research will mainly use the literature survey method and the inductive analysis method to analyze the relevant documents of the blockchain technology in the CNKI database to find out the trends and characteristics of the development and application of the blockchain technology and explore the use of the blockchain technology-based on these characteristics. Here, we need to analyse the feasibility of creating a knowledge management process model for digital resources. The blockchain itself has the feature of decentralization, self-operation, and sharing, which is highly compatible with the knowledge management of digital resources, especially in the field of knowledge sharing.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory']"
doi:10.1007/978-981-19-5221-0_11,en,Environmental Characteristics Leveraging Crop Recommendation Based on Bayesian Optimisation-Support Vector Machine (BO-SVM) Approach,OriginalPaper,"Agriculture automation is a mechanical process that can be done with or without human intervention. Due to the limited space available on domestic lands, it has become critical to select the most appropriate crops based on the prevailing factors in the designated area. The most prevalent problem faced by Indian farmers is that they do not choose the appropriate crop for the prevailing agro-climatic conditions. As a result, they are experiencing difficulty for optimum production. Precision agriculture is a cutting-edge way to grow crops. It uses research data on soil attributes, soil types, and crop yield information to help farmers choose the best crops for their land. This article used machine learning to come up with a system that would help farmers grow more crops by taking into account things like temperature, humidity, pH, and rainfall. In the proposed model, the SVM with the Bayesian optimiser was the most important part. It achieved 98.8% accuracy with fivefold cross-validation.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Sociology, general', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-3951-8_15,en,Deep Learning Techniques for Leaf Health Prediction,OriginalPaper,"Food security is one of the most important issues discussed worldwide. Furthermore, it becomes more challenging in countries like India, where major population is vegetarian and farmers still follow old conventional farming methods. Plants’ growth is often affected by viral, bacterial diseases. However, experts’ advice on these plant diseases may be costly and time-consuming matter. Recently, computer vision and machine learning are successfully applied to the smart farming. Plant health can be easily monitored, and syndromes can be easily identified by applying machine learning and image processing techniques, over the conventional methods. Leaves are important part of the plant. It generates food for plants using photosynthesis. Hence, damage to leaf may result in reduced food supply to the plant. This results to lesser growth of the plant and lesser flower and fruit bearing capacity. This paper addresses various bacterial and fungal diseases among plants. Impact of each disease on the leaves such as color and shape is also discussed in this paper. This paper studies various deep learning techniques such as convolutional neural network (CNN) model and learning vector quantization (LVQ) algorithm which can be used to distinguish among healthy and disease plants. Difference between healthy and diseased leave was used to train these deep learning classifier. This paper also addresses remedial actions such as recommendation of specific pesticide and its quantity. It was observed that there exists and tradeoff between practical usage of automated system by farmers and accuracy of the system.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2126-1_2,en,Neural Network-Based Motion Control Algorithm for Perching Nano-Quadrotor on Outdoor Vertical Surface,OriginalPaper,"In this paper, a nano-quadrotor (40 g, diameter less than 0.10 m) is used for the self-controlled perching task on vertical wall surfaces using an adaptive neural network model. Due to its very light weight, the effect of aerodynamics drag is more severe. The proposed neural control scheme is developed for unmodelled dynamics of the nano-quadrotor. The unmodelled dynamics are estimated using a Chebyshev neural network. This single-layer neural network is adopted for developing the control laws for perching on vertical structures. The Lyapunov theory-based analysis is utilized to derive the update law for weights of the neural network. The proposed control algorithm confirms robustness under unknown dynamics of nano-quadrotor. The validation of system is demonstrated by experiments which shows the effectiveness of proposed control approach in perching application of nano-quadrotor.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Machine Learning', 'Big Data', 'Computer Systems Organization and Communication Networks']"
doi:10.1007/978-981-19-2188-9_34,en,Intelligent Evaluation of Ball Bearing Health Degradation Using Wavelet Packet Transform and k-Nearest Neighbor,OriginalPaper,"The attempt to automate the condition maintenance strategies of industrial sectors has been dramatically rising since the last decade. The automatic fault detection of ball bearings and real-time system monitoring is also one of those application domains which aims at preventing unpredicted failures and unnecessary machine halts, without substantial human intervention. The rising needs with parallel efforts have led to the development of numerous machine learning (ML) techniques and investigative studies-related thereto. Studies on the influence of different sets of features for training classifiers and number of datasets, on the performance of different ML classifiers, are also available in abundance; however, none emphasizes the importance of sample size before extracting the feature vector, on determination of classification results and computational efficiency. Considering this, the present work intends to examine the effect of four different fault feature sets and the sample size, on the overall performance of k-nearest neighbor (KNN) algorithms with different kernel functions. For this, the signal was first preprocessed using wavelet packet transform (WPT), and the impulsive bands, having significant correlation with the raw signal, were combined, and the resultant wavelet coefficients were used for signal reconstruction. Next, a set of features comprising root mean square, kurtosis, spectral entropy, and Hjorth’s mobility and complexity parameters were extracted from the reconstructed signal for classification purpose. The maximum accuracies of 99.3% and 99.6% of fine KNN classifier with tenfold validation were achieved in case of samples with sizes 1024 and 4096 data points, respectively.","['Engineering', 'Industrial and Production Engineering', 'Mechatronics', 'Engineering Thermodynamics, Heat and Mass Transfer', 'Energy Storage', 'Materials Engineering']"
doi:10.1007/978-3-031-14859-0_13,en,Towards the Detection of Hateful Sentiment in Social Networks,OriginalPaper,"Hate speech in social networks is affected and therefore increased thanks to anonymity. The use of opinion mining and Natural Language Processing (NLP) have increased their activity during the last few years because they provide an approach to analyze people's opinion, attitude ratings and emotions in the evolution of web 2.0. This article shows the analysis of hateful sentiment in social networks, specifically on Twitter. For this purpose, the tweets have been obtained through the source of information provided by the Tweepy API, thus forming a corpus with tweets that will be labeled as hate and non-hate, as the input of the analysis. To carry it out, a series of tasks are performed: preprocessing, feature extraction, vectorization, training of the Naive Bayes classification algorithm and validation of the algorithm along several metrics. We conclude the validity of the method, which could be used to make a more precise specification of hate speech, with the aim of identifying social biases, such as gender or racial discrimination, among others.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-17752-1_8,en,Platonism as a Way of Life,OriginalPaper,"The Platonic way of life aims at transforming you into a deity. And while ancient Platonists recommended many contemplative practices for self-deification, they also recommended ascetic ways of life. Ancient Platonists pursued the he telestike techne , the craft of self-surpassing. Further, they recommended theurgical procedures for raising your self to the heights of the deities. But the old Platonic dream of self-deification evolved into the dreams of the modern transhumanists, and the ancient craft of self-surpassing evolved into practical transhumanism. Practical transhumanists apply the experimental method to the self. They update the craft of self-surpassing into the hacker methodology. The Platonic way of life is the way of self-hacking.","['Philosophy', 'Philosophy of Religion', 'History of Philosophy']"
doi:10.1007/978-981-19-5240-1_5,en,Automated Paragraph Detection Using Cohesion Network Analysis,OriginalPaper,"The ability to express yourself concisely and coherently is a crucial skill, both for academic purposes and professional careers. An important aspect to consider in writing is an adequate segmentation of ideas, which in turn requires a proper understanding of where to place paragraph breaks. However, these decisions are often performed intuitively, with little systematicity in sequencing ideas. Thus, an automated method of detecting the optimal hierarchical structure of texts using quantifiable features could be a valuable tool for learners. Here, we aim to define a framework grounded in Cohesion Network Analysis to establish the structure of a text by modeling paragraphs as clusters of sentences. The analogy to clustering enables us to identify paragraph breaks that maximize inter-paragraph separation while ensuring high intra-paragraph cohesion. Our approach consists of two steps acted on texts without paragraph breaks. First, the number of paragraphs is automatically inferred with an absolute error of 1.02 using a Recurrent Neural Network, which relies on text features and cohesion flow. Second, paragraph splits are detected using two algorithms: top k which selects the largest cohesion gaps between adjacent utterances, and divisive clustering which iteratively splits the text into paragraphs. Silhouette scores are used to assess performance and the obtained values denote adequately inferred structures.","['Engineering', 'Computational Intelligence', 'Sociology, general', 'Big Data', 'Artificial Intelligence']"
doi:10.1007/978-3-031-20322-0_21,en,Speaker Identification in Noisy Environments for Forensic Purposes,OriginalPaper,"The speech is a biological or physical feature unique to each person, and this is widely used in speaker identification tasks like access control, transaction authentication, home automation applications, among others. The aim of this research is to propose a connected-words speaker recognition scheme based on a closed-set speaker-independent voice corpus in noisy environments that can be applied in contexts such as forensic purposes. Using a KDD analysis, MFCCs were used as filtering technique to extract speech features from 158 speakers, to later carry out the speaker identification process. Paper presents a performance comparison of ANN, KNN and logistic regression models, which obtained a F1 score of 98%, 98.32% and 97.75%, respectively. The results show that schemes such as KNN and ANN can achieve a similar performance in full voice files when applying the proposed KDD framework, generating robust models applied in forensic environments.","['Engineering', 'Computational Intelligence', 'Software Engineering/Programming and Operating Systems']"
doi:10.1007/978-3-031-16038-7_17,en,Classification of Rice Using Genetic Fuzzy Cascading System,OriginalPaper,"Classification can be done using various AI methods currently available in the literature. However most of the AI techniques are black boxes. We do not know what is going on inside them and hence explainability of the model is very limited. A fuzzy system can increase the explainability to a certain degree. In this paper, we classify two different types of rice with the use of a genetic fuzzy cascading system and compare the accuracy with other methods. A total of rice grain images are converted to greyscale images and with help of computer vision, the attributes are obtained. These data are used for classification using a 7 input 2 output Fuzzy Inference System (FIS) with multiple levels of cascading. Each of the input, output membership functions and the rule base are tuned using Genetic Algorithm. Our current approach was able to produce 94% accuracy in the validation set.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Engineering']"
doi:10.1007/978-981-19-0098-3_21,en,Smart Water Management: A Learning-Based Approach,OriginalPaper,"To ensure efficient management of resources, i.e., water was a constraint due to lack of supportive technology. The latest advancements in Internet of Things (IoT) and artificial intelligence (AI) have provided the opportunity to build real-time resource monitoring and management systems. We propose to build a pipeline to predict every day water usage. It can be integrated to any IoT device. The pipeline established can predict the requirements of water with 90.14% accuracy. The system is also designed to learn from every day’s data; thus, ensuring the model is improving everyday without any human intervention. The data collected through sensors from various departments of the University was used. The data was preprocessed and used to train various ML and deep learning models out of which the RF model proved to be the best. AWS is used to deploy the model over the cloud and connect it to IoT devices which monitor the water levels and update the model.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Statistics, general', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4182-5_6,en,Portable Electronic Tongue for Characterisation of Tea Taste,OriginalPaper,"Tea, being one of the largest consumed beverages in the world, is exported to many countries from India. This calls for the need for a rapid and effective method for quality assessment of tea. The present practice of quality evaluation involves human tasters who assign scores to tea samples based on taste, smell and visual appearances. Hence, these scores are subjective of human biases, non-repeatability and error-prone. Attempts for alternate evaluation techniques were made to evolve an efficient and objective technique for quality assessment of tea using the biomimetic measurement system such as electronic nose, electronic tongue and electronic vision in the last few years. In this study, we have developed a portable Electronic Tongue (e-Tongue) for the characterisation of tea. We have taken a novel approach to develop and fabricate polymer membrane sensors that operate on the potentiometric principle. We have trained the e-Tongue device with various statistical and neural network-based classification algorithms. Back Propagation-Multi Layer Perceptron, Accuracies obtained employing Probabilistic Neural Network, and Multiple Discriminant Analysis are 90%, 92% and 96%, respectively. The potential of e-Tongue using potentiometry in the evaluation of the quality of tea, as found in this study, can be explored further to make it suitable for commercial use.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Computer Systems Organization and Communication Networks', 'Statistics, general']"
doi:10.1007/978-3-031-18409-3_10,en,Efficient Implementation of Stream Cipher SNOW 3G for Resource-Constrained Devices,OriginalPaper,"SNOW 3G is one of the stream ciphers proposed by the standard to protect data in 3G and 4G mobile communications. In recent years, the possible adaptation of the algorithm to the requirements of 5G communications has been studied, resulting in more efficient implementations, although modifications of the cipher, such as SNOW-V and SNOW-Vi, have finally been proposed to achieve the throughput and security that 5G requires. In this article, an efficient implementation of SNOW 3G is presented. It takes advantage of the 32-bit architecture of the processors and employes n -grouped operations giving raised to similar performance than the SIMD instructions set employed in the most recent stream ciphers. The implementation is based on the use of the equivalent binary model of the LFSRs defined in $$GF(2^n)$$ G F ( 2 n ) . Although SNOW 3G seems ruled out for 5G communications, it is still interesting to have efficient implementations in 4G that allow its integration in devices with limited processors.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Education, general']"
doi:10.1007/978-981-19-3035-5_67,en,Machine Learning for Cloud Resources Management—An Overview,OriginalPaper,"Nowadays, an important topic that is considered a lot is how to integrate Machine Learning (ML) to cloud resources management. In this study, our goal is to explore the most important cloud resources management issues that have been combined with ML and which present many promising results. To accomplish this, we used chronological charts based on keywords that we considered important and tried to answer the question: is ML suitable for resources management problems in the cloud? Furthermore, a short discussion takes place on the data that are available and the open challenges on it. A big collection of researches is used to make sensible comparisons between the ML techniques that are used in the different kind of cloud resources management fields and we propose the most suitable ML model for each field.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Statistics, general']"
doi:10.1007/978-981-19-2225-1_22,en,Survey on Algorithmic Trading Using Sentiment Analysis,OriginalPaper,"In recent years as the computation power and availability of the data has increased exponentially, there has been significant increase in study of human sentiment in various fields. This paper examines the use of sentiment analysis in algorithmic trading. Macroeconomic variables such as GDP, Internet consumption and various other socio-economic factors are also taken into consideration in this paper. The main aim of this paper is to determine all factors and technical indicators that would give us a proper analysis. Human sentiment affects human behaviour adroitly, and thus, market is also not acquitted from its effect. This survey presents current advances in natural language processing (NLP) and prerogative positions of algorithms in market.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Statistics, general', 'Mobile and Network Security']"
doi:10.1007/978-981-19-2840-6_32,en,Survey on Attendance System Using Face Recognition,OriginalPaper,"In this framework, face is distinguished and perceived while the video is real time, to recognize the individual amongst difficulties. This recommends comparing people on either pictures or sequential recordings. For video based face acknowledgment, it is tough to accomplish the comparative levels of general execution. There are a few drawbacks in video based face acknowledgment, when face identification depends on the verification with existing face pictures. The drawbacks are indicated by the following: At first, CCTV cameras get pictures which are generally of low norm. Second, picture assurance is generally decreased for video frameworks. Third, face picture varieties, which incorporate light, appearing, stance, obstruction, and development, are more serious in video real time. Therefore this review concentrates on different face position and learning calculations to break down the proficiency in recognition framework.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-1412-6_34,en,Comparative Analysis of KNN Classifier with K-Fold Cross-Validation in Acoustic-Based Gender Recognition,OriginalPaper,"Gender recognition based on acoustic attributes plays an important role in various audio forensic level tasks. When we talk about forensic level issues, accuracy is the most prominent attribute that needs to be taken care of. This article shows our attempts to observe the impact of multiple folds applied to the popular KNN classifier on the accuracy of results while recognizing the gender of the speaker. We demonstrate our experiments by using python programming language on the dataset available on Kaggle. The results show that 20-folds KNN can provide maximum accuracy (95.77%) and saturate afterward with the size of the dataset up to 3168. Results also show that changing the number of nearest neighbors in this algorithm will not put any impact on the accuracy.","['Engineering', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security']"
doi:10.1007/978-981-19-3379-0_20,en,Predictive Analysis of Air-Cooled Condenser by Considering Fouling Using Machine Learning Algorithm,OriginalPaper,"Refrigeration and air-conditioning play a major role in energy consumption which results in huge demand for energy. An experimental study is done to investigate performance variables such as pressure drop, compressor power, superheated temperature, coefficient of performance, and cooling capacity due to the fouling across condenser by particle deposition of various sizes on fin and tube heat exchanger. Characterization of deposition should be obtained from experimental observations related to the air-cooled condenser. There is gradual blockage of the condenser by artificial fouling. Data of experimental setup should be used to develop the model for assessment of fouling and remaining useful life of condenser. Developed predictive model validity would have to be applied for wide applications of the heat exchanger. The database will be used by a designer to generate a machine learning algorithm to develop the correlation. The study will provide the predicted data of the system based on current operating conditions with R410a as the refrigerant. Different machine learning algorithms are used to predict the fouling and finding the best algorithm by validating the experimental results.","['Engineering', 'Engineering Fluid Dynamics', 'Solid Mechanics', 'Mechanical Engineering']"
doi:10.1007/978-981-19-1669-4_22,en,Detection of Human Behavior Using Swarm Technique and Neural Networks,OriginalPaper,"Artificial neural network plan is a complicated job since its demonstration relies upon the design, the selected task and the knowledge calculation used to prepare the arrangement of synaptic loads. Here, these papers present a technique that consequently plans a neural system utilizing particle swarm advancement. Neural network merges faster and comes into sight throughout the best neural system design. Utilizing PSO for the preparation interaction expects to enhance the outcome of the collection vectors on neural system which thus improves the classification precision to appear at the quality presentation contrasted with the best in group strategy the assessment investigates the performance of convolution neural system with swarm method. The simulation results showed that convolution neural system using swarm technique is capable to attain elevated enactment of accurateness after compared by other algorithm.","['Engineering', 'Signal, Image and Speech Processing', 'Circuits and Systems', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1844-5_38,en,Seizure and Drowsiness Detection Using ICA and ANN,OriginalPaper,"The EEG recording resembles a wave with peaks and dips. Every peak and valley has distinct frequencies and is well defined. Abnormalities in this wave structure reflect a variety of brain-related disorders, including epileptic seizures, sleepiness, memory loss, tumour, drowsiness and so on. The EEG signal can detect a variety of brain-related disorders. In the head, there can be both minor and severe disorders. EEG datasets are gathered and analysed for peak conditions which are analysed in this paper. The input is an EEG data file, which consists of different noises which are removed using high-pass filter as a part of preprocessing. After the noise has been removed, independent component analysis (ICA) is used as a feature extraction methodology for extracting the features from the signal. Artificial neural network (ANN) is a deep learning concept used for classifying the signal from the extracted features. When compared to existing combinations on the market today, the proposed system, which is a combination of ICA and ANN, allowed the performance characteristics to reach a high value.","['Engineering', 'Communications Engineering, Networks', 'Mobile and Network Security', 'Artificial Intelligence', 'Big Data']"
doi:10.1007/978-3-031-02063-6_16,en,Domain-Specific Security Approaches for Cyber-Physical Systems,OriginalPaper,"In recent years, attacks have emerged in various cyber-physical systems (CPS), causing power outages, disrupting water treatment processes, and so on. These attacks, which are often referred to as advanced persistent threats (APT), reveal a daunting fact. Adversaries are no longer amateurs that randomly probe and compromise many computing devices; they are equipped with advanced intelligence of domain-specific knowledge of the target system and act to achieve a specific goal, e.g., disrupting physical processes. Like a well-trained sniper, adversaries can target a small number of certain devices and can exploit legitimate control operations or well-crafted measurements to inflict physical damage without introducing system- or network-level anomalies. This chapter will present our belief that can effectively address those advanced threats, i.e., integrating domain-specific knowledge of a target system (with the main focus on smart power grids) into general-purpose security solutions. This approach will allow us to reveal adversaries’ malicious intentions and preemptively prevent damage from happening.","['Engineering', 'Engineering Economics, Organization, Logistics, Marketing', 'Mathematical Modeling and Industrial Mathematics', 'Risk Management', 'Industrial Organization']"
doi:10.1007/s40544-021-0584-3,en,Long short-term memory based semi-supervised encoder—decoder for early prediction of failures in self-lubricating bearings,"['OriginalPaper', 'Research Article']","The existing knowledge regarding the interfacial forces, lubrication, and wear of bearings in real-world operation has significantly improved their designs over time, allowing for prolonged service life. As a result, self-lubricating bearings have become a viable alternative to traditional bearing designs in industrial machines. However, wear mechanisms are still inevitable and occur progressively in self-lubricating bearings, as characterized by the loss of the lubrication film and seizure. Therefore, monitoring the stages of the wear states in these components will help to impart the necessary countermeasures to reduce the machine maintenance downtime. This article proposes a methodology for using a long short-term memory (LSTM)-based encoder—decoder architecture on interfacial force signatures to detect abnormal regimes, aiming to provide early predictions of failure in self-lubricating sliding contacts even before they occur. Reciprocating sliding experiments were performed using a self-lubricating bronze bushing and steel shaft journal in a custom-built transversally oscillating tribometer setup. The force signatures corresponding to each cycle of the reciprocating sliding motion in the normal regime were used as inputs to train the encoder—decoder architecture, so as to reconstruct any new signal of the normal regime with the minimum error. With this semi-supervised training exercise, the force signatures corresponding to the abnormal regime could be differentiated from the normal regime, as their reconstruction errors would be very high. During the validation procedure for the proposed LSTM-based encoder—decoder model, the model predicted the force signals corresponding to the normal and abnormal regimes with an accuracy of 97%. In addition, a visualization of the reconstruction error across the entire force signature showed noticeable patterns in the reconstruction error when temporally decoded before the actual critical failure point, making it possible to be used for early predictions of failure.","['Engineering', 'Mechanical Engineering', 'Nanotechnology', 'Tribology, Corrosion and Coatings', 'Physical Chemistry', 'Surfaces and Interfaces, Thin Films']"
doi:10.1007/978-981-19-2126-1_7,en,RFE and Mutual-INFO-Based Hybrid Method Using Deep Neural Network for Gene Selection and Cancer Classification,OriginalPaper,"A DNA microarray is used to measure a large gene expression profile simultaneously. It can diagnose and classify cancer and other tumorous diseases. However, due to the large number of genes present that are less correlated with the class and having a small number of samples. Various techniques have been proposed to identify the most relevant genes with the highest predictive efficiency for the class. Deep learning models also performed admirably well on classification tasks. But its application is rare in gene classification due to the limited number of samples available to train the model. We used a hybrid method in which recursive feature elimination (RFE) in conjunction with mutual information is used to produce a low-dimensional subset. Sample expansion is done to increase the number of samples for training deep neural networks. Finally, cancer classification is done using deep neural networks (1DCNN) and existing deep/machine learning models. In terms of accuracy, our proposed method outperformed other existing methods in four of the seven datasets.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Machine Learning', 'Big Data', 'Computer Systems Organization and Communication Networks']"
doi:10.1007/978-3-031-07258-1_19,en,Deep Convolutional Neural Network for Segmentation and Classification of Structural Multi-branch Cracks,OriginalPaper,"Structural Health Monitoring (SHM) has been a significant research topic to help with damage detection in civil structures and to stop further deterioration. Traditional methods of SHM are time consuming and cost ineffective. In addition, civil structures such as dams and high raised buildings are burdensome and risky to inspect manually, especially after a natural disaster. Crack signals the beginning of failure for any structure. Most of the existing methods largely deal with only the detection of cracks. Proposed work concentrates on segmentation, classification, and subsequent detection of cracks based on pattern i.e., Linear vs branching, apart from the single and multiple cracks. The image dataset was obtained from real-time visual inspections. This study is significant because a branching crack shows greater structural stress than a linear crack. Furthermore, results quantify the damage in the image using instance segmentation techniques. Experimental analysis achieves classification and quantification of the data with good accuracy.","['Engineering', 'Building Repair and Maintenance', 'Cyber-physical systems, IoT', 'Industrial and Production Engineering', 'Monitoring/Environmental Analysis', 'Analytical Chemistry']"
doi:10.1007/978-981-19-4052-1_50,en,Machine Learning Methods to Identify Aggressive Behavior in Social Media,OriginalPaper,"With the more usage of Internet and online social media, platforms creep with lot of cybercrimes. Texts in the online platforms and chat rooms are aggressive. In few instances, people target and humiliate them with the text. It affects victim mental health. Therefore, there is a need of detecting the abuse words in the text. In this paper, a study of machine learning methods is done to identify the aggressive behavior. Accuracy can be improved by incorporating additional features.","['Engineering', 'Computational Intelligence', 'Information Storage and Retrieval', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Data Structures and Information Theory', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2065-3_7,en,An Efficient Security Technique Using Steganography and Machine Learning,OriginalPaper,"With the recent advancement in e-commerce technology and IoT-enabled smart devices, where every bit of information passing through unsecured channel, it became mandatory to secure the information from unethical use. Cryptography and steganography are two significant approaches that have been applied strenuously in various algorithms to prevent the information from unauthorized use. However, every scientific terminology has some deficiencies due to time and advancements in mechanization; it needs to rebound with recent advancements in technology. This paper presents an efficient secure communication framework by using steganography technique. In the proposed framework, information in the form of images, hyperlinks, and text have been concealed using heuristic approach. This framework further has been improved by applying machine learning tools. The significance of proposed framework has been verified by MATLAB tools.","['Engineering', 'Communications Engineering, Networks', 'Artificial Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Machine Learning']"
doi:10.1007/978-981-16-9901-6_3,en,The Development of Information Technology,OriginalPaper,Information technology and industry are the basis of information construction.,"['Engineering', 'Communications Engineering, Networks', 'Computer Applications', 'e-Commerce/e-business', 'Computer Science, general']"
doi:10.1007/978-981-19-0098-3_25,en,Long Short-Term Memory (LSTM) Layers as a Proposed Learning Algorithm for Rainfall Prediction,OriginalPaper,"Rain is an important component of the overall cycle since it is capable of accumulating the majority of the freshwater on the planet. Hence, all variations in the weather have an impact on the agriculture as well as on the economy of the country. India being a farmer’s-dependent economy indirectly depends on good rainfall. India gets a yearly precipitation of roughly 4000 billion cubic meter (BCM) which include snowfall, with an average rainfall of about 1170 mm. In the current times, climate change is a matter of major concern. Autoregressive integrated moving average (ARIMA) and point spread function (PSF) were used. But traditional methods have some limitations, are expensive and require large data set. Predictions are created by mathematical model defined by a set of equations that predict future rainfall with the help of a dynamical strategy. The paper performs a comparison between multiple linear regression (MLR), K-nearest neighbour (KNN), backpropagation with ANN and long short-term memory (LSTM) on the prediction of rainfall. Statistical methods are performed such as MAE, RMSE, MSE to compare the different prediction model and to choose the best suitable one. The test cases provided a lower MAE, RMSE and MSE value in case of LSTM model as it can memorize how elements in a series are ordered in a time series data. Instead of having the information which was before and unchangeable, LSTMs have the capacity to identify the context necessary to make forecasts in time series forecasting scenario.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Statistics, general', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1669-4_7,en,Hybrid Cryptosystem’s Design with AES and SHA-1 Algorithms,OriginalPaper,"Web turned into a remarkable part in our consistently life. We use Web for making exchanges and sending significant and delicate records. In the event that the data to be sent are vital, and we require a solid method for correspondence in order to send the information. Cryptography is intended for that reason which will give security to our information. Here, security is given to the information by executing both AES and SHA calculations. The plan is synthesized utilizing Verilog. The plan of AES calculation is tweaked to execute just on Xilinx programming. AES is a symmetric key code calculation that can be utilized for move of information from sender to recipient in a powerful way. Encryption is performed at sender side which is a method for changing over unique message into specific example of codes called figure message for security reasons. Unscrambling is performed at beneficiary side to receive unique message from the coded message. In AES relying on adjusts, distinctive key sizes (194, 128, 256) p can be utilized. AES comprises of various advances like preround change, key development, shift lines, and blend segments. Some vital benefits of AES encryption and unscrambling calculation are quick in execution, and it utilizes higher length size 128 bits for encryption which gives greater security to the information as it requires 2^128 endeavors to send or hack the information. Secure hashing is utilized for creating hash codes from the information, and this technique is viewed as secure on the grounds that it is difficult to convey the first message from hash code. In this task, SHA-1 is executed. SHA-1 deals with information having length of 512 pieces and produces a 160 cycle information called as hash codes or digest. SHA utilizes diverse rationale tasks like and shift and XOR. SHA is utilized for creating the way to encryption calculation which prompts greater security.","['Engineering', 'Signal, Image and Speech Processing', 'Circuits and Systems', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-0095-2_20,en,Effect of Data Compression on Cipher Text Aiming Secure and Improved Data Storage,OriginalPaper,"Cryptography is a technique of protecting the data from an unauthorized access using encryption process. Encryption converts the plain text into cipher text which is in non-readable form. Past studies suggest that the size of cipher text is the major concern which hinders users from adopting encryption methods to secure the data. This work involves an experimental study on exploring the effect of data compression on an amino acid form of cipher text using dictionary-based methods as well as entropy coding methods without compromising the security. Compression ratio is measured for different file sizes. The results show that 47% storage savings is achieved using entropy coding method and 60% using dictionary-based coding method. Owing to this, storage efficiency is also doubled. The advantage of this method is thus convinced and provides an improved data storage.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Systems and Data Security', 'Artificial Intelligence', 'Computational Intelligence']"
doi:10.1007/978-981-19-2821-5_26,en,Occlusion Problem in 3D Object Detection: A Review,OriginalPaper,"In computer vision, 3D object detection has numerous applications such as robotics, augmented reality (AR), medical field, manufacturing industries, and safe autonomous driving. But the real-object detection may involve various problems such as noise, missing data, and occlusion problem. From past few years, the great progress in 3D object detection has been made. Object recognition and identification in occlusion remain a difficult challenge, despite recent breakthroughs in 3D object detection. The occlusion problem is one of the difficulties in object tracking. The paper highlights a number of research hurdles and open concerns that researchers must address.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-3-030-79827-7_35,en,Process Simulation,OriginalPaper,"In this chapter an outline of the very diverse topic of process simulation is given. This includes the process steps of ion implantation and thermal annealing, which introduce, activate, and modify dopant distributions, and the process steps lithography, deposition, and etching, which are used to structure the semiconductor wafer. The section on oxidation deals with the simulation of the oxide growth, whereas the aspect of dopant segregation is included in the section on diffusion. Finally, the impact of process variations is outlined. Overall, the process simulation chapter primarily deals with the physics and the related models for the various process steps, whereas the discussion of generic algorithms, e.g., for the solution of partial differential equations, is left for another dedicated chapter of this book. However, some algorithms which are specific for process simulation are also briefly described in this chapter. Due to the diversity of the area of process simulation, this chapter could not strive for completeness in the presentation of the physical models. We largely refer to silicon technology, whereas most models can also be applied for or adapted to other top-down semiconductor technologies where, in contrast to bottom-up technologies based on self-assembling, patterning steps, ion implantation and high-temperature process steps are used to generate three-dimensional geometries and dopant distributions.","['Engineering', 'Circuits and Systems', 'Electronic Circuits and Devices', 'Electronics and Microelectronics, Instrumentation']"
doi:10.1007/978-3-031-20029-8_8,en,Evaluation of the Information Flow Control in the Fog Computing Model,OriginalPaper,"In the IoT (Internet of Things), data are exchanged among subjects and objects in devices through manipulating objects. Even if subjects manipulate objects in accordance with the CBAC (Capability-Based Access Control) model, the subjects can get data which are not allowed to be gotten by the subjects, i.e. illegal information flow and late information flow occur. Hence, the OI (Operation Interruption) and TBOI (Time-Based OI) protocols where operations occurring illegal and late types of information flows are interrupted are implemented. Moreover, capability token selection algorithms are proposed and applied to the protocols. The protocols are implemented and evaluated in terms of the request processing time, communication traffic, and electric energy consumption. However, the more number of operations are interrupted to prevent both types of illegal and late information flows because the amount of data kept by entities monotonically increases through manipulating objects in the protocols. Therefore, reduction of the number of operations interrupted is important. For this aim, an FC (Fog Computing) model of the IoT where data from devices are processed in a fog layer and the processed data are sent to subjects is considered in this paper. In the evaluation, it is shown that the number of operations interrupted is reduced in the FC-based protocols compared with the conventional protocols.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence']"
doi:10.1007/978-981-19-3590-9_27,en,Early Prediction of Heart Anomalies Using Machine Learning,OriginalPaper,"Our goal is to build a web application that can prevent heart diseases. Heart Disease ranks as one of the leading causes of the deaths worldwide. To give an outcome as to when an individual will be in a gamble of having a coronary illness is dreary work and needs expertise yet, prevailing in that work will save heaps of lives. Detection/diagnosis of illness is one of the applications where information mining apparatuses are achieving victories all over the world. It involves Machine Learning Technique which helps in the identification of coronary illnesses. It has been thoroughly evaluated showing satisfactory degrees of precision. Human heartbeat elements have been exhibited to give promising markers of Congestive Heart Failure. The principle objective of this exploration paper is to foster an Intelligent System utilizing information analytics demonstrating method and Artificial Intelligence (AI), specifically support vector classifier to anticipate coronary illness with high accuracy.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security', 'Mobile and Network Security']"
doi:10.1007/978-981-19-1669-4_26,en,Multispectral Image Compression Using Adaptive Thresholding in Wavelet Domain with Binary Plane Techniques,OriginalPaper,"Multispectral image acquirement systems create multilayer images in which each layer having the different pixel values which are not negative in general. The compression of these images aims to transform the image into more solid form that is convenient for pressuring, transmission, processing, and recovery. In this paper, band decomposition and discarding approach are proposed with wavelet and correlation coefficients. The resultant spectral image is subjected for spatial binary plane method for based compression algorithm. The approach is operated in lossless mode and differentiating against traditional JPEG-LS with multiple metrics. Experiments were conducted on several regular multispectral images that are available for research and observed that the proposed method provides an average compression ratio of 8.34 which is 1.86 times more than earlier method.","['Engineering', 'Signal, Image and Speech Processing', 'Circuits and Systems', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3938-9_28,en,A Methodology for Multi-objective Design Optimization (MDO) of Automotive Suspension System,OriginalPaper,"Original Equipment Manufacturers (OEMs) should innovate ways to delight the customers by creating affordable products with improved drive experience and occupant comfort. Vehicle refinement is an important initiative that is often take-up by the project teams to ensure that the product meets the customer expectations. Few important aspects of vehicle refinement includes improving the noise vibration harshness (NVH), ride and handling performance pertaining to the functional image (FI) of the product. Optimizing the suspension design variables meeting both ride and handling performance is often challenging as improving ride will have a deteriorating effect on handling and vice versa. The present work involves multi-objective design optimization (MDO) of suspension system of an automotive sports utility vehicle (SUV) platform considering both ride and handling requirements, simultaneously. Using advanced simulation tools (ADAMS) and design of experiments (DoE)-based approach, functional forms were derived for objective function and constraint variables. The mathematical forms of the predictive models were obtained from various machine learning-based algorithms. Trade studies were done to arrive at optimal design decisions. In the available literature, there are very few machine learning-based optimization studies done considering both ride and handling attributes, simultaneously, covering wide range of design verification plans (DVPs).","['Engineering', 'Mathematical and Computational Engineering', 'Optimization', 'Machine Learning']"
doi:10.1007/978-3-031-16072-1_34,en,A Comprehensive eVTOL Performance Evaluation Framework in Urban Air Mobility,OriginalPaper,"In this paper, we developed an open-source simulation framework for the evaluation of electric vertical takeoff and landing vehicles (eVTOLs) in the context of Unmanned Traffic Management (UTM) and under the concept of Urban Air Mobility (UAM). Unlike most existing studies, the proposed framework combines the utilization of UTM and eVTOLs to develop a realistic UAM testing platform. For this purpose, we first develop an UTM simulator to simulate the real-world UAM environment. Then, instead of using a simplified eVOTL model, a high-fidelity eVTOL design tool, namely, SUAVE, is employed and an dilation sub-module is introduced to bridge the gap between the UTM simulator and SUAVE eVTOL performance evaluation tool to elaborate the complete mission profile. Based on the developed simulation framework, experiments are conducted and the results are presented to analyze the performance of eVTOLs in the UAM environment.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-3-031-18461-1_19,en,"Enhancing Artificial Intelligence Control Mechanisms: Current Practices, Real Life Applications and Future Views",OriginalPaper,"The popularity of Artificial Intelligence has grown lately with the potential it promises for revolutionizing a wide range of different sectors. To achieve the change, whole community must overcome the Machine Learning (ML) related explainability barrier, an inherent obstacle of current sub symbolism-based approaches, e.g. in Deep Neural Networks, which was not existing during the last AI hype time including some expert and rule-based systems. Due to lack of transparency, privacy, biased systems, lack of governance and accountability, our society demands toolsets to create responsible AI solutions for enabling of unbiased AI systems. These solutions will help business owners to create AI applications which are trust enhancing, open and transparent and also explainable. Properly made systems will enhance trust among employees, business leaders, customers and other stakeholders. The process of overseeing artificial intelligence usage and its influence on related stakeholders belongs to the context of AI Governance. Our work gives a detailed overview of a governance model for Responsible AI, emphasizing fairness, model explainability, and responsibility in large-scale AI technology deployment in real-world organizations. Our goal is to provide the model developers in an organization to understand the Responsible AI with a comprehensive governance framework that outlines the details of the different roles and the key responsibilities. The results work as reference for future research is aimed to encourage area experts from other disciplines towards embracement of AI in their own business sectors, without interpretability shortcoming biases.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-6068-0_34,en,A Review of the Detection of Pulmonary Embolism from Computed Tomography Images Using Deep Learning Methods,OriginalPaper,"Medical imaging has been evolving at a steady pace generating enormous amounts of health data, and the use of deep learning (DL) has helped a great deal in processing the detailed data. Deep learning-based methods are used in different medical imaging tasks to detect and diagnose diseases. For example, medical imaging is used to diagnose pulmonary embolism (PE), a commonly occurring cardiovascular disease with high mortality and prevalence and a low diagnosis rate. According to medical experts, PE has resulted in many deaths because of missed diagnoses for the medical condition. Another critical aspect of the disease is the possibility of permanent lung damage if left untreated. The use of deep learning methods in medical imaging is attributed to their ability to use learning-based methods to process enormous amounts of data. However, there are some unique challenges in the detection of PE. PE is not specific in its clinical presentation and is easily ignored, making it difficult to diagnose. Deep learning-based detection methods help a great deal in the disease detection in miniature sub-branches of the alveoli, and images with noisy artifacts easily compared to manual diagnosis.","['Computer Science', 'Artificial Intelligence', 'Computational Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-14859-0_3,en,Drawing Music: Using Neural Networks to Compose Descriptive Music from Illustrations,OriginalPaper,"The creative capacity of machines is still questioned by researchers and users alike. For this reason, computational creativity does not only focus on the development of machines for the creation of artistic content but also on the evaluation of the generated content. This works presents a system that composes polyphonic music from the drawings of a user in real time. Our proposal provides an analysis of the Fantasia film, produced in 1940 by Walt Disney and deduces the relationship between its audio and images. As part of system development, an LSTM-based Recurrent Neural Network was trained with MIDI music files and a model was obtained. As a result, the proposed system generates polyphonic music with expressive timing and dynamics by inferring chords from the user’s drawings. To assess the creative ability of the machine a Turing test was conducted and the quality of the interconnection between drawings and music was measured by another user test. Additionally, the performance of the considered classifiers is discussed.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16865-9_33,en,Dropout Early Warning System (DEWS) in Malaysia’s Primary and Secondary Education: A Conceptual Paper,OriginalPaper,"School dropout is an issue that plagues almost every nation globally, and Malaysia is not an exception. According to Malaysia’s Education Ministry, dropouts are defined as Malaysian students in the school system who choose to leave before completing their education. Student dropout is a grave issue as it impacts the students and negatively implicates society and policymakers. At present, machine learning is the talk of the town as the world has a wealth of data that can be used freely. Machine learning is a method of data analysis that digitizes the development of analytical models. It is a technique that is based on the insights derived from data, recognize patterns, and make decisions with very little human intervention. From the Malaysian education perspective, no study thus far has looked into primary and secondary public-school dropouts while simultaneously using supervised machine learning. Consequently, this study intends to contribute to the literature, especially from Malaysia’s perspective by proposing a dropout early warning system for primary and secondary students using supervised machine learning algorithms. The predictive model with machine learning has an enormous potential to develop early warning systems to identify and help students who are likely to drop out.","['Engineering', 'Computational Intelligence', 'Data Engineering']"
doi:10.1007/978-3-031-08815-5_8,en,Towards Sustainable Smart Cities: The Use of the ViaPPS as Road Monitoring System,OriginalPaper,"Smart cities are an opportunity to overcome the concerns regarding the rapid increase in highly dense populated urban areas. Using ICT, smart cities make urban areas greener, sustainable and at the same time increase their competitiveness and their economic growth. Road networks play a significant role to improve the sustainability of smart cities. Indeed, deteriorated roads cause tied mobility, traffic congestion, CO $$_2$$ emissions and economic damages to cities and their citizens. To prevent these negative aspects, the road network have to be continuously maintained. A satisfactory road maintenance relies on a continuous monitoring of road network which can be facilitated deploying ICT. This article presents the role of ICT in road monitoring and showcases the ViaPPS: a mobile Pavement Profiling System. The ViaPPS offers accurate and detailed geo-referenced information of the state of the road and the corresponding furniture with the deployment of LiDAR and computer vision techniques. After presenting the capabilities of the ViaPPS, this article discusses the strategy of the smart city of Oslo towards its sustainable development goals and the role of ICT in road maintenance.","['Engineering', 'Computational Intelligence', 'Transportation Technology and Traffic Engineering']"
doi:10.1007/978-3-031-15191-0_43,en,Hybrid Movie Recommender System Based on Word Embeddings,OriginalPaper,"A recommender system is an application intended to offer a user item that may be of interest to him according to his profile, the recommendations have been applied successfully in various fields. Recommended items include movies, books, travel and tourism services, friends, research articles, research queries, and much more. Hence the presence of recommender systems in many areas, in particular, movies recommendation. The problem of film recommendation has become more interesting because of the rich data and context available online, what advance quickly the research in this field. Therefore, it’s time to overcome traditional recommendation methods (traditional collaborative filtering, traditional content-based filtering) wich suffer from many drawbacks like cold start problem and data sparsity. In this article we present a solution for these limitations, by proposing a hybrid recommendation framework to improve the quality of online films recommendations services, we used users ratings and movies features, in order to use two models into the framework based on word2vec and Knn algorithms respectively.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Mobile and Network Security']"
doi:10.1007/978-981-19-2538-2_14,en,Topic Popularity Prediction Using Similarity Graph on Twitter,OriginalPaper,"Information about what are the most popular topics is highly demanded and has a variety of uses in different areas such as marketing, business and even politics since it is an indication of public's thoughts and viewpoint. Predicting topics that may become popular in the recent future has even more practical applications, which includes user behaviour analysis, strategising campaigns for events, brand marketing, planning stock investments, and in politics to analyse public opinion. In our study, we aim to identify such popular topics on Twitter, which is a widely used microblogging platform with its users generating enormous data on a daily basis. Features such as hashtags are utilised to enrich the data obtained via Twitter API. We make use of techniques such as TF-IDF and LDA and present a unique approach to compare them on a similarity graph for popularity prediction. The glove model, an unsupervised algorithm that generates meaningful vectors from words, is used for mapping words to the graph, providing a visual representation for better understanding.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory', 'Mobile and Network Security']"
doi:10.1007/978-3-031-17752-1_1,en,Renewing Atheism,OriginalPaper,"Much of contemporary atheism is stuck in Plato’s cave. This is also Nietzsche’s cave, which is filled with the shadows of God. And while twilight atheists don’t believe in God, they still believe in his shadows. They are cultural theists who endorse theistic if-then chains which bind valuable things to God. Twilight atheists agree with theists that if there is no God, then: there is no objective meaning to life; there is no objective morality; there is no cosmic meaning or purpose; there is no modal or mathematical objectivity; there is no life after death; and there are no deities and no things with any divine attributes. Twilight atheism is nihilism. Atheistic Platonists seek to overcome both theism and twilight atheism. We aim to construct new cultures which depend neither on theism nor on its nihilistic negation.","['Philosophy', 'Philosophy of Religion', 'History of Philosophy']"
doi:10.1007/978-3-031-07258-1_102,en,Damage Detection Using Supervised Machine Learning Algorithms for Real-World Engineering Structures,OriginalPaper,"Vibration-based structural health monitoring represents an efficient way to evaluate structural integrity and the presence of damage at an early stage. These methods usually assume that damage manifests itself as a deviation in the modal properties of the structure with respect to its normal conditions. Traditional procedures for modal parameters estimation require the use of a dense sensor arrangement and complex logic techniques, thus making them not particularly suitable for the case of large engineering structures, where the need for cost-effective monitoring solutions is of utmost importance because of the large number of substructures to be monitored. This paper proposes the use of simple statistical and spectral features as a mean to characterize accelerations signals. Starting from this set of features, the principal component analysis (PCA) is first used to reduce data dimensionality still preserving the relevant information about the structural conditions, then a k-Nearest Neighbors (k-NN) procedure is adopted as a supervised machine learning method to classify different types of damage. The procedure is validated using the experimental data from the permanent monitoring system of the G. Meazza stadium grandstands of, where one accelerometer per stand is installed to get vibration data during the main events. Four grandstands located on the same ring and having the same nominal geometry are considered. The leading idea is to reproduce different scenarios where, due to the impossibility of imposing realistic damages, one grandstand is assumed to be the safe structure, while the others represent a proxy for small structural changes to be identified.","['Engineering', 'Building Repair and Maintenance', 'Cyber-physical systems, IoT', 'Industrial and Production Engineering', 'Monitoring/Environmental Analysis', 'Analytical Chemistry']"
doi:10.1007/978-3-031-11128-0_7,en,Towards Human Activity Recognition Enhanced Robot Assisted Surgery,OriginalPaper,Medical robotics have drawn increasing research interests in the past years. The potential of employing intelligence techniques is still not yet fully utilized to improve the capabilities of medical devices for assisting human beings during surgical operations. This book chapter presents a novel human activity recognition enhanced robot-assisted surgery to promote human enhancement with AI techniques. Novel-designed multisensory fusion systems can be used to provide more knowledge to boost the recognition rate and robustness. Then the identification results in the complex environment using deep learning can be used to determine the machine behavior using a hierarchical control framework. A detailed explanation is introduced in this chapter.,"['Engineering', 'Robotics and Automation', 'Engineering Design', 'Industrial and Production Engineering']"
doi:10.1007/978-981-19-4258-7_2,en,Literature Review,OriginalPaper,"In the past two decades, spacecraft attitude coordination has gained significant developments. This chapter aims to present a survey of recent research on the spacecraft attitude consensus problem, paying particular attention to the papers published in major aerospace, dynamics, automation and robotics journals.","['Engineering', 'Aerospace Technology and Astronautics', 'Control, Robotics, Mechatronics']"
doi:10.1007/978-981-19-3938-9_49,en,Differential Evolutionary (DE) Method for Strut Performance Design and Optimization Using Machine Learning-Based Meta-Models Prediction,OriginalPaper,"Evolutionary algorithms (EA) of nature-inspired metaheuristics approach are gaining a lot of interest in computational intelligence methods and are very useful for global optimization problems. In this paper, a differential evolutionary algorithm is applied to strut design and optimization. Struts are used in vehicle suspension systems that can withstand sufficient road load that would ensure the desired performance metric of stiffness and strength. Optimum design of strut is essential to arrive at minimum mass. In this work, the meta-model linking input variables to output performance are developed using efficient machine learning tool to get desired prediction accuracy even with highly nonlinear behavior. Subsequently, differential evolution method of optimization is done on the ML meta-model for arriving at optimum strut design parameters to meet the desired performance. It is observed that the optimized design of the strut does result in a mass reduction for the required performance significantly compared to baseline design parameters.","['Engineering', 'Mathematical and Computational Engineering', 'Optimization', 'Machine Learning']"
doi:10.1007/978-981-19-3951-8_56,en,Recurrent Neural Network Model for the Classification of Tamil Speech Sound Disorder Signals,OriginalPaper,"Articulation disorder is defined as a person who encounters complications in the pronunciation of specific speech sounds correctly. It is caused due to the physical structural problems found in an individual’s tongue, lips, palate, jaw, respiratory system, vocal tract, height of the larynx and air flow through nasal. In this paper, an efficient and robust classifier is constructed based on recurrent neural network (RNN) algorithm to categorize Tamil speech sound disorder signals into four classes, namely substitution, omission, distortion and addition. The distinct number of articulation test words suggested by speech-language pathologists (SLPs) are compiled and used in this study. Tamil speech sound disorder dataset comprise of vowels (Uyir eluthukkal) and consonants (Meiyeluthukkal) are collected from the participants who are affected by articulation disorder. Noise removal techniques include moving average filter, Savitzky–Golay filter, low pass filter, Gaussian filter and Butterworth filter are utilized to remove the acoustic noise present in the ground truth samples. The prominent features are extracted from the denoised signals using Mel-frequency cepstral coefficients (MFCCs) technique. The fine-tuned feature subset is selected from the feature vector space by applying principal component analysis (PCA) method. The refined features are employed into RNN model that classify Tamil speech sound disorder signals into the four aforementioned class labels. Experimental outcomes illustrate that the proposed model gives 90.25% classification accuracy when compared to other most popular algorithms, such as feed forward neural network (FFNN), backpropagation neural network (BPN) and random vector functional link network (RVFLN).","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-3-031-10507-4_10,en,An Investigation of Blockchain Technology and Smart Contracts Deployment in Smart Medicine 4.0,OriginalPaper,"Internet of Medical Things (IoMT) and Internet of Health Things (IoHT) are the most significant and at the same time the most controversial areas of Internet of Things (IoT). Nowadays, almost every country contemplates about the development and implementation of the most technically advanced, user-friendly, and secure means of management, control, and performance in these areas. Private companies and patients are no less interested in this. One of such means for building the smart medicine ecosystem is blockchain technology, and it’s such significant element as smart contracts. This chapter presents a review on existing initiatives, frameworks, theoretical research, and practical implementations of the blockchain and smart contracts technologies into the healthcare industry’s facilities and activities as well as a critical assessment of the security aspects of the various solutions related to smart medicine of the blockchain-based solutions. Conclusions are drawn regarding the prospects for the introduction of blockchain technology in the healthcare sector and an implementation of it to improve the designing process and maintenance of smart medicine.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Systems and Data Security']"
doi:10.1007/978-3-031-16072-1_44,en,Experimental Design of a Quantum Convolutional Neural Network Solution for Traffic Sign Recognition,OriginalPaper,"Quantum convolutional neural networks encapsulate and combine complex features of both Artificial intelligence and principles of Quantum Mechanics to develop complex systems capable of solving intricate and detailed machine learning problems such as object recognition. In this paper, we propose an experimental design for a quantum convolutional neural network to be used in conjunction with the GTSRB dataset and compare the results to that of both a traditional neural network and a hybrid neural network, enabling an accurate comparison between the various methods. A detailed look into the mathematical and architectural constructs of the QCNN will be depicted alongside the potential flaws that Quantum computing may incur.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2004-2_21,en,Reliable Biometric Authentication with Privacy Protection,OriginalPaper,"Objectives To study and compare different types of biometric systems and to obtain the result for the same, this paper has discussed the need of biometrics, ways of performing it and the best type of biometrics that should be implemented. Methods and findings: We used various statistics, graphical and tabular representations for showing data studied from different papers and reviewing them. Instances of infringements of right to privacy and protection of personal data are proliferating. Biometric systems are identity authentication systems for information assurance and protection via biological traits since they are unique. Technology is rapidly advancing in every field and choosing passwords are not enough. Biometric systems are the best approach to keep data safe, and it also makes the accessing of data simple. Everything has its own pros and cons so; we will be discussing the pros and cons of various biometric technologies in order to determine the best among them.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Artificial Intelligence', 'Materials Science, general']"
doi:10.1007/978-3-031-11686-5_7,en,Machine Learning for Feature Constraints Discovery,OriginalPaper,"Constraints among features are central to the success and quality of software product lines (SPLs). Unfortunately, the number of potential interactions and dependencies, materialized as logical constraints, grows as the number of features increases in an SPL. In particular, it is easy to forget a constraint and thus mistakenly authorizes invalid products. Developers thus struggle to identify and track constraints throughout the engineering of more and more complex SPLs. In this chapter, we show how to leverage statistical machine learning (and more specifically decision trees) to automatically prevent the derivation of invalid products through the synthesis of constraints. The key principle is to try and test some product of an SPL and then identify what individual features or combinations of features (if any) are causing their non-validity (e.g., a product does not compile). A sample of derived products is used to train a classifier (here a decision tree but other classifiers might also be used as long as constraints can be easily extracted) that can classify any remaining products of the SPL. We illustrate the chapter through different application domains and software systems (a video generator, parametric programs for 3D printing, or the Linux kernel). We also discuss the cost, benefits, and applicability of the method.","['Computer Science', 'Software Engineering/Programming and Operating Systems', 'Software Management', 'Computer System Implementation']"
doi:10.1007/978-3-030-79827-7_33,en,Nanoelectronic Systems for Quantum Computing,OriginalPaper,"Nanoelectronic systems have driven the technology advances for the past half century. But, as we move forward in the twenty-first century, new concepts for computing, notably quantum computing, have appeared that promise dramatic increases in computational efficiency. While these are new systems concepts, they likely will continue to be manufactured using the technology of nanoelectronics. Here, we discuss a variety of approaches which are currently being studied for applicability to quantum computing. But, issues such as scalability, which has facilitated the development of nanoelectronic systems so far, pose important questions for these new and novel approaches.","['Engineering', 'Circuits and Systems', 'Electronic Circuits and Devices', 'Electronics and Microelectronics, Instrumentation']"
doi:10.1007/978-3-031-18292-1_10,en,A Deep Learning Based Target Coverage Protocol for Edge Computing Enabled Wireless Sensor Networks,OriginalPaper,"The sensor networks have attracted a numerous research attention due to its diverse applications ranging from surveillance and monitoring applications. The sensor nodes are usually characterized as having scarce resources; hence energy efficient mechanisms which can enhance the resource utilization are of great significance. The integration of edge computing framework with the sensor network can aid in the data collection, dissemination and decision making. Scheduling approaches which divide the nodes into a number of set covers and monitor the given points of interest with the desired confidence level along with the objective of maximizing coverage and network lifetime have been proved a prominent approach. The determination of set covers is a NP hard problem and is dependent on different network parameters such as node contribution, trust values and coverage probability. In this scheme, the node has to monitor the neighboring node parameters at regular intervals, which incurs a huge number of communication overhead. The nodes in sensor network can employ the learning strategy to determine its best possible action to enhance the network coverage as well as network lifetime. The chapter proposes a LSTM based strategy for an edge computing enabled WSN to determine the status of the node depending on the network parameters such as number of communications, number of packets transmitted and initial energy of the nodes. The proposed protocol is implemented using tensor flow and keras libraries in the python language. The keras tuner package has been used to determine the best parameters such as number of hidden layers and number of neurons in each layer. The obtained parameters are used to construct a hyper model and the efficiency of the model is evaluated in terms of the loss function. The explainability of the proposed model is investigated using the Local Interpretable Model-agnostic Explanations (LIME) framework and the effect of all the features on the status prediction have been determined.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16281-7_4,en,A Novel Rule-Based Modeling and Control Approach for the Optimization of Complex Water Distribution Networks,OriginalPaper,"This work applies Rule Based Control, a new rule-based, computationally efficient machine learning method for optimizing complex networks. This approach does not require a rigorous formulation of the optimization model, since only a set of historical data, where solutions are labeled as good or bad, is needed. It makes use of a rule-based machine learning method, which allows the optimization of complex networks, where a full description of the system is not available or too complex. The proposed approach is currently under evaluation in the water distribution system of the Milan (Italy) water main. The application of the approach to synthetic data shows its ability of reducing the energy consumption, while ensuring a good quality of service.","['Engineering', 'Cyber-physical systems, IoT', 'Machine Learning', 'Robotics and Automation']"
doi:10.1007/978-981-19-1142-2_31,en,A Comprehensive Study of Pose Estimation in Human Fall Detection,OriginalPaper,"According to a study, unexpected fall is one of the main causes of sudden demise in elder persons. Therefore, it is very important to take immediate safety measures for the people having age 65 or above, or the people who are physically or mentally disabled. A powerful fall detection system to identify and provide immediate assistance to senior citizens or the people who is prone to falls is needed. A medical alert system with fall detection allows the user to summon assistance without pressing the call button. This review paper identifies the comparison in the approaches used for fall detection based on machine learning algorithm. A brief discussion on the methods used in pose estimation like OpenPose and PoseNet, which are majorly used to detect the fall and non-fall of a person is done. Moreover, we have also discussed the privacy concern of a person while using camera-based technique for detecting fall.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Mobile and Network Security', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1142-2_44,en,Use of a Precious Commodity—‘Time’ for Building Skills by Teachers for Online Teaching During Pandemic by Using Decision Tree and SVM Algorithm of Machine Learning,OriginalPaper,"The competency to perform a particular task effectively and efficiently is what we call a developed skill. Skills could be of any type: communication, leadership, interpersonal, problem solving, decision making, etc. This crucial period of the pandemic has brought along the threats and challenges and several opportunities with it. A chance to learn something new, think out of the box, be creative, convert our idle time into a quality one, etc. All this has given rise to using our time for some productive purpose. For months, we have been facing this pandemic, and ‘Work from Home’ is the policy adopted by almost every company, firm, and educational institution. And this has given all the employees working from home an opportunity to put their saved time into something innovative and productive. So, this study has emphasized the usage of time for skill development by teachers of the educational institutions of Mumbai for online teaching during the period of the COVID-19 pandemic through different training programs. This study is based on the primary data that has been collected from the teachers aged from 30 to 60 and above. Also, its results state that the skills which are required by the teachers for their effective teaching–learning process are developed successfully, and the majority of the faculties have improved their technical skills as well, which in turn have enabled them to adopt new and innovative teaching techniques.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Mobile and Network Security', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2535-1_67,en,Comprehensive Prediction Model for Player Selection in FIFA Manager Mode,OriginalPaper,"Game is one of the most entertaining shows for today’s all generation peoples, particularly Football in most part of countries of the world. Football as a sport is only growing more and more popular every day. It is currently the world’s most-watched sport and has the highest viewership audience. As a result, a whole industry has arisen around this sport with one important part of it being FIFA. The amount of budget allocated and the number of persons involved in a Football game directly or indirectly can affect the financial budget of a person to a federation's finance. In such cases, player selection for a finalist from the federation is the most crucial task. Every year different approaches were investigated for player selections, but none of them was regarded as the best approach for team selection. Thus, there is a need for a standard approach for finding out the perfect players for their teams with the exact qualities that they demand. In response, we have developed a machine learning model that predicts players who could replace a current existing player in a team. Along with that, we have also incorporated Data Analytics that helps us decide which factors would be more important than others. The proposed prediction model is implemented and the results of our machine learning (SAGA-ML) tool are applied to Electronics Arts’ FIFA Soccer game.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-3-031-19032-2_21,en,Classification of Neuron Type Based on Average Activity,OriginalPaper,"Neuronal activity recorded in experiments is the basis for the processing, storage and transmission of information in the brain, as well as functional states. It can also carry information about the structure and type of neuronal cells involved in these processes. This paper proposes a new approach to the analysis of this type of data using modern methods of data classification. It was found that the average activity representation of spike sequences carries information about the type of neuronal cells and allows to effectively classify the initial data.","['Engineering', 'Computational Intelligence', 'Machine Learning', 'Neurosciences']"
doi:10.1007/978-3-031-13588-0_79,en,Detecting and Correcting Errors in Mental Cutting Test Intersections Computed with Blender,OriginalPaper,"Mental Cutting Test is a widely used format to develop or measure the spatial skills of people in various situations, having different purposes. An exercise consists of a 2D projection of a 3D shape and an intersection plane, denoted by a frame. The task is to choose the shape of their intersection from the set of five shapes. In this paper, we investigate a great number of different shapes that are rendered with Blender, containing various errors that change the basic morphological features of the shapes. After a human-based validation process, we developed a post-processing Python script which detects and corrects the issues of the automatically generated intersections.","['Engineering', 'Engineering Mathematics', 'Computational Intelligence']"
doi:10.1007/978-3-031-19039-1_1,en,Artificial Intelligence: An Introduction,OriginalPaper,"Artificial Intelligence has become a ripe topic of discussion, including among business leaders and in the popular press. While some of this discussion has a speculative element to it, much of it is predicated on the enormous successes of AI over the last decade, especially owing to deep learning. This chapter begins with a brief introduction to AI and its relatively young history and the differences between AI, machine learning, and deep learning. We then turn to a discussion of industries of the future and why we prefer that terminology to others. Drivers of industries of the future, including non-AI drivers, are discussed, with real-world examples and citations. We then turn briefly to the interesting question of where AI-based innovations driving industries of the future will likely come from and the important role of fundamental research. In the subsequent chapters, we dive into many of these issues in depth.","['Business and Management', 'IT in Business', 'Industries', 'Artificial Intelligence', 'Business Strategy/Leadership']"
doi:10.1007/978-981-19-3951-8_5,en,Artificial Neural Network-Based Tic-Tac-Toe Game,OriginalPaper,"The tic-tac-toe is a game for two players in which the three-row, three-column square block is filled with a cross (X) or a circle (O). A changeover will occur between the participants in the game, allowing each player shall make a choice. Reward points are awarded, if one of the players has marked the same markers as the other like horizontally, vertically, or diagonally. The goal of this research is to train an artificial neural network (ANN) how to play the tedious game of tic-tac-toe using a series of mathematical combinations of the sequences that the system would play if the rules were followed. We developed the most effective technique in the game of tic-tac-toe. The performance measures of the ANN classifier are calculated, the results of the experiment revealed that ANN can improve accuracy, and it might be utilized in other board games like Go and chess.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-3-031-11058-0_118,en,Approaches to the Task of Searching for Anomalies on the Conveyor Line Using Neural Networks,OriginalPaper,"When transporting the fabric along the conveyor, it is necessary to check the quality of the fabric. The authors have developed approaches to the problem of finding anomalies on the conveyor line. The developed approach uses neural networks. Tissue defect detection is a quality control process that aims to identify defects and determine their location. An important task is also to detect the location of defective areas. This process allows for the precise identification of defective areas and avoidance of them entering the finished product, which is of great importance for textile manufacturers. The ability to accurately pinpoint defect points to support a fabric quality control process is the primary goal of an automated patterned fabric defect detection and classification system. This should be achieved at the expense of good processing speed, less computational complexity, and less computation time. Thus, the designed systems require reliable and efficient algorithms for detecting defects. Although various types of defects have been mentioned in the literature, only a few of them have been mentioned in the case of the transportation of textiles along the conveyor. Therefore, the purpose of this article is to present personal experience of applying various approaches to detecting defects on the conveyor using technical vision and machine learning technologies.","['Engineering', 'Control and Systems Theory', 'Control, Robotics, Mechatronics', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-3391-2_39,en,MultiCity: A Personalized Multi-itinerary City Recommendation Engine,OriginalPaper,"Tourism plays a vital role for every nation today, as it can generate a large number of jobs and is the major source of revenue. Tourists face a lot of difficulties in choosing their itineraries in terms of their interest, popularity and a number of constraints. In general, it is also hard to suggest a certain city to a traveler. This work is useful for tourists who desire to visit various cities across the world. The proposed approach MultiCity recommends multiple cities keeping in mind interest, popularity and travel costs. The proposed MultiCity approach results reveals that it outperforms benchmark approaches with respect to real-life values.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Statistics, general', 'Cyber-physical systems, IoT', 'Professional Computing', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-3998-3_115,en,Dynamic Weapon-Target Assignment for Active Protection of Aircraft,OriginalPaper,"The scenario of the active protection of an aircraft is that the aircraft threatened by multiple incoming missiles (denoted as attackers) defends itself by launching multiple defending missiles (denoted as defenders). To assign defenders to attackers properly so that the survivability of the aircraft is maximized, a multi-objective Dynamic Weapon Target Assignment (DWTA) model is developed. The objectives include: the hit probability of each defender, the miss distance of each defender, the final speed of each defender, and the distance between the aircraft and the attacker when the attacker is intercepted. These objectives are various and can be calculated based on the given flight states. Machine learning algorithms are used to predict these objectives so that the computational runtime is improved. With the calculated objectives, the DWTA problem can be solved using the Kuhn–Munkres algorithm. A comparison to the traditional single objective model demonstrates that the proposed multi-objective DWTA model can provide better solution with a computational runtime improvement.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-981-19-4863-3_41,en,Automatic Brain Tumor Detection Using Convolutional Neural Networks,OriginalPaper,"Artificial Intelligence has the potential to bring about an exemplary reposition in the detection of brain tumors. Many health organizations have identified brain tumors as the second leading cause of mortality in humans worldwide. The possibility of an effective medical therapy exists if a brain tumor is identified at an early stage. For appropriate diagnosis, Magnetic Resonance Imaging (MRI) is firmly recommended for individuals with brain tumor indications. The immense geographical and structural variety of the brain tumor’s surrounding environment makes automatic brain tumor classification a challenging task. The differences in the tumor site, structure, and size present a significant difficulty for brain tumor identification. This research proposes the design and implementation of Convolutional Neural Networks (CNN) classification for enabling automatic brain tumor detection. When compared to other cutting-edge methodologies such as Support Vector Machines (SVM) and Deep Neural Networks (DNN), obtained results demonstrate that CNN repositories have a rate of 97.5% accuracy with minimal intricacy.","['Engineering', 'Computational Intelligence', 'Engineering Design', 'Machine Learning', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-1142-2_32,en,Study and Develop a Convolutional Neural Network for MNIST Handwritten Digit Classification,OriginalPaper,"The goal of this analysis has been on the development of handwritten digit recognition with the use of the MNIST dataset. In the latest days, the identification of handwritten digits has become a challenging research topic in machine learning. Due to physically formed digits having varying lengths, widths, orientations, and positions. It may be utilized in several ways, such as the amount and signature on bank checks, the location of postal and tax papers, and so on. This research used CNN for recognition. Total four steps followed by pre-processing, feature extraction, training CNN, classification, and recognition. Along with its great higher accuracy, CNN outperforms other methods in detecting essential characteristics without the need for human intervention. On top of that, it incorporates unique levels of convolution and pooling processes. Through CNN, 97.78% accuracy was obtained.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Mobile and Network Security', 'Artificial Intelligence']"
doi:10.1007/978-3-031-11447-2_4,en,The Challenge of Autonomy: What We Can Learn from Research on Robots Designed for Harsh Environments,OriginalPaper,"In addition to areas of application in people’s everyday lives and the area of education and services, robots are primarily envisioned in non-immediate living environments by the society—i.e., in inaccessible or even hostile environments to humans. The results of this population survey clearly demonstrate that such application options come across with a high level of acceptance and application potential among the population. Nevertheless, it is expected that the underlying AI in such systems works reliably and that safety for humans is guaranteed. In this chapter, the results of the study are compared with state-of-the-art systems from classical application environments for robots, like the deep-sea and space. Here, systems have to interact with their environment to a large extent on their own over longer periods of time. Although typically the designs are such that humans are able to intervene in specific situations and so external decisions are possible, the requirements for autonomy are also extremely high. From this perspective one can easily derive what kind of requirements are also necessary, and what challenges are still in front of us, when robots should be acting largely autonomous in our everyday life.","['Social Sciences', 'Sociology, general', 'Nursing Ethics', 'Artificial Intelligence', 'Social Policy', 'Politics of the Welfare State', 'Social Work and Community Development']"
doi:10.1007/978-981-19-0098-3_48,en,Error Detection and Error Concealment of Medical Images Using Frequency Selective Extrapolation (FSE) Algorithm,OriginalPaper,"The fundamental problem of any transmission procedure is the introduction of unwanted discrepancies at the output obtained. These discrepancies cause a hindrance to the further processing of vital data present in the transmitted image. As a result, some mechanisms through which error can be identified and rectified is needed. Error is prone to occur during transmission and error detection becomes extremely important. The method for error detection through correlation function and spatial error concealment of lost image information through frequency selective extrapolation (FSE) algorithm in erroneous medical image transmission on a network is illustrated in this paper. X-ray image is used here as a medical image. This can be used for testing whether COVID, normal, or pneumonia. In this COVID scenario, the traveling is restricted and even in rural areas they cannot travel frequently. So, diagnosis can be done through the transmission of medical image taking into account the availability of a suitable transmission medium for the same.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Statistics, general', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3371-4_7,en,A Multi-objective Optimization Framework for Sustainable Retrofit of Indian Buildings,OriginalPaper,"The energy efficiency of an existing building is a major concern for ensuring sustainability in the building sector, and repairs and retrofitting are the major options that are currently being followed to enhance the energy performance. To get an optimal choice of building materials and getting a feasible decision on various retrofitting activities within the given cost and energy constraints, the Multi-objective optimization technique (MOO) is implemented in the building energy science domain. It gives an optimal solution between cost and energy criteria that helps the decision-makers to take balanced and feasible decisions for the selection of building materials and improving building energy performances. However, while doing repairs and retrofit of the building, minimizing the retrofitting cost as well as minimizing the energy consumption is a challenging part to achieve. This paper focuses on the optimization of retrofitting works on an existing residential building under Indian conditions in which the MOO technique is implemented to get feasible decisions both in terms of cost and energy savings. The Genetic Algorithm (GA) based optimization method is used to perform optimization on two objective functions. Based on various budget constraint equations, the Pareto optimal solutions set is obtained between the overall retrofitting cost and embodied energy of materials used in retrofitting. This helped as a decision-supporting tool to get the optimal choice of energy saving construction materials and to take feasible decisions for both material cost and energy. This study helps the decision-makers in achieving economic feasibility as well as improving building energy performance which is essential for sustainable buildings.","['Engineering', 'Building Construction and Design', 'Building Materials', 'Structural Materials']"
doi:10.1007/978-981-19-4975-3_57,en,VSC for DG Integration and Harmonics Reduction,OriginalPaper,"This paper presents an algorithm for optimum utilization of the grid connected Voltage Source Converter (VSC) for power quality improvement and the integration of Distributed Generation (DG) sources. Conventionally, VSC is used as an interfacing device for DG with grid, and a separate VSC is used for intensification of power quality issues. This paper suggests the use of the same VSC for DG integration and for power quality enhancement also. The targets of the application is to: (1) inject available active power from DG to power grid, (2) harmonic mitigation of load side grid current, (3) keep grid current three phase balanced in case of fault at the load side, (4) operate system safely in condition of frequency deviation. The proposed algorithm shows very fast and robust response which is due to its less complex circuitry. Furthermore, the use of phase-locked loop (PLL) is eliminated with increase in the speed of operation of the system. Simulation of the proposed work considering most of the power system operating conditions is done to present the effectiveness of the work.","['Engineering', 'Power Electronics, Electrical Machines and Networks', 'Energy Policy, Economics and Management', 'Energy Systems']"
doi:10.1007/978-981-19-5292-0_2,en,Scientific Exploration of Music Recommendation System Using Facial Expressions,OriginalPaper,"This paper is about the music recommendation system, which will provide songs to the user according to their facial expressions or emotions. The deep learning algorithm and the CNN approach are being used to build the system. DNN approach is been used for classification of music. This paper surveys the various methods that identify the mood of a user through the user’s facial expression, which, in turn, helps in recommending the music to be played as per the user’s mood. The algorithm is quite helpful when the playlist is shuffled and has a number of songs in it. Thus, a user is confused in identifying the music to be played based on the moment. In case of a sad mood, the user may even get into the worse mood, if he/she needs to scan the playlist. The paper studies the state-of-the-art methods given by various researchers and compares their accuracy and efficiency among each other. The objective of this paper is to convey the researchers about the work done in this area and identify the issues and challenges in different models.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-981-19-1610-6_76,en,A Post-quantum Zero-Knowledge Proof System Using Quantum Information Theory,OriginalPaper,"In recent decades, the importance of protecting computer systems and networks from information disclosure (relevant to information technology and cybersecurity fields) has risen to the utmost importance. With wide applications in subjects such as voting registration, insurance, credit card information, personal identity security, and as of recently crypto-based blockchains, the field is becoming increasingly significant. Due to the perpetual and expanding reliance on computer systems, the way that we handle and send our data is vital. Improper methods of establishing privacy for secure data transmission can compromise substantial amounts of user data, making the development of high-level privacy-preserving mechanisms impervious to tampering of immense importance. For example, the existence of most cryptographic systems is threatened by the development of quantum computing, and therefore, the development of making post-quantum/quantum-resistant cryptographic systems is in great demand. In this research, unlike most current existing systems, we propose a classical to quantum mapping channel for zero-knowledge that will not be negatively affected by the existence of quantum technologies.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4863-3_52,en,Popularity of Optimization Techniques in Sentiment Analysis,OriginalPaper,"In today’s scenarios, online marketing and social networking require sentiment for opinion mining to understand its customers and users. The sentiment analysis involves extracting information from the text and symbols shared by the individuals over the website reflecting their opinions. It describes various emotions of the customers based on any product. Sentiment analysis is applicable to monitor social media that recognized the mood of customers against the brand or any other product. It has been observed that a variety of techniques were used to optimize the features extracted during sentiment analysis. In the present paper, the author has presented a detailed literature survey to outline the popularity of optimization techniques used in the field of sentiment analysis. The literature review conducted over the authenticated research published in the last decade had illustrated that most of the researchers had implemented Ant Colony Optimization (ACO) and Particle Swarm Intelligence (PSO) as optimization techniques. In addition to this hybrid, optimization had also been emerging in recent years. The work outcomes are supported by the graphical illustrations to show the rising popularity of optimization techniques in the field of sentiment analysis.","['Engineering', 'Computational Intelligence', 'Engineering Design', 'Machine Learning', 'Communications Engineering, Networks']"
doi:10.1007/978-3-031-20141-7_2,en,Using Optimization to Construct Naturally Parametrized Curve with Cubic Curvature,OriginalPaper,The article describes a mathematical model and an algorithm to construct a curve passing through two given points and having given tangent angles and curvature values. The conditions imposed on the curve are formulated by four nonlinear integral equations with respect to four unknown variables. Finding a solution of this system of equations is reduced to a non-smooth optimization problem solved by a modification of r-algorithm. Computational results are presented for a corresponding problem in aerodynamics.,"['Engineering', 'Computational Intelligence', 'Transportation Technology and Traffic Engineering', 'Manufacturing, Machines, Tools, Processes']"
doi:10.1007/978-981-19-0179-9_11,en,Comparative Study of Eight Classification Models for Diagnosis and Prediction of Breast Cancer,OriginalPaper,"Nowadays, breast cancer is creating wea big problem for women all over the world. Correct and early prediction of disease is very much important for the treatment of curing the disease. Women identified at the stage of benign have high chances of getting curable but identifying at the stage of malignant is regarded as a dangerous state of cancer. Many machine learning algorithms are used for the diagnosis of breast cancer effectively. In this article, eight classification models such as Logistic Regression (LR), K-Nearest Neighborhood (K-NN), Decision Tree (DT), Random Forest (RF), Artificial Neural Network (ANN), Gaussian Naïve Bayes (NB), Support Vector Machine (SVM), and AdaBoost classifier are used for predicting two classes, i.e., benign and malignant. To choose the best fit classification model for prediction, a confusion matrix is used to evaluate the performance of each model. Also, parameters such as accuracy, precision, recall, specificity, F-measure, and Matthews correlation coefficient (MCC) are discussed for each model. For experimental results, the Wisconsin Breast Cancer Diagnosis dataset and Coimbra Breast cancer datasets are used, and at last, a comparison is being done for all of these models.","['Engineering', 'Computational Intelligence', 'Engineering Mathematics', 'Communications Engineering, Networks', 'Statistics, general', 'Artificial Intelligence']"
doi:10.1007/978-3-031-18409-3_5,en,An Anomaly Detection Approach for Realtime Identification Systems Based on Centroids,OriginalPaper,"The present research describes a novel adaptive anomaly detection method to optimize the performance of nonlinear and time-varying systems. The proposal is based on combining the real-time identification algorithm, Recursive Least Squares, with a centroid-based methodology. For anomaly detection, the method compares the current system dynamics with the average (centroid) of the dynamics identified in previous states for a specific setpoint. If the dynamics difference exceeds a certain threshold, the system classifies it as an anomaly. Otherwise, the centroid is updated by introducing the newly identified data. Finally, the proposed method was tested on a real system, in this case, on the level control plant, obtaining a good performance in anomaly detection.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Education, general']"
doi:10.1007/978-981-19-3679-1_56,en,Comparative Analysis on Effect of Different SVM Kernel Functions for Classification,OriginalPaper,"Besides linear classification, Support Vector Machine (SVM) is proficient in non-linear classification by deploying kernel tricks that implicitly maps and transform input features to high dimensional feature space. Kernel-SVM, can be utilized to secure progressively complex connections on datasets with no push to do changes all alone. In this paper, 5 different SVM kernel functions are implemented on 4 datasets, viz., IRIS, Breast Cancer Wisconsin (diagnostic), Mushroom and Letter Recognition Dataset. The five kernel functions considered in this paper are: Linear kernel, Gaussian Radial Basis Function (RBF) kernel, Laplacian kernel, Polynomial kernel and Sigmoid kernel. Our goal is to locate the best non-linear kernel. The outcomes show that the precision of expectation for Laplacian kernel is most extreme with a forecast scope of (max 100%, min 97.53%) and least for the sigmoid kernel with a forecast scope of (max 100%, min 47.28%).","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-3-031-18256-3_46,en,Lung Segmentation Algorithm and SVM Classification of COVID-19 in CT Images,OriginalPaper,"The analysis of COVID-19 by tomographic imaging has been a standard for pandemic management. The application of different types of artificial intelligence algorithms has proven to be an accurate method for disease detection. This study presents a method of lung segmentation and a classification algorithm that allows to discriminate between images that show signs of the disease and those that don’t. In addition, the article seeks to establish what kind of features are relevant when feeding a machine learning algorithm. Texture features extracted from Gray Label Concurrence Matrix (GLCM) and a Gabor filter are used for this purpose. Then, we trained and evaluated a SVM algorithm using different combinations of features. It is found that the features extracted from the Gabor filter work better than those extracted from the GLCM, finding that those features focused exclusively on intensity description work better than those focused on spatial description, at least in early stages.","['Engineering', 'Biomedical Engineering and Bioengineering', 'Regenerative Medicine/Tissue Engineering', 'Bioinformatics']"
doi:10.1007/978-981-19-5403-0_28,en,Automated Room Occupancy Prediction Using Fuzzy-Rough Set Theory-Based Supervised Learning,OriginalPaper,"Among the many research problems that appeal to the scientific community toward smart, IoT-enabled developments, human activity recognition has always been relevant and interesting. This human activity recognition of active research offers several enticing challenges, such as single person activity recognition, group activity recognition, monitoring and tracking toward indoor healthcare, and room occupancy estimation. Out of these, room occupancy classification from passive data is an important one. While most works focus on the use of conventional learning or deep learning algorithms toward developing an automated solution, the recent progress in fuzzy-set and rough-set theory can be advantageous in solving data-driven problems. The proposed work leverages this mathematical complexity of the convergence of fuzzy-rough set theories along a conventional machine learning algorithm to provide a smart solution to the problem of room occupancy estimation. The experiments reveal that the conventional learning algorithm alone is outperformed by the chosen fuzzy-rough set theory-based classification approach, with a high accuracy of 99.96%.","['Engineering', 'Computational Intelligence', 'User Interfaces and Human Computer Interaction', 'Data Structures and Information Theory', 'Artificial Intelligence', 'Data Mining and Knowledge Discovery']"
doi:10.1007/978-981-19-3387-5_172,en,Cell Expansion Priority Recommendation Based on Prophet Algorithm,OriginalPaper,"In recent years, both LTE and 5G experiences fast development and construction world-widely. Under the explosive business demand and massive mobile terminal equipment connection, the guarantee of network load is of vital importance. This paper proposes a recommendation model for cell expansion priority. Initially, it uses the Prophet algorithm to predict cell traffic trends based on user behavior characteristics in different scenarios. Then it defines expansion warning thresholds according to different expansion types. Finally, combining cell traffic trends and expansion thresholds, a recommendation model is established. The proposed model can assist network optimizer more accurately grasp the current network capacity situation and future capacity trend, monitor the indexes of network expansion dynamically. Besides, this model can also follow the expansion principle of timeliness and predictability, which can make rational use of expansion investment and guarantee user perception.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Aerospace Technology and Astronautics']"
doi:10.1007/978-3-031-19032-2_3,en,Addressing Task Prioritization in Model-based Reinforcement Learning,OriginalPaper,"World models facilitate sample-efficient reinforcement learning (RL) and, by design, can benefit from the multitask information. However, it is not used by typical model-based RL (MBRL) agents. We propose a data-centric approach to this problem. We build a controllable optimization process for MBRL agents that selectively prioritizes the data used by the model-based agent to improve its performance. We show how this can favor implicit task generalization in a custom environment based on MetaWorld with a parametric task variability. Furthermore, by bootstrapping the agent’s data, our method can boost the performance on unstable environments from DeepMind Control Suite. This is done without any additional data and architectural changes outperforming state-of-the-art visual model-based RL algorithms. Additionally, we frame the approach within the scope of methods that have unintentionally followed the controllable optimization process paradigm, filling the gap of the data-centric task-bootstrapping methods.","['Engineering', 'Computational Intelligence', 'Machine Learning', 'Neurosciences']"
doi:10.1007/978-3-031-15758-5_40,en,Numerical Evaluation of Parametric Updating by Genetic Algorithm Implementation,OriginalPaper,"The present work compares the numerical performance of parametric updating between a proprietary tool and the GA/Matlab toolbox, using a genetic algorithm. The precision and processing time of parameter identifications are evaluated for two structural systems: (a) a numerical cantilever beam; and (b) the experimental results of a free-free beam. Parametric updating uses classic metrics for cost functions, for example: natural frequency, modal form, and the linear weights of the above. This work is part of the Demonstration Platform on Structural Integrity, a project developed collaboratively between the PPG Integrity (FGA-FT/UnB) and Embraer.","['Engineering', 'Vibration, Dynamical Systems, Control', 'Robotics and Automation', 'Computational Mathematics and Numerical Analysis']"
doi:10.1007/978-981-19-1669-4_21,en,Network Intrusion Detection Using Machine Learning for Virtualized Data,OriginalPaper,"Network uses the intrusion detection system when it has to examine the malicious activity in it. In this process, the system is scanned by the intrusion detection system which is a device or software for detecting or identifying the malicious activity. Security mechanisms are required for the substantial growth in the number of applications in order to maintain their protection. There are different types of intrusion detection methods like anomaly based and signature based, but most trending subject to the researchers is machine learning (ML)-based methods. Accuracy is the most influenced parameter for intrusion detection performance. False alarm reduction and detection rate increment or detecting time decrement can be achieved with improvement in the intrusion detection system accuracy. A network intrusion detection using ML for virtualized data is proposed in this paper. Better accuracy is simultaneously increasing the performance. Intrusion detection system main work is huge network traffic data analysis. The classification problems can be solved by machine learning techniques such as Naïve Bayes, random tree, and support vector machine (SVM). NSL-KDD (knowledge discovery dataset) is used for evaluation of proposed intrusion detection system. To perform comparative analysis, average detection time, misclassification rate, and accuracy are calculated.","['Engineering', 'Signal, Image and Speech Processing', 'Circuits and Systems', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-18461-1_14,en,Graph Emotion Distribution Learning Using EmotionGCN,OriginalPaper,"Emotion of a person can be identified by the patterns in their ability to think, respond, communicate, or behave in a social environment. It is highly influenced by the emotion, making decisions, and exhibiting behaviors with the surroundings and other well-being. The emotion identification of person is very much useful in the case medical domain. The problem in detecting the emotions from these data is a single image can exhibit different emotions for different persons in their own perspective. With the advancement in the field of computer vision, the adoption of deep convolutional network paved a way to creating a convolutional neural network model which can learn these emotions from the input given and a graph convolutional network to estimate the probability distribution of whole data of emotions as well as the form the data of each emotion separately. The distribution of each emotion can be converted to a graph-based data so that it can be stored and used to train new models without the need for long training time. These graph data are more compatible and paves the way to perform further psychological analysis to extract patterns in them.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3998-3_166,en,An Optimized Flocking Motion with Attention Module for Obstacle Avoidance,OriginalPaper,"A flocking control algorithm with attention module for obstacle avoidance is proposed, which is based on the classical rules of Reynolds. To enable the self-organized swarm having better environmental adaptability, the coefficients of social force are determined as variables, optimized by using the non-dominated sorting genetic algorithm II (NSGA-II). In this work, two different obstacle avoidance models are elaborated, one is with obstacle attention module and the other is with potential field module. Then, the experiment for the self-organized swarm with tasks moving towards the target zone without obstacle collisions is set up and the two models are compared in this scene. From the results, the flocking control model with attention module shows better performance in collisions and motion consistency, nearly 32.35% improvement in time cost and a 30.94% improvement in aggregation degree.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-981-19-0561-2_5,en,Optimum Scheduling and Routing of Material Through Computational Techniques,OriginalPaper,"Scheduling and routing are two dominating factors in any production house that determine the throughput of the system. Proper scheduling ensures ‘When’ a particular activity is carried out, while the routing guarantees ‘Where’ is the activity executed. This paper emphasizes the collective use and elaboration of computational techniques for optimum scheduling and routing of material flow in an industrial environment achieved by amalgamating traditional techniques and methodologies with modern computational solutions. This computational piece of program deployed in and for the industry is programmed in python language along with further post computation enhancement that is done using Project Libre’s .xml file support. The program computes the minimum possible production time for given inputs subjected to constraints applicable and also the most optimum route for smooth material flow throughout the floor. A user-friendly U.I. has been developed along with further analysis aided by modifying the .xml file to provide the Gantt chart for floor level reference. A substantial increment in production activity was observed which also led to the establishment of an autonomous system for scheduling and routing.","['Engineering', 'Industrial and Production Engineering', 'Engineering Design', 'Machinery and Machine Elements']"
doi:10.1007/978-981-19-2394-4_8,en,Comparative Analysis Between Macro and Micro-Accuracy in Imbalance Dataset for Movie Review Classification,OriginalPaper,"Classification for multi-class dataset provides exciting and explorative domain to be studied in data science domain. And yet, the challenges of measuring the accuracy of multi-class performance rise an issue worth detailed research to be explored. Due to multi-class accuracy may be lower due to imbalance dataset, this paper aimed to analyze the usage of macro and micro-accuracy in classifying text data with multi-class label. This research focused on text data of movie reviews being classified by three multi-class classifier which are Naïve Bayes (NB), Support Vector Machine (SVM), and Random Forest (RF). We set five performance measure to be analyzed; recall, precision, f-score, sensitivity and specificity with regards of micro and macro-accuracy. We successfully yielded a significant result of comparative analysis where average micro-accuracy (87.3%) produced 14.8% higher than macro-accuracy (72.5%) for imbalance dataset. Result also shown a significant gap between balanced and imbalanced dataset. For further analysis, the flexibility of class label in multi-class may be studied to obtain the changing of learning behavior of the classifier as future work.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4143-6_2,en,General Technology,OriginalPaper,"The three core tasks of autonomous vehicle are cognition, decision-making and control. In the process of driving, the vehicle perceives the surrounding environment and road conditions by itself, completes the processing and fusion process based on perceptual information to form an understanding of the overall situation, then makes decisions on how to deal with it through various algorithms.","['Engineering', 'Mechanical Engineering', 'Machinery and Machine Elements', 'Artificial Intelligence']"
doi:10.1007/978-3-031-12011-4_82,en,Hyper-parameter Optimised Artificial Neural Network Model for Failure Mode Identification of RC Shear Wall,OriginalPaper,"A reinforced concrete (RC) shear wall is a popular lateral-force-resisting element in high-rising structures for better seismic performance and damage reduction. Hence, it is essential to predict the shear wall’s failure modes and collapse resistance. The mechanics-based approach is very involved and time-consuming to accurately predict failure modes of RC shear walls subjected to seismic loading. Neural networks can describe complex input–output functional relationships with their general nonlinear mapping capacity. This study investigates the efficiency of the Artificial Neural Network (ANN) model to predict the failure modes of RC shear walls employing a limited experimental dataset. The dataset consists of 393 one-story, one-bay reinforced concrete shear walls with sliding shear failure, shear failure, flexure-shear failure, and sliding shear flexural failure as the four classes of failure modes. For each data sample in the database, nine input parameters are considered as the input features, including the wall configuration, reinforcement index, and cross-section shape. The study also optimises the performance of the model by investigating the hyper-parameters. Various hyper-parameter optimisation methods such as random search, grid search, hyperband, genetic algorithm (GA), Bayesian Optimization (BO), and particle swarm optimisation (PSO) are considered to improve the baseline model. These hyper-parameter tuned models are evaluated and compared using various performance parameters such as accuracy and f1 score. This study can contribute to developing improved ANN models by effectively identifying the proper hyper-parameter configurations and their subsequent optimisation.","['Engineering', 'Construction Management', 'Building Construction and Design', 'Geotechnical Engineering & Applied Earth Sciences']"
doi:10.1007/978-981-19-3250-2_12,en,A Hybrid Random Walk Algorithm for 3-D Thermal Analysis,OriginalPaper,"A hybrid random walk method is presented for the thermal analysis of integrated circuits. Preserving the advantage of generic random walk method (GRW), i.e. the suitability for simulating local hot-spots, the proposed techniques largely reduce its runtime for accurate high-resolution simulation, and is suitable for the realistic pyramid-shape IC model. This is achieved by combining the GRW and the floating random walk techniques, and a novel usage of rectangular cuboid transition domain. The techniques to handle Neumann boundary and convective boundary in thermal simulation are also discussed. Numerical experiments on several integrated circuit (IC) test cases validate the efficiency and accuracy of the proposed techniques, and demonstrate several tens times speedup over the GRW method while keeping high accuracy.","['Engineering', 'Electronics and Microelectronics, Instrumentation', 'Engineering Mathematics']"
doi:10.1007/978-981-19-3788-0_25,en,Research of Projection Algorithms for Solving Problems of Measuring Angular Coordinates of Low-Flying Radar Targets,OriginalPaper,"In the presented work, the urgent problem of detecting low-flying radar targets is touched upon. The problem has been known for a long time, but only now, there are computing capacities for testing algorithms for measuring angular coordinates. In this regard, the study of the ESPRIT super-resolution algorithm is carried out, and the error of measuring angular coordinates is estimated depending on the height of the surface irregularities. The presence and magnitude of this error are directly related to an increase in the power of the diffuse component of the signal, which in turn destroys correlations in the elements of the antenna array, on which the measurement of angular coordinates by the ESPRIT algorithm is based.","['Engineering', 'Aerospace Technology and Astronautics', 'Engine Technology', 'Engineering Thermodynamics, Heat and Mass Transfer']"
doi:10.1007/978-3-031-17544-2_9,en,Diabetes Twitter Classification Using Hybrid GSA,OriginalPaper,"In today’s world, it is important to understand individuals’ health related opinions through sentiment analysis. Recently, many deep learning methods such as deep convolution neural network (CNN), Gated Recurrent Unit (GRU) and LSTM (Long short-term memory) are used to classify sentiments. This chapter focuses on diabetes tweet classification using the proposed Hybrid GSA, which is a combination of a Capsule Network (Deep Learning technique) and a Gravitational Search Algorithm. This approach is applied to perform sentiment classification such as positive, strong positive, negative, strong negative, and neutral using tweets on Twitter. It is observed from the results that the proposed approach produced better classification results compared to the existing approach. This work proved to be very effective in handling health tweets and accurate in classification.","['Engineering', 'Computational Intelligence', 'Biomedical Engineering and Bioengineering', 'Health Informatics']"
doi:10.1007/978-981-19-3590-9_43,en,An ECG Signal Encryption and Classification Utilizing Advanced Encryption Standard and Support Vector Machine,OriginalPaper,"Encryption has sparked interest in privacy concerns in health care, with a growing demand for privacy-preserving data collecting methods that keep personal information buried in otherwise useable data. Data is sometimes encrypted for multiple authentication tiers, with a semi-authorized user gaining access to data scrubbed of sensitive or personal information, while a fully authorized user recovering the entire signal. Hence, in this paper, an encryption and classification process is done on the basis of AES together with chaotic logistic mapping for the purpose of ECG signal encryption as well as decryption. The feature extraction is accomplished by CNN. Finally, the data classification is done with the help of SVM. The suggested strategy achieves better classification accuracy in experimental verification, which is significantly superior to traditional classification algorithms.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security', 'Mobile and Network Security']"
doi:10.1007/978-981-19-3998-3_37,en,Distributed Switching Time Optimization for Interconnected Switched Systems,OriginalPaper,"In this paper, the problem of time distributed optimization for interconnected switched system is considered. Two hierarchical scheme-based optimization algorithms are proposed, where one is an off-line algorithm based on the dual decomposition technique and the other one is an on-line algorithm based on state feedback control formulated by the optimal switching hyperplane.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-3-031-08693-9_10,en,Advanced Issues in Migrating to Hardware: MIMO Decoders as Case Studies,OriginalPaper,"In this chapter, we use MIMO decoders as an example of migrating complicated algorithms to hardware. In this case, we do not have straightforward arithmetic or logic that can be readily transformed to hardware. Instead, we must invest some effort into finding a processing unit that best maps the strange arithmetic of MIMO decoding to hardware. In this case, we are best served by the CORDIC processor, which simultaneously solves a lot of our problems while creating a host of new ones.","['Engineering', 'Circuits and Systems', 'Microwaves, RF and Optical Engineering']"
doi:10.1007/978-3-031-06829-4_8,en,An Automated 4D BIM Model Development and Optimization,OriginalPaper,"Integrating Building Information Modelling (BIM) and Integrated Project Delivery (IPD) is highly recommended for better project delivery. Although there is a methodology for this integration, the BIM requires some improvements to foster the adoption of IPD. This chapter presents an innovative way to support the 4D BIM automation/optimisation within the IPD approach. This research proposes a planning library similar to structural and architectural design libraries to automate schedule formulation and embed multiobjective optimisation into the 4D BIM. The literature review was utilised to highlight the existing improvement of using 4D BIM and the multiobjective schedule optimisation. Using a case study to validate the developed framework and measure its applicability, the results show a cost-saving of 22.86% due to the proposed automated multiobjective optimisation. Furthermore, the case study shows the significance of integrating Activity-Based Costing (ABC) into 4D BIM to configure the hierarchy level of overhead activities with the IPD approach. Therefore, the most contribution level in managing the IPD project was by the trade package level by 33.33%, and the minimum contribution was around 8.33% by the project level. This research presents a new philosophy to develop the 4D BIM model—Planning and scheduling—A BIM library of the project activities is developed to enable the automation of creating the project schedule concerning the 3D BIM design sequence. The optimisation of the project duration is considered to be automated within the creation process using the proposed genetic algorithm model.","['Engineering', 'Building Construction and Design', 'Cyber-physical systems, IoT', 'Professional Computing', 'Construction Management']"
doi:10.1007/978-981-19-4975-3_53,en,Retinal Image Enhancement for Detection of Medical Complications—A Summary,OriginalPaper,"Retinal Image is an image obtained from a Fundus camera which is used for the detection of abnormalities and unwanted growth of cells. For proper identification of abnormalities (Retinal Diseases) present in an image, an adequate amount of image enhancement is required. The presence of any medical complications may lead to loss of eye vision, thus a diagnostic system is extremely required. Diabetic retinopathy is one of the majorly present medical complications that affect human vision. In this paper, the retinal image enhancement techniques using histogram equalization, adaptive histogram equalization, brightness preserving bi-histogram equalization, dual-tree complex wavelet transform, and contrast limited adaptive histogram equalization techniques are discussed. For comparison of these techniques, parameters like mean square error, peak signal-to-noise ratio, structural similarity index metrics, absolute mean brightness error, and root mean square error are available. These parameters can help in an early-stage diagnosis of retinal complications.","['Engineering', 'Power Electronics, Electrical Machines and Networks', 'Energy Policy, Economics and Management', 'Energy Systems']"
doi:10.1007/978-981-19-4863-3_15,en,Hybrid Approach of Modified IWD and Machine Learning Techniques for Android Malware Detection,OriginalPaper,"Mobile phones have become an indispensable part of our daily lives due to the rapid improvement in smartphone technologies. The increased use of smartphones in online payments has attracted cybercriminals and is contributing to the rise of malware infections. Many cyberattacks are caused by mobile application vulnerabilities and malware. As a result, these attacks pose a significant threat to smartphone security. In general, big datasets are employed for malware analysis, and these datasets may contain numerous redundant, inappropriate, and noisy features, causing misclassification and low detection rates. So, we have to choose the most important features from the dataset. This research work presents a hybrid model for malware detection, based on a modified intelligent water drop algorithm (IWD) and ML techniques. To investigate the performance of the proposed techniques, we used the DREBIN dataset. The results of the experiments reveal that this approach removes more than 60% of irrelevant features from the dataset effectively and produce a promising result.","['Engineering', 'Computational Intelligence', 'Engineering Design', 'Machine Learning', 'Communications Engineering, Networks']"
doi:10.1007/978-3-031-06780-8_15,en,Towards Learning-Based Control of Connected and Automated Vehicles: Challenges and Perspectives,OriginalPaper,"The exploitation of communication technologies enables connected and automated vehicles (CAVs) to operate more collaboratively, that is, by exchanging or even negotiating future trajectories and control actions. That way, CAVs (or agents) can establish a networked control system such as to safely automate road traffic in a collaborative fashion. A rich body of literature is available, e.g., on intersection automation, automated lane change or lane merging scenarios. These control concepts, though, are most tailored to the particular application and are in general not applicable to multiple scenarios. This chapter conveys the challenges and perspectives of modeling and optimization-based control techniques for the safe coordination of multiple connected agents in road traffic scenarios. Along these lines, the perspective of generalizing controller design to serve multiple use cases simultaneously instead of designing separate controllers for every use case is discussed. Moreover, the opportunities of learning-based control in case of model uncertainties and mixed-traffic scenarios, involving connected and non-connected agents, are outlined.","['Engineering', 'Automotive Engineering', 'Computational Intelligence', 'Transportation Technology and Traffic Engineering', 'Signal, Image and Speech Processing']"
doi:10.1007/978-981-19-1669-4_9,en,Intelligent Traffic Light System Using YOLO,OriginalPaper,"Day-by-day traffic is increasing due to the technology limit in the traffic control. We made a critical survey and found the existing systems and their shortcomings. Currently time slot is fixed for each lane. Though the traffic is less in any lane the lights will glow up to a fixed time slot. As a result, vehicles in the other lanes having more traffic density have to wait for a long time. This problem can be solved by our proposed system that works depending up on the traffic density in each lane. A real-time traffic detection is extremely significant especially in the metropolitan cities. In this paper we are proposing a real-time traffic controlling system that is developed by using image processing, cloud, embedded board and You Only Look Once (YOLO) v4 algorithm. Our system computes the vehicle detection, vehicle count and classifies the vehicle. The vehicle count is utilized to calculate the traffic density. This YOLO v4 network maintains the precision, recall and F-score in the vehicle detection and traffic control. Our proposed system executes better performance than the existing systems.","['Engineering', 'Signal, Image and Speech Processing', 'Circuits and Systems', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3148-2_2,en,"Process of Recognition of Plant Diseases by Using Hue Histogram, K-Means Clustering and Forward-Propagation Deep Neural Networks",OriginalPaper,"Nowadays, plant disease detection became recent research area for scientists all over the world that segment and recognize leaf disease from plant image. In order to automatically segment and classify various leaf disease regions, a new method is proposed. The suggested procedure is broken down into four steps: To begin with, the background noise in the plant image is reduced using the median filter. Hue histograms and K-means algorithms are used to identify disease spot and separate leaves spots into uniform areas. Cluster that has highest hue value is extracted as disease segment. Finally, a forward-propagation deep neural network (FPDNN) classifier is adopted that uses fifteen colours and texture features extracted from disease objects to make accurate diagnoses. We used the Levenberg–Marquardt back-propagation procedure to fine-tune the results. This classifier outperformed other state-of-the-art classifiers when tested on hidden layers ranging from one to forty. The proposed approach is implemented in Neural Network Pattern Recognition Tool (NPRT) in MATLAB 20a. The experimental results on the developed model achieved high accuracy and F1 measures as 94 and 96%, respectively.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory']"
doi:10.1007/978-981-19-2255-8_19,en,Traffic Flow Prediction of Expressway Section Based on RBF Neural Network Model,OriginalPaper,"In order to further improve the prediction accuracy of expressway traffic flow, this study proposed an RBF neural network model. Firstly, RBF is used to train the model by using ETC (Electronic Toll Collection) gantry historical data considering the time-varying characteristics of the flow, to ensure the similarity of the flow curve and robustness of the model. Then, taking three typical ETC gantries from thirty gantries of Beijing-Shanghai Expressway in Shandong province as an example, the accuracy of the model is verified by using the historical operation data of them during holidays. The results show that: (1) The flow of ETC gantry section in holidays predicted by RBF is closer to the actual value, and the prediction accuracy is significantly better than that of BP and ELMAN. (2) The MAE is within 75 veh/min, the RMSE is within 6veh/min, and the MAPE is less than 4.5%.","['Engineering', 'Communications Engineering, Networks', 'Wireless and Mobile Communication', 'Signal, Image and Speech Processing', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-5438-2_17,en,Stationary Wavelet Transform Aided Fault Detection for LDTV Systems,OriginalPaper,"This chapter confines to a stationary wavelet transform (SWT) aided parity space approach to FD for LDTV systems, aiming at improving the FD performance of lower parity space order with an acceptable increase of computation load. In the sense of maximizing the sensitivity/robustness ratio criteria, a bank of parity relation based residual generators are first constructed. By virtue of the merits of wavelet transform in capturing the time-frequency features of faults, the selection of a bank of parity space vectors are then converted into solving a group of sensitivity/robustness ratio maximization problems. SVD based analytical solutions are derived by using the recursive algorithm of SWT. Compared with the traditional parity space-based method, this scheme, on the one hand, can improve the sensitivity/robustness ratio performance with a given parity space order and, on the other hand, can detect faults within wider frequency band at a zero FAR, while with acceptable increase of computation cost.","['Engineering', 'Control and Systems Theory', 'Mathematical and Computational Engineering', 'Systems Theory, Control']"
doi:10.1007/978-981-19-0095-2_34,en,A Review of Various Line Segmentation Techniques Used in Handwritten Character Recognition,OriginalPaper,"Segmentation is a very critical stage in the character recognition process as the performance of any character recognition system depends heavily on the accuracy of segmentation. Although segmentation is a well-researched area, segmentation of handwritten text is still difficult owing to several factors like skewed and overlapping lines, the presence of touching, broken and degraded characters, and variations in writing styles. Therefore, researchers in this area are working continuously to develop new techniques for the efficient segmentation and recognition of characters. In the character recognition process, segmentation can be implemented at the line, word, and character level. Text line segmentation is the first step in the text/character recognition process. The line segmentation methods used in the character recognition of handwritten documents are presented in this paper. The various levels of segmentation which include line, word, and character segmentation are discussed with a focus on line segmentation.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Systems and Data Security', 'Artificial Intelligence', 'Computational Intelligence']"
doi:10.1007/978-981-19-2535-1_13,en,Distributed Consensus Mechanism with Novelty Classification Using Proof of Immune Algorithm,OriginalPaper,"Peer-to-peer lending is an emerging financial domain enabling people to receive instant credit facilities without much complicated procedures and intermediaries. Many financial institutions are focusing on setting up peer-to-peer lending platforms to enable hassle-free credit facilities with transparency between lenders and borrowers. The trust and transparency for hassle-free settlement and addressing novelties is a major concern in this domain which is hindering the mainstream adoption of such lending platforms. The objective of this paper is to propose a trusted and transparent distributed ledger approach using blockchain technology for setting up peer-to-peer lending platforms. The proposed approach creates cryptographically secured transactions stored over a publicly verifiable immutable ledger, which ensures credibility and auditability to investors and borrowers on every aspect of security. Proof of Immune Algorithm was proposed by leveraging the potential dendritic cell algorithm mimicking human immune system to provide consensus among peers involved in the lending process to enable trust.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2535-1_22,en,The Proposed Context Matching Algorithm and Its Application for User Preferences of Tourism in COVID-19 Pandemic,OriginalPaper,"Currently, many applications of information search tourism are limited in the COVID-19 pandemic using a search engine. However, most application service online has not supported directly, matching end users with their preferences to find suitable tourist places. This paper has presented a proposed model using the Context Matching algorithm mostly based on the Smartphones; matching with user’s preferences and behaviors allows users to find tourism packages and regions. The experimental results show that the proposed model achieves significant improvements in matching user preferences for the domain under dynamic uncertainty. We posit that our novel approach holds the prospect of improvements in user preferences for tourism and weather in the COVID-19 Pandemic.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-7210-2_5,en,Multi-fidelity Surrogate Assisted Efficient Global Optimization,OriginalPaper,"As reported in the previous literature, multi-fidelity (MF) surrogate assisted design optimization techniques can be classified into two types: offline and online techniques. In the offline technique, a prespecified number of sample points is used to build an MF model to replace the simulation analysis in the engineering optimization process.","['Engineering', 'Engineering Design', 'Optimization', 'Engineering Mathematics', 'Mathematical Modeling and Industrial Mathematics']"
doi:10.1007/978-981-19-4143-6_6,en,Motion Control and Planning Decision-Making Technology,OriginalPaper,"PID control is one of the earliest control strategies, and its algorithm principle is shown in Fig.  6.1 . Because of its simple algorithm, strong robustness and high reliability, it is widely used in various control systems, especially in deterministic control systems with an accurate mathematical model.","['Engineering', 'Mechanical Engineering', 'Machinery and Machine Elements', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4606-6_77,en,Selection of Optimal Process Parameters for Electric Discharge Machining of 13/8 PH Steel Using Genetic Algorithm,OriginalPaper,"EDM is a non-traditional machining process used for high strength to weight ratio material and high-heat resistance materials. This paper undertakes a comparative study between optimization using the Taguchi method and the genetic algorithm on 13/8 PH steel using die sinking EDM. The advantage of EDM is its unconventionality wherein performs machining without any contact between tool and work piece. This machining involves thorough usage of parameters that affect output response like pulse-on time, pulse-off time, tool lift time, input current on MRR. Genetic algorithm is performed in MATLAB optimization tool box. Taguchi optimization and ANOVA are performed in Minitab-19. ANOVA is performed to analyze effect of input parameters on output response. This research also provides a list of optimized process parameters for 13/8 PH steel machining.","['Engineering', 'Industrial and Production Engineering', 'Machinery and Machine Elements', 'Materials Engineering']"
doi:10.1007/978-981-19-0098-3_11,en,An Efficient Underwater Image Restoration Model for Digital Image Processing,OriginalPaper,"Digital image processing (DIP) is showing a massive growth in today’s trending world particularly, in the field of biological research. Underwater image analysis plays a vital role, where the images are easily prone to attenuation and haziness. Capturing underwater images has always been a challenging job due to dispersion and scattering of light inside water on a high scale. Several image enhancement and restoration methodologies are currently available to address these issues, where hazing and color diffusion are viewed as a common phenomenon in it. Such procedures normally includes two basic methodologies in it, namely dehazing and contrast or color enhancement, which improves the overall output of the degraded image. However, the quality and processing time of the images can still be enhanced with additional techniques incorporated to it. This work is intended toward proposing one such channel called improvised bright channel prior for dehazing the underwater images. The technique further improves on the existing methodologies by estimating the atmospheric light and refining the transmittance of the image along with image restoration. The experimental results show that the improvised bright channel prior methodology is found to perform better in dehazing underwater images with a balanced intensity in terms of dark and white patches obtained from it. When comparing and contrasting the processing time of the proposed methodology with the existing techniques, it is found that improvised bright channel prior performs better. Also, the quality of the dehazed underwater image obtained from the proposed channel is found to be effective when compared with the existing channels.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Statistics, general', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3035-5_57,en,Semantic-Based Feature Extraction and Feature Selection in Digital Library User Behaviour Dataset,OriginalPaper,"World Wide Web has become a universal environment for human interface, collaboration, communication, data storage and data sharing. Information retrieval is a technique to understand the text in the web pages. The purpose of Semantic Web is to allow the machines to advance knowledge itself by recognizing its meaning. The essential intention of this research is to predict variation in the directional behaviour of the digital library user, based on their recommended data. The significance of this research lies in enlightening the user behaviour in digital library using semantic-driven approach. An important contribution of this research work corresponds to retrieve accurate data from websites by using semantically enhanced various algorithms. This research concerns on identifying educational digital library web user’s behaviour. The user behaviour unstructured data are pre-processed and semantically extracted using suggested weighted TF-IDF normalization method. Then the extracted features are selected using improved Ensemble-based FS method. It improves the performance and reliability of classification by eliminating unnecessary and superfluous features from the extracted user behaviour datasets.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Statistics, general']"
doi:10.1007/978-981-19-3387-5_133,en,Local Edge Structure Guided Depth Up-Sampling,OriginalPaper,"The current depth up-sampling cannot effectively using the pixel correlation and the edge structure between depth map and color map. In this paper, we proposes a new depth up-sampling method based on the local edge structure. Firstly, the non-robust pixel refinement in the low resolution (LR) depth image is obtained from the LR sobel-based edge map. Then, the structural consistency judgment within the depth map and the color map and the pixels classification is implemented with the guidance of the gradient matrix of the high resolution (HR) color image. Finally, according to the influence between pixels and spatial location constraints, the depth map is refined by the effective depth. Extensive experiments demonstrate that the proposed method outperforms conventional interpolation algorithms and some other edge-based depth up-sampling methods.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Aerospace Technology and Astronautics']"
doi:10.1007/978-3-031-18516-8_24,en,Cardiovascular Diseases Prediction Based on Dense-DNN and Feature Selection Techniques,OriginalPaper,"Cardiovascular Diseases (CVDs) are a group of disorders affecting the heart and blood vessels. They have been considered in recent years as one of the main causes of death in the world. Patients with heart disease do not feel sick until the very last stage of the disease and most heart patients die before receiving any treatment. Machine Learning and Deep Learning techniques play an important role in early prediction of heart disease, to improve the quality of healthcare and help individuals to avoid earlier health complications as coronary artery infection and decreased function of blood vessels . Nowadays, the field of health care produces a large amount of data. The need for efficient techniques for processing this data has become necessary. In this paper, a model for cardiovascular disease prediction based on Dense Deep Neural Networks (Dense-DNN) is developed and attributes selection is performed via a Genetic Algorithm (GA). The GA is used to identify the best subset of attributes from the entire features in the dataset, to improve the performances and reduce the training time of the classification model. Our prediction model is compared to several traditional Machine Learning techniques. The performances of our system have been evaluated based on six parameters: (1) accuracy, (2) sensitivity, (3) specificity, (4) F-measure, (5) RMSE, and (6) MAE. Experimental results show that our proposed model outperforms state-of-the-art methods in terms of performance evaluation metrics. The achieved accuracy of the proposed model is 91.7% without using feature selection and 95% with the use of feature selection.","['Engineering', 'Complexity', 'Computational Intelligence', 'Control and Systems Theory']"
doi:10.1007/978-981-19-2065-3_39,en,Task Allocation in IoT: A Systematic Review of Techniques and Issues,OriginalPaper,"Due to rapid expansion of IoT devices, huge data traffic is being generated and lot of data is bogus and utilizes unnecessary bandwidth, causing congestion and leading to performance issues. To avoid unnecessary data traffic and bandwidth consumption, data offloading concept came into existence where only relevant data can be offloaded to the servers. This concept helps to overcome data traffic, avoids congestion, and proper bandwidth consumption is maintained. Further, offloading data to the cloud servers requires task allocation protocols which help to allocate the resources to the offloaded data like server allocation using different optimization techniques. Since task allocation is considered as an NP-hard problem, so we require new task allocation protocols to optimize the problem of allocating servers to the offloaded data to avoid issues like energy consumption, response delay, and latency. In order to recognize the state-of-the-art mechanism on this important topic and address outstanding difficulties, this research presents a systematic literature review (SLR) on job allocation strategies in IoT network edge and fog nodes in the form of a classical taxonomy. All of the research done by researchers on classified task allocation methodologies is compared to one another based on significant variables such as performance measurements, used methodology, and assessment tools, as well as their benefits and drawbacks. Finally, a smart architecture-based method for dealing with task allocation difficulties is proposed.","['Engineering', 'Communications Engineering, Networks', 'Artificial Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Machine Learning']"
doi:10.1007/978-981-19-3632-6_21,en,Intelligent System of Scientific and Technological Talent Inquiry Based on Deep Learning Algorithm,OriginalPaper,"With the rapid development of the socialist market economy, scientific and technological talents play a vital role in all aspects of our country’s socialist economic development and social progress. In recent years, with the widespread application of e-government projects in various administrative agencies, business service efficiency and other aspects have been significantly improved. Despite the relatively rapid changes in corporate growth, many employers may still be unable to recruit ideal scientific and technological talents that can help companies survive and develop. In order to better absorb and introduce scientific and technological talents, creating an intelligent system for scientific and technological talents has become an inevitable trend in the development of modern scientific and technological talent management technology. This paper aims to study the intelligent system of scientific and technological talents query based on deep learning algorithms. Based on the analysis of system requirements, non-functional requirements and deep learning algorithms, the functional modules of the intelligent system of scientific and technological talents query are designed and implemented, and finally tested. The performance of the system and the test results show that the intelligent system designed in this paper is available.","['Engineering', 'Cyber-physical systems, IoT', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing']"
doi:10.1007/978-981-19-2600-6_30,en,Inverse Contexture Abstractive Term Frequency Model Using Surf Scale Diffusive Neural Network for Analysis of Fake Social Content in Public Forum,OriginalPaper,"Increasingly heterogeneous information on social discussion forums, fake news arises to create rumors to change the reliability of information resources due to contextual terms miss classification. The problem is that features definitions and their relational contexts are not properly extracted to analyze the contextual terms. The Original sense of contextual terms is affected by lexical terms, interrogative terms, extortion, semantic features, and sarcastic terms. To concentrate originality, subjective terms are extracted as positive credibility correlation scores between positive and negative content ratios. To propose a Fake content analysis based on Inverse Contexture Abstractive Term Frequency Model using Surf Scale Diffusive Neural Network for public forum social content. By analyzing the positive correlation of the sentence using Reliable Subjective Influence Score (RSIS), this selects the positive terms depends on mutual content dependencies between the originality terms. To analyze the Inverse Contexture Abstractive Term Frequency Model (ICATFM) for feature selection to select the credibility score in the sentence to relate to subjective real or non-real terms. The selected features are trained into a deep neural classifier optimized with Surf Scale Diffusive Neural Network (S2DNN). This implementation proves the best performance by identifying the fake detection to produce higher precision and recall rate to increase the classification accuracy compared to other methods.","['Engineering', 'Data Engineering', 'Statistics, general', 'Machine Learning', 'Artificial Intelligence', 'Data Storage Representation', 'Data Structures and Information Theory']"
doi:10.1007/978-3-031-18344-7_5,en,On the Reusability of Machine Learning Models in Edge Computing: A Statistical Learning Approach,OriginalPaper,"The adoption of Edge Computing continues to grow with edge nodes recording increasingly more data, which inevitably requires that they should be processed through Machine Learning (ML) models to speed up the production of knowledge. However, training these models requires an increased amount of resources, which are limited, thus, the reuse of ML models becomes of paramount importance. Given that we do not have a pool of models to choose from, is it possible to determine which nodes in the network require distinct models and which of them could be reused? In this paper, we propose a solution to this question, an online model reuse framework which is evaluated for its precision and speedup. The framework considers all possible combinations of pairs in the network to determine which are good reusability pairs, by adopting statistical learning methods. Then for each pair, the node model is chosen that has the highest data space overlap. Our comprehensive experimental analysis in the context of both regression and classification shows the feasibility our solution in model reusability in Edge Computing environments.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3490-2_9,en,Passive and Active Balancing,OriginalPaper,"For battery pack in charge and discharge, the available capacity is limited by the cell with the least capacity. Due to the heterogeneities between cells in pack, the charge throughput of individual cells is different. Thus, cells in the pack are degraded differently. For battery pack of 18,650 cells in parallel, the difference of their available capacity can reach 3%. This difference accumulates with time and accelerates degradation of the battery pack.","['Engineering', 'Automotive Engineering', 'Transportation Technology and Traffic Engineering', 'Energy Systems', 'Energy Materials']"
doi:10.1007/978-981-19-3998-3_99,en,Self-adversarial Network Based on MADDPG for Emergency Power Dispatch,OriginalPaper,"A self-adversarial network based on Multi-Agent Deep Deterministic Policy Gradient (MADDPG) is proposed for emergency power dispatch. This paper proposed two methods to improve the performance of MADDPG in mixed cooperative-competitive environments. The self-adversarial mechanism sat an adversarial network to improve the convergence and training speed. For the relations of cooperation, a self-attention layer is set for improving communication efficiency. Experiment results on the MPE environment show that the proposed model method has better performance and greater learning speed than MADDPG.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-981-19-3391-2_34,en,A Comparative Study of Hierarchical Risk Parity Portfolio and Eigen Portfolio on the NIFTY 50 Stocks,OriginalPaper,"Portfolio optimization has been an area of research that has attracted a lot of attention from researchers and financial analysts. Designing an optimum portfolio is a complex task since it not only involves accurate forecasting of future stock returns and risks but also needs to optimize them. This paper presents a systematic approach to portfolio optimization using two approaches, the hierarchical risk parity algorithm and the Eigen portfolio on seven sectors of the Indian stock market. The portfolios are built following the two approaches on historical stock prices from January 1, 2016, to December 31, 2020. The portfolio performances are evaluated on the test data from January 1, 2021, to November 1, 2021. The backtesting results of the portfolios indicate that the performance of the HRP portfolio is superior to that of its Eigen counterpart on both training and the test data for the majority of the sectors studied.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Statistics, general', 'Cyber-physical systems, IoT', 'Professional Computing', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-3679-1_31,en,Recent Trends in Opinion Mining using Machine Learning Techniques,OriginalPaper,"Opinion mining is a sub-field of data mining and natural language processing that concerns extracting users’ opinions and attitudes towards products or services from their comments on the web. Human beings rely heavily on their perceptions. When making a choice, other people’s perspectives are taken into account. Currently, billions of Internet users communicate their opinions on several disciplines via journals, discussion forums, and social media sites. Companies and institutions are constantly interested in hearing what the general public thinks regarding their services and goods. It is critical in e-commerce and e-tourism to dynamically evaluate the vast number of user data available on the Internet; as a result, it is essential to establish ways for analysing and classifying it. Opinion mining, also known as sentiment classification, autonomously extracts opinions, views, and feelings through literature, audio, and data inputs using natural language processing. This paper provides an understanding of the machine learning strategies for classifying comments and opinions. This paper compares various machine learning-based opinion mining techniques such as Naive Bayes, SVM, genetic algorithm, decision tree, etc.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-3-030-79827-7_36,en,A Digital Twin for MEMS and NEMS,OriginalPaper,"In this chapter we consider a comprehensive, multiphysical digital twin for NEMS and MEMS, in particular, for a range of effects that are currently of interest in electromechanical MEMS. The chapter first approaches the formation of a digital twin from the viewpoint of analytical equations. Once these approach their validity limit, numerical approaches become necessary. This will, most generally, lead to a topology optimization formulation, in order to drive the discovery of optimal device layout, which is next described. Due to mesh refinement, such models quickly become unwieldly to handle, since they result in to many degrees-of-freedom. In the last section of the chapter, we consider model order reduction as a means to turn large discrete models into compact models, approaching the lower order analytical models in complexity, but retaining the specific accuracy of the general numerical approach.","['Engineering', 'Circuits and Systems', 'Electronic Circuits and Devices', 'Electronics and Microelectronics, Instrumentation']"
doi:10.1007/978-981-19-3387-5_53,en,A Distributed Real-Time Orbit Determination Algorithm Based on Asynchronous Multi-sensor,OriginalPaper,"To solve the problem of asynchronous sampling and communication delay of sensor network in Real-time Orbit Determination, an asynchronous distributed algorithm based on information filtering is proposed. local state information and measurement information with sampling time are transmitted between local sensor and adjacent nodes in a certain topology structure. The local sensor sorts the received asynchronous information by time, and calculates the target state respectively. This method is simple to implement and the frequency of communication between sensors is small. Algorithm has been checked by real measured data of the first BDS-3 GEO satellite, the results show that the orbit determination results of each station converges to a centralized estimate, and the precision of 100 s real-time orbit determination results can be used to quickly evaluate the control effect.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Aerospace Technology and Astronautics']"
doi:10.1007/978-3-031-04098-6_17,en,An Optical Temporal and Spatial Vibration-Based Damage Detection Using Convolutional Neural Networks and Long Short-Term Memory,OriginalPaper,"Structural dynamics provide critical information for structural health monitoring (SHM), such as changes in the modal behavior which indicate damages. However, for complex systems with noisy operational environments, many factors may influence the estimation of natural frequencies and other modal domain SHM features, such as varying mass distribution of bridges and the variation due to fluctuating temperature and unideal boundary conditions. For this reason, allying the mode shapes with the natural frequencies to forecast damages would pose a more robust solution. Among the techniques existent to perform damage detection, data-driven models, such as machine learning algorithms, are becoming widely used currently. For mode shape extraction, convolutional neural networks (CNN) have been applied to imagery data, allowing to extract full-field mode shapes with a denser spatial resolution (quasi-full field) of the structure if compared to traditional hardware. Combining CNN with long short-term memory (LSTM) network will associate the temporal dependency of the frames with its features which will be more specific for SHM decision-makings. In addition, for the circumstances with low vibration amplitude and subpixel image resolution, applying phase-based motion estimation (PME) and phase-based motion magnification (PMM) allows to extract the natural frequencies with subtle motion magnified at the resonances aiding to emphasize the dynamic features desired. As the training of the deep learning model, a lab-scale truss structure was adopted with different load conditions in order to obtain the required data, and the performance is cross-validated.","['Engineering', 'Machinery and Machine Elements', 'Mechanical Engineering', 'Measurement Science and Instrumentation', 'Aerospace Technology and Astronautics', 'Vibration, Dynamical Systems, Control']"
doi:10.1007/978-981-19-3303-5_52,en,Extracting Ground Points and Generating Digital Elevation Model (DEM) from Point Clouds from Point Clouds,OriginalPaper,"Digital elevation models (DEM) is essential information for leveling, surveying in building construction. There are many methods for generating DEM. Because of consuming much time and labor, directed methods are replaced by many indirect methods for generating DEM. In this study, DEM is proposed to be generated from point clouds rapidly collected by laser scanning or photogrammetry. Two datasets are used for checking the proposed data processing process. As a result, two ground point cloud areas were extracted. Many ground points in the steepest areas cannot be extracted. For a flat area with less than 10° of slope angle, the results of ground point extraction are good. The surface is divided into many equal grid cells for generating DEM, and the grid cell’s elevation is computed from the point’s elevation inside it. Finally, DEMs are displayed as TINs by creating Delaunay triangle networks.","['Energy', 'Sustainable Architecture/Green Buildings', 'Structural Materials', 'Geotechnical Engineering & Applied Earth Sciences', 'Building Construction and Design', 'Construction Management', 'Environmental Policy']"
doi:10.1007/978-981-19-2635-8_40,en,Research on Obstacle Avoidance Technology of Fire Fighting UAV,OriginalPaper,"In this paper, two basic aspects of multi-rotor UAV, the air braking capability and obstacle avoidance function, are analyzed and studied on a certain type of fire-fighting UAV. Firstly, based on the motion model, the force analysis of the UAV is carried out to explore the factors that affect the braking ability; the mathematical relationship is established between the influencing factors and the braking distance, and the braking problem is solved in PYTHON. After that, the obstacle avoidance function of the multi-rotor UAV is developed based on the ROS environment. Several commonly used obstacle detection technologies and path planning algorithms are introduced and their advantages and disadvantages are compared. Under the ROS environment, simulating the advanced obstacle avoidance strategy according to VFH algorithm, and using PX4 external control mode in Gazebo simulation environment to verify the feasibility of the designed obstacle avoidance strategy. The results show that in actual flight, when the braking pitch angle is 30°, the UAV can slow down and hover within a safe distance of 10 m, meanwhile the advanced strategy based on VFH algorithm can be realized in simulation environment.","['Engineering', 'Aerospace Technology and Astronautics', 'Engine Technology', 'Automotive Engineering', 'Mechanical Engineering']"
doi:10.1007/978-981-19-2255-8_18,en,Research on Power IoT Intrusion Detection Method Based on Federated Learning,OriginalPaper,"The development of electricity Internet of Things (IoT) is potentially accompanied by an increase in network attack invasion. With the rapid development of artificial intelligence, machine learning, deep learning and other technologies are gradually applied to intrusion detection. However, the existing artificial intelligence program is seriously dependent on data, and with the attention of the world's attention to data privacy protection, the traditional artificial intelligence algorithm causes the model effect to be unsatisfactory because it cannot guarantee a certain amount of training. In order to protect the network security of the power network, this paper proposes an intrusion detection model based on federal learning, and uses a cluster algorithm to physically deploy an edge server, and use logic regression algorithm to network data. Intrusion detection. The intrusion detection model proposed in this paper not only protects the privacy of the grid user, but also determines the accuracy and robustness of the model on the data volume due to the problem of “data island” problem.","['Engineering', 'Communications Engineering, Networks', 'Wireless and Mobile Communication', 'Signal, Image and Speech Processing', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-1976-3_41,en,An Integrated Methodology of TsF-KNN-Based Automated Data Classification and Security for Mobile Cloud Computing,OriginalPaper,"In present days, most of the communication systems need the cloud technology. The data is transferred between the number of devices, so there is a chance of threats in the transformation of data. This can be prevented by using the data protection techniques. The security of the communication is required, and personal data can take more interest on this security of big data mobility. The present systems which provide the security are not having that much of efficiency because of its data determining techniques. For efficient data management, machine leaning (ML) is used by the big data mobility. In a document public data and secret data, prediction is more complicated even by using some existed machine learning algorithms. Therefore, an integrated methodology-based automated data classification and security for mobile cloud computing of Training dataset Filtration Key Nearest Neighbor (TsF-KNN) classifier is introduced in this paper. This classification secures the mobile big data training datasets by using the integrated methodology with TsF-KNN classifier and Hadoop Distributed File System (HDFS). This process gives the best security in confidentiality level of the records. So the proposed model improves the security of the cloud system data mobility.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-2764-5_26,en,Parameter Estimation of Photovoltaic Module Using Sine Cosine Algorithm,OriginalPaper,"The increasing demand for electrical energy has made it inevitable to bring forth an environment-friendly energy resource which has to be robust as well as economic. Solar energy fulfils these criteria significantly, and to cultivate such energy, a reliable photovoltaic (PV) model is required. But most of the typical PV system undergoes a low energy conversion ratio because of improper choice of PV parameters. To build a proficient PV model, the estimation of precise and accurate parameters is mandatory. This paper portrays the Sine Cosine Algorithm (SCA) for the estimation of photovoltaic (PV) module parameters. Unknown parameters of the PV model of a single diode PV module are estimated under the standard test condition (STC). PV parameter estimation using SCA has shown a significant minimum value of the fitness function hence maximizing the convergence. A comparative study has been done between SCA and other existing popular techniques named as the nonlinear least square (NLS) method and the modified Newton–Raphson (N-R) method. From the power–voltage (P-V) and current–voltage (I-V) characteristics, it’s found that the SCA model matches more accurately with the datasheet values.","['Energy', 'Energy Systems', 'Artificial Intelligence', 'Machine Learning', 'Cyber-physical systems, IoT', 'Professional Computing', 'Power Electronics, Electrical Machines and Networks']"
doi:10.1007/978-981-19-4052-1_72,en,A Hybrid Gray Wolf Optimizer for Modeling and Control of Permanent Magnet Synchronous Motor Drives,OriginalPaper,"The model order diminution and controller design of the permanent magnet synchronous motor drive, which is commonly called PMSM, are performed in the complex delta framework using a hybrid metaheuristic algorithm. Two fundamental algorithms, viz., the firefly technique and the gray wolf optimizer (GWO) are combined to develop a new topology termed as the hybrid gray wolf optimizer (HGWO). A PMSM drive made up of both the speed and current controllers was originally generated, by using an identification method used for signal processing, to yield a lower-order model. The second-order model in cascade with an appropriate controller is thus compared with a chosen reference to estimate approximately the control parameters which are not known beforehand. The continuous parameters almost imitated the parameters set with the delta operator. Thus, for the drive, thereby, a unified control system is built. Therefore, both for order reduction and for calculating the control parameters of PMSM drives, the proposed algorithm is successfully used. Besides, a case study for the control of such special motor drives can also be investigated in the future for many household as well as commercial purposes.","['Engineering', 'Computational Intelligence', 'Information Storage and Retrieval', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Data Structures and Information Theory', 'Artificial Intelligence']"
doi:10.1007/978-3-031-05445-7_1,en,Optimal Sensor Placement and Model Updating of Axial Compressor Casing Components,OriginalPaper,"Experimental modal analysis of complex structures requires a good sensor concept to capture the component’s vibrational behavior ideally. Especially, when the geometry is big or consists of many attached parts and the number of available sensors is limited, the sensor placement in order to maximize the gained output information is relevant. For this purpose, several methods and algorithms are implemented and tested on the stator housing of an axial compressor test rig. These procedures include among others a genetic algorithm, an artificial bee algorithm, a method based on the QR-decomposition, as well as the effective independence method. This work contributes to the provision of more validation data for real structures, which are rarely found in the literature. The resulting measurement data are analyzed in order to evaluate the qualification of the methods presented for modal parameter extraction. The positioning techniques are compared among each other in order to choose the most suitable method for the modal identification of a complex mechanical structure. Additionally, the experimental results are compared to results from a finite element model. In order to improve the fit between experimental data and numerical results, a model updating procedure is carried out.","['Engineering', 'Building Repair and Maintenance', 'Vibration, Dynamical Systems, Control', 'Fourier Analysis', 'Abstract Harmonic Analysis']"
doi:10.1007/978-981-19-2635-8_33,en,Performance Verification System for Navigation Algorithm~Simulation of Flight Evaluation Profile Specified in RTCA DO-334 MOPS~,OriginalPaper,"Shinshu University has been developing a computer simulation-based navigation algorithm verification system. The system performs the final confirmation of a subject navigation algorithm by executing the flight test items specified in Table 2–9 of the RTCA DO-334 MOPS by computer simulation of an aircraft’s flight along a reference trajectory. Generating a high-precision reference trajectory requires many aircraft parameters and is computationally intensive. To alleviate these burdens, we developed a program that generates a simplified trajectory from takeoff to landing that includes turning maneuvers. In this paper, dynamic motions such as pitch up/down and lateral-directional motions such as steady sideslip, which are required in DO-334, were newly incorporated into the trajectory generation program, and inertial navigation and GPS navigation were performed along the output trajectory to confirm the usefulness of the verification system. The obtained navigation outputs were consistent with the characteristics of true data, and confirmed that the influence of flight test maneuvers on the navigation could be evaluated. It was therefore demonstrated that the system can simulate the DO-334-based verification of a navigation algorithm.","['Engineering', 'Aerospace Technology and Astronautics', 'Engine Technology', 'Automotive Engineering', 'Mechanical Engineering']"
doi:10.1007/978-3-031-15699-1_5,en,Placement Algorithm of Superconducting Energy-Efficient Magnetic FPGA,OriginalPaper,"Field Programmable Gate Arrays (FPGAs) are user programmable digital devices that provide efficient, yet flexible, implementations of digital circuits. FPGAs consist of configurational logic blocks surrounded by routing network and bounded on a grid by I/O pins. FPGAs provide a significantly cheaper solution for various applications of traditional semiconductor electronics. The Rapid Single Flux Quantum (RSFQ) technologies are developing rapidly and the availability of SFQ-specific FPGA will be very useful. Prior research highlights a first energy-efficient magnetic SFQ-specific FPGA which promises to operate at very high frequency with low power dissipation. In this paper, we propose a new innovative placement algorithm for energy-efficient magnetic superconducting FPGA complying with all the SFQ design constraints. We have explored placement and routing problems in RSFQ FPGA precisely and proposed a placement algorithm which comprises three main attributes, namely cell grouping, global placement, and detailed placement which aims to minimize overall placement area and congestion on switch boxes by reducing the distance between connected logic blocks and provides best legal placement solution. We were able to reduce cost (wirelength) and final placement area by 68% and 39%, respectively, compared to legal initial placement.","['Engineering', 'Circuits and Systems', 'Electronic Circuits and Devices']"
doi:10.1007/978-981-19-3632-6_66,en,Application of Computer Trajectory Planning Algorithm in UAVs Power Line Patrolling System,OriginalPaper,"In order to complete the transmission circuit inorganic and automatic search, shrink deviation hand control, this paper is devoted to the complete type of uav autonomous cruise system based on laser point precise positioning, through the high precision 3 d laser spot time data to complete the course of independent planning, automatically generated, and then complete the inorganic and the whole flow of automatic cruise work. Experiment results shows that, given the precise positioning of the laser point cloud drones in autonomous cruise phase, with space collision testing and automatic blocking function, high efficiency to ensure the safety of the unmanned aerial vehicle (uav) navigation, reduce the latent threat to power grid, improve power transmission cable inspection results and the safety of the operation, provide strategies for the development of power transmission cable inspection to explore in the late.","['Engineering', 'Cyber-physical systems, IoT', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing']"
doi:10.1007/978-981-19-2225-1_41,en,In Plane and Out Of Plane Rotation Face Detection Model,OriginalPaper,"Face Detection is a famous topic in computer vision. Over the most few couple of years researchers have attempted to improve the performance of face detection algorithm in plane and out of plane rotation. In this paper, we propose a quick way to deal with face detection algorithm using support vector machine (SVM) and golden ratio. For performing this new algorithm, the main prerequisite is the preparation dataset in the front facing appearances to prepare SVM for skin filtering. In the proposed algorithm first we apply color histogram equalization (If the face detection algorithm is not able to detect any face) which can address the mistake of the skin filter then apply SVM for removing non-skin color, i.e., a skin filter machine is developed using SVM and lastly apply golden ratio for detecting the face region correctly. Proposed algorithm is compared on three datasets XM2VTS, FERET, and BioID with a high discovery rate not less than 95%. The experimental result shows the proposed algorithm not only runs comparatively fast but also gives an upgrade performance.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Statistics, general', 'Mobile and Network Security']"
doi:10.1007/978-981-19-2635-8_80,en,Dubins Path Generation and Tracking in 3D for UAVs,OriginalPaper,"Excessive maneuvering may pose risk of damage to the aircraft. This paper presents methods to solve this problem. Specifically, the shortest path between two given points in the 3D space of an unmanned aerial vehicle (UAV) is generated, and the generated path is traced. Moreover, the designed controller is introduced. The path generation algorithm is based on the existing path generation algorithm pertaining to the Dubins curve. The path generated by this algorithm can satisfy the constraints regarding the minimum allowable turning radius; moreover, the algorithm involves rapid computation and can be applied for path generation in real time. Notably, in this algorithm, the shortest path to fixed initial and final points is geometrically obtained in a 2D plane; however, real aircraft path generation problems must be implemented in 3D. Therefore, a path in 3D space is generated by deriving a solution through a numerical technique, using the same principle as that of the problem in 2D. Furthermore, the line-of-sight guidance algorithm corresponds to basic waypoint guidance. The proposed 3D path tracking approach is implemented using a nonlinear controller, resembling those of line-of-sight guidance algorithms. The controller guarantees, under certain assumptions, asymptotic tracking of the path, in terms of both the position and attitude. Finally, we adopt a sliding mode controller, which is a robust controller that can ensure high control performance and stability even under uncertainties. The proposed controller satisfies the constraint through the saturation function, specifically, by introducing the constraint on the angular velocity to the existing sliding mode controller. The stability of the designed controller is verified considering Lyapunov stability, and the performance of the proposed algorithm is verified through numerical simulation.","['Engineering', 'Aerospace Technology and Astronautics', 'Engine Technology', 'Automotive Engineering', 'Mechanical Engineering']"
doi:10.1007/978-3-031-14537-7_5,en,An Application of the Bees Algorithm to Pulsating Hydroforming,OriginalPaper,"Pulsating hydroforming Hydroforming is a sheet forming process proposed in the last decade. The numerical simulation of this process requires biaxial stress–strain curves which can be obtained by performing a pulsating hydraulic bulge test Bulge test . In this study, the input parameters Parameters of a pulsating hydraulic bulge test Bulge test with titanium alloy sheets (Ti-6Al-4 V) Ti-6Al-4V are optimised using the Bees Algorithm (BA). The input parameters are amplitude and base pressure; bulge height (h) and minimum thickness (t) at dome apex are outputs. The mathematical modelling Modeling of h and the design of an objective function (J) are needed for optimisation. A second-degree polynomial equation is derived for h using curve fitting Curve fitting for three frequencies. Additionally, t is calculated depending on h. The objective function is designed for maximum normalised bulge height and minimum normalised thickness. The results show less thinning at the dome apex with a bulge height similar to that of the traditional monotonous method. Thus, a uniform thickness distribution Thickness distribution , which is a critical quality Quality indicator in hydroforming Hydroforming , is obtained with acceptable loss in bulge height. After optimisation, Δt (t-t 0 ) is improved by approximately 9%. The bulge height increases by 15 and 13% in the best experimental case and the BA-optimised results, respectively. Consequently, the ductility Ductility of Ti-6Al-4 Ti-6Al-4V  V sheet is increased, and the input parameters are optimised.","['Engineering', 'Robotics and Automation', 'Artificial Intelligence', 'Industrial and Production Engineering', 'Professional Computing', 'Robotics', 'Machine Learning']"
doi:10.1007/978-981-19-2225-1_36,en,Application of Watershed Algorithm in Digital Image Processing,OriginalPaper,"Segmentation of image is the method of separating objects from its background. It is helpful finding and deciding about which pixel belong to which objects. It is the process of making pixels of every region has similar visual characteristics. The watershed algorithm provides a complementary approach to the segmentation of an object. It is essential for segmenting objects where they touch their boundaries. Watershed is a dividing ridge between drainage areas. In digital image processing, the banks are the watershed lines and the drainage areas are catchment basins. Watershed is the representation of the grayscale image as topographic relief. Watersheds with adjacent catchment basins are being built during the repeated flooding of the gray value relief. This flooding method is performed on the gradient image. The magnitude of gradient value is intensely sensitive to image noise. So noise value plays a vital role in watershed processing. In computer-world watershed is a classical algorithm used for image segmentation. In this paper, we will witness the approaches of the watershed transformation in an image with a proper analysis of its advantages over other methods.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Statistics, general', 'Mobile and Network Security']"
doi:10.1007/978-981-19-3387-5_151,en,Improved Federated Average Algorithm for Non-independent and Identically Distributed Data,OriginalPaper,"Federated learning is a distributed machine learning model that can protect data privacy, where a large number of clients and servers participate in the joint train procedure. However, the problem of heterogeneous data has been a potential obstacle for federated learning. Traditional joint averaging algorithms suffer from low accuracy and slow convergence on non-IID (identical and independently distributed) data. To this end, this paper proposes an improved FedAvg based algorithm called FedAvg-Z. We introduce penalty coefficients and adaptive parameter averaging methods in our algorithm, which adjusts the influence of clients on the global model as a way to increase the convergence and stability of the model. We first demonstrate the reliability of our method on the dataset and then compare it experimentally with the traditional algorithm. The experiments show that the algorithm has higher accuracy and convergence speed in the non-IID case.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Aerospace Technology and Astronautics']"
doi:10.1007/978-981-19-4208-2_6,en,Development of Complex Feature Extraction System from Prismatic Parts Using Hybrid Algorithms,OriginalPaper,"In the current scenario most of the industries want to produce superior quality products with less production time and manufacturing cost to full fill the customer needs. The integration of computer-aided design (CAD) and computer-aided manufacturing (CAM) attain the industry's needs. However, the integration of CAD and CAM is most difficult task and facing lot of challenges. Feature recognition (FR) is the key link between integrate CAD and CAM and overcome the issues present in it. This paper presents a development of complex feature extraction system to extract different features like slant edges, bends, fillets, and chamfers from prismatic parts. A hybrid automatic feature recognition algorithm (HAFRA) combination of milling feature extraction algorithm (MFEA) and cylindrical feature extraction algorithm (CFEA) is proposed to identify the complex features using STEP file and then validation of the algorithm is done through case study. The developed hybrid automatic feature extraction system is well suited to extract the complex features from prismatic parts and thereby improve the downstream applications like process planning, CAPP, CAE, CAM, CAI, etc.","['Engineering', 'Industrial and Production Engineering', 'Robotics and Automation', 'Manufacturing, Machines, Tools, Processes']"
doi:10.1007/978-3-031-13588-0_62,en,Implicit Curves: From Discrete Extraction to Applied Formalism,OriginalPaper,"This paper addresses the issue of visualizing the right information among large data sets by proposing to represent raw data as a set of mathematically-based implicit curves. Implicit curves are proving to be a powerful yet underused tool. The methodology we propose not only allows a more relevant visualization of information, but also a faster and efficient access to it: (1) since curves are extracted and compressed during precomputation, real-time rendering is possible on the end-user’s computer, even for very large datasets; (2) this property can be extended by enabling real-time data access and transfer at the server level – i.e. simultaneously saving local storage costs and increasing raw data security. Our proposal also achieved a high compression ratio (3%) while maintaining the visual significance of the data and reducing discrete artifacts such as curve gaps and pixel aliasing. We based our tests using two-dimensional height maps, but extending it to more dimensions is not a problem since we can consider any two-dimensional slice in these data.","['Engineering', 'Engineering Mathematics', 'Computational Intelligence']"
doi:10.1007/978-981-19-1061-6_14,en,Stacking Different Spatial Statistics in a Novel Recursion Algorithm to Improve the Design of Waste Management Regions in Saskatchewan,OriginalPaper,"Canadians disposed 25 million tonnes of waste in 2018. Some Canadian provinces have implemented regionalized waste management systems such as Alberta and Nova Scotia. In Saskatchewan, the idea of regionalization has been discussed since the 1990s, however, transition to regional systems has been difficult due to the autonomous nature of prairie communities. Currently, the Government of Saskatchewan intends to investigate and encourage regional collaboration among municipalities. Previous work on regionalized waste management systems introduced an algorithm capable of improving and optimizing regions for waste management in various jurisdictions. It was theorized that regions could be optimized when the number of landfills, populated places, and roads across regions was spread evenly; mathematically, regions were optimized when the standard deviation of these parameters was reduced across all regions. Successful application of the tool yielded reductions in the standard deviation these parameters by 4.9–46.1% in Saskatchewan. In more recent work, different spatial statistics such as central feature, mean center, and median center have been substituted into the proposed Centroidal Voronoi Tessellation (CVT) algorithm with varying success. The objectives of this study are to: (i) stack different spatial statistics (mean and median center) on top of the initial CVT algorithm and (ii) compare the results to those using only the CVT algorithm to determine if the stacking method proposed in this study can further improve the results of the CVT algorithm. The results from this study may help to further develop data driven regions for waste management in Saskatchewan and Canada.","['Engineering', 'Building Materials', 'Geoengineering, Foundations, Hydraulics', 'Transportation Technology and Traffic Engineering', 'Environment, general']"
doi:10.1007/978-3-031-14537-7_3,en,The application of the Bees Algorithm in a Digital Twin for Optimising the Wire Electrical Discharge Machining (WEDM) Process Parameters,OriginalPaper,"In digital manufacturing, Digital Twins (DTs) Digital Twin (DT) can be used to represent a physical manufacturing process Manufacturing process . In this study the application of the Bees Algorithm Bees Algorithm (BA) for the optimisation of Wire Electrical Discharge Machining (WEDM) Wire Electrical Discharge Machining (WEDM) process on a DT was considered. To do this a virtual copy of the product being machined was created to provide an accurate description of the parameters that needed to be modified to complete its production. The proposed approach looks at the measured inputs and outputs from the WEDM Wire Electrical Discharge Machining (WEDM) process and uses the BA to optimise and achieve the best combination of WEDM process parameters Process Parameters .","['Engineering', 'Robotics and Automation', 'Artificial Intelligence', 'Industrial and Production Engineering', 'Professional Computing', 'Robotics', 'Machine Learning']"
doi:10.1007/978-981-16-9967-2_41,en,Survey on Cloud Auditing by Using Integrity Checking Algorithm and Key Validation Mechanism,OriginalPaper,"Cloud computing can be used to access and storing data and delivery of different services over the internet. Using cloud storage, users can remotely store their data. Cloud service provider (CSP) provides data owners to store and access their valuable data in the cloud server and offers them to make use of on-demand data access without maintaining a local copy of their data. Even though this service avoids the data owners from making use of their third-party auditor, it certainly possesses serious security threats in maintaining the data owners cloud data. In addition, integrity is also an important issue in maintaining the data owners data stored in the cloud server. This survey presents an overview of integrity check and continuous auditing. The review work based on creating secure clouds by continuous auditing and cloud certification system (CCS) is used for high level security. This survey helps to provide the security by continuous auditing and overcome the integrity issues and to avoid the attacks by integrity checking algorithm and key validation mechanism. In this survey paper, various researchers’ ideas based on integrity checking and key schemes have been analyzed as literature review.","['Computer Science', 'Computer Systems Organization and Communication Networks', 'Computational Intelligence', 'Artificial Intelligence', 'Wireless and Mobile Communication', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-16-9131-7_6,en,Data-Model Fusion RUL Prediction,OriginalPaper,"This chapter mainly concentrates on data-model fusion RUL prediction methods of mechanical systems. In industries, it is generally feasible to obtain both prior mechanical system degradation knowledge and condition monitoring data, and the effective fusion of them would output more satisfactory RUL prediction results. Motivated by this superiority, this chapter first elaborates the basic framework of data-model fusion RUL prediction methods, and introduces four types of internal and external variabilities of mechanical system that substantially influence the RUL prediction accuracy, i.e., random fluctuation variability, unit-to-unit variability, time-varying operational conditions, and competing failure processes. Then, modeling methodologies are developed with respect to different types of variabilities, and corresponding algorithms are designed to fulfill the RUL prediction task. Finally, experimental analyses on various types of mechanical systems are conducted to demonstrate the effectiveness of the introduced methods in practical cases.","['Engineering', 'Machinery and Machine Elements']"
doi:10.1007/978-981-19-3387-5_145,en,Chinese Word Segmentation of Ideological and Political Education Based on Unsupervised Learning,OriginalPaper,"This paper proposes an unsupervised Chinese word segmentation algorithm for ideological and political education. The algorithm is divided into two parts: language model generation algorithm and Viterbi algorithm. Language model generation algorithm calculates the conditional probability based on the big texts and determines the number of occurrences between single character and character. Then we can have a character-level N-gram language model. Viterbi algorithm uses the idea of dynamic programming. Viterbi algorithm can use character-level language model to find the optimal word segmentation path, so as to further improve the accuracy of segmentation. Finally complete the task of Chinese word segmentation supported by big texts. Experiments show that the proposed algorithm has a good recognition rate for vocabulary in the field of ideological and political education. With the characteristics of unsupervised learning, the algorithm can save a lot of labor costs and meet the needs of word segmentation in the field of ideological and political education.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Aerospace Technology and Astronautics']"
doi:10.1007/978-981-19-1577-2_47,en,Study on the Recognition of Driver’s Starting Intentions Based on Fuzzy Inference-SVM Cascade Algorithm,OriginalPaper,"Research of the identification method on driver’s starting intention is very necessary. It can provide basis and support for subsequent vehicle clutch control, optimized shift curve and driving style recognition, and also contribute to vehicle assisted driving and intelligent driving. This paper presents a fuzzy inference-support vector machine (SVM) cascade algorithm to recognize the driver’s starting intentions, which can make up the low accuracy of fuzzy inference algorithm and overcome the difficulty to identify large samples of SVM algorithm. The proposed recognition method of driver’s starting intentions includes two-layer: the first layer is fuzzy inference layer while the second layer is SVM layer. At the same time, the fuzzy inference-SVM cascade algorithm is trained and tested with the sample data acquired from the actual vehicle. The experimental results show that the cascade algorithm has high recognition accuracy and moderate recognition time. Accordingly, the fuzzy inference-SVM cascade algorithm is an effective way to recognize driver’s starting intentions.","['Engineering', 'Electronics and Microelectronics, Instrumentation', 'Computational Intelligence', 'Biomedical Engineering and Bioengineering', 'Measurement Science and Instrumentation']"
doi:10.1007/978-981-19-3632-6_70,en,Application of Big Data in Management Information System,OriginalPaper,"With the rapid development of social economy and the acceleration of urbanization in China, the scale of urban road network is expanding day by day, and the total mileage of all levels of roads is growing rapidly. As the road with the highest level of technology and service in the urban road network, urban expressway plays the role of the skeleton road network in the urban road system, bearing the traffic demand of high flow and high speed. Once a traffic incident occurs, it is easy to produce traffic congestion. If it is not handled in time, it will also cause secondary accidents, which will have a serious impact on the operation of the whole urban expressway network. In this paper, an algorithm design based on Intelligent Transportation nonlinear dynamic control and automatic accident detection algorithm is proposed to improve the coverage and uncertainty of expressway incident detection.","['Engineering', 'Cyber-physical systems, IoT', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing']"
doi:10.1007/978-3-031-02097-1_25,en,Application of POA Algorithm in Optimal Operation of Reservoir Flood Control and Water Storage,OriginalPaper,"By understanding step by step optimization algorithm and the reservoir flood control optimization scheduling model, in addressing the problem of local optimal acquired experience, combined with practical computing needs water balance as the core of the improved algorithm is put forward, thus preventing the total decision-making sequence in overly complex constraint conditions is divided into multiple subsequence of the role of each other is not, to ensure application algorithm is more rapid, It is not easy to fall into local optimization problems. Based on understanding the current research status on the basis of reservoir flood operations, according to the actual building model and the improved algorithm, to verify this practice, the application of the case analysis, the final result shows step by step optimization algorithm can guarantee the water balance at the same time, using piecewise compensation as the core of the improved algorithm under complex conditions, accurate calculation of reservoir operation, and the results.","['Engineering', 'Mechanical Engineering', 'Computational Science and Engineering', 'Theoretical, Mathematical and Computational Physics']"
doi:10.1007/978-3-031-12807-3_9,en,A Smart System for the Assessment of Genuineness or Trustworthiness of the Tip-Off Using Audio Signals: An Explainable AI Approach,OriginalPaper,"Assessment of the genuineness or trustworthiness of a Tip-off is a challenging research area as it depends on the mental state and perception of the Tip-off providers. Thus, in the proposed work an attempt has been made to help the Law Enforcement (LE) personnel to assess the legitimacy of a Tip-off from a voice call. For the aforesaid objective, four widely used mental states such as ‘Anger’, ‘Happy’, ‘Sadness’, and ‘Neutral’ have been considered. To placate our goal, a few classical Machine Learning (ML) models, as well as a few latest ML models, have been employed. Regional, international, and a combination of both audio sets have been engaged for an in-depth study. The novelty of this work is to, select a set of Important 26 or 13 Mel-Frequency Cepstral Coefficients (MFCCs) using Explainable AI (XAI) approaches (Mean Decreased Impurity based Gini and Permutation), whereas most of the researchers had employed either the First 26 or 13 MFCCs in their works. The proposed model shows the supremacy over the conventional approach of using sequential MFCCs feature vector result analysis shows the supremacy of XAI-based features over conventional approaches thereby making our system better and smarter. Among the employed models, 1D CNN has shown its supremacy over other employed models for this study. Hence, the 1D-CNN-based Machine learning approach has been proposed.","['Engineering', 'Computational Intelligence', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-7369-7_1,en,Introduction,OriginalPaper,This chapter provides an introduction to data science and Wineinformatics.,"['Computer Science', 'Data Structures and Information Theory', 'Artificial Intelligence', 'Machine Learning', 'Natural Language Processing (NLP)', 'Knowledge based Systems', 'Business Information Systems']"
doi:10.1007/978-3-031-19032-2_44,en,Use of Classification Algorithms to Predict the Grade of Geomagnetic Disturbance,OriginalPaper,"This paper presents different approaches for predicting the grade of geomagnetic Kp index using machine learning algorithms. The Kp index is considered to be an indicator of the energy input from the solar wind into the Earth’s magnetosphere. In this study, a wide range of machine learning algorithms were tested for the purpose of classifying Kp index grade, such as gradient boosting models, linear models, and neural networks. The main challenge of this classification task is a strong class imbalance, due to the fact that extreme values of Kp index are rarely observed. To overcome the issue, the SMOTE technique for minority classes oversampling was utilized. It is shown that SMOTE improves quality of the classification at far horizons. We also test time-series cross-validation for hyperparameters optimization and show that it does not improve the quality. All the models are scored against an out-of-sample test set to assess their quality and compare the results. Finally, we highlight the directions of further research based on the results obtained in this study.","['Engineering', 'Computational Intelligence', 'Machine Learning', 'Neurosciences']"
doi:10.1007/978-981-19-4052-1_17,en,Machine Learning for Speech Recognition,OriginalPaper,"Machine learning paradigms that are used in automatic speech recognition (ASR) have been improved in the past decade. The improvement in speech recognition has been developed to help make the technology more efficient by dealing with various challenges affecting speech recognition such as speaker identification, capitalization, correct formatting, domain-specific terminology, background noise, the timing of words, and punctuation placement. Some other issues that have come up in speech recognition include data security and privacy, deployment, and language coverage. Any speech recognition system must have a noise-removal feature to perform in the best way possible. This paper gives a brief about the machine learning techniques that can be used in speech recognition. A better understanding of the models will help understand the systems, and it may help improve the technology even further for the benefit of society.","['Engineering', 'Computational Intelligence', 'Information Storage and Retrieval', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Data Structures and Information Theory', 'Artificial Intelligence']"
doi:10.1007/978-3-031-19377-4_5,en,The Discrete Fourier Transform,OriginalPaper,"In this chapter, the discrete Fourier transform and its inverse are derived using the orthogonality property of harmonically related discrete sinusoidal or complex exponential waveforms. This version is the only one of the four versions of Fourier analysis in which the variables in both the time-domain and frequency-domain are discrete and finite. The finite extent signal is periodically extended and represented by a finite set of harmonically related discrete sinusoidal or complex exponential waveforms. The difference between time-domain and frequency-domain representations is pointed out. A brief view of the Fourier analysis is given. Properties of the DFT are presented. Some applications of the DFT are described.","['Engineering', 'Signal, Image and Speech Processing', 'Fourier Analysis', 'Circuits and Systems']"
doi:10.1007/978-3-031-20141-7_66,en,Influence of the City Transport Route Network Discrete Model Geometrical Parameters on a Quality of a Passenger Traffic System Operation,OriginalPaper,"The research is dedicated to an investigation of an influence of geometrical parameters of a discrete model of the city transport route network on a quality of a passenger traffic system operation and to a discovery of the priority criteria of the developed characteristics while searching for the ways of improvement of its structural components. Quality characteristics of the city passenger routes network substantially depend on a complexity of their geometrical configuration and topological structure. Afterwards, a development of a city routes network goes, as a rule, by the way of complication of a travel routes topological structure and of interrelation between geometrical characteristics of their separate elements. Such a trend allows to make a conclusion about the necessity of elaboration of the effective mathematical methods of modeling of the new ones and of optimization of the existing networks, on the base of which there would be situated the algorithms of the quantity evaluation of a quality of the city transport system operation on the base of an all-round analysis of geometrical parameters of the route schemes discrete models. In the present research work there were examined and analyzed the discrete models of geometrical images, their main characteristics, there were offered the methods of determining of separate parameters of the geometrical structures concerning the determining of optimal ways of improvement of the technical and technological characteristics of a city transport network. All the examined images can be set as principles of analysis of its accessibility and determining of the possibilities and ways of improvement of the already existing routes network.","['Engineering', 'Computational Intelligence', 'Transportation Technology and Traffic Engineering', 'Manufacturing, Machines, Tools, Processes']"
doi:10.1007/978-981-19-0105-8_28,en,Analyzing Behavior to Detect Cervical Cancer,OriginalPaper,"Cervical cancer is preventable if one can detect it at an early stage. Due to cervical cancers, the human body imparts various behaviors and seven different determinants of this behavior. Behaviors can be conscious and also subconscious. And also, all expressing behaviors might not be completely correlated. In this work, a strategy has been proposed to exclude non-correlated features to maintain or enhance the detection accuracy of cervical cancer at an early stage. Experimental results show a maximum of 94.4% accuracy, and thus, it proves the efficacy of the proposed work.","['Engineering', 'Communications Engineering, Networks', 'Artificial Intelligence', 'Computational Intelligence', 'Bioinformatics']"
doi:10.1007/978-3-031-16075-2_1,en,How to Improve the Teaching of Computational Machine Learning Applied to Large-Scale Data Science: The Case of Public Universities in Mexico,OriginalPaper,"Teaching along with training on Machine Learning (ML) and Big Data in Mexican universities has become a necessity that requires the application of courses, handbooks, and practices that allow improvement in the learning of Data Science (DS) and Artificial Intelligence (AI) subjects. This work shows how the academy and the Information Technology industry use tools to analyze large volumes of data to support decision-making, which is hard to treat and interpret directly. A solution to some large-scale national problems is the inclusion of these subjects in related courses within specialization areas that universities offer. The methodology in this work is as follows: 1) Selection of topics and tools for ML and Big Data teaching, 2) Design of practices with application to real data problems, and 3) Implementation and/or application of these practices in a specialization diploma. Results of a survey applied to academic staff and students are shown. The survey respondents have already taken related courses along with those specific topics that the proposed courses and practices will seek to strengthen, developing needed skills for solving problems where ML/DL and Big Data are an outstanding alternative of solution.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16174-2_8,en,Platforms and Practice of Graph Neural Networks,OriginalPaper,"Graph Neural Networks (GNNs) are widely used in structured data analysis. However, most typical deep learning platforms, such as PyTorch and TensorFlow, have inadequate support for the manipulation of sparse matrices, resulting in inefficiency in building GNNs. For these reasons, some platforms are designed for GNNs. In this chapter, we will give descriptions of some mature platforms of GNNs with their features, and present a multi-backend graph learning platform GammaGL, which can use the same code implementation to support TensorFlow, PyTorch, PaddlePaddle, and MindSpore. Finally, we will give a practical demonstration of GammaGL.","['Mathematics', 'Graph Theory', 'Computer Science, general', 'Mathematical Applications in Computer Science', 'Mathematical Models of Cognitive Processes and Neural Networks', 'Data Mining and Knowledge Discovery']"
doi:10.1007/978-3-031-16159-9_7,en,Simulation Model and Scenarios for Testing Detectability of Cyberattacks in Industrial Control Systems,OriginalPaper,"This article concerns the detection of cyberattacks in industrial installations. A comprehensive experimental stand, and any associated simulator, have been developed in the Institute of Automatic Control and Robotics, Warsaw University of Technology. This article focuses on the simulator, its properties and its functionalities. The simulator can work in standalone mode or hardware-in-the-loop mode. For testing purposes, a wide range of cyberattacks can be designed and injected in the simulator. The approach is illustrated by a numerical example of a replay attack.","['Engineering', 'Control and Systems Theory', 'Computational Intelligence']"
doi:10.1007/978-981-16-9131-7_1,en,Introduction and Background,OriginalPaper,"The availability of industrial big data offers great opportunities as well as challenges for intelligent maintenance of mechanical systems. This chapter presents the general introduction to big data-driven fault diagnosis and prognosis for mechanical systems. Three popular maintenance strategies are briefly discussed first, which are followed by the introductions of artificial intelligence technologies, big-data-driven predictive maintenance concepts, and some examples of big data analytics platforms in the industries. Next, the overview of the big data-driven prognostics and health management is presented. The five major processes are described, including data acquisition, data processing, fault diagnosis, prognosis, and maintenance. In the last part, the organization structure of the remaining chapters in this book is introduced to guide readers.","['Engineering', 'Machinery and Machine Elements']"
doi:10.1007/978-3-031-14125-6_40,en,Dynamic Smoothing of the Path of a Wheeled Robot with Automatic Fulfillment of Design Restrictions,OriginalPaper,"The main concern when planning the path of an autonomous robot is to ensure the safety of movement. The next problem is to make the path curvature smooth, boundedness and limit its rate of change with design restrictions of the robot. If one tries to solve these problems directly and simultaneously, he will need to perform such cumbersome calculations that cannot be done in real-time mode. We propose to simplify and automate the generation of planar paths for a wheeled robot in this study by splitting the solution into two stages. At the first stage, we construct a primitive path as a planar polyline. Its segments connect the control points and ensure the working scenario executes safely. At the second stage, we solve the problem of smoothing the polyline joints without any geometric calculations. The proposed solution uses a dynamic generator constructed as a copy of the equations describing the movement of the center of mass of the wheeled platform. To imitate the robot’s control actions, we synthesize the generator’s corrective actions using the decomposition and S-shaped feedbacks. This approach ensures that the robot’s design restrictions on velocity, acceleration, and control torques are met. Also, the output variables of the generator simulate the coordinates of the robot’s center of mass. Thus, these variables will generate a naturally smoothed path with an acceptable curvature under tracking the coordinates of the reference non-smooth route.","['Engineering', 'Industrial and Production Engineering', 'Engineering Design', 'Mechatronics']"
doi:10.1007/978-3-031-07654-1_2,en,Experimental Comparative Analysis on Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) on Aspect-Level Sentiment Analysis,OriginalPaper,"Sentiment analysis is a process of inferencing subjective text with sentiments. Huge data generated by social media, business, medical industry, e-commerce, engineering, and academia are analyzed to understand customer satisfaction, trends, experience, opinion, and influence. Various algorithms have been proposed in the literature to analyze the generated data. This paper summarizes various types of sentiment analysis and the process of sentiment analysis and discusses the application of two main deep learning architectures convolutional neural networks (CNN) and recurrent neural networks (RNN) in sentiment analysis. The experimental analysis also has been carried out on these two architecture and performance metrics, viz., accuracy, loss, precision, and recall, which have been compared.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Computer Communication Networks', 'Computational Intelligence']"
doi:10.1007/978-3-031-05476-1_6,en,Zooming In: Learning with Videoconferencing as Posthuman Pedagogy,OriginalPaper,"This chapter explores shifts in global human interaction through the rapid adoption of videoconferencing during the pandemic of 2020, which have manifested forms of work and education open to new and sometimes troubling possibilities. Using an actor-network theory methodology to assemble a social ontology of the videoconferencing platform Zoom, this chapter explores how we may come to understand the varied nonhuman contributions to media arts learning that these platforms provide. Zoom is perceived as performing pedagogical acts that introduce stressors to the body often referred to as Zoom fatigue, create unique and augmented cinematic events that may lead to terror, and repeat larger trends in algorithmic bias that affects the access of all users. These pedagogical formations impact curriculum design, augmenting the assemblage of learning and compelling educators to ask ethical questions concerning digital well-being and what this means for the media arts.","['Education', 'Creativity and Arts Education', 'Education, general']"
doi:10.1007/978-3-031-16281-7_11,en,Resource-Constrained Implementation of Deep Learning Algorithms for Dynamic Touch Modality Classification,OriginalPaper,"Integrating Machine Learning (ML) algorithms with tactile sensing arrays yield sophisticated systems capable of performing intelligent tasks. Such systems can be used in prosthetic devices and robotics applications, enabling conducting daily tasks and manipulations. This paper presents low-cost and resource-constrained implementations of deep learning algorithms for the classification of dynamic touch modality based on alphabetic letter patterns. This work provides a comparison between two types of deep neural networks: 1-D Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs). Moreover, the models providing the best performance in terms of accuracy and computational cost have been deployed on a resource-constrained embedded system. Experimental results show that 1-D CNN outperforms RNNs in terms of both accuracy and computational cost achieving a classification time of 242 ms using 32-bit floating point on the Arduino Nano BLE hardware device.","['Engineering', 'Cyber-physical systems, IoT', 'Machine Learning', 'Robotics and Automation']"
doi:10.1007/978-981-19-5073-5_1,en,Introduction,OriginalPaper,"With the advent of Cloud Computing, Big Data, and Internet of Things, the twenty-first century can be fairly seen as an age of data and unearthing patterns from them. Everywhere, the move is toward extracting information from data and embedding intelligence in devices/applications like smartphones, security systems, home appliances, etc. Such advances indeed help us to make our lives easier, more efficient, and resourceful.","['Computer Science', 'Machine Learning', 'Computational Intelligence', 'Pattern Recognition']"
doi:10.1007/978-981-19-2126-1_27,en,Aerial Object Detection Using Different Models of YOLO Architecture: A Comparative Study,OriginalPaper,"Aerial object detection is a key to many functionalities like security systems, pedestrian counting, animal population estimation, security surveillance and many more. Previously used traditional machine learning approaches made use of handmade features and algorithms that failed to generalise on a larger data set. Therefore, deep learning models have outperformed the traditional machine learning models, especially in the computer vision field. Aerial object detection is a subdomain of object detection that has been a hot topic of interest in recent years. Transfer learning has emerged as one of the go-to methods to adapt models well on a small data set. This paper proposes a comparative study of the performance of three state-of-the-art object detection models on an aerial images data set using Transfer learning. The paper aims at studying how well a model can adapt to aerial images using transfer learning. The three models used are the YOLOv5m6, YOLOv5x6 and the YOLOv5l6 models based on the YOLO architecture. The data set used is the Vehicle Detection in Aerial Imagery (VEDAI) data set. The study finds out that the YOLOv5m6 model outperforms the other two models.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Machine Learning', 'Big Data', 'Computer Systems Organization and Communication Networks']"
doi:10.1007/978-3-031-20650-4_14,en,Medical Deepfake Detection using 3-Dimensional Neural Learning,OriginalPaper,"In recent years, Generative Adversarial Networks (GAN) have underlined the necessity for exercising caution in trusting digital information. Injection and removal of tumorous nodules from medical imaging modalities is one method of maneuvering deepfakes. The inability to acknowledge medical deepfakes can result in a substantial impact on healthcare procedures or even cause of death. With a systematic case study, this work seeks to address the detection of such assaults in lung CT (Computed Tomography) scans generated using CT-GANs. We experiment with machine learning methods and a novel 3-dimensional deep neural architecture on the topic of differentiating between tampered and untampered data. The proposed architecture on the CT-GAN dataset attained a remarkable accuracy of 91.57%, sensitivity of 91.42%, and specificity of 97.20%. Sectioned data cubes containing the affected region of interest seem to perform better compared to raw CT slices with a gain of approximately 20%. Furthermore, 3DCNN outperforms its 2-dimensional counterpart as it extracts temporal features unlike the spatial relationship insufficient for medical data processing. The outcomes of this research reveal that nodule injection and removal manipulations in complicated CT slices may be recognized with a high degree of precision.","['Computer Science', 'Artificial Intelligence', 'Computers and Education', 'Data Mining and Knowledge Discovery', 'Information Systems Applications (incl. Internet)', 'Computer Appl. in Social and Behavioral Sciences', 'Image Processing and Computer Vision']"
doi:10.1007/978-981-19-1610-6_50,en,Systematics Review on Detecting Cyberattack Threat by Social Network Analysis and Machine Learning,OriginalPaper,"This literature review gives an up-to-date overview of studies aimed at analyzing the information contained in social media messages, which reflect malicious activity that threatens cyberspace. This work presented studies aimed at detecting and predicting cyberattacks with the intent of altering, controlling, manipulating, damaging, or affecting victims’ digital services, computing equipment, and communications equipment of the victims. The method used in this systematic literature review is based on the model proposed by Petersen et al. The conclusion from the studies showed that the use of machine learning algorithms, deep learning, and natural language processing tools contributes to better detection of threats in social media. For future research, it is necessary to continue the implementation of the most recent tools of machine learning and deep learning and natural language processing, to improve the effectiveness of the results. The findings of this systematic review will enable the researcher to develop methodologies and mechanisms that could help detect and prevent future cyberattacks.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-030-99075-6_38,en,An Investigation of Unsupervised Data-Driven Models for Internal Combustion Engine Condition Monitoring,OriginalPaper,"Internal combustion (IC) engines are widely employed in power systems such as marine ships, small power stations and vehicles. However, due to its complex working conditions and sophisticated degradation mechanisms, IC engines commonly suffer various types of malfunctioning and faults, which affects their performance in power delivery. Therefore, it is important to monitor the condition of IC engines and detect faults occurred in time. In this paper, two unsupervised data-driven models using machine learning techniques are employed and investigated for the purpose of online condition monitoring and fault isolation of IC engines. A misfire and a lubrication system filter blocking faults are experimentally studied on a purposely built marine engine test rig. The performance of the two models and their contribution maps are discussed, which provides guidance for using such unsupervised models for the condition monitoring and fault detection of IC engines.","['Engineering', 'Industrial and Production Engineering', 'Mechanical Engineering', 'Machinery and Machine Elements']"
doi:10.1007/978-3-031-08782-0_15,en,Autonomous Vehicle Travel Between Multiple Aisles by Intelligent Agent-Based Modeling,OriginalPaper,"With the recent increase in e-commerce, automated warehousing industries seek technology solutions providing high transaction rates with economic investment costs. In this context, the application of smart operational policies towards future smart factories’ concepts becomes a critical issue. With the help of recent IT and technological advancements towards Industry 4.0 developments, we study intelligent autonomous vehicle operation policies where vehicles can make decentralized decisions for their safe and flexible travels between multiple aisles in a warehouse. By that, instead of assigning vehicles within a dedicated zone, we allow vehicles to travel freely between multiple aisles. The advantage of such a travel policy might result in a reduced number of vehicle requirements in a warehouse compared to a dedicated path policy. However, the disadvantage of such a flexible travel policy might be the development of smart collision and deadlock control algorithms, and that travel of vehicles might result in increased travel time during their operation due to deadlock and collision cases. First, we develop a smart travel policy approach for the vehicles using an agent-based simulation modeling approach. Then, we apply a statistical method, analysis of variance (ANOVA), to identify which input design factors significantly affect the system performance. As a result, it is observed that the number of bays is the most significant factor affecting the performance of such a system.","['Engineering', 'Engineering Economics, Organization, Logistics, Marketing', 'Business and Management, general', 'Computational Intelligence']"
doi:10.1007/978-3-031-20631-3_11,en,Multi-mode Control of Technical and Technological Systems: Analysis of Construction Methods and Areas of Effective Application,OriginalPaper,"The article deals with multi-mode electric drives of ship outboard equipment. A feature of the problem under consideration is the compensation of non-linear perturbations of the packet type. When performing work on the example of the descent-ascent of a manned underwater vehicle of the “Rus” type, an analysis of the properties of the operating modes of the controlled object was carried out, and the need to use a multi-mode controller for a qualitative solution of the task was substantiated. The result of the analysis of object properties and presented methods is the substantiation of rational approach for the development of control systems for multi-mode moving objects (descent-lifting operations) using a certain set of informative signs formed on the basis of measured values characterizing the current state of the object and the environment, combined with the methods of neural network technology and fuzzy logic. In this paper, this approach is used as the basis for the structural-parametric synthesis of scalable control systems for unmanned underwater complexes with multi-mode functioning algorithms. The purpose of the study is to analyze the methods and briefly characterize them for constructing multi-mode control systems for objects and processes.","['Engineering', 'Electronics and Microelectronics, Instrumentation', 'Electrical Engineering']"
doi:10.1007/978-981-19-2397-5_46,en,Designing a Driverless System Architecture,OriginalPaper,"In this paper, a driverless system architecture is proposed which is designed with the requirements regarded for the Formula Student competitions, but can also be related to general autonomous systems. In order to drive autonomously, a racing car relies on precise sensor data and accurate real-time algorithmic calculations. The autonomous system of a race car requires a lot of information about its environment, and several sensors can be combined to form a fail-safe system. Existing system design approaches are evaluated and a novel system architecture for a Formula Student driverless race car is modelled. Furthermore, relevant hardware interfaces for communication between the electrical and driverless components of the race car are defined.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4676-9_38,en,Hybrid Texture-Based Feature Extraction Model for Brain Tumour Classification Using Machine Learning,OriginalPaper,"The effort of detecting brain tumours by radiologists or clinical experts is arduous and time-consuming, and their accuracy is dependent on their level of knowledge. Medical scans, such as magnetic resonance imaging (MRI), provide a wealth of data that can be exploited to overcome these constraints by creating advanced methodologies and approaches for tumour detection. These approaches can assist radiologists in offering a second opinion when predicting tumours, hence reducing the human aspect in the process . In this context, the paper proposes a hybrid texture-based feature extraction (HTFE) technique by employing Grey level co-occurrence matrix (GLCM) and Gabor Filters for identifying brain tumours. Specially, the proposed HTFE technique assists the classifiers Gradient Boosting (GB), Random Forest (RF), and Decision Tree (DT) in predicting Glioma, Meningioma, and Pituitary brain tumours from T1-weighted contrast-enhanced MRI (T1-CEMRI) dataset. To train and evaluate the classifiers, the HTFE technique extracts a total of seventy-two second order texture features from T1-CEMRI. In terms of accuracy, the suggested HTFE approach beats state-of-the-art techniques.","['Engineering', 'Computational Intelligence', 'Systems and Data Security', 'Artificial Intelligence', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-981-19-6737-5_24,en,Generative Adversarial Network-Based Improved Progressive Approach for Image Super-Resolution: ImProSRGAN,OriginalPaper,"Recently, convolutional neural networks (CNNs) have been explored to achieve exceptional performance on super-resolution (SR) in terms of distortion metrics. In these methods, pixel-based loss functions have been employed to optimize their networks leading to overly smooth blurry solutions. In contrast, a generative adversarial network (GAN) has the proficiency to bring out perceptually better SR solutions. In the case of larger upscaling factors, some degradations are still discovered in the SR observations that can be reduced by increasing the number of convolution layers. However, such approach tends to increase the number of trainable parameters and additionally provides a lot of burden on resources which leads it to be unavailable for many real-world tasks. Here, we propose an improved progressive approach for SISR using GAN (i.e. ImProSRGAN). The potency of the proposed model has been seen by conducting different experiments where we observe that the introduced ImProSRGAN model performs better than existing GAN-based SISR approaches even though picking up fewer training parameters.","['Computer Science', 'Computer Communication Networks', 'Computer Applications', 'Computer System Implementation', 'Artificial Intelligence', 'Image Processing and Computer Vision']"
doi:10.1007/978-981-16-9967-2_72,en,Threats and Challenges of Artificial Intelligence in the Healthcare Industry,OriginalPaper,"The authors provide a crisp yet in-depth summary of the relevance of artificial intelligence (AI) in providing healthcare solutions. Artificial intelligence is a relatively new concept in the field of health care. AI aids in the prediction of disease patients for medical procedures. Patients, pharma companies, health services, insurance companies, and medical institutions benefit from AI’s application in health care. Artificial intelligence supports different concepts, counting computing, computer program improvement, and information exchange. Machine learning, profound learning, normal dialect generation, discourse acknowledgment, robots, and biometric distinguishing proof are illustrations of artificial intelligence’s innovation. Artificial intelligence is used in a variety of areas, including health care, manufacturing, and business. It is also used in the automotive industry. The authors have discussed the current scenario of artificial intelligence and the threats and challenges posed for AI in the healthcare industry.","['Computer Science', 'Computer Systems Organization and Communication Networks', 'Computational Intelligence', 'Artificial Intelligence', 'Wireless and Mobile Communication', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-0098-3_5,en,Smart Health and Cybersecurity in the Era of Artificial Intelligence,OriginalPaper,"Since 2020, the world has been impacted badly by the pandemic situation that arose due to the coronavirus. Artificial intelligence plays a crucial role in the healthcare system, specifically identifying symptoms of disease with the help of various machine learning algorithms during the diagnosis stage. The identified symptoms in various diagnostic tests are used to predict the clinical outcome of early detection of diseases, which results in human life saving. Machine learning algorithms have been successfully used in automated interpretation. With the advanced technology of cybersecurity aspects, we can emphasize data protection for better results. Artificial intelligence can enhance the security of medical science data. Furthermore, they improvise cybersecurity techniques with machine learning technologies.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Statistics, general', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-15928-2_61,en,Geometric Analysis of Product CAD Models to Support Design for Assembly,OriginalPaper,"Design For Assembly (DFA) aims at improving product design facilitating assembly phases via the application of evaluation metrics and design guidelines. However, DFA analyses are usually performed manually and the adoption of supporting tool is poor. This paper investigates the application of algorithms allowing to extract from CAD assembly models the required data to perform automated DFA analyses, thus providing a tool to support designers’ everyday works. In particular, attributes from geometric feature recognition algorithms, solids properties and assembly parts’ semantics are leveraged and mapped to the parameters required to accomplish DFA evaluations. The proposed approach is illustrated on a 3D printer for home use. At first, a manual DFA analysis has been performed on the product identifying product BOM, components properties, assembly cycle and times according to models in the literature. Then, the CAD model of the printer has been processed with some geometric algorithms to verify the possibility to extract the required data to be used as input to the DFA analysis. The test case has demonstrated the feasibility of the approach, even if some design considerations and improvement directions still need the critical evaluation of the designer.","['Engineering', 'Engineering Design', 'Industrial and Production Engineering', 'Computer-Aided Engineering (CAD, CAE) and Design']"
doi:10.1007/978-3-031-19958-5_65,en,Monitoring and Intelligent Management of Agrophytocenosis Productivity Based on Deep Neural Network Algorithms,OriginalPaper,"According to the “Strategy of Scientific and Technological development of the Russian Federation” and within the framework of the implementation of the program “Digital Agriculture” in the coming years, one of the priority areas of development is the transition to highly productive agro-agricultural farming. The main direction of scientific and technical development in agriculture is to increase agrophytocenoses based on the development and implementation of intelligent decision support systems implementing neural network models that allow monitoring the growth and development of agricultural crops in precision farming. Progressive agricultural producers using modern data collection tools have several thousand data collection points in the fields. However, the difficulties arising in the process of monitoring and managing information flows throughout the growing season, give rise to the need to create intelligent data processing systems based on the analysis of multispectral data obtained using remote monitoring tools. The relevance of the research conducted by the authors on the creation of an intelligent monitoring system for agrophytocenoses, implemented on the basis of neural network algorithms for deep learning, is due to the systematization of approaches to increasing agricultural productivity based on operational data of field monitoring.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-1-0716-2609-2_5,en,Molecular Dynamics Methods for Antibody Design,OriginalPaper,"Complex and coordinated dynamics are closely connected with protein functions, including the binding of antibodies to antigens. Knowledge of such dynamics could improve the design of antibodies. Molecular dynamics (MD) simulations provide a “computational microscope” that can resolve atomic motions and inform antibody design efforts.","['Biomedicine', 'Antibodies', 'Bioinformatics', 'Pharmaceutical Sciences/Technology']"
doi:10.1007/978-981-19-4676-9_19,en,IoTFEC-19: Internet of Things-based Framework for Early Detection of COVID-19 Suspected Cases,OriginalPaper,"World is battling with COVID-19 Pandemic, it has infected 236 million and taken over 4.83 million lives globally. In India alone, 33.89 million are infected and caused over 4.49 Lakh of fatalities. In Jammu and Kashmir, 3.3 Lakh are infected and caused over 4.4 thousand deaths. Researchers are trying their best to come up with solutions that can combat COVID-19. It is slated that the world has to battle with it and to follow SOP’s until and unless an effective vaccine will be developed. On the technological side, IoT is a new and promising area to combat with the COVID-19 Pandemic. Nowadays, smartphones and wearables have various onboard sensors like temperature sensor, proximity sensor, an audio sensor, camera, inertial sensor, color sensor, etc. that can be used in getting the data of a person. The temperature sensor reading can tell us the temperature of a person. Based on that reading, a person can be sent for further clinical tests at an initial level. IoT technology can accurately manage patient information, and can be effective in proactive diagnosis with reduced cost. The IoT technology, a set of well-organized components, can work together as a part of an system to fight against and will lower the spread of the COVID-19 Virus. IoT has gained considerable attention from almost every field, such as industries and especially from healthcare. IoT technology is reshaping the traditional healthcare system by incorporating technology into it. In this article, a IoT layered architecture have been proposed with three different layers. The detailed working of all three layers is explained. A novel IoTFEC-19 framework has been proposed to detect COVID-19 suspects early with sensors and wearable devices. The Framework consists of three layers: Sensing Layer or Data Collection Layer, Data Analytics Layer, and Prediction Layer. In Sensing Layer, different sensors are used to collect the data and send it for analysis. In Analysis Layer, the level of symptoms is calculated from the data received from the Sensing Layer. The third layer is the Prediction Layer, in which prediction is made from the computed values in Analysis Layer, whether the suspected may be COVID-19 positive or negative. The last layer is the cloud layer used for storage services and data used for further analysis. The proposed IoTFEC framework aims to detect the COVID-19 suspected early, provide early treatment, and stop further spreading.","['Engineering', 'Computational Intelligence', 'Systems and Data Security', 'Artificial Intelligence', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-3-031-18344-7_48,en,"A Universal IT Support System for Teachers for Educational Processes, Publishing and Academic Research Using All-in-One Educational Software",OriginalPaper,"Current learning technologies do not meet the needs of teachers and individuals. There is an information overload and the academic field has also become technology driven. Rather than technology operating according to the teacher’s needs, individuals are required to adapt to the existing software. Due to the incompatibilities between software, hardware and the formats of computer files, information chaos is growing to huge proportions. Unless educational algorithms (i.e., what is done with educational content) are defined, computer algorithms, software, and systems for the integration of IT into teaching cannot be designed. As part of our research into the automation of knowledge-based processes, which includes educational processes, we have managed to solve the problem of how to simulate human knowledge and pass it on to a computer, so that it can ‘understand’ it. Our solution is a model of virtual knowledge that can be processed quickly by a computer. The computer ‘understands’ this as a universal representation of knowledge, while from a teacher's point of view, it is an ordinary table into which the teacher inserts educational content. This virtual knowledge (having the structure of a database table) acts a kind of knowledge container that isomorphically connects the mental processes of the teacher with the physical processes of the computer. Our WPad educational software is programmed to control the structure (content), so, it is possible to create educational knowledge tables and personal knowledge base for any activity that the teacher performs during teaching, or research. The teacher does not need to adapt to the technology; instead, the technology adapts to the teacher's activities. Since the software runs on every Windows computer and works as a multiple-in-one educational IT tool for a variety of lessons, it is probably the most efficient and cheapest technology solution. It is used to support the integration of technology into classroom and distance learning. Future research will focus on the creation of multilingual educational packages.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-3-031-15928-2_34,en,Design and Development of an IoT Enabled Device for Remote Monitoring of Hydraulic Hammers,OriginalPaper,"Hydraulic hammers, also known as breakers and peckers, are utilized in a wide variety of applications for the demolition of a structure and breaking rocks into smaller sizes. These tools and equipment are extremely sensitive and operate in harsh environments. As a result, there is a widespread requirement for remote control and monitoring of equipment and machines. Thus, Remote monitoring of industrial equipment such as hydraulic hammers has become an important part of Industry 4.0 and Internet of Things technologies. This paper presents the design and development of an Internet of Things (IoT) device (data logger) to improve the usage and performance of hydraulic hammers based on remote monitoring by implementing sensors for data collection, analysis, and management. It is expected that with the design of the platform and optimal sensor placement, huge data (Big Data) will be obtained from the vibration, machine operation time, oil pressure, temperature, and oil flow of the hydraulic hammer, based on operation conditions and type of material. Extracting this information and analysis of huge data generated by the Data logger directly from the hydraulic hammer during operation provides unique prior information and can be useful to adjust process planning, the possibility to implement predictive maintenance, and provide standard technical information for different modes of the Hydraulic hammer.","['Engineering', 'Engineering Design', 'Industrial and Production Engineering', 'Computer-Aided Engineering (CAD, CAE) and Design']"
doi:10.1007/978-3-030-89123-7_194-2,en,Intelligent Weed Control for Precision Agriculture,ReviewPaper,,"['Life Sciences', 'Agriculture', 'Data Engineering', 'Signal, Image and Speech Processing', 'Control, Robotics, Mechatronics']"
doi:10.1007/978-3-031-19945-5_22,en,A Resource Allocation Technique for VANETs Inspired to the Banker’s Algorithm,OriginalPaper,"With the fast growth of the number of vehicles on our roads, the traffic congestion problem is becoming an issue in big cities. This work is inspired by a known algorithm, the banker’s algorithm, used in operating systems to handle the resource allocation to processes. By following this lead, we treat vehicles like processes making requests and roads as resources to be allocated, and we provide an algorithm to manage the vehicle distribution over the available paths so to reduce the traffic congestion.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Computer Applications']"
doi:10.1007/978-981-19-3679-1_44,en,A Survey of Different Supervised Learning-Based Classification Models for Student’s Academic Performance Prediction,OriginalPaper,"Despite delivering high-quality learning, the need to evaluate student’s academic achievement has become increasingly essential to optimize the integrity and aid learners to achieve excellent results in academics. One of the critical challenges is the inadequacy of an accurate and efficient estimation method. Predictive analytics (PA) can help organizations make more intuitive and intelligent decisions. The purpose of this paper is to evaluate existing educational-based student performance analytics study that focuses on forecasting learner educational excellence. Earlier academics have presented several strategies for developing the optimal process framework, employing various academic statistics, methodologies, methods, and platforms. Numerous learning challenges, like categorization, prediction, and cluster analysis, are associated with the predictive Analysis used during estimating students’ achievement. The student performance prediction model has various advantages and applications, such as it is used to help instructors in curriculum design and improvement. SPP provides recommendations to the students and offers comments to educators. In this paper, several methods of student performance prediction (SPP) are compared with the help of different performance parameters such as accuracy, specificity, and sensitivity.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1610-6_7,en,A Machine Learning Approach to Predict SEER Cancer,OriginalPaper,"The SEER database is among the persuading stores regarding malignancy pointers inside us. The SEER list helps impact investigation for the gigantic measure of patients’ bolstered viewpoints for the most part ordered as an insightful segment and impact. Assistant careful proof nearly the carcinoma dataset is ordinarily started on the site of the National Cancer Institute. The main point of this work is that depending on the individual’s manifestations, and we will foresee whether individuals are in danger of malignant growth or not. Perseverance and desire for the benefit of malignant growth patients have the option to upsurge prophetic exactitude and limit in the end cause better-educated decisions. To the current end, various amendments smear AI to disease data of the surveillance, epidemiology, and end results database. It may be used to better forecast cancer in the medical sector, and these studies can give a good chance to enhance existing models and build new models for uncommon cancers of minority groups in particular. In this paper, the authors contribute to getting more predicted accuracy for SEER cancer and use it to better forecast cancer in the medical sector.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16237-4_6,en,"Secure Design of Cyber-Physical Systems at the Radio Frequency Level: Machine and Deep Learning-Driven Approaches, Challenges and Opportunities",OriginalPaper,"With the deployment of new 5G services, many of the critical infrastructures such as connected vehicles, remote healthcare and smart infrastructures will be deployed on radio frequency (RF)- based networks. As such, society will be heavily dependent on the ability to protect these new wireless networks as well as the radio spectrum. Solutions such as artificial intelligence (AI)-based transmitter fingerprinting to identify and track unintended interference sources or malicious actors will be one of the several key technologies required to meet the needs of the next generation wireless networks as this technology is deployed as part of a critical infrastructure (CI). As an example, connected and autonomous vehicles (CAVs) can be considered under these cyber-physical systems and critical infrastructures. As 95 percent of new automobiles are expected to be equipped with vehicle to infrastructure (V2I), vehicle to vehicle (V2V), and other telecommunications capabilities by 2022. To ensure the safety of the public, new and automated techniques are needed to protect CAVs on the road from unintentional or malicious interference. Against these requirements, this chapter presents the state of the art in real time decision support systems for the cyber-physical systems that build on critical infrastructures such as CAVs, through radio fingerprinting solutions. In this chapter, we first present the legacy approaches used to detect, classify and identify a transmitter, and then we move towards the machine and deep learning-based (ML/DL) approaches for transmitter identification using RF fingerprinting techniques. Following upon a comparative study on the open issues, challenges, and opportunities towards ML/DL-driven security of the critical cyber-physical systems through RF fingerprinting.","['Engineering', 'Cyber-physical systems, IoT', 'Data Engineering', 'Computational Intelligence', 'Big Data', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16598-6_12,en,Multi-layered InterCriteria Analysis as a Digital Tool for Studying the Dependencies of Some Key Indicators of Mortality During the Pandemic in the European Union,OriginalPaper,"Intelligence healthcare expert systems (HCISs) assist decision-makers diagnose accurately and treat patients’ diseases. In a pandemic, they can also, by identifying the causes of higher mortality, predict a higher number of hospitalizations in intensive care units. The theory of intuitionistic fuzzy sets (IFSs), which is one of the first extensions of fuzzy sets of Zadeh, analyzes uncertain data. Uncertainty in data determines the need for the introduction of intuitionistic fuzzy HCISs (IFHCISs) for digital transformation of these processes which analyze uncertain data. The main determinant of the effectiveness of IFHCISs for diagnosing and treatment of diseases, prediction of ICU admission of patients during the pandemic and determining the main factors for higher mortality in pandemics is the optimal multicriteria system. An intuitionistic fuzzy interpretation of the classical rank correlation analyzes under the form of intercriteria analysis (ICrA) is proposed for optimizing each evaluation system of criteria in IFHCISs, based on the theories of index matrices and IFSs. The purpose of the chapter is to develop a model for successful optimization of multicriteria systems embedded in IFHCISs by expanding three-dimensional ICrA to multilayer ICrA (3-D MLICrA). The current pandemic situation raises problems about the dependence of pandemy deaths on certain factors. These problems have to process large data sets related to Covid’s mortality, some of which differ in the various reports. The effectiveness of 3-D MLICrA approach for optimizing the criteria of the IFHCIS is also demonstrated by an application on a dataset of total deaths attributed to COVID-19 and 15 key indicators of the European Union countries determining this mortality, provided by European Centre for DPC for 2021.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-19958-5_14,en,Impact of Artificial Intelligence on DOOH Advertising: Message-Persuasion Level Enhancement Using Illusion Board and Personalized Insights,OriginalPaper,"The marketing, more precisely, advertising industry has always been driven by the pursuit of personalization, precise identification of target groups, attracting the right audience and attribution for the least effort with the lowest cost. In order for this technique to be successful, it requires a significant and deep knowledge of the audience. That deep knowledge relies on data science, especially in marketing areas of search engine optimization, customer engagement, responsiveness, profiling and real-time marketing campaigns. Moreover, new ways to apply data science and analytics in marketing emerge every day as we witness activities like extreme personalization, micro-targeting, micro-segmentation, and many others. And as result OOH (“out-of-home advertising”) was disregarded until recently because of its lack of ability to provide attribution or consumer data. Nevertheless, transformation from traditional out-of-home advertising to digital out-of-home (“DOOH”) advertising or any “digital media endorsing audio and video messages related to products or services outside of the home”, illustrates how the advertising industry is leveraging new technologies to continue the pursuit of personalization and customization. Our research starts with traditional OOH and expand to usage of anamorphic illusion technology, which is the art of bending images through optical illusions which rely on viewers to be standing or viewing from a specific angle to actually see or realize the full effect of the finished creative. Being able to predict where viewers will stand, based on illusion board content, our research provide methodology which brings platform for message-persuasion level enhancement by collecting anonymized data and turn them into business-driven personalized insights. Research include AI empowered platform for recognition and collection of insights from audience.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-0108-9_32,en,An Investigation on Impact of Machine Learning in Additive Manufacturing,OriginalPaper,"One of the final phases in the product design process is prototyping or model creation. It is beneficial in the conception of a design. A model is produced and evaluated on a regular basis prior to the start of complete assembly. Historically, manual prototyping was employed to create a prototype. Additive manufacturing is a buzzword in the industrial and manufacturing industries. Initially, the CAD model of the components for the product was created in modeling software according to the specifications. Following the creation of a CAD model, the model is sliced by parallel planes equal to the layer thickness. As a result, the edges of these slices are quite sharp and squared, like a stair effect. These three-dimensional models will now be broken into small two-dimensional objects called slices. Simply said, a complicated three-dimensional problem has been reduced to a set of two-dimensional difficulties. These small two-dimensional files are known as STL files, and they are sent by tessellating the geometric three-dimensional model. Different surfaces of a CAD model are piecewise approximated by a sequence of triangles in tessellation, and the coordinates of triangle vertices and their surface normal are recorded. The predictive nature of various machine learning algorithms makes them the best instrument for dealing with additive manufacturing challenges. Machine learning techniques are capable of evaluating previous data and predicting future outcomes based on that analysis. This article discusses machine learning applications in additive engineering.","['Engineering', 'Manufacturing, Machines, Tools, Processes', 'Renewable and Green Energy', 'Materials Science, general', 'Nanotechnology']"
doi:10.1007/978-981-19-3951-8_68,en,"Application of ANN for Prediction of Heat Index in Historic Streets of Gwalior, India",OriginalPaper,"Urban heat island effect is a key agenda in the sustainable cities program initiated by United Nations. Increasing heat stress on cities influences the health of citizens and the energy demands of the built environment. In this study, the heat index is predicted using artificial neural network (ANN) models for typical summer months (March–June). Twenty-four neural network models were developed for two historic streets of Gwalior, India. Air temperature, relative humidity, month of year, day of month, and hour of day were used as input parameters, and the heat index was used as a target parameter. Optimal results were obtained with 6 hidden neurons and 2 hidden layers. The developed models were validated using coefficient of correlation (R2 = 0.816, 0.901) and root mean square error (RMSE = 2.81, 2.06) for both the streets. The results of this study establish the high predictive ability of developed ANN models. The study contributes by illustrating ANN as a potential tool for smart city initiatives in urban heat stress forecasting, thereby creating scope for real-time policymaking.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-981-19-7622-3_11,en,Intelligent Transportation System Services Using Internet of Things Devices,OriginalPaper,"Today with the Internet of Things (IoTs) we can easily connect real-world objects to the virtual world almost anytime and everywhere. It refers to a world in which real-world objects connect with virtual data. IoT-based solutions are playing a significant role in propelling the worldwide IoT in intelligent transportation systems (ITS). Communication among different automobiles via IoT would lead to a new era of connectivity that would lead to ITS. As more automobiles connect to the Internet, a tremendous volume of data is created. As a result, in order to construct effective systems, this massive volume of data must be managed and turned into meaningful information data. In this chapter, we focus on integrating intelligent transportation systems with the IoTs and Traffic optimization in intelligent transportation systems and their future prospect along with how they can solve real-world problems. Toward the end of the chapter, we have discussed open issues and their future.","['Engineering', 'Communications Engineering, Networks', 'Automotive Engineering', 'Transportation Technology and Traffic Engineering', 'Computer Applications']"
doi:10.1007/978-981-19-5798-7_1,en,Introduction,OriginalPaper,This chapter introduces the background and challenges of the collaborative multi-vehicle fleet maneuvering problem. The objectives and structure of this book are introduced as well.,"['Engineering', 'Control, Robotics, Mechatronics', 'Robotics and Automation', 'Control and Systems Theory']"
doi:10.1007/978-3-031-11047-4_9,en,Exploratory methodology for power delivery,OriginalPaper,"The conventional power network design process requires iterative modifications to the existing power network to eliminate hot spots and to converge to target impedance parameters. At later stages in the IC design process, this procedure may require significant time and labor due to the limited flexibility to accommodate necessary changes. Power delivery exploration during early stages of the design process may bring considerable savings to the system development effort. The number of iterations may be greatly reduced by choosing the initial parameters sufficiently close to the optimum. A power delivery exploration framework based on constrained global optimization is presented in this chapter. The parameters characterizing the power network are estimated at early stages of the development process, while considering both electrical and nonelectrical factors, such as area and cost. A Laplace transform-based circuit simulator is well suited for optimization purposes due to the high computational efficiency when a large number of iterations is required. In the first case study, a 15% reduction in decoupling capacitance along with a 38.6% reduction in power consumption is achieved while satisfying performance and power quality constraints. The proposed framework has also been applied to the distribution of voltage domains in a large scale integrated system, while minimizing the decoupling capacitance. The optimal number of voltage rails are determined, requiring approximately 40% less on-chip area than alternative solutions.","['Engineering', 'Circuits and Systems']"
doi:10.1007/978-3-031-19032-2_37,en,Development of Convolutional Neural Network for Defining a Renal Pathology Using Computed Tomography Images,OriginalPaper,"It is known that impaired kidney function leads to a deterioration of human health and quality of life. Modern medicine offers a method of computed tomography (CT) for the diagnosis of various types of renal pathology. At the same time, the risk of incorrect diagnosis by a doctor is still high, even with wide practical experience. The quality of CT scan analysis can be significantly improved by Convolutional Neural Networks (CNNs). This paper represents a construction of a CNN for the task of multiple classification of renal pathology, as well as a modification of the algorithm using a variety of activation functions.","['Engineering', 'Computational Intelligence', 'Machine Learning', 'Neurosciences']"
doi:10.1007/978-1-0716-2617-7_2,en,Synthetic Biology Meets Machine Learning,OriginalPaper,"This chapter outlines the myriad applications of machine learning (ML) in synthetic biology, specifically in engineering cell and protein activity, and metabolic pathways. Though by no means comprehensive, the chapter highlights several prominent computational tools applied in the field and their potential use cases. The examples detailed reinforce how ML algorithms can enhance synthetic biology research by providing data-driven insights into the behavior of living systems, even without detailed knowledge of their underlying mechanisms. By doing so, ML promises to increase the efficiency of research projects by modeling hypotheses in silico that can then be tested through experiments. While challenges related to training dataset generation and computational costs remain, ongoing improvements in ML tools are paving the way for smarter and more streamlined synthetic biology workflows that can be readily employed to address grand challenges across manufacturing, medicine, engineering, agriculture, and beyond.","['Life Sciences', 'Bioinformatics']"
doi:10.1007/978-981-19-0151-5_37,en,AI and TB: A New Insight in Digital Chest Radiography,OriginalPaper,"With reports of 9.9 million people being infected with tuberculosis by WHO, there is a dire need to curtail the spread of tuberculosis. In spite of having faced many impediments like lack of certified radiologist and chest radiography hardware which are expensive, diagnosis of tuberculosis still remains undetected at early stage. Chest radiography is one of the earliest method of detection used and is an asset for diagnosis of TB especially in early stages of infection, in a resource limited setting as well as for differential diagnosis. In the times of artificial intelligence (AI), we can see many modern platforms for the development of Computer-aided detection (CAD) through machine learning (ML) and deep learning (DL) and there are data coming forth indicating their utilization to the maximum. These approaches involve in hospital settings for examining the diseases through clinical aetiology as well as X-ray images of the patient. Presently, efforts and strategies are being framed and articulated to bring more accuracy adopting the use of the AI and machine learning approaches for the diagnosis of TB. This survey provides an insight to the application and use of CAD for the diagnosis of TB.","['Engineering', 'Biomedical Engineering and Bioengineering', 'Artificial Intelligence', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Biological and Medical Physics, Biophysics', 'Information Storage and Retrieval']"
doi:10.1007/978-981-19-1607-6_63,en,Iterative Approach for Reduction of Index-2 Periodic Models Using Generalized Inverse Procedure,OriginalPaper,"This chapter studies the structure-preserving iterative approach for reduction of index-2 periodic models descriptor systems using generalized inverses of periodic matrix pairs. This work fulfills two objectives. The first part of our research is concerned with the discrete-time generalized a system which reformulate from the discrete-time descriptor system by changing the structure of the system. Then the periodic matrix pairs are computed from the generalized inverse matrices, and the reformulated system is represented by a cyclic lifted structure. Smith method is exploited to find the iterative solutions of the associated Lyapunov equations of the cyclic lifted system. The original periodic system is contained in the solutions of the periodic Lyapunov equations. The periodic system is then reduced by using projectors computed from those periodic solutions. The above procedures are applied to reduce an artificial problem of the index-2 periodic structure. To verify the accuracy and performance of the algorithm, we have demonstrated the results obtained from numerical simulations.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-5077-3_9,en,Development of ANN-Based Risk Prediction Model in Construction Projects,OriginalPaper,"Construction projects are one among various major businesses which need high investments like time, money, resources to meet project requirements. As a result, risk is involved in executing construction projects. Timely completion of project within allocated budget is the main goal of any project. However, due to various risks involved, most of the projects are delayed and result in cost overruns. Thus, prediction of risk impacts on time and cost before their occurrence is essential for successful management of projects. Therefore, the objective of the study is to develop a model to predict risks using artificial neural network (ANN) approach. To achieve this objective initially, through literature review, 60 risk factors are identified. A questionnaire survey was conducted with 100 respondents to determine the probability and impact values of all risk factors. Based on survey data, an ANN model was developed using MATLAB software to predict risks. The findings revealed that ANN-based prediction can be utilized effectively to predict risks at early stages of construction project.","['Environment', 'Environment, general', 'Geoengineering, Foundations, Hydraulics', 'Sustainable Development', 'Environmental Engineering/Biotechnology']"
doi:10.1007/978-3-031-10507-4_1,en,Fundamentals of Blockchain Technology,OriginalPaper,"Blockchain is a technology developed for securely storing and transmitting information. It offers transparency and security by design without the need of any trusted third party (TTP) to validate the stored information. More precisely, the blockchain allows its users, connected by a peer-to-peer network, to share data without intermediaries. It also allows the implementation of advanced data structures, called smart contracts, that are used to automate agreements between users and institutions. Recently, the blockchain has gained an increasing attention from research and industry because of its capabilities of secure and transparent information storage. In addition, it is implemented today as a new system to decentralise several types of IT applications. In the field of cryptocurrencies, Bitcoin was the first application based on the blockchain technology, being the first known implementation of a blockchain to solve the problem of a decentralised ledger for financial affairs. In this chapter, we are interested in presenting the main fundamentals of blockchain technology and smart contracts and its current developments beyond cryptocurrencies.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Systems and Data Security']"
doi:10.1007/978-981-19-5224-1_24,en,Attack Detection in Internet of Things: A Systematic Literature Review,OriginalPaper,"As the frequency of security breaches continues to rise, cybersecurity remains a critical concern for every industry in the online. Thousands of zeroday attacks are known to emerge on a regular basis as a consequence of the integration of multiple protocols, primarily from the Internet of Things (IoT). The majority of such attacks are minor variants on previous research findings intrusions. This suggests that even sophisticated techniques like typical machine learning (ML) algorithms have difficulties spotting these tiny kinds of attacks over time. These attacks are called as DDoS attack; they are used to prevent clients from accessing a server or website. DDoS attacks have been employed by cybercriminals to bring down targeted servers and breach venture networks with the ability to overwhelm results. Because of the growing volume and complexity of DDoS attacks, many organizations are having difficulty handling them. Smart gadgets and IoT are particularly vulnerable to a wide range of DDoS hits due to resource constraints such as limited memory and processing capacity, thus cybercriminals are aware of these current technologies and their flaws. Because of an attack on their internet service providers in 2016, many firms, including Netflix, CNN, and Twitter, were forced to go down for nine hours. This technological failure resulted in several issues, including financial losses, productivity losses, brand damage, insurance rating drops, unstable client-provider relationships, and IT budget overruns. We need to construct an IDS system to expose and prevent DDoS attacks to secure data processing, information technology, and commercial components. The cost of cybersecurity will be greatly lowered if security teams use current and new technology like ML, automation, and artificial intelligence (AI). This study will examine the detection performance of DDoS attacks using several ML, DL techniques and also categorize it into cloud and fog ecosystems.","['Engineering', 'Communications Engineering, Networks', 'Statistics, general', 'Cyber-physical systems, IoT', 'Sociology, general', 'Professional Computing']"
doi:10.1007/978-3-031-19620-1_25,en,Data Mining Approach to Characterization of Bioactive Inorganic Scaffold Properties Using Synthetic Images,OriginalPaper,"The fundamental scientific problem in the paper is the patterns discovery using artificial intelligence to search for and determine the properties of bioactive inorganic scaffold nanomaterials from datasets with scanning electron microscopy (SEM) images. Bioactive inorganic scaffold nanomaterials are bioactive structures that are designed to temporarily provide bone functions. Due to the complexity of biomechanical processes of bone tissue regeneration, there is a set of requirements for scaffolds that exists. For example, porosity, diffusivity, permeability, and tortuosity are included in that set as main mechanical properties. Experimental chemical synthesis of scaffolds with predefined properties requires routine and manual cyclic laboratory operations with consumption of chemical substances until now. In this cycle, operators control desired scaffold properties by visually looking at SEM images of synthesized nanomaterial. Usually, SEM image datasets are not publicity distributed, have a limited number of samples and properties of material shown in SEM images can vary and out of interest depending on research conditions. As a novel approach, we have proposed an intelligent technology that applies the synthetic generation of SEM images and involves properties detected from images to the control process. Intelligent technology requires the minimum number of iterations in experimental synthesis of a material with the predefined biomechanical and functional characteristics. The main result of this paper is the intelligent convergence the chemistry exploration with SEM image synthesis that improves the characterization of scaffold morphology and determination of its mechanical properties.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-07254-3_43,en,Integration of Fatigue Estimation into Experimentable Digital Twins for Structural Applications,OriginalPaper,"Digital Twins are becoming a trend topic, as they raise expectancies for economic benefits in wide fields of industry, e.g., through better inventory prediction, improved product capabilities, predictive maintenance, and related business objectives. One concept to push Digital Twins into practice is the so-called Experimentable Digital Twin (EDT), which allows interaction between Digital Twins in a pure virtual or in a hybrid environment. We expect EDTs to generate additional values for structures and thus, provide an incentive for a more wide-spread use of SHM as the link between digital and real twin. An application, where EDTs generate extra value, is the use for fatigue problems of structures. By predicting the life fraction costs of their physical twins, EDTs allow to compare different process options in a virtual experiment. This is particularly useful if there are multiple options for the same mission. As an example, a crane trolley on a cantilever beam is inspected. The EDT is equipped with a plugin for cyclic counting for variable amplitude loading, which illustrates that basic analytical methods enable the EDT to give a quick estimation of life fraction costs.","['Engineering', 'Building Repair and Maintenance', 'Cyber-physical systems, IoT', 'Industrial and Production Engineering', 'Monitoring/Environmental Analysis', 'Analytical Chemistry']"
doi:10.1007/978-3-031-16281-7_6,en,Image Based Classification of Methods-Time Measurement Operations in Assembly Using Recurrent Neuronal Networks,OriginalPaper,"Image based classification enables the acquisition and transfer of data from manual assembly workstations into a digital environment. Based on the Methods-Time Measurement method, assembly processes are transformed into short, discrete basic operations that are recognised by means of image processing and used as input data for a multilayer neural network. A recurrent neural network algorithm is investigated for its applicability in combination with the sensor data. The five basic MTM operations reaching, grasping, bringing, releasing, and positioning are classified and additional influencing factors, as well as the implementation of an object recognition, are investigated. The following paper addresses the question of the extent to which manual assembly processes can be reliably derived from visual sensor data and classified by machine learning algorithms.","['Engineering', 'Cyber-physical systems, IoT', 'Machine Learning', 'Robotics and Automation']"
doi:10.1007/978-3-031-07654-1_13,en,Finger Knuckle Print Recognition Using Complex Conjugate Feature Vector,OriginalPaper,"Biometrics are human-specific traits that are employed in person identification and access control. Various biometrics such as fingerprints, finger knuckle, iris, palmprint, vein patterns, and DNA are used in recognition. Among these numerous biometrics, the researcher is drawn to the hand-based finger knuckle print (FKP). On the dorsal side of the hand, the FKP biometric is found. The creases and folds in the finger knuckle print are rich in textural pattern and can be utilized to identify individuals. The recognition of finger knuckles based on a complex feature fusion is proposed in this chapter. The subspace techniques such as principle component analysis (PCA) and linear discriminant analysis (LDA) are used to extract complex number features. These extracted complex vectors are fused using a parallel fusion strategy. Finally, finger knuckle PolyU and IIT Delhi datasets are used to test the developed parallel fusion complex features. The experimental results show that the proposed parallel fusion of complex vector for feature extraction techniques improve the classification accuracy.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Computer Communication Networks', 'Computational Intelligence']"
doi:10.1007/978-3-031-04524-0_18,en,Deep Learning Approach for IOT-Based Multiclass Weed Classification Using YOLOv5,OriginalPaper,"The quality information about soil, local climate, and the crop in an IOT environment is captured by the sensors. Furthermore, it is possible to obtain statistics that goes beyond human observation. They enhance and speed up data collection; perform commands automatically or remotely; and perform remote tasks and actions in real time. Agriculture lives in a digital age, of big data and of the IoT (Internet of Things). The technical management of weeds in row crops is carried out by applying herbicides mechanically or manually. Mechanical systems are generally effective in eliminating weeds at certain stages of growth. But different types of weeds restrict the performance of mechanical system. As a consequence, labor is required to remove weeds in close proximity to the plants, which can be more expensive than the mechanical procedure and not completely effective and results in large amount of pesticide usage which brings down the quality of crops. This paper presents the hybrid effective normalized vegetation index (NDVI) and YOLOV5 structure for multiclass classification of weeds. Nine different classes have been classified with good classification accuracy.","['Engineering', 'Cyber-physical systems, IoT', 'Communications Engineering, Networks', 'Computer Communication Networks']"
doi:10.1007/978-981-19-3148-2_11,en,Service Matter Judgement Prediction Using Machine Learning,OriginalPaper,"Machine learning (ML) algorithms can be used for predicting the judgement of legal matters. ML models get the ability to learn and improve from experience and can predict the verdicts of the petitions filed in appropriate courts. This paper analysed the basic description of the censure entry (CE) petitions and identify important factors related to CE cases that affect the outcomes. The relevance of ML in justice delivery will be predicated on the acquisition of clear and well-labelled datasets. A labelled dataset is made including all identified features and appropriate ML algorithms are applied. There are several supervised and unsupervised machine learning algorithms as Naïve Bayes, support vector machine (SVM), K-nearest neighbour, logistic regression, K-means, ensemble learning, and many others. This paper aims to apply the Naïve Bayes classifier for correctly predicting the verdict and find out whether a petition is ‘allowed’ or ‘dismissed’. The forecasting results can assist the presiding officers and judges to make decisions and final disposal of the petitions. It can also help the legal and non-legal professionals to have a basic understanding of the cases and their outcomes. The judgement prediction model is implemented on censure entry cases filed in concerned court against Home Department in U.P. State in India. Based on metrics values calculated for accuracy, precision, recall, and F 1 score, the performance is evaluated. The proposed model achieved 85% accuracy, 92% precision, 88% recall, and 90% F 1 score. Thus, the performance of the model proposed using Naïve Bayes classifier is very useful for predicting the outcomes of the petitions related to the employment matters of government servants and also of the employees of local authorities and government corporations and companies.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory']"
doi:10.1007/978-981-19-2126-1_16,en,Text Classification Using Deep Learning: A Survey,OriginalPaper,"In this paper, we have briefly reviewed the previous paper in this domain. The paper presents some of the state-of-the-art text classification techniques. We have discussed some of the best deep learning classification techniques and word representations. After reviewing several papers, we found that some of the authors had improved their performance by doing better preprocessing while some of them have made changes in the algorithms for better accuracy. We have compared models on different data sets based on their accuracy score. We have also discussed some metrics for evaluating the text classification models.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Machine Learning', 'Big Data', 'Computer Systems Organization and Communication Networks']"
doi:10.1007/978-3-031-13714-3_9,en,Local Search Learning,OriginalPaper,"If local research constitutes the backbone of metaheuristics, tabu search, looking to learn how to iteratively modify a solution can be considered the master of metaheuristics. Moreover, this term was proposed by his inventor. This chapter focuses on the ingredients at the basis of taboo search, namely, the use of memories and tactics for exploring the solution set. Other ingredients proposed in the context of taboo search by his inventor, like the candidate lists, ejection chains, and vocabulary building have a more logical place in other chapters.","['Business and Management', 'Operations Research/Decision Theory', 'Optimization', 'Computational Mathematics and Numerical Analysis', 'Algorithms', 'Computational Science and Engineering', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4204-4_18,en,Automated Crowd Parameter Estimation and Crowd Movement Analysis in Kumbh Mela,OriginalPaper,"Understanding crowd behavior is essential in mass religious gatherings for crowd managers. Surveillance devices such as CCTV provide data in real time in the form of raw video, while the crowd manager estimates the crowd state from video based on their experience. In this study, we propose a methodology to automate the crowd parameter estimation process using an object detection model and tracking algorithm, which will assist crowd managers in estimating the state of the crowd. There are two key contributions to this study. First, the study proposes a methodology to automate crowd parameter estimation from video in a mass religious gathering. Second, the existing state-of-the-art object detection model has been improved to adapt to the challenging situation of mass religious gatherings with high density, high diversity crowd videos. CCTV videos from Kumbh Mela 2016 are used for this study.","['Engineering', 'Transportation Technology and Traffic Engineering', 'Construction Management', 'Sustainable Development']"
doi:10.1007/978-981-19-1976-3_47,en,Static Hand Gesture Recognition for ASL Using MATLAB Platform,OriginalPaper,"Generally, communication with people in our daily life is by speaking with voice but some communications can be possible with body language, facial expressions, and hand signs. We can also communicate with others without voice. Apart from that, hand gestures are playing very important role in communication. Here, we developed a gesture identification system which interprets the American Sign Language. This system helps the people who are deaf and dumb. This system leads them to understand and communicate as like normal people. Lot of proposals are introduced on gestures specified with their languages like ASL, ISL, etc. Here, we are introducing new static gestures using MATLAB on bases of existing systems. Our input is captured from camera; then, system applies the pre-processing on captured image. The set of features are retrieved using PCA. Comparison of the features is done using Euclidean distance with the help of training sets. Finally, optimal gestures identify and produce the output inwards of text or voice.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-4388-1_10,en,A Study on Stability Condition for an Inconsistent Formulation in High-Density Ratio Flow,OriginalPaper,"Instability is a common occurrence in numerical simulation of flow issues with excess/high-density ratio. It frequently results in non-physical outcomes. The prime factor of such outcome was the numerical formulation unreliability. In order to get correct findings, the authors ensure that the algorithms are consistent. As a result, computational cost rises by jeopardising the simplicity of the algorithms. In this current study authors illustrate that for aforementioned flow problems, correct findings can be generated by the selection of proper scale of parameters along with inconsistent formulation. Moreover, a study is performed by the authors in order to determine the circumstances within which an inconsistent formulation can be as precise as a consistent formulation.","['Engineering', 'Engineering Fluid Dynamics', 'Industrial and Production Engineering', 'Engineering Thermodynamics, Heat and Mass Transfer']"
doi:10.1007/978-981-19-2126-1_33,en,A Novel Ensemble Model to Summarize Kannada Texts,OriginalPaper,"Automatic text summarization is the task of producing a smaller piece of text containing important sentences and all relevant important information from the original document. With the existence of abundant digital data, this technique helps in gaining quick access to the required data in native languages. In this work, we present a technique for an efficient extractive summarization of Kannada documents and articles. In the proposed novel ensemble model, each of the sentences in the input text are assigned a ‘Weighted Terms value’. This is computed by leveraging the concepts of term frequency—inverse document frequency (TF–IDF) algorithm, Galavotti Sebastiani Simi (GSS) coefficients and positional ranking of sentences. An additional mathematical function is also devised to compute weights for sentences as a whole, based on their positions in the text. The final summary is curated by coherently picking the sentences whose ‘weighted terms value’ exceeds the threshold which is set based on the size of the required summary.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Machine Learning', 'Big Data', 'Computer Systems Organization and Communication Networks']"
doi:10.1007/978-981-19-5331-6_33,en,Review of Deep Learning: A New Era,OriginalPaper,"Deep learning (DL) made surprising progress in different Artificial Intelligence (AI) and Computer vision applications. The learning permits different handling layers to learn highlights without help from anyone else inverse to traditional AI approaches, which could not handle the information in their normal structure. Deep convolution networks have shown incredible execution in handling pictures and recordings, though intermittent nets have shown extraordinary accomplishment for consecutive information. This paper surveys every one of the angles and investigates done work now around here alongside their future prospects.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-20601-6_18,en,A Comparison of Deep Learning Techniques for Corrosion Detection,OriginalPaper,"Corrosion—degradation in metal structures—is problematic, expensive to rectify, and can be unpredictable in the rate at which it spreads. Traditional preventative maintenance techniques are complemented by human visual inspection, in turn complemented by artificial intelligence vision techniques. The primary objective of this paper was to determine the most accurate deep learning model for use in corrosion detection; to achieve this, we devised an experimental comparison that tested five machine learning algorithms for the detection of corrosion from image data. The deep learning that forms the basis of algorithms used to solve object recognition problems traditionally requires large amounts of training data. As this data requires manual labelling by a person who is expert in the domain of corrosion, it is difficult and expensive to obtain; time and expense that increase considerably as more sophisticated pixel-level annotation is applied. We discovered that high levels of accuracy (98%) can be achieved using deep learning to detect corrosion using samples annotated with simple, image-level labels. We achieved this headline accuracy through the application of transfer learning using models that had been trained on the ImageNet dataset. With many deep learning algorithms to choose from, we systematically determined the most accurate model to use as a basis for further experimentation.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-18311-9_11,en,Measuring and Assessing the Resource and Energy Efficiency of Artificial Intelligence of Things Devices and Algorithms,OriginalPaper,"Artificial Intelligence (AI), the Internet of Things (IoT) and digitization are very influential topics in current times, changing many areas in which they are applied. The combination of AI and IoT (Artificial intelligence of things—AIoT) has already showed many useful applications and opportunities in many industries and other fields, like ecology, disaster management, and the society. Over the past decade, the idea has gained attention that not only computer hardware consumes resources (raw materials and energy) over its life cycle, but software also significantly contributes to the footprint of these systems, since it triggers their production, usage, and eventual disposal and renewal. To counter this consumption, it is necessary to have appropriate tools to assess it first. Therefore, in this paper, we extend upon existing methods for the measurement, assessment, and eventual optimization of software, regarding their resource- and energy efficiency and apply them to the field of AIoT-based systems.","['Business and Management', 'IT in Business', 'Environmental Management', 'Geotechnical Engineering & Applied Earth Sciences', 'Energy Policy, Economics and Management', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3387-5_161,en,Panoramic Video Quality Assessment Based on Spatial-Temporal Convolutional Neural Networks,OriginalPaper,"The development of 5G technology and Ultra HD video provide the basis for panoramic video, namely virtual reality (VR). At present, the traditional VQA method is not effective on panoramic video. Therefore, it is crucial to design objective VQA models for the standardization of panoramic video industry. With the development of deep learning, excellent algorithms of VQA methods based on convolutional neural network have emerged. In this paper, we propose a full reference VQA model based on spatial-temporal 3D convolutional neural network, the feature extraction combined the time and spatial information. we verify and optimize the proposed VQA model based on VQA-ODV panoramic video database, its objective score has a higher correlation with subjective scores than that of traditional VQA methods.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Aerospace Technology and Astronautics']"
doi:10.1007/978-981-19-6004-8_11,en,A Survey on Hybrid PSO and SVM Algorithm for Information Retrieval,OriginalPaper,"This research study investigates different methods for rating an archive by using AI methodologies for determining Information Retrieval [IR] ranking position. SVM (Support Vector Machine) and PSO (Particle Swarm Optimization) are considered as the significant IR positioning methods. Selecting matching bounds in SVM is a complex process, yet it provides possible alternatives for positioning. One of the streamlining solutions, Particle Swarm Optimization (PSO), is simple to use and has a global inquiry capacity. As a result, a hybrid SVM-PSO model is presented to search for the fitness capability in order to advance the positioning of report recovery. This study has developed a novel PSO-SVM model, a combination of PSO and SVM to improve the order exactness with a limited and suitable element subset. This streamlining tool combines the discrete PSO with the continuous PSO to advance the information included in subset determination and the SVM bit boundary establishment. To decrease computational time, the hybrid PSO-SVM information mining framework was executed by using a distributed design accompanied with web administration innovation.","['Engineering', 'Computational Intelligence', 'Cognitive Psychology', 'Personality and Social Psychology', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-3575-6_48,en,Analysis of EEG Signals Using Machine Learning for Prediction and Detection of Stress,OriginalPaper,"The working stress has really affected our lives. People around us are facing challenges due to various reasons that can be stressful and can also cause strong emotional unbalance in adults and children. All the public health actions like social distancing, to stay isolated, has lead people to be not only stressful but also anxious, which directly affects health and tends to worsening of chronic health problem. Also, working under such conditions is not recommendable and henceforth in this paper we stated that using non-invasive method how we can early detect the level of stress and then the individual can take respective precautionary measure against it. Since any type of stress can be fatal, thus need of stress detection is most important. Various methods exist to detect stress like Magnetic Resonance Imaging, Electromyography, Electrocardiogram, and Positron Emission Tomography which can help to quantify stress in an individual’s body. EEG is physiological features produced by brain’s electrical activity, and thus, we get the voltage difference when we take EEG signals form brain scalp it is a non-invasive method. Also, the EEG signals are precise and reliable so it is better option to be considered for stress detection. We have considered various classifiers and compiled a detail analysis of all, and among that, we got the maximum accuracy for SVM. Output expected from this project is to detect stress so that further diseases can be prevented and one can lead to happy, healthy, and productive life.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-3951-8_17,en,A Deep Learning Model for Air Quality Forecasting Based on 1D Convolution and BiLSTM,OriginalPaper,"Particulate matter has a significantly larger impact on human health than other toxins which makes air pollution a highly serious problem. The air quality of a given region can be utilized as a primary determinant of the pollution index, as well as how well the industries and population are controlled. With the development of industries, monitoring urban air quality has become a persistent issue. At the same time, the crucial effect of air pollution on individuals’ healthiness and the environment and monitoring air quality is becoming gradually important, mainly in urban areas. Several computing methods have been studied and compared to verify the accurateness of air quality forecasting requirements to date, ranging from machine learning to deep learning. This paper introduced a deep learning air quality forecasting approach based on the convolutional bidirectional long short-term memory (CBLSTM) model for PM 2.5, which combines 1D convolution and bidirectional LSTM neural networks. The experiment findings demonstrate that the suggested approach outperforms the LSTM, CBLSTM, and CBGRU comparison models and achieves a high accuracy rate (MAE = 6.8 and RMSE = 10.2).","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4971-5_56,en,A Data-Driven Machine Learning Model for Transmission Line Faults Detection and Classification for the Smart Grid,OriginalPaper,The smart grid is an intelligent power system network that should be reliable and resilient for sustainable operation. Wide area measurements systems are deployed in the power grid to provide real-time situational awareness to the power grid operators. Deriving meaningful insights from the growing voluminous data will be an excellent approach toward effectively using data being captured. This paper proposes an ensemble machine learning model for fault detection and fault type classification. The model is trained with features derived from data using an Ensemble feature extraction method. The ensemble feature extraction method’s efficacy is compared with state-of-the-art feature extraction methods. The proposed model gives an accuracy of 99.9% for fault detection and above 90% for fault classification. A considerable decrease in model training time is also a beneficial characteristic of this model. The model is trained and validated by data from IEEE 39 bus system.,"['Engineering', 'Power Electronics, Electrical Machines and Networks', 'Energy Policy, Economics and Management', 'Energy Systems']"
doi:10.1007/978-981-19-2126-1_19,en,Noise Removal in ECG Signals Utilizing Fully Convolutional DAE,OriginalPaper,"The electrocardiogram signals (ECG) are helpful in determining the rate and rhythm of heartbeats and also the presence of any harm to the heart muscle cells. These signals have various applications that include the detection and prevention of arrythmia disease. But these signals are by default predicted with noise which leads to wrong classifications. To avoid noisy inference, numerous approaches for denoising ECG signals have been proposed, including adaptive filtering, wavelet methods, and empirical mode decomposition. Our motive is to illustrate supremacy of clinical practice by demonstrating enhanced denoising as well as compression performance. Here, we offer a new /emphFCN-based denoising technique for ECG data in this study. DAE is well known for its ability to learn low-dimensional representations and for its ability in recreating noise-free data. To eliminate noises from the noise-corrupted ECG data, we propose an FCN-based DAE. As a result, the experiment’s findings reveal that FCN is superior with the lower RMSE, PRD and greater SNRimp. This denoising approach has a low computing complexity and is quite accurate.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Machine Learning', 'Big Data', 'Computer Systems Organization and Communication Networks']"
doi:10.1007/978-981-19-3490-2_16,en,Cloud Battery Management System,OriginalPaper,"An intelligent battery management system is a crucial enabler for energy storage systems with high power output, increased safety and long lifetimes. With recent developments in cloud computing and the proliferation of big data, machine learning approaches have begun to deliver invaluable insights, which drives adaptive control of battery management systems (BMS) with improved performance.","['Engineering', 'Automotive Engineering', 'Transportation Technology and Traffic Engineering', 'Energy Systems', 'Energy Materials']"
doi:10.1007/978-981-19-3575-6_57,en,Implementation of Threats Detection Modeling with Deep Learning in IoT Botnet Attack Environment,OriginalPaper,"IoT forensics where security and privacy are the key concern as the data the majorly hold personal information. So how to work on the vulnerabilities available from the IoT environment and classify them to get the best results to perform the forensics is covered in the paper. In IoT forensics, botnet dataset analyzed using deep learning classification to get the understanding that how deep learning can be used effectively for forensic analysis. So research work provides advanced digital forensics methods, i.e., collection of evidences and analysis of dataset for IoT forensics implementation. Since a decade ago, we are seeing a reality where hacking into a client's PC utilizing small bots or blocking a gathering of interconnected gadgets is not any more unthinkable. These little bots are called botnets (e.g., Mirai, Torii and so on.), which are a gathering of deadly codes that can obstruct the whole security. As Internet of Things (IoT) is developing quickly, the interconnected gadgets are helpless to penetrate as one influenced gadget can crumple the entire system. As Internet of Things (IoT) is developing quickly, the interconnected gadgets are defenseless to break as one influenced gadget can hamper the entire system. The security danger stays as botnet assaults increment their essence to the interconnected gadgets. In this work, we are proposing a novel correlation between AI (SVM and KNN) and profound learning draws near (neural system) to discover which approach creates better outcome while learning the assault designs. Research explores the IoT forensics analysis. In IoT forensics, models were applied on a composite information storehouse which was made by consolidating the outcomes found from the examination we did on Torii botnet test, with the CTU-13 dataset of botnet assaults on IoT environment.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-3951-8_34,en,Numerical Modelling and Simulation of Improved Partial Transmit Sequence for PAPR Reduction in OFDM Communication System,OriginalPaper,"Wireless communication systems rely on channel capacity and peak average to power ratio (PAPR) to deliver reliable communication across wireless medium. A high peak-to-average power ratio affects both the amplifier rating in OFDM systems and the potential future contenders for 5G systems like Filter Bank Multicarrier (FBMC) and Universal Filtered Multicarrier (UFMC). Increases in wireless network users cause a fluctuation in demand for channel capacity. For fading channels, multiple input, multiple output and orthogonal frequency division multiplexing (MIMO OFDM) is a persuasive approach of improving the capacity. Channel capacity is limited by the use of power allocation methods. Because of the current capacity of the channel, we can thank the water filling power allocation mechanism. In order to reduce PAPR in OFDM systems, a technique based on enhanced partial transmit sequence must be developed, analysed, and put into use (PTS). MIMO OFDM system capacity enhancement is presented in the proposed research by applying a water filling technique to improve the OFDM system's capacity utilisation efficiency. Other current algorithms, such as selective mapping and clipping, were compared in the suggested study. The suggested algorithm's performance was also compared to other capacity-enhancing solutions. Channel capacity and the peak average to power ratio both fell by 5% in the proposed system. Cooperative network dynamics can be better understood with the help of a comprehensive research conducted in MATLAB.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']"
doi:10.1007/978-3-031-11051-1_33,en,The Effect of Distributed Generation Plants’ Prognostic Controllers on Power Quality in Power Supply Systems of Non-traction Consumers,OriginalPaper,"In power supply systems powered from mainline railroads’ traction substations, the problem of ensuring the electric power quality is acute. One of the effective ways to solve it is the use of smart grid technologies, an important segment of which are automatically controlled distributed generation plants. The article presents the results of computer simulation of transients during an increase in traction load, which leads to deterioration of power quality in non-traction consumers’ power supply systems. The purpose of the study was to determine the efficiency of using distributed generation plants to improve the power quality in power supply systems of on-site facilities powered from mainline railroads’ traction substations. Particular attention was paid to the setting and algorithms of the automatic controllers of the distributed generation plant synchronous generator and their influence on the indicators of the transient process and the power quality in the power supply system. The studies were conducted in the MATLAB development and simulation environment. Their results indicated that the presence of distributed generation plants allows to improve the power quality factors at the busbars of non-traction consumer; concordant setting of controllers provides the possibility for additional improvement of these indicators. The use of prognostic controllers ensures maintaining of power quality factors at a constant level when changing the generator load. The use of direct current link and prognostic controllers almost completely eliminates voltage asymmetry and harmonic distortions, significantly reduces the oscillability and value of voltage overshoot and generator rotor speed of the distributed generation plant.","['Engineering', 'Control and Systems Theory', 'Control, Robotics, Mechatronics', 'Communications Engineering, Networks']"
doi:10.1007/978-3-031-16072-1_9,en,Siamese Neural Network for Labeling Severity of Ulcerative Colitis Video Colonoscopy: A Thick Data Approach,OriginalPaper,"Research on learning automatically medical image descriptors requires very large sample training data along with complex deep learning neural networks models. This is a challenging requirement for many medical specialties. However, new research trends indicate that Siamese neural network can be trained with small samples and still provide acceptable accuracy, but this yet to be demonstrated for medical practices like identifying ulcerative colitis severity in video colonoscopy. In this research paper, we are introducing a Siamese neural model that uses triplet loss function that enables the gastroenterologist inject anchor images that can correctly identify the ulcerative colitis severity classes and we are using for this purpose the Mayo Clinic Ulcerative Colitis Endoscopic Scoring scale. The Python prototype demonstrates performance accuracy of 70% in average by only training the model with one video of 75 frames along with 24 anchor images. This research is part of our ongoing effort to employ more thick data techniques for enhancing the accuracy and interpretations of deep learning analytics by incorporating more heuristics from the experts. We are following this attempt by other validation methods including the YOLO visual annotation and additive image augmentations.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-3-031-09016-5_4,en,Proportionality,OriginalPaper,"A key difference among ABC rules is how they treat minorities of voters, i.e., small groups with preferences different from larger groups. Let us illustrate this issue with the following simple example.","['Computer Science', 'Artificial Intelligence', 'Social Choice/Welfare Economics/Public Choice/Political Economy', 'Theory of Computation', 'Multiagent Systems']"
doi:10.1007/978-3-031-16281-7_49,en,Motor-Unit Ordering of Blindly-Separated Surface-EMG Signals for Gesture Recognition,OriginalPaper,"Hand gestures are one of the most natural and expressive way for humans to convey information, and thus hand gesture recognition has become a research hotspot in the human-machine interface (HMI) field. In particular, biological signals such as surface electromyography (sEMG) can be used to recognize hand gestures to implement intuitive control systems, but the decoding from the sEMG signal to actual control signals is non-trivial. Blind source separation (BSS)-based methods, such as convolutive independent component analysis (ICA), can be used to decompose the sEMG signal into its fundamental elements, the motor unit action potential trains (MUAPTs), which can then be processed with a classifier to predict hand gestures. However, ICA does not guarantee a consistent ordering of the extracted motor units (MUs), which poses a problem when considering multiple recording sessions and subjects; therefore, in this work we propose and validate three approaches to address this variability: two ordering criteria based on firing rate and negative entropy, and a re-calibration procedure, which allows the decomposition model to retain information about previous recording sessions when decomposing new data. In particular, we show that re-calibration is the most robust approach, yielding an accuracy up to 99.4%, and always greater than 85% across all the different scenarios that we tested. These results prove that our proposed system, which we publish open-source and which is based on biologically plausible features rather than on data-driven, black-box models, is capable of robust generalization.","['Engineering', 'Cyber-physical systems, IoT', 'Machine Learning', 'Robotics and Automation']"
doi:10.1007/978-981-19-4193-1_20,en,"Using HMM, Association Rule Mining and Ensemble Methods with the Application of Latent Factor Model to Detect Gestational Diabetes Mellitus",OriginalPaper,"Gestational diabetes mellitus (GDM) is a condition often seen during pregnancies in which a hormone made by the placenta prevents the body from using insulin effectively. Women with GDM are at an increased risk of complications during pregnancy and during delivery. The offspring and the mother are also at an increased risk of getting diabetes in the future. Therefore, careful screening is necessary to avoid further complications. The objective of this research is to facilitate proper prediction of the presence of GDM in women so that timely intervention can help prevent future adversities. Multiple machine learning algorithms with data analysis methods are employed to investigate the probability of GDM and reach an optimal solution. The methodology makes use of the latent factor model and stochastic gradient descent to account for the missing data. Information entropy is used to calculate the amount of information each variable presents. The final classification is done and compared using three methods. These include ensemble method, hidden Markov model, and association analysis. Experiments reveal that the ensemble method involving decision trees, k-nearest neighbors, and logistic regression with weighted averaging delivers promising performance. Test data accuracy of 80% was recorded on the ensemble method.","['Engineering', 'Computational Intelligence', 'Information Storage and Retrieval', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Data Structures and Information Theory', 'Artificial Intelligence']"
doi:10.1007/978-3-031-19958-5_109,en,Bangla Song Suggestion Using Face Detection,OriginalPaper,"Face recognition system has gained a lot of interest because of its wide range of applications and business potential. Facial recognition system is a bit of technology that can match a person's face in a digital picture or video frame to a database of faces. Face detection, feature extraction, and face recognition are the 3 steps of facial recognition software. In image analysis, face detection is a challenging problem. It's now included in a multitude of fields, such as security systems, streaming video analysis, and other scientific innovations. Also, melody is really do have a deeper emotional bond than other forms of art. It possesses a one-of-a-kind ability to lift one's mood. This investigation, on the other hand, focuses on creating an excellent music recommendation system that leverages Facial Recognition methods to determine the user's mood. Music recommendation technique is an independent learning system that analyzes several users' playlists and makes suggestions for each user's specific playlist. This concept is built on user-to-user suggestions. The applied algorithm is OpenCV which is outperform existing systems. This would result in the saving of time and effort spent physically conducting the operation. The technique overall aim consists to identify swiftly suggest melodies based on facial expressions. The suggested process will have both advantages and disadvantages.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-15900-8_16,en,Cyber Security,OriginalPaper,"Ground and space infrastructure are continuously growing in terms of software and hardware complexity and are therefore getting more and more subject to cyber attacks. This chapter provides an overview of the basic principles of attack vectors and how they can abuse vulnerabilities present in an IT system. The need for cyber security to be an integral part of the ground segment systems engineering process is emphasised, and a basic understanding of the various types of attacks and the potential damage they can cause is developed. The concept of the attack surface is introduced as a measure of the overall vulnerability of a system and a means to identify the specific areas where weaknesses prevail. This allows a better and faster improvement through targeted security updates. The difference between cyber security audits as a method to understand the current cyber state of a system, and penetration tests as a tool to find new vulnerabilities is elaborated. The importance to perform both of them on a regular basis is stressed and the application of the cyber kill chain concept as a good practice to design more realistic attack scenarios is recommended. The concept of threat analysis is introduced as a means to find a more robust design that takes into account the actual cyber threat environment a system is exposed to. A basic introduction to cryptography is provided and explains the most common algorithms, the importance of key complexity, and possible means to exchange keys securely over a network.","['Engineering', 'Aerospace Technology and Astronautics', 'Astronomy, Astrophysics and Cosmology', 'Communications Engineering, Networks', 'Management of Computing and Information Systems', 'Operations Management', 'Security Science and Technology']"
doi:10.1007/978-3-031-16075-2_45,en,Mitigating IoT Enterprise Vulnerabilities Using Radio Frequency Security Architecture,OriginalPaper,"Internet of Things (IoT) as an emerging technology has metamorphized the use of smart devices, exchange of information and enhanced business processes in a ubiquitous and multi-faceted way. As Internet of Things (IoT) continues to gain tractable usage by billions of connected devices personal area network vulnerabilities, as identity and data theft, malware attacks and DDOS (Distributed Denial of Service) have become prevalent. In this study, we investigate the use of Radio Frequency (RF) technology mitigating IoT vulnerabilities. Deployment of secure RF network that enhances interoperability of IoT Devices by allocating unique ID (signature) is evaluated. This study further explores clustering of heterogenous networks of IoT devices using an intelligent Radio Frequency model that identifies labels and anonymizes Radio Waves shared by IoT devices within electromagnetic field. This vulnerability mitigation process encompasses use of Machine learning and neural networks classification to cluster heterogenous IoT and networks shared by IoT devices. The use of unique ID for clustered heterogenous is simulated in this study as against foreign and unauthorized radio frequency threats to paired IoT devices in a shared network.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3148-2_24,en,Using AI-Based Approaches in Health Care for Predicting Health Issues in Pregnant Women,OriginalPaper,"In developing countries, healthcare monitoring is a crucial component for determining the well-being of the patient, and at the same time, it is highly effective for managing the hospital resources which are limited in developing countries like India. With the increase in amount of digital data available for healthcare sector and the development of tools for data analysis, a new era of medical treatment could be arrived at with stringent methods of checking the efficacy of medicines and devising statistically valid tests that would authoritatively show the scope of medical treatment. This paper proposes a conceptual healthcare data model based on data mining techniques. The predictions have been made based on NHRM and RCH dataset, and three data mining tools, i.e., IBM SPSS Modeler, RapidMiner, and Weka, are used for determining the performance of the proposed model. Different classifiers, namely CHAID, random forest, K-nearest neighbor, logistic regression, decision tree, Naïve Bayes, and C5.0, are used for predicting the stay of pregnant ladies in the hospital. A detailed analysis of these classifiers on the data mining toolset is also presented in this paper.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory']"
doi:10.1007/978-981-19-5244-9_1,en,"Climate Change and AI in the Financial, Energy, Domestic, and Transport Sectors",OriginalPaper,"Chapter 1 outlines a brief description of various domains covered in this book and the carbon emitted by each one of them while performing their normal activities. The chapter highlights the usage of AI/ML to predict the climate change consequences arising due to investment in fossil fuel sectors, predicts CO 2 emissions from the transport sector, forecasts average land temperature due to non-renewable sources of energy, and segments Indian states on the basis of household carbon emissions. The remaining chapters dive deep into the individual domains and present insights which can guide us to arrest the negative impacts of climate change. The financial institutions, energy, and transportation sectors, as well as individuals, can be encouraged to collect data from operations activities and every part of the value chain, and then use AI-powered data engineering to track emissions throughout their carbon footprint.","['Engineering', 'Computational Intelligence', 'Sustainable Development', 'Artificial Intelligence', 'Data Structures and Information Theory', 'Machine Learning']"
doi:10.1007/978-981-19-1939-8_47,en,A Case Study to Predict Structural Health of a Gasoline Pipeline Using ANN and GPR Approaches,OriginalPaper,"Almost all fluid transportation in oil and gas facilities from one point to another are mainly using simple and complex pipelines system. These pipelines system is vital as it generates significant cash revenue to the facilities. However, the structural health of pipeline deteriorates over time due to various damage mechanism. Any Loss of Primary Containment (LOPC) to the pipelines can lead to heavy business losses. Facility engineers will normally apply the most common approach to mitigate the LOPC by providing schedule maintenance, perform repair activities as well as system replacement. These activities are mostly controlled manually by the engineers. This paper will focus on the prediction of structural health monitoring of gasoline pipeline located in one of the facilities in Malaysia, using historical inspection reports by means Artificial Neural Networks (ANN) and Gaussian Process Regression (GPR) regression techniques. The collected data was analyzed and applied on these two methods to determine the best fitness and performance. It is noticed that both Bayesian-regularization ANN and exponential GPR model demonstrate better performance compared to the others when assessed based on the highest R 2 value. The results were deemed satisfactory as the R 2 value for both methods were close to 1.0. The results also showed that both ANN and GPR models were almost equal in predicting the structural health of a pipeline with an accuracy of 99% and 97.3%, respectively. This work may help in controlling/monitoring the inspection cost and to preplan the maintenance scheduling for gasoline pipeline network in oil and gas industry.","['Engineering', 'Industrial and Production Engineering', 'Power Electronics, Electrical Machines and Networks', 'Energy Storage']"
doi:10.1007/978-1-4842-8928-0_4,en,Deep Learning for Metaverse XR and Multimedia Systems,OriginalPaper,"Metaverse and XR systems use a lot of artificial intelligence (AI) technology in every aspect of the systems and services. For example, AI, machine learning (ML), and deep learning (DL) are used for computer vision, feature extraction and tracking, avatar and robotic control, user eye and motion tracking, speech recognition, natural language processing, sensor signal tracking, computational creativity, and future predictions ( www.coursera.org/learn/deep-learning-business ).","['Computer Science', 'Hardware and Maker', 'Programming Techniques']"
doi:10.1007/978-3-031-11686-5_8,en,Extraction of Software Product Line Architectures from Many System Variants,OriginalPaper,"Software Product Line Architecture (SPLA) describes the architecture of a set of software variants by describing (1) what components can be included in the product configuration based on the selected features of this product (2) how these components can be configured to form a concrete architecture of the product, (3) shared components, and (4) individual architecture characteristics of each product. However, developing SPLA from scratch is known a highly, costly and risky task. The alternative is to exploit the already developed legacy software variants to reverse engineer SPLA. This reduces the cost of Software Product Line (SPL) development and allows to manage software variants as a SPL. In this chapter, we discuss the extraction of SPLA based on the analysis of several software variants. Precisely, we discuss the variability in SPLA. Then, we discuss challenges in extracting variability of SPLA and highlight a number of good practices proposed in the-state-of-the-art of the SPLA extraction. Next, we discuss one example approach that completely extracts SPLA of software variants.","['Computer Science', 'Software Engineering/Programming and Operating Systems', 'Software Management', 'Computer System Implementation']"
doi:10.1007/978-3-031-17024-9_2,en,Machine Learning and Deep Learning Techniques for Epileptic Seizures Prediction: A Brief Review,OriginalPaper,"The third most common neurological disorder, only behind stroke and migraines, is Epilepsy. The main criteria for its diagnosis are the occurrence of unprovoked seizures and the possibility of new seizures appearing. Usually, the professional in charge of detecting these seizures is a neurologist who interprets the patients’ electroencephalography. However, more accurate, precise, and sensitive methods are needed. Machine learning has increased as a viable alternative, reducing costs and ensuring rapid diagnostic time. This work reviews the state of the art in machine learning applied to epileptic seizure detection and prediction as a prospective study before developing a novel seizure prediction algorithm.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Bioinformatics']"
doi:10.1007/978-3-031-13588-0_53,en,The Cuneiform Brick,OriginalPaper,"The study presents some results of an experimental research on brick wall cladding, proposing methodological approaches for the creation of new geometric-compositional configurations. Citing innovative case studies of historical and contemporary architecture, the research has allowed to determine a different geometric shape of the brick, which takes its cue from the traditional wedge-shaped brick in majolica brick, widespread in Sicily since the sixteenth century for the realization of cusps and domes. Through the definition of procedural parametric algorithms for the analysis and geometric-spatial control, it is described the path that led to the digital prototype of a modular component of new design, able to adapt in shape and size to design patterns of cladding surfaces with simple and variable curvature free-form. The design of complex geometric and organic shapes, through the visual programming of digital algorithms (generative modelling, algorithmic modelling, computational modelling), as well as bringing a methodological and applicative renewal, has initiated interdisciplinary insights. Starting from a support grid for installation, we report several structural solutions of wall tessellations that highlight and validate its potential applications. The re-proposal of the building element with materials and techniques of the latest generation is in line with the goals of sustainable development OSS (Sustainable Development Goals SDGs) of the ONU 2030 Agenda.","['Engineering', 'Engineering Mathematics', 'Computational Intelligence']"
doi:10.1007/978-981-19-0503-2_9,en,Optimization of Multi-Skilled Labor to Minimize Lost Man-Hours in Construction Projects,OriginalPaper,"The current practice of single-skilled labor allocation in construction schedules poses some inefficiencies. In such practice, at any instance in the project lifecycle, some of the workforce become idle waiting for other labor types to finish work. Companies may allocate idle workers to other projects and return them back to their original project when needed again. This complicates the resource management process and causes a lot of confusion and is not often performed successfully. Project managers, many times, may also keep the idle workforce at their projects because they will be needed in a later stage and pay them in their idle days; which adds unnecessary cost. Another solution would be doing continuous hiring and laying off; which has severe negative impacts on projects and firms. On the other hand, some research discussed the idea of “multi-skilled” labor, where a number of workers on site may have enough experience to carry out different types of tasks. Multi-skilling decreases inefficiencies and ensures a smooth and continuous progress of projects whilst maintaining the workforce and keeping their idle time to a minimum. Multi-skilling could be also used to speed up progress in construction schedules. The objective of this research is to develop a framework for optimizing training and allocating multi-skilled labor in construction projects. In doing so it is expected to minimize idle times of labor by allocating them to ongoing activities.","['Engineering', 'Building Construction and Design', 'Geoengineering, Foundations, Hydraulics', 'Transportation Technology and Traffic Engineering', 'Environment, general']"
doi:10.1007/978-981-19-3571-8_46,en,Automated Perpetrator Identification by Face Recognition,OriginalPaper,"In the present scenario, the perpetrator identification procedure is done by the police force with the help of automated systems. Many buildings and streets have surveillance cameras installed to monitor the activities that occur within the focus. The videos recorded in these cameras have become one among the shreds of evidence for the police force to investigate the crime. Recognizing the person face from the captured videos is the most challenging task. The objective of this paper is to propose a face recognition model that can detect and then recognize the perpetrator’s faces automatically from the videos captured using the surveillance camera. The system implements three components: Face detection, facial features extraction, and face recognition. Haar cascades is used for face detection. Algorithms like local binary pattern histograms, fisherface, and eigenface are used for implementing the face recognition and the results obtained are plotted.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-11170-9_9,en,Potential Benefits of Artificial Intelligence in Healthcare,OriginalPaper,"Healthcare systems worldwide are confronted with numerous challenges such as an aging population, an increasing number of chronically ill patients, innovations as cost drivers and growing cost pressure. The COVID-19 pandemic causes additional burden for healthcare systems. In order to overcome these challenges, digital technologies are increasingly used. Especially the past decade witnessed a tremendous boom of artificial intelligence (AI) within the healthcare sector. AI has the potential to revolutionize healthcare and to mitigate the challenges healthcare systems are confronted with. The existing literature has frequently examined specific benefits of AI within the healthcare sector. However, there are still research gaps according to different application areas in healthcare. For this reason, an empirical study design has been conducted to investigate the potentials of AI in healthcare and to consequently identify its role. Based on a Systematic Literature Review (SLR), the following application areas for key determinants in healthcare have been identified: management tasks , medical diagnostics , medical treatment and drug discovery . By means of structural equation modeling (SEM), the study confirmed medical diagnostics and drug discovery as positive and significant influencing factors on the potential benefits of AI in healthcare. The other determinants didn’t prove a significant influence. Based on the findings of the study, various recommendations have been derived to further exploit the potentials of AI in healthcare.","['Computer Science', 'Health Informatics', 'Artificial Intelligence']"
doi:10.1007/978-3-031-05476-1_5,en,"Disruption, Innovation, Creativity, and the “Right Thing” in the Age of Global Media Arts",OriginalPaper,"This chapter describes how the global media pursuits of the five big technology platforms—Facebook, Amazon, Apple, Microsoft, and Google, coined as FAAMG by the financial firm Goldman Sachs (Molina, What the FAAMG is happening to tech stocks? USA Today . https://www.usatoday.com/story/tech/talkingtech/2017/06/09/tech-stocks-fang-dead-long-live-faamg/385200001/ , 2017)—have made de-democratization central to their core business. Drawing from reporting, research, and scholarship on FAAMG, this chapter highlights their practices of collecting and using user data, along with their anticompetitive practices, making them vulnerable to autocratic manipulation and disinformation. To counter the pervasive presence of FAAMG, this chapter highlights how the “parasitic artistic behavior” framework of Anna Watkins Fisher ( The play in the system: The art of parasitical resistance . Duke University Press, 2020) is helpful to understand how artists and art educators can create forms of resistance while continuing to participate in a global digital media society. Through an analysis of artists who are cognizant, critical, and subversive with FAAMG platforms, tactical pedagogical and curricular recommendations are made to conceptualize art classrooms as spaces of resistance to global media control.","['Education', 'Creativity and Arts Education', 'Education, general']"
doi:10.1007/978-981-19-4193-1_7,en,A Stacking Ensemble Framework for Android Malware Prediction,OriginalPaper,"Every Android application needs the collection of permissions during installation time, and these can be used in permission-based malware detection. Different ensemble strategies for categorising Android malware have recently received much more attention than traditional methodologies. In this paper, classification performance of one of the primary ensemble approach (Stacking) in R libraries in context of for Android malware is proposed. The presented technique reserves both the desirable qualities of an ensemble technique, diversity, and accuracy. The proposed technique produced significantly better results in terms of categorisation accuracy.","['Engineering', 'Computational Intelligence', 'Information Storage and Retrieval', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Data Structures and Information Theory', 'Artificial Intelligence']"
doi:10.1007/978-3-031-07322-9_38,en,A Review on Technological Advancements in the Field of Data Driven Structural Health Monitoring,OriginalPaper,"Recent advancements in sensor technology, as well as fast progress in internet-based cloud computation; data-driven approaches in structural health monitoring (SHM) are gaining prominence. The majority of time is utilized for reviewing & analyzing the data received from various sensors deployed in structures. This data analysis helps in understating the structural stability and its current state with certain limitations. Considering this fact, integration with Machine Learning (ML) in SHM has attracted significant attention among researchers. This paper is principally aimed at understanding and reviewing of vast literature available in sensor-based data-driven approaches using ML. The implementation and methodology of vibration-based, vision-based monitoring, along with some of the ML algorithms used for SHM are discussed. Nevertheless, a perspective on the importance of data-driven SHM in the future is also presented. Conclusions are drawn from the review discuss the prospects and potential limitations of ML approaches in data-driven SHM applications.","['Engineering', 'Building Repair and Maintenance', 'Cyber-physical systems, IoT', 'Industrial and Production Engineering']"
doi:10.1007/978-981-19-1610-6_54,en,A Novel Software Architecture to Calculate Effort Estimation for Industrial Big Data,OriginalPaper,"Software development effort estimation is one of the main sub-disciplines of software cost estimation, which comes under software project management. To estimate effort accurately, we noted different estimation models. With the combination of expert judgment, data mining, and machine learning, the motive of this study is to propose a new software architecture for effort estimation. The proposed architecture uses techniques such as expert judgment along with K-means clustering and machine learning techniques such as ANN, SVR, LR, RF, and KNN. At last, we used RMSE, MAE, MMRE, and Pred (.25). After the experimentation, we noted the increase in estimation accuracy was seen with the use of the proposed estimation model. Moreover, support vector regression outperformed all other algorithms with K  = 3 and 5 and expert input. Therefore, we concluded the effort estimation of industrial big data is an important step and needs to be given attention in software organizations.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2468-2_26,en,Comparison of Different Feature Selection Approaches on Breast Cancer Dataset,OriginalPaper,"Breast cancer was found to be the second most common type of cancer which occurred around the world in the year 2018. It takes a huge amount of effort from the healthcare team to diagnose the type of breast cancer. It is crucial to correctly classify the tumor type, as misclassification might lead to the loss of life of the patient. This work aims at investigating different nuclear features present in the dataset and using this domain knowledge, determines the features which could assist in achieving the model with the highest accuracy. Also, select features using other feature selection algorithms such as Boruta, exhaustive search methods, and choose the best among them. Further, compare numerous model performances using domain knowledge and the selected feature selection approach, respectively.","['Engineering', 'Electronics and Microelectronics, Instrumentation', 'Quantum Physics', 'Measurement Science and Instrumentation']"
doi:10.1007/978-3-031-17697-5_31,en,Analysis of Neuroevolution for Feedforward Neural Networks,OriginalPaper,"This paper presents a mathematical model for a layer-less feed-forward neural network defined as an acyclic weighted directed graph, which allows for easy manipulation of the network components (neurons, connections, and activation functions). In contrast, layered feed-forward neural networks have only two ways of simulating the addition/removal of network elements such as adding/removing whole layers of neurons or using a dropout technique. The main contribution of this paper is about the reconfigurability of a layer-less feed-forward neural network whereas new elements (neurons and connections) can be added and removed at will as long as those modifications keep the target network acyclic with the ability to perform propagation of values properly. Additionally, every neuron can modify its activation function, which results in a variety of different network behaviors and characteristics. A novel propagation method is introduced which allows the input data to conform with the network structure via vector representation. Based on the principle of conforming to the input dataset, the mathematical model is defined as a recursive non-linear equation. Once the mathematical description for a given network is obtained another concept is introduced, that is network sensitivity which has the goal of measuring the impact of genetic operations (such as mutations) on the network functionality. There are four major mutation types, which are discussed in detail in the paper. The method allows for the definition of functional equivalence between networks and the analysis of change in functional similarity based on the impact of each type of mutation. Applying this analytical method it can be shown that the functional equivalence between applying different types of mutations on a target network. Our future work will focus on generalizing the results of the current paper.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1669-4_27,en,Privacy Ensured Transmission of Healthcare Records Using IoT-Enabled Systems,OriginalPaper,"As an end result of the huge development of the Web of Points within the hospital treatment place, the safety and safety, and also the honesty of the medical statistics became huge annoying situations for healthcare answers programs. In this paper a hybrid safety model for shielding the analysis message records is proposed in patient medical scan reports or images. The endorsed version is advanced with integrating either 2-D discrete wavelet exchange 1 diploma (2D-DWT-1L) or 2-D discrete wavelet trade 2 diploma (2D-DWT-2L) steganography approach with a proposed cross breed document encryption plan. The proposed crossbreed encryption schema is built utilizing an aggregate of Advanced File encryption Requirement, and moreover Rivets, Shamir, and also Adelman algorithms. The proposed version begins by us in encrypting the secret statistics; then it hides the bring about a cover photo the use of 2-D discrete wavelet exchange 1 diploma or 2-D discrete wavelet trade 2 diploma. Both color as well as gray-scale photographs are utilized as cover snap shots to hide one in every of a type message dimensions. This machine performance end up tested mainly based on six parameters are the pinnacle signal-to-noise percent (PSNR), imply square mistake (MSE), little bit mistake price (BER), structural resemblance (SSIM), structural Internet content material (SC), and also connection. The PSNR worth had been quite differed from (50.59 to 57.44) in case of color pix in addition to from (50.5 to 56.09) with the gray-scale pix. The MSE (0.12 to 0.57) for the shade images and from (0.14 to 0.57) for the gray-scale picas. The little bit mistake worth was 0 for both photographs, while SSIM, SC, and connection worth have been ones for each photo. Compared with the latest approaches, the advocated version showed its functionality to cover the private patient's facts right into a transmitted cover picture with immoderate imperceptibility, capability, and additionally minimum condition inside the acquired steno-image.","['Engineering', 'Signal, Image and Speech Processing', 'Circuits and Systems', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-0098-3_44,en,Prediction of Employee Attrition Using Stacked Ensemble Method,OriginalPaper,"Employee attrition is becoming a big issue in businesses. The question that many HR managers are asking is why workers quit the company. Hiring new staff, rather than maintaining existing personnel, will always take more time and money. The project’s objective is to anticipate employee attrition before he or she departs the organization. The problem is predicting whether or not an employee will leave based on specific indications. Instead of focusing on a single classifier technique, the proposed study would tackle the problem utilizing a stacked classifier algorithm. The ensemble model will compute the prediction of each classification, and a new model will be constructed based on the ensemble technique used for prediction. Accurate forecasting will aid businesses in taking the required actions to reduce attrition.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Statistics, general', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4052-1_12,en,Sentiment Analysis in Airlines Industry Using Machine Learning Techniques,OriginalPaper,"With the increasing power of Internet, businesses get a huge number of customer feedbacks through: their business website, social media page, business listings, etc. Majority of business do not know how to use this information to improve themselves. However, unstructured feedback on Facebook/Instagram/Twitter is where the volume lies. But the problem is these feedbacks are unstructured and there is no aggregated sentiment that we may conclude from them. To analyze these unstructured customer feedbacks at scale, machine learning is used. In this work we present a survey on various machine learning techniques that have been used in past eight years for analysis of tweets/comments related to airline industry.","['Engineering', 'Computational Intelligence', 'Information Storage and Retrieval', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Data Structures and Information Theory', 'Artificial Intelligence']"
doi:10.1007/978-981-19-6004-8_34,en,Pre-processing of Leukemic Blood Cell Images Using Image Processing Techniques,OriginalPaper,"Application of digital image processing on medical images could greatly help the doctors to identify the disease in an early phase before it starts spreading. In this research work, the pre-processing steps needed to find out the leukemic blood cells have been discussed and the resultant images are given at the end of each pre-processing step. The major aim of this research work is to detect the malignant leukemia at the earliest, so that it could improve the chances of survival of the patients. The quality of the images have been improved by using pre-processing methods such as DWT, KSVD, and HKSVD.","['Engineering', 'Computational Intelligence', 'Cognitive Psychology', 'Personality and Social Psychology', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-16159-9_15,en,Condition-Based Monitoring of DC Motors Performed with Autoencoders,OriginalPaper,"This paper describes a condition-based monitoring system estimating DC motor degradation with the use of an autoencoder. Two methods of training the autoencoder are evaluated, namely backpropagation and extreme learning machines. The root mean square (RMS) error in the reconstruction of successive fragments of the measured DC motor angular-frequency signal, which is fed to the input of autoencoder, is used to determine the health indicator (HI). A complete test bench is built using a Raspberry Pi system (i.e., motor driver controlling angular frequency) and Jetson Nano (i.e., embedded compute node to estimate motor degradation) to perform exploratory analysis of autoencoders for condition-based monitoring and comparison of several classical artificial intelligence algorithms. The experiments include detection of degradation of DC motor working in both constant and variable work points. Results indicate that the HI obtained with the autoencoders trained with the use of either training method is suitable for both work points. Next, an experiment with multiple autoencoders trained on each specific work point and running in parallel is reviewed. It is shown that, in this case, the minimum value of RMS error among all autoencoders should be taken as HI. Furthermore, it has been shown that there is a near-linear relationship between HI and the difference between measured and reconstructed angular-frequency waveforms.","['Engineering', 'Control and Systems Theory', 'Computational Intelligence']"
doi:10.1007/978-981-19-4005-7_18,en,Company’s Management Information Systems for Solving the Tasks of Implementing Integrated Marketing Communications in the Conditions of Digitalization of the Economy,OriginalPaper,"The relevance of the article’s problems is determined by the fact that in the digital economy, technical and information capabilities actively stimulate the dynamics of marketing communications development, as well as the transformation of concepts and management strategies in marketing. The purpose of the study is to substantiate proposals for the implementation of the coordinating role of marketing information systems (MIS) when integrating them into corporate information systems (CIS) in order to solve the management task of implementing integrated marketing communications (IMC) in the conditions of digitalization of the economy. Research methods include: analysis of intra-organizational processes in the company, assessment of the marketing environment in which IMC is implemented, factor and strategic analysis, systematization of empirical and factual information, segmentation of the structure of marketing information systems. The results of the article consist of the author's analysis of the prospects for the development of MIS in the conditions of digitalization of the economy and informatization of society with the introduction of IMC. The interpretation of the issue of the introduction of MIS in the framework of intra-organizational events is new. An expanded list of elements of the IMC is proposed, the ideology and features of the functioning of marketing information systems in the implementation of the concept of integrated marketing communications are described. An expanded set of organizational solutions to improve the efficiency of communications using an integrated information system is proposed to optimize the company’s management conditions and achieve a total positive result of the IMC in the digital economy.","['Business and Management', 'Business Strategy/Leadership', 'Management', 'Economic Growth', 'Entrepreneurship', 'Asian Economics', 'International Organization']"
doi:10.1007/978-981-19-3035-5_51,en,Forest Fire Prediction Using Machine Learning and Deep Learning Techniques,OriginalPaper,"Forests are considered synonyms for abundance on our planet. They uphold the lifecycle of a diversity of creatures, including mankind. Destruction of such forests due to environmental hazards like forest fires is disastrous and leads to loss of economy, wildlife, property, and people. It endangers everything in its vicinity. Sadly, the presence of flora and fauna only increase the fire spread capability and speed. Early detection of these forest fires can help control the spread and protect the nearby areas from the damage caused. This research paper aims at predicting the occurrence of forest fires using machine learning and deep learning techniques. The idea is to apply multiple algorithms to the data and perform comparative analysis to find the best-performing model. The best performance is obtained by the decision tree model for this work. It gave an accuracy of 79.6% and a recall score of 0.90. This model was then implemented on front-end WebUI using the flask and pickle modules in Python. The front-end Website returns the probability that a forest fire occurs for a set of inputs given by the user. This implementation is done using the PyCharm IDE.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Statistics, general']"
doi:10.1007/978-981-19-5403-0_3,en,"Systematic Study of Detection Mechanism for Network Intrusion in Cloud, Fog, and Internet of Things Using Deep Learning",OriginalPaper,"Development of latest technologies creates human life more convenient and easier. However, along with such technological advancements, several complications are generated in various segments. Network security also experiences inconvenient situations those are literally originated from infinite number of complex intrusions. A network intrusion detection system (NIDS) is an advanced and revolutionary system that has been established to resolve the problematic behaviors of the networking environment through accurate detection of unidentified attacks. Several methods and techniques have been taken active part for the development of an ideal NIDS but merging with deep learning technologies, NIDS achieves miracle performance against various intrusive activities in the security domain. In this paper, we serialize and present an adequate number of existing deep learning-based NIDSs in the Internet of things (IoT), cloud, fog, and edge networks domain. Different NIDS approaches along with their utilization, advantages, and restrictions are perfectly described in this paper so that people can achieve proper and detailed knowledge of security issues in the above-mentioned networks.","['Engineering', 'Computational Intelligence', 'User Interfaces and Human Computer Interaction', 'Data Structures and Information Theory', 'Artificial Intelligence', 'Data Mining and Knowledge Discovery']"
doi:10.1007/978-3-031-15191-0_29,en,Interpretability Based Approach to Detect Fake Profiles in Instagram,OriginalPaper,"The explosive rise of OSNs, as well as the vast quantity of personal data they hold, has attracted attackers and imposters looking to steal personal information, propagate fake news, and carry out destructive actions. Researchers, on the other hand, have begun to look at effective approaches for detecting anomalous behaviors and phony accounts using account characteristics and classification algorithms. Creating fake accounts, which is used to increase the popularity of an account in an immoral way, is one of the security challenges in these networks that has become a major concern for users. An attacker can affect the security and privacy of legitimate users by spreading spam, malware, and disinformation. Advertisers utilize these channels to reach out to a certain demographic. The number of false accounts is growing at an exponential rate, and in this study, we propose an architecture for detecting phony accounts in social media, particularly Instagram. We are utilizing Machine Learning techniques such as Bagging and Boosting in this study to make better predictions about detecting bogus accounts based on their profile information. We utilized the SMOTE technique to balance the two groups of data, which enables us to get the equal number of persons for each class. The approaches for understanding complicated Machine Learning Models to understand the reasoning behind a model choice, such as SHAP values and LIME, were also included in this article. The XGBoost and Random Forest models have a combined accuracy of 96%. An online fake detection method has been built to identify rogue accounts on Instagram, as shown below.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Mobile and Network Security']"
doi:10.1007/978-3-031-15928-2_33,en,Path Approximation Strategies for Robot Manufacturing: A Preliminary Experimental Evaluation,OriginalPaper,"Industrial Robots (IRs) are increasingly adopted for material subtraction or deposition functions owing to their advantages over machine tools, like cost-effectiveness and versatility. Unfortunately, the development of efficient robot manufacturing processes still faces unsolved issues related to the IRs poor positioning accuracy and to the tool path generation process. Novel engineering methods and tools are needed for CAD based programming of accurate paths and continuous robot motions to obtain the required manufacturing quality and tolerances. Within this context, to achieve smoothness along the tool path formed by linear G-code segments, the IR controllers’ approximation strategies, summarily reported in the manufacturer’s manuals, must be considered. The aim of this paper is to present the preliminary work carried out to identify the approximation algorithms of a Kuka IR when executing linear moves. An experimental study is conducted by varying the controller settings and the maximum translational velocity. The robot behavior has been acquired thanks to the controller tracing function and then processed to yield relations readily employable for the interpretation of G-Code commands and the subsequent generation of proper robot motion instructions. The obtained formulas allow to accurately predict the robot geometric path and kinematics within the corner transition between two linear segments.","['Engineering', 'Engineering Design', 'Industrial and Production Engineering', 'Computer-Aided Engineering (CAD, CAE) and Design']"
doi:10.1007/978-3-031-11814-2_5,en,Multi-Echelon Inventory Optimization Using Deep Reinforcement Learning,OriginalPaper,"In this chapter, we provide an overview of inventory management within the pharmaceutical industry and how to model and optimize it. Inventory management is a highly relevant topic, as it causes high costs such as holding, shortage, and reordering costs. Especially the event of a stock-out can cause damage that goes beyond monetary damage in the form of lost sales. To minimize those costs is the task of an optimized reorder policy. A reorder policy is optimal when it minimizes the accumulated cost in every situation. However, finding an optimal policy is not trivial. First, the problem is highly stochastic as we need to consider variable demands and lead times. Second, the supply chain consists of several warehouses incl. the factory, global distribution warehouses, and local affiliate warehouses, whereby the reorder policy of each warehouse has an impact on the optimal reorder policy of related warehouses. In this context, we discuss the concept of multi-echelon inventory optimization and a methodology that is capable of capturing both, the stochastic behavior of the environment and how it is impacted by the reorder policy: Markov decision processes (MDPs). On this basis, we introduce the concept, its related benefits and weaknesses of a methodology named Reinforcement Learning (RL). RL is capable of finding (near-) optimal (reorder) policies for MDPs. Furthermore, some simulation-based results and current research directions are presented.","['Economics', 'Health Economics', 'Pharmaceutical Sciences/Technology', 'Economics, general', 'Biomedicine, general', 'Biotechnology', 'Economic Theory/Quantitative Economics/Mathematical Methods']"
doi:10.1007/978-3-030-79827-7_39,en,Spherical Harmonics Expansion and Multi-Scale Modeling,OriginalPaper,"By far, most numerical device simulations are still based on the drift-diffusion (DD) model, owing to its versatility, numerical efficiency, and robustness. However, the DD model is of limited physical accuracy for nanoscale devices and hot carrier effects. Advanced physical modeling in the regime of semi-classical transport must therefore be based on the Boltzmann transport equation (BTE), and the typical solution method for this equation is a Monte-Carlo (MC) algorithm owing to its small memory requirements. Unfortunately, this popular solution method makes the BTE model much less versatile than the DD approach, as, for example, no AC and noise analysis in the small-signal framework based on the Jacobian of the numerical model is available if the MC method is used. Moreover, evaluating the complete transport of carriers in a device by the BTE model is always several orders of magnitude less efficient in terms of CPU time than the application of the DD model. Thus, there is a clear demand to increase the versatility of the BTE model and to enhance the physical accuracy of the DD model without compromising its numerical efficiency and robustness. Solving the BTE model with the spherical harmonic expansion (SHE) method allows the calculation of the full Jacobian of the discrete system and to establish AC and noise analysis in the small-signal framework, thus making the BTE model much more versatile. Moreover, sequential and concurrent multi-scale methods using microscopic models such as the BTE model where necessary and macroscopic models such as the DD model otherwise are well suited to enhancing the physical accuracy of the DD model without compromising its efficiency and robustness. In addition, using the SHE method allows many of the discretization methods and principles previously developed for the DD model to be applied for the discretization of the BTE model. Therefore, a short overview of the historic development of discretization methods and principles, finally making the DD model as efficient and robust as it is today, is added as well.","['Engineering', 'Circuits and Systems', 'Electronic Circuits and Devices', 'Electronics and Microelectronics, Instrumentation']"
doi:10.1007/978-981-19-6780-1_13,en,Design of an Autonomous Agriculture Robot for Real-Time Weed Detection Using CNN,OriginalPaper,"Agriculture has always remained as an integral part of the world. As the human population keeps on rising, the demand for food also increases and so is the dependency on the agriculture industry. But in today’s scenario because of low yield, less rainfall, etc., a dearth of manpower is created in this agricultural sector and people are moving to live in the cities, and villages are becoming more and more urbanized. On the other hand, the field of robotics has seen tremendous development in the past few years. The concepts like Deep Learning (DL), Artificial Intelligence (AI), Machine Learning (ML) are being incorporated with robotics to create autonomous systems for various sectors like automotive, agriculture, assembly line management, etc. Deploying such autonomous systems in the agricultural sector helps in many aspects like reducing manpower, better yield, and nutritional quality of crops. So, in this paper, the system design of an autonomous agricultural robot that primarily focuses on weed detection is described. A modified deep learning model for the purpose of weed detection is also proposed. The primary objective of this robot is the detection of weed on a real-time basis without any human involvement but it can also be extended to design robots in various other applications involved in farming like weed removal, plowing, harvesting, etc. in turn making farming industry more efficient. The source code and other paper-related documents can be found at https://github.com/Dhruv2012/Autonomous-Farm-Robot","['Engineering', 'Circuits and Systems', 'Energy Systems', 'Computer-Aided Engineering (CAD, CAE) and Design']"
doi:10.1007/978-3-031-21062-4_22,en,Machine Learning and Inertial Sensors to Estimate Vertical Ground Reaction Force During Gait,OriginalPaper,"During gait, vertical ground reaction forces (vGRF) can reach magnitudes which could cause different lower limb injuries. Measuring and studying generated vGRF can help to prevent musculoskeletal disorders. However, in order to measure vGRF, it is required the use of expensive equipment, which may also limit the study environment. This work presents different Machine Learning models to predict vGRF employing inertial sensors.","['Computer Science', 'Robotics', 'Robotics and Automation', 'Computational Intelligence']"
doi:10.1007/978-3-031-20141-7_16,en,Modeling of Distributed Mosaic Systems of Mobile Bionic Robots,OriginalPaper,"The paper considers features of using the concept of “mosaic warfare” based on dynamic management of distributed systems of mobile robotics complexes using multi-agent approach. It describes modelling mechanisms for controlling a group of bionic robots for search and rescue operations, reconnaissance and military diversions with the provision of mechanisms for autonomy, adaptation, coordination and collective behavior. The mosaic structure of the distributed system of mobile robotics complexes was suggested. The features of the algorithms of the motion planning, formation of the agents’ trajectory and group control are described. It also describes an agent-based model for the analysis of control processes of a group of unmanned aerial vehicles, unmanned ground vehicles, and ground-based robots.","['Engineering', 'Computational Intelligence', 'Transportation Technology and Traffic Engineering', 'Manufacturing, Machines, Tools, Processes']"
doi:10.1007/978-981-19-5224-1_21,en,Predicting the Heart Disease Using Machine Learning Techniques,OriginalPaper,"Heart disease refers to the condition when the heart is not capable to push required amount of blood to the entire body. Heart disease (HD) is the prevailing reason behind deaths among the world-wide population. Early prediction of heart diseases can save lives. Predicting cardiovascular or heart disease in advance, a person can be warned beforehand, and the death can be prevented in turn. Machine learning (ML) has made a huge contribution to classify the population with heart disease from the healthy population. This paper proposes three heart disease prediction (HDP) models namely LOFS-ANN, LOFS-SVM, and LOFS-DT utilizing lion optimization-based feature selection (LOFS) method and three ML-based classifiers. The datasets used are from UCI repository. The comparative analysis reflects that the model LOFS-ANN performs best among all three models, with the values of 97.1% and 90.5% for AUC measure and accuracy measure, respectively. It can be concluded that the LOFS-ANN has a significant potential to predict heart disease after drawing its statistical comparison with the competing models.","['Engineering', 'Communications Engineering, Networks', 'Statistics, general', 'Cyber-physical systems, IoT', 'Sociology, general', 'Professional Computing']"
doi:10.1007/978-3-031-19958-5_26,en,A Sustainable Approach Between Satellite and Traditional Broadband Transmission Technologies Based on Green IT,OriginalPaper,"Although satellite internet has low performance in the case of data transmission compared to traditional internet services such as broadband internet networks and cellular networks, it may have a low environmental impact as well. Traditional internet services are located on earth so the latency is fairly high. However, if the environmental impact is the only consideration, satellite internet may be a viable option. This research paper tries to analyze this aspect of the internet. Based on green IT which internet service can provide the best and if there is a way to make internet services more efficient? This paper aims to provide as much information regarding this and provide a solution to this. In this paper, a thorough investigation has been conducted to include direct or indirect environmental impact, power consumption, greenhouse emission, building material, etc. A comparative analysis shows if satellite internet can negate the environmental impact of traditional internet services. Based on the study, solutions have been provided for traditional internet services using real-time simulation and machine learning algorithms. The simulation of cabling gives a significant reduction in cable use and the implemented machine learning algorithms in routing devices yield a 30% energy consumption reduction and an almost 25% GHG reduction per month. This paper contributes to the overall process to make the internet greener. This paper can especially help decide which internet service is based on environmental friendliness. This paper can also help internet service providers to reduce costs in connectivity.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-0095-2_50,en,CoviFacts—A COVID-19 Fake News Detector Using Natural Language Processing,OriginalPaper,"Fake news confronts us on a daily basis in today’s fast-paced social media world. While some instances of fake news might seem innocuous, there are many examples that prove to be menacing. Misinformation or disinformation which takes the form of these weaponized lies which eventually amount to defective information, defamatory allegations, and hoaxes. The only motive behind such a malicious act is to engender emotional instability among the public. One such prevalent example today is COVID-19 which has caused an unprecedented paradigm shift in numerous businesses and quotidian activities across the globe. One of the primary activities is being news reporting. On average, people are spending almost one hour a day reading news via many different sources. The development in technology has obviated the barriers between sharing of information, thereby truly making the industry cosmopolitan. Therefore, it is paramount to curb fake news at source and prevent it from spreading to a larger audience. This paper describes a system, where the user can identify apocryphal news related to COVID-19 so as to ensure its authenticity.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Systems and Data Security', 'Artificial Intelligence', 'Computational Intelligence']"
doi:10.1007/978-981-19-2538-2_26,en,Early Detection of Autistic Children Using Wrapper-Based Feature Selection Technique,OriginalPaper,"Selection of features is a crucial technique in ML classifiers, especially for datasets with a lot of dimensions. Feature selection is a popular machine learning method in which subsets of the data’s available features are chosen for use in a learning algorithm. The remaining, insignificant dimensions are removed from the most excellent feature, which has the fewest number of dimensions that contribute the most to precision. The goal of the selection of features is to choose a subset of info factors by eliminating characteristics that have practically or no prognostic value. Strategies for choosing elements can be partitioned into three categories. Filter strategies are one, Wrapper techniques are another, and Embedded strategies are the third. Our main goal is to develop a subset feature for autism spectrum disorder premature prediction using several wrapper-based feature selection algorithms. Autistic is a group of neuro-developmental disorders characterized by societal communiqué difficulties, restricted interests and activities, and abnormal tactile sensitivities. This study looks into the use of wrapper features selection techniques such as sequential forward selection (SFS), sequential backward selection (SBS), Sequential Backward Floating Selection (SBFS), Sequential Forward Floating Selection (SFFS), and Recursive Feature Elimination (RFE) as well as optimal selection approaches based on classifiers like RF, GBC, and CART. According to this study, the search methodology employing RFE based on the RF algorithm outperformed other methods in terms of average accuracy of 87%. The advantage of selecting feature subsets is that they are more accurate and take less time to run.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory', 'Mobile and Network Security']"
doi:10.1007/978-981-19-7622-3_8,en,"Security, Privacy, and Trust Issues in Intelligent Transportation System",OriginalPaper,"Introduction to security, privacy, and trust in intelligent transportation systems (ITS), security, privacy, trust requirements in intelligent transportation systems, and cryptographic approaches in ITS are discussed in this chapter. In addition, the chapter discusses biometric-based intelligent transportation systems, blockchain-based intelligent transportation systems, and peer-to-peer ride-sharing via blockchain-based intelligent transportation systems. Aside from that, the chapter discusses the automotive intelligent transportation system and the various services available in an intelligent transportation system. Traditional cryptography is ineffective in a communication environment with limited space or time. A deep reinforcement learning algorithm is used to improve the performance of each subsystem as well as the overall mix of cars and trucks. Some argue that the blockchain is a public database that no one owns. A distributed data storage system with point-to-point transmissions and consensus mechanisms. Blockchain blocks store time stamps and digital signs in addition to using encryption algorithms, smart contracts, and other computer tools. Data is stored in multiple locations, making it easier to share data. The data records’ digital signatures can also verify the data. Because hash points connect the blocks, hackers cannot alter the data. People don’t have to trust a central authority or anyone else to agree on what’s going on with the ledger. Using the blockchain, people can share data securely, dependable, and traceable manner. There are several ways to improve transportation using blockchain technology. The blockchain has the potential to transform the concept of car sharing. All information is kept in one place on the blockchain, making it easy to find and track.","['Engineering', 'Communications Engineering, Networks', 'Automotive Engineering', 'Transportation Technology and Traffic Engineering', 'Computer Applications']"
doi:10.1007/978-981-19-4863-3_18,en,A Combined Approach of Steganography and Cryptography with Generative Adversarial Networks: Survey,OriginalPaper,"Secure transformation of data over public networks like the Internet is nothing but achieving authenticity, secrecy, and confidentiality in secure data transmission is now the primary concern. These issues may be solved by using data hiding techniques. Steganography, cryptography, and watermarking techniques are used to hide data and ensure its security during transmission. Objective of this submission is to analyze and examine several methods of deep learning in image cryptography and steganography. The hidden message is revealed via steganography, but its format is altered through cryptography. Steganography and cryptography are both essential and robust techniques. This paper’s primary goal is to explore several integrating steganography with encryption to create a hybrid system. In addition, specific differences were also given between cryptography and steganographic approaches. This paper aims to help other researchers’ summaries current trends, problems, and possible future directions in this area.","['Engineering', 'Computational Intelligence', 'Engineering Design', 'Machine Learning', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-3387-5_132,en,Spectral Optimization for Multi-carrier NOMA-Enabled Industrial Internet of Things,OriginalPaper,"Non-orthogonal multiple access (NOMA) guarantees good spectral efficiency and better enhance system capacity. However, the deployment of NOMA is not easy due to complexity of resource management. This paper provides a new resource optimization architecture to improve the spectrum efficiency (SE) of the multi-carrier NOMA enabled Industrial Internet of Things (IIoT) network. Specifically, we jointly optimize carrier-user assignment and power control to maximize the SE of the system while satisfying the constraints on users quality of services (QoS) requirements, transmit power budget and successive interference cancellation. Since the optimization problem is a mixed integer non-convex programming problem, it is very difficult to solve. We decouple it into two sub-problems to solve. Sub-problem one: subcarrier-user assignment problem; Sub-problem two: power allocation to users on each subcarrier. Particularly, two subcarrier-user assignment algorithms (SUAA1 and SUAA2) are proposed to solve sub-problem one. In which SUAA1 is based on the traditional NOMA user pairing scheme, SUAA2 is based on strong users first. The sub-problem two is solved based on the Monotonic optimization method. The simulation results show that our resource management scheme has higher SE comparing with OMA scheme. Specifically, SUAA2 can improve the SE of the system while increasing the rate of far users comparing with SUAA1 and the random matching scheme under our power allocation algorithm.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Aerospace Technology and Astronautics']"
doi:10.1007/978-981-19-5292-0_47,en,Design of Neural Network Algorithm Controller Using Simulink for Actuator of Dynamic Robot Systems,OriginalPaper,"The automation and its control have been accelerated to the future generation by initiating neural network algorithms and highly developed computing potential processors in control systems for different applications. The era of research is still going in the controller design and tuning field using neural network algorithms. Neural network controller addresses a comprehensive study on the neural network learning algorithm’s efficiency and application to design the auto control for the actuator of dynamics systems and robotics actuator. Here, we provide an overview of neural network algorithms and illustrate how to control robots and dynamics systems.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory', 'Computer Imaging, Vision, Pattern Recognition and Graphics']"
doi:10.1007/978-981-19-3679-1_37,en,Analysis on Detection of Brain Tumor Using CS and NB Classifier,OriginalPaper,"Brain tumor segmentation ad classification plays vital role in tumor diagnosis using various image processing techniques, as brain tumor is a critical and life threatening condition which is spreading worldwide. So, early detection of brain tumor can improve the patient survival. For this, computer-aided methods play a major role with better accuracy. It includes steps like preprocessing, segmentation, extraction, and classification with the help of MRI Images. Multiple proposed methods are already implemented with few limitations. In order to overcome existing limitations in current automation process, a model is proposed which detects the brain tumor using following approaches; ICA is chosen for extraction of features, and further, optimized technique will be the cuckoo search, and then, classification is done with Naïve Bayes.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1142-2_13,en,Decision Tree Algorithm for Diagnosis and Severity Analysis of COVID-19 at Outpatient Clinic,OriginalPaper,"This study investigates the feasibility of decision tree algorithm like CART recursive method for classifying participants into test-based positive cases and negative cases to detect COVID-19 in the outpatient and suggest admission or home isolation according to the evaluated parameters. It also evaluates the severity of the outpatients using the values of RTPCR test and Chest X-Ray imaging results. A theoretical and predicted decision tree is proposed in the study after focus group interview with a clinical physician. Primary data was collected from the survey of patients visiting a physician for treatment of COVID-19 during the first wave. CART algorithm was applied for predicting the required decision tree. According to the predicted decision tree, it was determined that the most important feature while treating a COVID-19 patient is their history of contact with the positive coronavirus patient. Based on the valuation of dataset, the predicted decision tree provided similar results to that of the conceptual tree. Thus, comparing both trees, it can be evidently said that the predicted decision tree is a subset of conceptual decision tree and can be used by physicians for diagnosis and severity analysis of COVID-19.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Mobile and Network Security', 'Artificial Intelligence']"
doi:10.1007/978-3-031-09640-2_18,en,Application of Homomorphic Encryption in Machine Learning,OriginalPaper,"Big data technologies, such as machine learning, have increased data utility exponentially. At the same time, the cloud has made the deployment of these technologies more accessible. However, computations of unencrypted sensitive data in a cloud environment may expose threats and cybersecurity attacks. We consider a class of innovative cryptographic techniques called privacy-preserving technologies (PPTs) to address this problem. That might help increase utility by taking more significant advantage of the cloud and machine learning technologies while preserving privacy. The first section provides a brief introduction to the so-called homomorphic encryption “HE” by giving an overview of the most promising schemes and then giving the current state of the art of HE tools such as libraries and compilers. This section aims to help non-cryptographer developers propose HE solutions by explaining what makes developing HE applications challenging. Then, we address the privacy-preserving in machine learning (PPML), an approach that allows to train and deploy ML models without exposing their private data. After exploring state of the art for the most used ML models in PPML, we will overview applications of homomorphic encryption in machine learning.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Computational Intelligence', 'Security Science and Technology']"
doi:10.1007/978-3-031-16832-1_7,en,Application of Metaheuristic Techniques for Enhancing the Financial Profitability of Wind Power Generation Systems,OriginalPaper,"While climate change is distressing human lives all over the planet, international associations are struggling unremittingly to rein in the release of greenhouse gases for realizing the universal carbon neutrality target as insinuated by the Paris accord of 2015. As power generation corporations are one of the major contributors of the global greenhouse gas emanation, it turns out to be unquestionably crucial for them to harness the eco-friendlier substitutes proficiently for attaining superior financial sustainability. This chapter deliberates the appliance of different metaheuristic approaches for expanding the financial profitability of wind farms with authentic wind flow patterns of three potential wind power generation sites in India and appraises their comparative competencies in assisting the renewable energy sector with expedient commercial potentials.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Engineering']"
doi:10.1007/978-981-19-4052-1_67,en,COVID-19 Disease Classification Model Using Deep Dense Convolutional Neural Networks,OriginalPaper,"Preventing the transmission of COVID-19 necessitates diagnosis and identification. Researchers have developed algorithms to detect the presence of COVID-19 in X-ray and CT scans and images. These methodologies produce skewed data and incorrect disease detection. So, in the case of COVID-19 forecasting utilizing CT scans in an IoT setting, the current study paper established an oppositional-based deep dense convolutional neural network (DDCNN) and chimp optimization algorithm. The framework proposed is divided into two stages: preprocessing and estimation. Previously, a CT scan pictures generated from anticipated COVID-19 are acquired utilizing IoT devices from an open-source system. After that, the photos are preprocessed with a Gaussian function. A Gaussian filter can be used to remove undesirable noise from CT scan pictures that have been obtained. The preprocessed photos are then transmitted to the prediction process. DDCNN is applied to the images preprocessed in this step. The recommended classifier is designed to be as efficient as possible using the oppositional-based chimp optimization algorithm (OCOA). This approach is used to choose the best classifier parameters under consideration. Furthermore, the suggested method is applied to forecast COVID-19 and categorizes the findings as COVID-19 or non-COVID-19. The proposed technique was used in Python, and results were assessed using statistical analysis. CNN-EPO and CNN-FA were compared to the new method. The results proved that the proposed model was optimal.","['Engineering', 'Computational Intelligence', 'Information Storage and Retrieval', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Data Structures and Information Theory', 'Artificial Intelligence']"
doi:10.1007/978-981-19-0151-5_24,en,Review on Lung Nodule Segmentation-Based Lung Cancer Classification Using Machine Learning Approaches,OriginalPaper,"Lung cancer or lung carcinoma is one of the major reasons for non-accidental death in the world with a high fatality rate in both men and women. The major cause of lung cancer is wrong lifestyle choices such as consumption of beedi, cigarette, and hukka. Lung cancer is broadly categorized as small cell lung carcinoma (SCLC) and non-small cell lung carcinoma (NSCLC). It is very difficult to detect lung cancer well in advance. However, technological advances in medical imaging have resulted in the diagnosis and prediction of various stages of lung cancer by analyzing CT scans. In the present paper, a constructive review of the existing approaches for lung nodule detection and classification using machine learning approaches is presented. Authors have analyzed the articles published in the last decade to access the current status of the research in the field of lung cancer classification. The survey study concluded that the involvement of optimization approaches to improve the feature extraction and segmentation stage has been involved in recent years. Further, it is observed that the integration of the neural network architecture has become the first choice of numerous researchers for lung cancer classification.","['Engineering', 'Biomedical Engineering and Bioengineering', 'Artificial Intelligence', 'Computer Imaging, Vision, Pattern Recognition and Graphics', 'Biological and Medical Physics, Biophysics', 'Information Storage and Retrieval']"
doi:10.1007/978-981-19-5303-3_6,en,Digital ECG Signal Watermarking and Compression,OriginalPaper,"Data privacy on the Internet seems to be becoming a thing of the past. It is going to be a struggle for individuals to manage personal medical information on the Internet. ECG data is considered as the most vulnerable dataset. To safeguard and protect the personal ECG data, the use of security schemes like watermarking of ECG data is the focus of the present Chapter.","['Engineering', 'Circuits and Systems', 'Biomedical Engineering and Bioengineering', 'Signal, Image and Speech Processing']"
doi:10.1007/978-3-031-16035-6_10,en,Three-Valued Model Checking Smart Contract Systems with Trust Under Uncertainty,OriginalPaper,"Blockchain systems based on smart contracts are critical systems that have to be verified in order to ensure their reliability and efficiency. Verifying these systems is a major challenge that is still an active topic of research in different domains. In this paper, we focus on verifying these systems that we model using trust protocols under uncertainty. Specifically, we address the problem using an effective verification approach called three-valued model checking. We introduce a new logic by extending the recently proposed Computation Tree Logic of Trust (TCTL) to the three-valued case ( $$3v-TCTL$$ 3 v - T C T L ) to reason about trust with uncertainty over smart contract-based systems. We also propose a new transformation approach to reduce the $$3v-TCTL$$ 3 v - T C T L model checking problem to the classical case. We apply our approach to a smart contract-based drug traceability system in the healthcare supply chain. The approach is implemented using a Java toolkit that automatically interacts with the NuSMV model checker. We verify this system against a set of specifications and report the results of our experiments.","['Engineering', 'Computational Intelligence', 'Data Engineering']"
doi:10.1007/978-981-19-3575-6_29,en,A Survey on Privacy Preserving Voting Scheme Based on Blockchain Technology,OriginalPaper,"The blockchain methodology utilizes cryptographic hashes to establish end-to-end demonstration to facilitate security for votes. The aim of the project is to establish a successful voting methodology with the help of blockchain mechanism. With this mechanism, every vote is reserved as a new block and gets updated in the database. The system assures that voting system maintains the one person, one-vote (democracy) principle. This is accomplished by matching the voter's unique face biometric at the start of each voting attempt to avoid double voting. In this, we have created an online voting system through blockchain methodology which is used to solve the issues that are faced by the pre-developed methodology. For each unique vote, different enactment is done. Miners will reject a vote if it is suspected as being malicious. Blockchain mechanism used here makes the vote trustworthy and reliable, and it will also aid to raise the number of voters besides it enhances trust toward the government. In this project, we apply the hash function using SHA—256 algorithms for secure password hashing. It is necessary to have unique hash for every vote that is being recorded by cryptographic hash by which each vote can be verified distinctly. This characteristic facilitates the general voting process’s verifiability. In addition to this, the vote that is being counted is more secure and not an individual including the operator knows about the details of the vote that is being recorded.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-07654-1_18,en,An Automated Cervical Cancer Detection Mechanism Using Pap Smear Images,OriginalPaper,"Cervical cancer is one predominant type of cancer and ranks as the second most common type of cancer that often affects women over 30 years. Among all cancers in women, 6–29% constitutes cervical cancer. The test used for detecting the tumor is called the Pap smear test, which requires expert pathologists to classify the abnormal cells in the precancerous earlier stages. In rural villages, such experts are not easily accessible, and they need emerging technologies for the early detection of precancerous lesions. This proposed model is constructed using a fully connected 24 × 1 CNN model in the Herlev dataset of Pap smear cell images. This automated pap smear image classification model works through the learning and analysis of fully connected CNN with data augmentation process. Experimental results of the proposed scheme claim that this model is classifying the abnormal cervical cancer cells with an accuracy of 90.2%.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Computer Communication Networks', 'Computational Intelligence']"
doi:10.1007/978-3-031-13150-9_30,en,Deconstructive Human Confront Acknowledgment Utilizing Profound Neural Arrange,OriginalPaper,"Face reconstruction or face optimization as a biometric, has a several advantages in forensic application. The size and structure of face are static of an individual. For reliable human face image reconstruction, the implementation system requires huge facial image datasets. Further the assessment of the system should be done by employing a testing procedure. This paper deals with the analysis and rectification of human face images for reconstruction and optimization of human face images. The advantage of using input human face image for reconstruction in forensic application and automatic face recognition system is that they are free from wide variety of poses, expression, illumination gestures and face occlusion. The whole research is divided into two phases; in the first phase reconstruction of destructed part of human face image is being done with template matching. Second phase deals with deep neural network applications to match the image carried out in phase one. The proposed algorithm is used to reconstruct the image and at the same time, reconstructed image is used as test image for biometrical face recognition. After reconstruction of image, it is examined with various well-known algorithms (SVMs, LDA, ICA, PCA & DNNs) of face recognition system for the evaluating the performance of speed, memory usage and metrics of accuracy.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Management']"
doi:10.1007/978-981-19-3035-5_6,en,An Efficient Machine Learning Classifier for Sarcasm Detection,OriginalPaper,"Irony is a sarcastic term that is used to actively criticize people. Irony is frequently expressed through indirect phrases. Politics, sports, business, and social media are the different places where ironic statements can be found. Some people can perceive irony in words, while others are clueless about how others have expressed themselves. To recognize these elements of speech, various machine learning and deep learning algorithms are applied. The main purpose of this study is to propose a broad summary of the ironic and non-ironic words found in subreddit data were used to categorize the text comments. This manuscript describes about the well-known datasets that are used to create the ironic detection networks by providing a major focus on classifying the comments. The considered dataset is partitioned to make the task easier. Finally, the process used for identifying irony phrases and the most successful classifiers and evaluation criteria are also discussed.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Statistics, general']"
doi:10.1007/978-981-19-4162-7_26,en,Text Recognition from Images Using Deep Learning Techniques,OriginalPaper,"One of the most significant methods utilized in the deep learning approach is text recognition. Text recognition is now a very significant activity that is utilized in many applications of current gadgets to recognize images in a detailed manner. Automatic number plate recognition, for example, is an image processing approach that detects the vehicle's number (license) plate. The automatic number plate recognition system (ANPR) is a key feature that is used to manage traffic congestion. The goal of ANPR is to devise a method for automatically identifying permitted vehicles using vehicle numbers. Automatic number plate recognition (ANPR) is utilized in a variety of applications, including traffic control, vehicle tracking, and automatic payment of tolls on roads and bridges, as well as monitoring systems, parking management systems, and toll collecting stations. The established approach first recognizes the vehicle before taking a picture of it. After that, the number plate region in the car is localized using a neural network, and the image is segmented. Using a character recognition approach, characters are retrieved from the plate. The results, together with the time stamp, are then saved in the database. It is implemented and performed in Python, and the results are tested on a real picture.","['Engineering', 'Computational Intelligence', 'Data Mining and Knowledge Discovery', 'Systems and Data Security', 'Mobile and Network Security', 'Information Systems Applications (incl. Internet)']"
doi:10.1007/978-981-19-5224-1_7,en,Analysis of Student Behavioural Patterns by Machine Learning,OriginalPaper,"An important task in education field is discovering student behavioural patterns to take timely action to improve student activities or grades. Sometime students may fell into depression due to misunderstanding of subjects or due to low grade which leads into abnormal behaviour, and by identifying such abnormal behaviour, institutions can take necessary steps to improve student’s condition. For this research, questionnaire method is used which includes collecting student data through survey and analyse students’ behavioural patterns. However, results by this method are not effective or accurate as this method largely relies on feedback data. So to solve this problem, an unsupervised clustering approach can be used. This produces relatively accurate results. The proposed framework integrates two unsupervised clustering approaches, i.e. density-based spatial clustering of applications with noise (DBSCAN) and k -means. The students data is collected from Kaggle data sets. The proposed framework extracts necessary behaviour features by statistics and entropy to find both anomalous behavioural patterns and main stream patterns. To predict whether the student is low active or high active or medium active, we can use supervised techniques as unsupervised clustering approaches are meant to form clusters. These findings can help students to improve their grades and personality and organization can also take appropriate steps to help students by providing better services and administrations such as psychological consultations and academic advices.","['Engineering', 'Communications Engineering, Networks', 'Statistics, general', 'Cyber-physical systems, IoT', 'Sociology, general', 'Professional Computing']"
doi:10.1007/978-981-19-2065-3_5,en,Mobile Image Analysis for Detecting Melanoma,OriginalPaper,"The devices of mobile like smartphones are getting utilized by millions of users all over the globe. This makes chance in styling mobile image applications among many imaging applications like health care which have drawn immense attention in recent times. In the existing design where the detecting system is enhanced to execute the resource-constrained with the smartphone, our system localizes the skin texture by binding lightweight techniques to detect the affected areas by using K-means segmenting method which is a fast segmentation approach. In the proposed system, statistical confidence intervals based segmentation model is implied; from this time forward, the grouping is additionally done by resilient neural network (RNN) to help the norm of arrangement. A morph legitimate review is been created here for profound comprehension of the image highlights and so forth.","['Engineering', 'Communications Engineering, Networks', 'Artificial Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Machine Learning']"
doi:10.1007/978-3-031-20241-4_5,en,Prediction of Airport Pavement Moduli by Machine Learning Methodology Using Non-destructive Field Testing Data Augmentation,OriginalPaper,"For the purpose of the Airport Pavement Management System (APMS), in order to optimize the maintenance strategies, it is fundamental monitoring the pavement conditions’ deterioration with time. In this way, the most damaged areas can be detected and intervention can be prioritized. The conventional approach consists in performing non-destructive tests by means of a Heavy Weight Deflectometer (HWD). This equipment allows the measurement of the pavement deflections induced by a defined impact load. This is a quite expensive and time-consuming procedure, therefore, the points to be investigated are usually limited to the center points of a very large mesh grid. Starting from the measured deflections at the impact points, the layers’ stiffness moduli can be backcalculated. This paper outlines a methodology for predicting such stiffness moduli, even at unsampled locations, based on Machine Learning approach, specifically on a feedforward backpropagation Shallow Neural Network (SNN). Such goal is achieved by processing HWD investigation and backcalculation results along with other variables related to the location of the investigation points and the underlying stratigraphy. Bayesian regularization algorithm and k-fold cross-validation procedure were both implemented to train the neural model. To enhance the training, a data analysis technique commonly referred to as data augmentation was used in order to increase the dataset by generating additional data from the existing ones. The results obtained during the model testing phase are characterized by a very satisfactory correlation coefficient, thus suggesting that the proposed Machine Learning approach is highly reliable. Notably, the proposed methodology can be implemented to evaluate the performance of every paved area.","['Engineering', 'Building Construction and Design', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence', 'Statistics, general']"
doi:10.1007/978-3-031-19032-2_48,en,Creating a Brief Review of Judicial Practice Using Clustering Methods,OriginalPaper,"Based on the results of previous research in the field of legal text processing, this article discusses a number of high-level modules of the “hybrid intelligent information system for analysis of the judicial practice of arbitration courts” that can be used in the work of lawyers. The development of the clustering module “Court Clustering” is discussed. A brief overview of related works based on clustering approach is given. The clustering experiments result are discussed, it is shown that the proposed algorithm solves the clustering problem better than the considered analogues for all the main clustering quality metrics. The module for creating a brief review of judicial practice is discussed. Module output include certain statistical information on the analyzed documents as well as paragraphs that can help in preparing for the dispute. The analytical module is discussed. Module can generate various reports based on data extracted from court documents.","['Engineering', 'Computational Intelligence', 'Machine Learning', 'Neurosciences']"
doi:10.1007/978-3-031-16078-3_55,en,Human Iris Image Analysis for the Classification of Fuchs’ Crypts and Peripupillary Rings,OriginalPaper,"The human iris is one of the most important identifiable features that contain many complex patterns. In this work, we attempted to automatically classify irises with machine learning models based on several different iris patterns in order to assist genetic research related to pigmentation and structural tissue differences within the human iris. Specifically, two main iris patterns that are commonly observed in the general population were analyzed: the Fuchs’ crypts and the peripupillary pigmented ring. A two-stage machine learning model was proposed to classify the iris crypt frequency, in which a Mask R-CNN model was first built to identify the number of crypts of each size level in the iris, followed by a SVM model to determine the final category. Another KNN model, which used the area-refined histogram features, was applied to classify the iris based on the peripupillary pigmented ring. The labels used in the images were generated independently by two trained expert raters. The performance of these models was evaluated on a test set with overall accuracies of the models estimated at 80.0% and 86.6% for crypts and pigmented ring, respectively. These optimized objective models were therefore concordant with the inter-rater reliability scores produced by expert human raters.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-3-031-16072-1_12,en,"Bregman Divergencies, Triangle Inequality, and Maximum Likelihood Estimates for Normal Mixtures",OriginalPaper,"The concepts of distance and angle and their algebraic realizations in the form of a scalar product are known to lead to kernel versions of sophisticated clustering algorithms. Here the more recently utilized Bregman Divergencies are treated. They possess all the properties of a metric apart from satisfying the triangle inequality. However, they can be suitably modified. En passant an apparent gap in a former paper is eliminated by exploiting an old proof concerning (conditionally) positive definite kernels. In addition an explicit isometric embedding of the modified Bregman Divergence in a Reproducing Kernel Hilbert Space is described. On a practical level recalling some basic facts on normal mixtures the well known connection between the parameter estimation problem for these mixtures and clustering algorithms is shown to hold in this abstract setting as well thus providing a more flexible approach to maximum likelihood estimates.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1976-3_6,en,A Queue Management System for Cloud Data Processing,OriginalPaper,"With cloud computing, businesses have to manage their systems effectively due to the amount of data they store every day. The Hadoop Distributed File System with MapReduce is an efficient and widely used cloud data processing platform that parallelizes data processing operations. However, Hadoop’s efficiency is heavily reliant on job scheduling. Centralized schedulers offer predictable execution at the cost of resource utilization; distributed schedulers, on the other hand, maximize cluster utilization but have lengthy job completion times when assignments are heterogeneous. The introduction of queues at operational nodes may help to resolve this issue. This paper introduces a queue management system to reduce job execution time while utilizing the system resources as effectively as possible. To achieve rapid job completion times, we can define policies that can be used to manage active queues, in which we specify which task will be executed next when a running task terminates. The proposed system’s performance is evaluated using three parameters: total time, average time, and capacity utilized.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-3998-3_106,en,Two-Stage Flocking Formation Control Based on Constrained Boundary,OriginalPaper,"Flocking is a special behavior that exists in the natural world. In this paper, a two-stage flocking formation algorithm is presented. The algorithm utilizes a varied range boundary to limit the agents in the group. As time increases, the agents tend to form an $$\alpha -lattice$$ α - l a t t i c e structure formation. The algorithm improved the converging speed of the flock formation. Simulations and analysis are provided to demonstrate the algorithm for 2D cases.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']"
doi:10.1007/978-3-031-07258-1_51,en,Measuring Thermal Response of Bridges Using Vision-Based Technologies and LVDTs,OriginalPaper,"A robust structural health monitoring approach measuring the structural responses of bridges such as displacements, strains etc. helps to ensure their safety and serviceability. Static and dynamic loads from vehicles and pedestrians influence the instantaneous responses of bridges, while thermal loads from daily and seasonal temperature variations influence bridge long-term responses. Vision-based monitoring (VBM) is an emerging non-contact, non-destructive monitoring approach. It utilizes cameras to capture sequential images of the structure under load and suitable image processing algorithms for target tracking. VBM has shown promising accuracy in static and dynamic response measurements of bridges, however, the evidence of its accuracy in thermal response measurements is limited. This research illustrates the results of laboratory experiments implementing VBM for thermal response measurements. Thermal responses of a laboratory truss are monitored with VBM and contact sensors such as thermocouples and linear variable differential transformers (LVDT). Cyclic temperature loads are applied to the truss to simulate daily temperature variations. The truss is monitored with GoPro cameras and contact sensors. Measured response trends by VBM and LVDT are comparable, indicating the accuracy of VBM to measure thermal responses. Thermal responses measured by VBM are higher than those of LVDT, signifying requirement for measurement resolution enhancement. The measurement resolution of VBM is 0.099 mm/°C and LVDT1 is 0.041 mm/°C respectively. This discrepancy can be attributed to non-identical targets of VBM and LVDT, resolution of the camera, efficiency of the feature tracking algorithm and robustness of LVDT output. This case study illustrates the feasibility and challenges of VBM for thermal response measurement.","['Engineering', 'Building Repair and Maintenance', 'Cyber-physical systems, IoT', 'Industrial and Production Engineering', 'Monitoring/Environmental Analysis', 'Analytical Chemistry']"
doi:10.1007/978-981-19-0108-9_29,en,Forest Fire Detection Using Satellite Images,OriginalPaper,"Forest represents a complex ecosystem on earth that is a refuge to several living beings such as plants, animals, birds and also a huge resource of minerals, lakes and rivers. It almost covers 30% land of the earth and is highly necessary to balance the ecosystem along with the climate. Therefore, the loss of forests is a severe disaster. Along with deforestation, forest fire has a major impact. Although, the wildfires are not in control fully and most of the time in the various region of the earth, which not only harm the climate but also make a very bad impact on the ecosystem. As forest fires are a very common phenomenon, some of the preventive actions and units are already defined such as McArthur Forest Fire Danger Index (FFDI), the establishment of a separate section in the disaster team for monitoring and assessment of wildfire but intense research for preventing wildfire is highly necessary. Nowadays, satellites are used to scan the earth’s surface. This technique can also be used to detect forest fires. With the help of the spatial high-resolution imagery system, the hot spot areas can be accurately located for determining the forest fire’s locations.","['Engineering', 'Manufacturing, Machines, Tools, Processes', 'Renewable and Green Energy', 'Materials Science, general', 'Nanotechnology']"
doi:10.1007/978-981-19-5845-8_33,en,An Efficient Classification Algorithm for Employee Well-Being Prediction Using Deep Learning,OriginalPaper,The impact of COVID-19 has changed the way work is being done especially in the IT sector. The emergence of work from home as an option has resulted in the evolution of hybrid work culture going forward as the world is moving towards endemic. On these circumstances there has been drastic change in work pattern of employees which clearly impacted the efficiency levels and their wellbeing (both physical and mental). It has also become imperative for the employers to track the efficiency of employees during their working hours in order to ensure maximum productivity in hybrid working model. This paper proposes a system that can detect and track the employee efficiency though facial landmarks by assessing the parameters like drowsiness and stress using deep learning techniques and hybridization of classification algorithms.,"['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-21203-1_8,en,Incorporating AI Methods in Micro-dynamic Analysis to Support Group-Specific Policy-Making,OriginalPaper,"An agent-based modelling approach is a powerful means of understanding social phenomena by modelling individual behaviours and interactions. However, the advancements in modelling pose challenges in the model analysis process for understanding the complex effects of input factors, especially when it comes to offering concrete policies for improving system outcomes. In this work, we propose a revised micro-dynamic analysis method that adopts advanced artificial intelligence methods to enhance the model interpretation and to facilitate group-specific policy-making. It strengthens the explanation power of the conventional micro-dynamic analysis by eliminating ambiguity in the result interpretation and enabling a causal interpretation of a target phenomenon across subgroups. We applied our method to understand an agent-based model that evaluates the effects of a long-term care scheme on access to care. Our findings showed that the method can suggest policies for improving the equity of access more efficiently than the conventional scenario analysis.","['Computer Science', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4960-9_46,en,Automated Stacking Ensemble Model for Forecasting COVID-19 Cases,OriginalPaper,"COVID-19 is an infectious disease caused by the SARS-Cov2 virus. Multiple variants of COVID-19 such as beta and omicron have spread all over the world that has caused more than six million fatalities till now and it is still not halted. Multiple vaccinations have been already created but are not full-proof solutions for all the existing mutations and also its protection against any upcoming mutations is not known. Therefore, forecasting of COVID-19 cases becomes the most important weapon to avoid the spread of COVID-19 due to any forthcoming mutation. This research presents an automated stacking ensemble method to forecast COVID-19 cases. The proposed method employs multilayer perceptron, long short-term memory, and linear regression together with a genetic algorithm. The purpose of this research is create an automated model to foresee COVID-19 cases so that any impending COVID-19 wave can be discovered at an early stage to prevent it from spreading.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Professional Computing']"
doi:10.1007/978-3-031-16868-0_11,en,Differential Evolution for Architecture Design,OriginalPaper,"The general goal of this chapter is to explore the capacity of DE, named DECNN, to evolve deep CNN architectures and parameters automatically. Designing new crossover and mutation operators of DE, as well as an encoding scheme, and a second crossover operator will help to achieve the goal. DECNN will be evaluated on six datasets of various complexity that are widely used and compared to 12 state-of-the-art methods.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-2535-1_5,en,Bomb Box: A Fortified Vault to Prevent Brute Force Attack,OriginalPaper,"The Internet of things encompasses many devices connected to the Internet including wearable devices or edge devices forming a smart system to manage many tasks without the intervention of humans. Securing such systems, whether it is a part of IoT framework or any industrial software, is a very crucial task to be considered. Protecting them with passwords or even encrypting them still leaves some loopholes in the system. The attacker uses the concept of brute force to predict passwords and hack the system. To protect and prevent the system, many policies related to passwords are adopted. This includes continuous updating of passwords, which creates another stress to memorize them. This paper depicts a novel concept of a bombing algorithm to create a secure system and help remove unnecessary stress. The further section describes the related work done and the methodology adopted. The last section displays the results and evaluation of the proposed system.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3866-5_43,en,Developments in Fusion Deposition Modelling Process Using Industrial Robot,OriginalPaper,"Fused deposition modelling (FDM) is an additive manufacturing process, where the material is deposited in horizontal layers, one on another to create a 3D object. In the conventional FDM process, the extruder head moves in two directions simultaneously to deposit one layer over a horizontal printing platform (heat bed) and the printing platform moves vertically downwards by a small amount (equal to layer thickness) to facilitate the deposition of the next layer. In conventional FDM machines, due to limited degrees of freedom, change in extruder orientation and printing on inclined planes are not possible. Recently, industrial robots are used to overcome these limitations using extruder as end effector. This paper reviewed various strategies adopted for conventions FDM and robotic FDM process to overcome various limitations. The major advantages of the FDM process with the robot are printing is possible on the inclined plane, multiple planes and curved surfaces without staircase effect.","['Engineering', 'Machinery and Machine Elements', 'Industrial and Production Engineering', 'Robotics and Automation']"
doi:10.1007/978-981-19-6290-5_8,en,Advancements in Reversible Data Hiding Techniques and Its Applications in Healthcare Sector,OriginalPaper,"Among all the approaches, Digital watermarking is the most widely implemented approach for copyright protection and authentication of data. In this technique, a unique piece of information is known as a watermark. Then the watermark gets into an image, later, to achieve its objective the watermark will be extracted. For the transmission of medical images, digital watermarking schemes are mostly used to ensure that the image has not gone through any unauthorized or illegal modifications during the transmission. Since conventional watermarking schemes alter the pixels in the original image, it is not suited for watermarking medical images. In medical images, permanent modifications may adversely affect the diagnosis process at the receiver side, caused by watermarking, especially when we are using some computer-aided diagnosis tools. This motivated computer scientists to work on reversible watermarking schemes. The reversible watermarking technology makes it possible to recover the required medical image from the watermarked image, while extracting the hidden watermark. So, the reversible watermarking technique does not affect the diagnosis in any way since the recovered image will be equivalent to the original image. This recovered image will be used by the user. The use of reversible watermarking techniques to send patient reports along with medical images is also explored, with the patient reports being embedded in the medical picture itself rather than the watermark. These techniques are commonly known as reversible data hiding techniques. This book chapter gives a brief overview of reversible data hiding techniques, reversible watermarking methods, and the major applications in medical image transmissions. In addition, the chapter addresses contemporary reversible data hiding and reversible watermarking algorithms intended specifically for medical picture transmission. The chapter also discusses some of the obstacles that must be overcome when developing a reversible watermarking system for healthcare applications.","['Computer Science', 'Systems and Data Security', 'Cyber-physical systems, IoT', 'Professional Computing', 'Artificial Intelligence']"
doi:10.1007/978-3-031-20631-3_10,en,Multi-criteria Software Selection of a Logical Process Control System,OriginalPaper,"This article describes methodology of multi-criteria choice of the best alternative (variant) of programming language (PL) of controlling element of technological equipment on the basis of multistage application of procedures of hierarchy analysis method. We have analyzed a number of sources, devoted to the problem of choosing the best variant of programming language with taking into account several criteria, necessary for the qualitative solution of the selection problem, which showed a low level of its elaboration. The problem of selecting the core for developing application software for automation systems is mainly related to the evolutionary development of programming technologies, core, architectural solutions and so on. Nowadays, system developers should not make a choice of a PL based on its ease of use or availability of many programs written in it, much less at random. Lack of general recommendations on software selection for logical control system of technological equipment and considering multi-criteria problem of choice and practical need to improve the efficiency of controllers cause the relevance of the problem. The first step in software development is a comparative analysis of a control system based on several criteria, in order to select the best (preferable) option of PL. The result is the selected preferred variant of PL for logical control of technological equipment. Recommendations for applying the proposed methodology are explained by increasing the quality of decisions at the present stage of selecting the PL of industrial automation system.","['Engineering', 'Electronics and Microelectronics, Instrumentation', 'Electrical Engineering']"
doi:10.1007/978-981-19-2188-9_54,en,Predictive Modeling of Surface Roughness Using Machine and Deep Learning Frameworks from Experimental Data of Chemically Etched Polished Silicon Wafer with DDMAF,OriginalPaper,"The newly developed double disk magnetic abrasive finishing (DDMAF) process has been recently executed to improve the finishing efficacy of polished silicon wafers. It is obvious to have induction of errors in the experimental processes for predicting the output response in form of surface roughness of polished silicon wafers. This work has been presented to model the actual experimental values of surface roughness of polished mono-crystalline silicon wafer with the predicted data of surface roughness by utilizing machine and deep learning libraries in Python’s JupyterLab. The experimental data of 31 experiments for surface roughness of polished mono-crystalline silicon wafer with chemically accompanied unconventional machining process known as DDMAF has been used here. The machine learning algorithm chosen for the specific data distribution was a polynomial regression from scikit-learn API. The data was split into 85% training and 15% testing for the same. The data was further modeled in Keras sequential neural nets, with the experimental data spitted into 85% training and 15% validation.","['Engineering', 'Industrial and Production Engineering', 'Mechatronics', 'Engineering Thermodynamics, Heat and Mass Transfer', 'Energy Storage', 'Materials Engineering']"
doi:10.1007/978-3-031-20506-4_3,en,Wind Turbine Wake Redirection via External Vanes,OriginalPaper,"The aerodynamic interactions of wind turbines are a wind farm’s most significant source of energy loss. Every wind turbine creates a low-speed, highly turbulent, plume-like airflow called a “wake.” To minimize the said losses, one needs to reduce the overall exposure to upstream turbines’ wakes. One can achieve this goal by optimizing the farm’s layout and actively controlling the parameters that can either steer or weaken the wake, such as yaw or pitch angles. Both practices, i.e., layout optimization and active yaw control, are still insufficient, leaving the wind farms as one of the least power-dense forms of plants with a power density of 1–2 W/m 2 . In this article, we propose the application of external vanes to steer the wake from downstream turbines in real time. While acknowledging that implementing this strategy with a current technology readiness level of 1 is not easy, this research only serves as a preliminary proof of concept demonstrating this idea’s effectiveness. The study utilized large-eddy simulations and an inline, three-turbine configuration. It revealed that a sizeable external vane between the front- and the second-row turbines increased the production of the second and third turbines by approximately 45% and 42%, respectively, which is significant compared to all other studied active wake control strategies.","['Energy', 'Renewable and Green Energy', 'Environmental and Sustainability Education', 'Sustainable Development', 'Sustainable Architecture/Green Buildings', 'Energy Policy, Economics and Management', 'Natural Resource and Energy Economics']"
doi:10.1007/978-3-031-12011-4_4,en,Intelligent Modeling for Shear Strength of RC Exterior Beam-Column Joint Subjected to Seismic Loading,OriginalPaper,"RC beam-column joints are subjected to impounding shear demand and bond-slip during the event of an earthquake. Accurate prediction of joint shear strength is necessary to avoid brittle shear failure in design and retrofitting procedures. In this study the accurate shear strength of RC exterior beam-column joints are predicted by providing a contemporary intelligent modeling approach through eXtreme Gradient Boosting regressor (XGBoost), an ensemble learning technique that combines several weak learners to generate a strong predictive model. From the experimental results of diverse publications on exterior beam-column joints, parameters affecting joint shear strength are found through examination of current models, and a vast database is constructed. Eleven such parameters that describe the material property, geometric configuration and bond resistance, are chosen as the inputs, and joint shear strength as the output. The model is then trained, tested and validated on this database. The performance of this model is evaluated by various regression evaluation metrics such as MSE, RMSE, and R 2 . Comparison of this model with the existing empirical equation, code provisions, and even with an individual ML algorithm, demonstrated its superiority over all the models in terms of accuracy and computation time. Sensitivity analysis done using predictive power score (PPS) showed that the most important parameter for the estimation of the shear strength of RC exterior beam-column joint is the percentage of beam longitudinal reinforcement.","['Engineering', 'Construction Management', 'Building Construction and Design', 'Geotechnical Engineering & Applied Earth Sciences']"
doi:10.1007/978-3-031-13249-0_8,en,Algorithmic Differentiation for Interactive CAD-Integrated Isogeometric Analysis,OriginalPaper,Algorithmic differentiation is used to analyse the interaction between input and output parameters of arbitrary computational models. We discuss the application of algorithmic differentiation at the interface between architecture and civil engineering in the field of CAD-integrated structural analysis and form finding.,"['Engineering', 'Engineering Design', 'Manufacturing, Machines, Tools, Processes', 'Industrial Design', 'Interaction Design', 'User Interfaces and Human Computer Interaction']"
doi:10.1007/978-3-031-21062-4_14,en,GadenTools: A Toolkit for Testing and Simulating Robotic Olfaction Tasks with Jupyter Notebook Support,OriginalPaper,"This work presents GadenTools, a toolkit designed to ease the development and integration of mobile robotic olfaction applications by enabling a convenient and user-friendly access to Gaden’s realistic gas dispersion simulations. It is based on an easy-to-use Python API, and includes an extensive tutorial developed with Jupyter Notebook and Google Colab technologies. A detailed set of examples illustrates aspects ranging from basic access to sensory data or the generation of ground-truth images, to the more advanced implementation of plume tracking algorithms, all in an online web-editor with no installation requirements. All the resources, including the source code, are made available in an online open repository.","['Computer Science', 'Robotics', 'Robotics and Automation', 'Computational Intelligence']"
doi:10.1007/978-981-19-3679-1_13,en,A Comprehensive Study of Machine Learning Techniques for Diabetic Retinopathy Detection,OriginalPaper,"Diabetic retinopathy is a threatening complication of diabetes, occurred due to damaged blood vessels of light-sensitive areas of the retina. DR leads to total or partial blindness if left untreated. DR does not give any symptoms at early stages, so earlier detection of DR is a big challenge for proper treatment of diseases. With advancement of technology various machine learning approaches based methods are designed for early detection of DR so that experts can provide proper treatment to the patients for preventing its harmful effects. This paper provides a comprehensive study of machine learning based approaches, e.g., Bossa Nova feature beyond lesson, pixel-based super classification, SVM and Gaussian Mixture Model, selective sampling and Patch-based sampling, Carl Zesis Meditec ML, BoVW Salient map, U-Net, LeNet, and STSF deep architecture, etc., used to detect diabetic retinopathy.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-1412-6_45,en,Traffic Sign Recognition Approach Using Artificial Neural Network and Chi-Squared Feature Selection,OriginalPaper,"With the rising population and vehicular traffic across the globe, driver safety on road has become a huge concern for most governments. Emerging technologies and industrial revolutions have given rise to concept of autonomous cars. The driving systems embedded in these cars identify the traffic signs on the road and then take appropriate action. In spite of all these efforts, the accuracy of traffic sign image detection still remains a challenge for most car manufacturers and drivers, especially under difficult weather conditions. Multiple authors have done research in past and have proposed approaches relevant to identification of traffic sign images. The proposed solutions on traffic sign image detection have been influenced largely by Artificial Intelligence (AI)-based implementation techniques. In this research paper, authors have used Mapillary public traffic image dataset and have proposed an innovative approach using chi-squared ranking algorithm along with ANN for image classification. The effectiveness of proposed approach is compared with some related works. Experimental results showed that the proposed enhanced algorithm based on ANN and chi-squared algorithm provided better results.","['Engineering', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security']"
doi:10.1007/978-981-19-6068-0_16,en,Analyze Ego-Centric Nodes in Social Network Using Machine Learning Technique,OriginalPaper,"Social network is an emerging area for grouping the similar interest people. The empowerment of human interaction is supported by the various services of the social media technologies. It provides the knowledge, inference among the users and their actions. Social media raises the students to discover key influence to choose their higher education institution in their interesting field. It provides constant incitement, prompt, decision, and guidance. The large volume of data has a bridge between the educational institution and students. The links among the users in the social media are playing a vital role in identifying the closeness among the nodes. The framework is used to enhance the properties of links that involves (1) follower of links, (2) followee of links, and (3) follower to followee of links to develop the influence in order to support the career guidance process. The social network metrics are used to evaluate the influence propagation through identifies the influence nodes. The nodes are identified based on the behavioral traits or structural properties of the nodes in the network. The development of career guidance in social network analysis causes an emerging demand for analyzing the closeness of links among the users. The closeness of links with various roles of dimensions using machine learning techniques is used to analyze the efficiency of nodes in the social network.","['Computer Science', 'Artificial Intelligence', 'Computational Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-16-9131-7_3,en,Hybrid Intelligent Fault Diagnosis,OriginalPaper,"In this chapter, hybrid intelligent fault diagnosis methods for mechanical systems are presented. Firstly, a multiple weighted K nearest neighbor ( K NN) combination method is introduced, where the same input feature set is considered. Next, a multiple adaptive neuro-fuzzy inference systems combination approaches with different input feature sets is demonstrated and validated using bearing fault diagnosis cases. Afterwards, a multidimensional hybrid intelligent fault diagnosis method is presented, which uses different classifier combinations with different input feature sets. The approaches of MLP, RBF, and K NN are integrated. The gearbox fault diagnosis case is considered for validation. Results show that the hybrid intelligent fault diagnosis method generally outperforms the conventional individual intelligent diagnosis approaches.","['Engineering', 'Machinery and Machine Elements']"
doi:10.1007/978-3-030-96276-0_3,en,Algorithmic Modelling and Prototyping of a Connection Joint for Reticular Space Structures,OriginalPaper,"The detailed research process proposes innovative and advanced solutions that allow for the determination and parametric control of any configuration of the reticular spatial structure. The system allows a variable number of culms of the same size can be joined and oriented in generic directions, ensuring the designer has optimal freedom in terms of composition. The algorithmic definitions, which are processed in the Grasshopper plug-in for the famous NURBS modelling software Rhinoceros , have allowed the project flow to be managed as an integrated process, ranging seamlessly from the concept to the manufacturing with numerically controlled machines. The structuring of a design process in algorithmic terms has had the advantage of obtaining flexible solutions to the different design conditions through form-finding methods, which can be optimised with genetic algorithms. The full-scale, three-dimensional printing—using professional machines for rapid additive prototyping—of a spatial-reticular-structure module with various types of connection joints and rods in bamboo culms have permitted experimentation and validation of the defined technological solution.","['Engineering', 'Building Materials', 'Light Construction, Steel Construction, Timber Construction', 'Sustainable Development']"
doi:10.1007/978-3-031-17548-0_1,en,Passenger Flow Control in Subway Station with Card-Swiping Data,OriginalPaper,"Congestion is a great concern for urban rail transit, because it has a great impact on commuting efficiency and passenger safety. In order to mitigate congestion, this paper proposes a passenger flow control framework. Its function is to predict passenger number with given data and algorithms, identify possible overcrowding in advance, implement control strategies, and therefore reduce congestion. A subway station model based on the AnyLogic software is built to verify the control framework and to simulate the movement of passengers and trains. Simulation results demonstrate that the control framework has a good effect on congestion alleviation at a station level.","['Engineering', 'Data Engineering', 'Computational Intelligence']"
doi:10.1007/978-981-19-1412-6_39,en,Digital Image Watermarking Techniques Using Machine Learning—A Comprehensive Survey,OriginalPaper,"Digital image watermarking is the most interesting and active field for research as it prevents unwanted access to multimedia data. The trade-off between imperceptibility, robustness, capacity and safety must be maintained for the conception of an efficient and strong digital picture watermarking system. Different studies have been conducted in order to ensure that these needs are hybridized by many domains, including spatial and transformational fields. An analytical analysis is performed on existing digital picture watermarking systems in this research. The digital information that has resulted in the request for a safe ownership of the information may recently be readily changed, reproduced, distributed and stored. The watermark solution for the authentication of content and copyright protection is quite good. This paper discusses basic concepts and features of digital watermarking, important attacks on watermarking systems, general embedding and extraction processes for watermarking marks, and important techniques for the transformation using machine learning are analysed. The objective of this paper is to provide an ephemeral study and background on the definition, and idea and major contributions of watermarking the techniques are classified according to different categories: host signal, sensitivity, robustness, kind of watermark, essential data for extraction, processing domain and applications.","['Engineering', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security']"
doi:10.1007/978-981-16-9967-2_7,en,A Novel Approach to Detect Plant Disease Using DenseNet-121 Neural Network,OriginalPaper,"The disease of crops is a major risk to food security and can incur a makeable loss to the people. But, the latest development in deep learning for solving this problem surpasses all the traditional methods in terms of efficiency, time period for detection and accuracy. In this paper, we came up with a rapid identification of leaf image and classify the image to correct class by using classical deep neural network architecture, DenseNet-121. This deep learning model has the ability to recognize 15 types of different plant disease, three of which are healthy ones, for better accurate results. The algorithm is highly optimized to produce results in less than 5 s after being fed into the system. The model’s total testing accuracy for plant disease detection is 99%.","['Computer Science', 'Computer Systems Organization and Communication Networks', 'Computational Intelligence', 'Artificial Intelligence', 'Wireless and Mobile Communication', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-5073-5_3,en,MVPC—A Classifier with Very Low VC Dimension,OriginalPaper,"In real-world problems, patterns found within the training data can be different from those found in the test data (dataset shift); obtaining reliable results with handcrafted (low-level) features becomes difficult even with linear kernel SVM. Such problems necessitate the creation of classifiers with low variance and high generalization as a driving function. In this chapter, we show the variance of a class of majority vote classifiers named Majority Vote Point (MVP) classifier, to be lower than that of linear classifiers, on account of lower VC dimension.","['Computer Science', 'Machine Learning', 'Computational Intelligence', 'Pattern Recognition']"
doi:10.1007/978-981-19-7842-5_7,en,Measuring Machine Intelligence Using Black-Box-Based Universal Intelligence Metrics,OriginalPaper,"Measuring the machine intelligence quotient (MIQ) of intelligent agent-based systems (IABSs) is very important based on the increasing number of intelligent systems applied to real-life problem solving. The most important property of an intelligence metric must be its universality. Developing universal intelligence metrics is difficult based on the very large diversity of intelligent systems. A feasible approach for ensuring the universality of measuring machine intelligence consists in using black-box-based methods able to measure the central intelligence tendency in problem solving. This paper represents a guide for choosing the most appropriate black-box-based intelligence metric for measuring the intelligence of developed IABSs, classification of IABSs in intelligence classes and detection of the IABSs with statistical low and high outlier intelligence. In research where the performance of heuristic and metaheuristic algorithms is studied, the performance indicator is frequently calculated as the mean or the median of experimental evaluation results. There is no consensus agreement regarding which of them is more appropriate. In some cases, both of them are reported. The manner in which it should be decided which of them to be used is scientifically grounded in this paper.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-981-19-3679-1_24,en,DroidApp: An Efficient Android Malware Detection Technique for Smartphones,OriginalPaper,"The huge development of Internet interconnectivity has brought about an extensive expansion in digital assault occasions, a considerable lot of which have decimating and serious impacts. Malware is one type of cyber assault that is becoming more prevalent day by day. The conflict between security researchers and malware creators is an ongoing battle with the quick evolution of malware as technological innovation develops. The aim of this research work is to detect Android malware using a recommendation system with less space and time complexity. This detection technique uses an app similarity graph (ASG) for Android application analysis. With this analysis, we achieved an accuracy of 98.22%.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']"
doi:10.1007/978-981-19-4863-3_30,en,Simulation of Water Table Depth Using Hybrid CANFIS Model: A Case Study,OriginalPaper,"Long-term water table depth (WTD) prediction in agricultural areas proves to be a challenging task. These regions have heterogeneous and complex hydrogeological characteristics, human activities, and boundary conditions; also, there are nonlinear interactions between these aspects. Machine learning (ML) approaches have been broadly implemented for WTD forecasting because of their capability of modelling nonlinearities amongst GWL and its conditional factors. A new ML model was developed known as the co-active neuro-fuzzy inference system combined with the firefly algorithm (CANFIS-FA) for estimating monthly WTD of Nuapada watershed located in Odisha state, India. Prediction results of CANFIS-FA model presented good performance with mean squared error of 1.084–3.709; the correlation coefficient is >0.98, demonstrating that the hybrid model is appropriate to assess multifaceted groundwater systems. Therefore, it is evident that proposed model can assist as an alternate method in WTD prediction, particularly in regions where hydrogeological data are challenging to acquire.","['Engineering', 'Computational Intelligence', 'Engineering Design', 'Machine Learning', 'Communications Engineering, Networks']"
doi:10.1007/978-981-19-3387-5_32,en,Research for Non-cooperative Space Objects Detection Methods Based on Image,OriginalPaper,"This paper takes a research on non-cooperative space objects detection methods based on the image. In order to design a new method suited for optical observation equipment with super-large field of view and high sensitivity, paper investigates existing methods and summaries the development trend from the appearing of object detection till now. According to the research, the main driving force for space objects detection methods is the upgrading of hardware used in observation equipment. Nowadays, methods in this field have gradually gain the unity of high sensitivity, high real-time performance and high accuracy. In the future, with the application of novel algorithms, new methods will achieve fast and accurate detection of darker or even obscured objects.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Aerospace Technology and Astronautics']"
doi:10.1007/978-981-19-3575-6_3,en,Design of a QoS-Aware Machine Learning Model for High Trust Communications in Wireless Networks,OriginalPaper,"Incorporating trust levels in wireless networks is always a trade-off between quality of service and control overheads. It requires an effective design of trust model that considers the nodes with high trust values. The trusted nodes show good performance in terms of various parameters that defines quality, like high packet delivery ratio, high energy efficiency, and minimum delay. For designing such protocol, one must consider such parameters and to classify whether the node is malicious or legitimate. This classification also must be accompanied with effective routing mechanism that will choose shortest and legitimate path for better QoS. For designing such a dynamic trust-based routing network, this work proposes a machine learning model for QoS-aware routing. This model considers node-to-node distance, node energy, and node clustering as performance in order to improve the overall routing trust levels. The proposed algorithm is compared with ad hoc-on-demand-distance-vector routing (AODV)-based non-trust routing algorithm, and an improvement in QoS is observed. This improvement ensured a delay reduction, and an energy consumption reduction when compared to the existing AODV-based non-trust-routing network.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-1607-6_50,en,Design and Implementation of Verifiable Blockchain-Based e-voting System,OriginalPaper,"Voting is the most representative way to express individual decision making in a democratic society. The classic voting method requires a lot of confirmation procedures, and requires a lot of time and money. In order to solve these kinds of problems, there have been efforts to introduce e-voting with IT services advantages, such as reduced election costs and shorter tally hours, compared to the existing voting methods. Despite many advantages, e-voting is not widely used for various technical concerns, including the risk of data manipulation. There has been much effort recently to apply the blockchain for voting data integrity to e-voting as a way to reduce the risk of voting data security and integrity. Blockchain could guarantee the integrity of voting data, but it has problems to be directly applied to e-voting system. In this paper, by applying cryptographic algorithms to the blockchain, we propose a verifiable blockchain-based e-voting system that allows voters to verify their votes while separating voters and voting results. Proposed the verifiable blockchain-based e-voting system satisfies the requirements of voting, including completeness, soundness, privacy, un-reusability, eligibility, fairness, verifiability.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']"
doi:10.1007/978-3-031-07823-1_9,en,A Planar Irregular Hexagonal Tessellation-Based Approach for Connected k-Coverage,OriginalPaper,"This chapter focuses on the connected k -coverage problem in planar (or two-dimensional) wireless sensor networks using a hexagonal tiling-based approach. First, it investigates a planar convex tile that best approximates the sensing range of the sensors, while maximizing the percentage being used of this sensing range.","['Engineering', 'Communications Engineering, Networks', 'Wireless and Mobile Communication', 'Computational Intelligence', 'Artificial Intelligence', 'Data Engineering', 'Computer Systems Organization and Communication Networks']"
doi:10.1007/978-981-19-3571-8_65,en,Portfolio Optimization Using Reinforcement Learning: A Study of Implementation of Learning to Optimize,OriginalPaper,"Portfolio optimization is defined as the process of asset distribution to achieve optimum expected returns and/or minimizing financial risk associated. It is crucial for a financial risk manager to provide the best returns possible in the market and calculation of risks like value-at-risk. The problem of portfolio optimization is not new to the financial world, and approach like efficient frontier is already known. While the work on optimization of portfolio is voluminous, this paper describes the portfolio optimization approach using reinforcement learning. This approach is particularly useful in the case where the search space is very large, and distribution of asset must be done in real time. Algorithmic trading could be a good candidate for this optimization approach. In this paper, the description is given for a few famous optimization algorithms also that is used in the financial industry. The main idea of this reinforcement learning (RL)-based approach is that agent learns the weights distribution across the portfolio by rewarding and punishing the weights ratio and by continuously doing so it can produce real-time distribution of the weights. The study has been done on a portfolio of four stocks though can be extends to any number of stocks in the portfolio.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-3-031-05347-4_14,en,Machine Learning Based Software Defect Categorization Using Crowd Labeling,OriginalPaper,"Defect categorization is an important task which helps in software maintenance. It also helps in prioritizing the defects, resource allocation, etc. Standard machine learning techniques can be used to automate the categorization of defects. Labeled data is needed for learning models. The expert is required for obtaining the labeled data. Sometimes, it is costly or expert is not available. So, to overcome this dependency, crowd labeled data is used to train a model. Crowd (a set of novices) is asked to assign a category as defined by IBM’s Orthogonal Defect Classification (ODC) to the defect reports. Obtaining categories through crowd can be inaccurate or noisy. Inferencing ground truth is a challenge in crowd labeling. Support Vector Machine, k Nearest Neighbor and Gaussian Naive Bayes classifier, are learnt effectively using new methodology from data labeled by a set of novices. In this chapter, we have proposed a learning model which learns effectively to predict the impact category of software defects using the expectation maximization algorithm and shows the better performance according to the various types of metrics by improving the existing technique by 8% and 11% accuracy for Compendium and Mozilla datasets respectively.","['Mathematics', 'Mathematical Modeling and Industrial Mathematics', 'Risk Management', 'Engineering Economics, Organization, Logistics, Marketing']"
doi:10.1007/978-981-19-3387-5_71,en,Simulation and Analysis of Influence of Group Delay Distortion on Satellite-to-Ground and Satellite-to-Satellite Link Channel,OriginalPaper,"In the high-speed satellite-to-ground and satellite-to-satellite data transmission, the signal suffers significant group delay distortion because the bandwidth is limited. Simultaneity, as high-order modulation has high spectral efficiency, it will be widely used in the high-speed satellite-based data transmission. At the same time, High-order modulation is sensitive to the group delay distortion. An 8PSK system is simulated to analyze the influence of group delay distortion. The results shows that when the group delay distortion is 4 symbol periods, the performance of 8PSK modulations is acceptable.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Aerospace Technology and Astronautics']"
doi:10.1007/978-3-031-18461-1_46,en,Towards Profitability: A Profit-Sensitive Multinomial Logistic Regression for Credit Scoring in Peer-to-Peer Lending,OriginalPaper,"This paper proposes a profit-sensitive learning method for loan evaluation in the peer-to-peer (P2P) lending market that could provide better investment suggestions for the lenders. Currently, the most widely utilized loan evaluation method is credit scoring, which focuses on evaluating the loans’ defaulting risk and formulates a binary classification problem. It screens out the non-default loans from the default ones and thus defines the best loans as those with a low probability of default (PD). However, the conventional credit scoring totally ignores the profit information while solely focusing on the risk. To address the above issue, we propose a profit-sensitive multinomial logistic regression model that incorporates the profit information into the credit scoring approach. More specifically, we first transform the binary classification problem in traditional credit scoring to a multi-level classification task by further dividing the default loans into two sub-classes: “default and profitable” and “default and not profitable”. Then we design a multinomial logistic regression model with a novel loss function to solve the above-defined multi-level classification task. The loss function weights loans differently according to their varying profits as well as their occurrence frequencies in the real-world practices. The effectiveness of the proposed method is examined by the real-world P2P data from Lending Club. Results indicate our approach outperforms the existing credit scoring only approach in terms of identifying more profitable loans while ensuring the low risk. Therefore, the proposed profit-sensitive learning method serves as an innovative reference when making investment suggestions in P2P lending or similar markets.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']"
doi:10.1007/978-981-16-9967-2_74,en,An Efficient Approach to Stamp Verification,OriginalPaper,"Stamps have become one of the most important security features in big companies where huge amounts of documents need processing daily. The stamp attached to a document is used to determine the authenticity of that document so that it is necessary to identify whether a stamp is forged or genuine. However, nowadays, it is easier for the general public to forge stamps. This paper presents a practical approach for stamp verification, based on the three stages process similar to some previous work: stamp segmentation, classification stamp or non-stamp, and stamp authenticity verification. In each stage, this work tries and tests new algorithms/methods to give a new way of solving the problem in each stage. Firstly, in our approach, an unsupervised learning machine method is implemented to detect all the objects in the input image, so all the regions including stamps and text are extracted. Next, two separate models of support vector machine classification are constructed. The first one is to distinguish between stamps and other objects in a document. The second model will determine the object which was classified as stamps in the first model whether it is genuine or not. The results show that this approach can perform the stamp verification tasks effectively.","['Computer Science', 'Computer Systems Organization and Communication Networks', 'Computational Intelligence', 'Artificial Intelligence', 'Wireless and Mobile Communication', 'Cyber-physical systems, IoT', 'Professional Computing']"
doi:10.1007/978-981-19-5224-1_68,en,PROPHETESS: A Tool for Prediction of Prophage Loci in Bacterial Genomes,OriginalPaper,"This paper describes the design, development, and implementation of a standalone bioinformatic tool for the prediction of putative prophage loci in bacterial host genomes using statistical measures, based on the algorithm published as the “Prophage Loci Predictor for Bacterial Genomes” and described as the loci predictor algorithm. This algorithm proposed a novel approach to the problem of detecting prophage regions in bacterial genomic information using particle swarm optimization, using a fixed size pattern lookup table to detect virus-like pattern distributions in the host/bacterial genome. As this algorithm was designed with the intension of providing highly consistent and fast performance, the time-to-process sequence is the primary metric for evaluating the performance of the tool, and the processing speed was expected to scale only with the size of the genome under consideration and not on the size of the pattern database as is the case with other algorithms in its class. The implemented tool was evaluated using both the algorithms test and training sets and was shown to obtain a linear co-related performance as expected in both training and prediction phases of the performance testing.","['Engineering', 'Communications Engineering, Networks', 'Statistics, general', 'Cyber-physical systems, IoT', 'Sociology, general', 'Professional Computing']"
doi:10.1007/978-3-030-99075-6_21,en,A TFG-CNN Fault Diagnosis Method for Rolling Bearing,OriginalPaper,"It is difficult to obtain enough data to train a robust diagnosis model for different rolling bearing faults, and the existing intelligent bearing fault diagnosis algorithms have insufficient generalization ability. Therefore, a rolling bearing fault detector based on the time–frequency graph and convolution neural network (TFG-CNN) is introduced to improve the generalization performance of the fault diagnosis algorithm as much as possible under the condition of considering the diagnosis accuracy and sample size. The specific implementation method is to use Fast Fourier transform (FFT) to transform the vibration data of rolling bearing into a two-dimensional network graph, and then use CNN to classify them. Finally, the performance of the proposed method is analyzed by using the rolling bearing fault datasets of Case Western Reserve University, and analysis results show that the proposed method can simultaneously diagnose the fault location and severity of rolling bearing, and has good cross-domain diagnosis ability and anti-noise performance.","['Engineering', 'Industrial and Production Engineering', 'Mechanical Engineering', 'Machinery and Machine Elements']"
doi:10.1007/978-981-19-1906-0_36,en,Use of Deep Neural Networks in Detecting Breast Cancer Lesion,OriginalPaper,This paper presents a deep neural network module for breast cancer lesion detection which is trained and tested over 569 datasets. The model produces an accuracy of 0.95 in predicting the benign and malignant lesions in the breast. This model gives high accuracy to few advancement in technology with multiple input views and optimised amongst many choices. A thorough analysis of the model’s performance on various populations is conducted. The python code used in the model uses tensor flow library and a seaborn visualisation library. The data sets used in the code are segregated as training and testing datasets. Training sets contain 80% of data and testing sets contain 20% of data. Histogram images are created to view all the parameters separately for training and testing. Later the accuracy and cost are found so that it can be implemented in real-world applications without any wrong predictions.,"['Engineering', 'Electronics and Microelectronics, Instrumentation', 'Computer Systems Organization and Communication Networks', 'Artificial Intelligence']"
doi:10.1007/978-3-031-15928-2_84,en,A Design Methodology for Graded Density Triply Periodic Minimal Surfaces,OriginalPaper,"Functionally Graded Cellular Materials (FGCM), characterized by a gradual change in their properties, have previously reported better mechanical responses than their uniform counterparts. One particular example of FGCM corresponds to the application of a gradient in the density. In this context, the use of variable volume fraction cells can further improve the generation of lightweight internal structures for additive manufacturing. Accordingly, this study considers the implementation of Triply Periodic Minimal Surfaces (TPMS) as elements for cellular constructs, given their advantages compared to traditional CAD lattices. Even though previous efforts in the literature have explored the generation of models with variable density TPMS, a modelling procedure has not been formally defined. Therefore, the main objective of this study is to propose a general design methodology for the development of graded density Primitive and Gyroid surfaces, which are common examples of TPMS, while considering a variation of the unit-cells’ design parameters, i.e. the pattern thickness and unit-cell length. The desired parameter variation is then used for the generation of the TPMS constructs by a manipulation of the TPMS function variables or the meshing process, inside a pre-defined design space. The differences in surface generation depending on TPMS type and input design parameters are presented and discussed, along perspectives for the process’s improvement. Ultimately, graded density TPMS can be developed in combination with topological optimization procedures of penalization algorithms for intermediate densities, while accounting for manufacturability restrictions.","['Engineering', 'Engineering Design', 'Industrial and Production Engineering', 'Computer-Aided Engineering (CAD, CAE) and Design']"
doi:10.1007/978-981-19-0588-9_8,en,Review of Energy Management Strategies in Plug-in Hybrid-Electric Vehicles,OriginalPaper,"As a step toward a pollution-free environment, governments and regulatory bodies worldwide are moving toward cleaner means of transportation. A lot of tailpipe emissions occur in a conventional internal combustion engine. One solution to these hazardous emissions is the use of hybrid-electric vehicles (HEVs) or fully electric vehicles (EVs). The HEVs, especially plug-in HEVs (PHEVs), are soon expected to have more significant commercial applications, as the EVs may take more time for their larger part of the share. A hybrid-electric vehicle employs an IC engine combined with a smaller battery and an electric motor. On the other hand, a PHEV consists of a much larger capacity battery storage known as a rechargeable energy storage system (RESS). It is equally important to apply a stable drivetrain topology for greater efficiency. PHEV blends power from battery and engine using an energy management system, which always tries to impart the best driving conditions, least emissions, and maximum mileage and range. In the paper, an overview of all the control strategies is reviewed with few simulation results.","['Energy', 'Energy Systems', 'Transportation Technology and Traffic Engineering', 'Electronics and Microelectronics, Instrumentation']"
doi:10.1007/978-981-19-0095-2_42,en,Speaker Diarization and BERT-Based Model for Question Set Generation from Video Lectures,OriginalPaper,"The year 2020 and the onset of the pandemic has, by and large, rendered the traditional classroom-based learning experiences obsolete. This rapid change in the learning experience has brought with it the opportunity to explore new avenues such as online learning. In this paper, we outline a methodology that aims to aid this paradigm shift by proposing an automated question set generation model based on the video lectures delivered by the teacher. We study the usage of pre-trained Scientific Bidirectional Encoder Representations from Transformers (SCIBERT) checkpoints for question generation on text derived from video lectures. The proposed methodology takes into consideration the presence of multiple speakers in the video lectures and employs speaker diarization for obtaining the audio corresponding to the teacher’s voice. Diarization is implemented using the mean shift clustering algorithm. For the purpose of answer-agnostic question generation, pre-trained SCIBERT checkpoint is used to warm start an encoder–decoder model. The model is fine-tuned using the SQuAD dataset. The results show that the model is able to successfully generate questions for a given context derived from the transcript of a diarized video lecture.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Systems and Data Security', 'Artificial Intelligence', 'Computational Intelligence']"
