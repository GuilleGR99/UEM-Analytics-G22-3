{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66ca074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#!pip install -U numpy\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from ast import literal_eval\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1eb0eef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e75f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"spring/total.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a7cca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"categorias\"] = data[\"categorias\"].apply(\n",
    "    lambda x: literal_eval(x)\n",
    ")\n",
    "data[\"categorias\"].values[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d44e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_split = 0.4\n",
    "\n",
    "# Initial train and test split.\n",
    "train_df, test_df = train_test_split(\n",
    "    data,\n",
    "    test_size=test_split,\n",
    "    stratify=data[\"categorias\"].values,\n",
    ")\n",
    "# Splitting the test set further into validation\n",
    "# and new test sets.\n",
    "val_df = test_df.sample(frac=0.5)\n",
    "test_df.drop(val_df.index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f433e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "terms = tf.ragged.constant(train_df[\"categorias\"].values)\n",
    "lookup = tf.keras.layers.StringLookup(output_mode=\"multi_hot\")\n",
    "lookup.adapt(terms)\n",
    "vocab = lookup.get_vocabulary()\n",
    "\n",
    "\n",
    "def invert_multi_hot(encoded_labels):\n",
    "    \"\"\"Reverse a single multi-hot encoded label to a tuple of vocab terms.\"\"\"\n",
    "    hot_indices = np.argwhere(encoded_labels == 1.0)[..., 0]\n",
    "    return np.take(vocab, hot_indices)\n",
    "\n",
    "\n",
    "print(\"Vocabulary:\\n\")\n",
    "print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b435c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_label = train_df[\"categorias\"].iloc[0]\n",
    "print(f\"Original label: {sample_label}\")\n",
    "\n",
    "label_binarized = lookup([sample_label])\n",
    "print(f\"Label-binarized representation: {label_binarized}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fb5e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df[\"abstract\"].apply(lambda x: len(x.split(\" \"))).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1778f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seqlen = 139\n",
    "batch_size = 128\n",
    "padding_token = \"<pad>\"\n",
    "auto = tf.data.AUTOTUNE\n",
    "\n",
    "\n",
    "def make_dataset(dataframe, is_train=True):\n",
    "    labels = tf.ragged.constant(dataframe[\"categorias\"].values)\n",
    "    label_binarized = lookup(labels).numpy()\n",
    "    dataset = tf.data.Dataset.from_tensor_slices(\n",
    "        (dataframe[\"abstract\"].values, label_binarized)\n",
    "    )\n",
    "    dataset = dataset.shuffle(batch_size * 10) if is_train else dataset\n",
    "    return dataset.batch(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97ae9ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = make_dataset(train_df, is_train=True)\n",
    "validation_dataset = make_dataset(val_df, is_train=False)\n",
    "test_dataset = make_dataset(test_df, is_train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ee27ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32de2c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_batch, label_batch = next(iter(train_dataset))\n",
    "\n",
    "for i, text in enumerate(text_batch[:3]):\n",
    "    label = label_batch[i].numpy()[None, ...]\n",
    "    print(f\"Abstract: {text}\")\n",
    "    print(f\"Label(s): {invert_multi_hot(label[0])}\")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef222ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source: https://stackoverflow.com/a/18937309/7636462\n",
    "vocabulary = set()\n",
    "train_df[\"abstract\"].str.lower().str.split().apply(vocabulary.update)\n",
    "vocabulary_size = len(vocabulary)\n",
    "print( vocabulary_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f849d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorizer = layers.TextVectorization(\n",
    "    max_tokens=vocabulary_size, ngrams=2, output_mode=\"tf_idf\"\n",
    ")\n",
    "\n",
    "# `TextVectorization` layer needs to be adapted as per the vocabulary from our\n",
    "# training set.\n",
    "with tf.device(\"/CPU:0\"):\n",
    "    text_vectorizer.adapt(train_dataset.map(lambda text, label: text))\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto\n",
    ").prefetch(auto)\n",
    "validation_dataset = validation_dataset.map(\n",
    "    lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto\n",
    ").prefetch(auto)\n",
    "test_dataset = test_dataset.map(\n",
    "    lambda text, label: (text_vectorizer(text), label), num_parallel_calls=auto\n",
    ").prefetch(auto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c761c7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model():\n",
    "    shallow_mlp_model = keras.Sequential(\n",
    "        [\n",
    "\n",
    "            layers.Dense(512, activation=\"relu\"),\n",
    "            layers.Dense(256, activation=\"relu\"),\n",
    "            layers.Dense(lookup.vocabulary_size(), activation=\"sigmoid\"),\n",
    "            #layers.Dense( len(vocab), activation=\"sigmoid\"),\n",
    "        ]  # More on why \"sigmoid\" has been used here in a moment.\n",
    "    )\n",
    "    return shallow_mlp_model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336798c1",
   "metadata": {},
   "source": [
    "def make_model():\n",
    "    shallow_mlp_model = tf.keras.models.Sequential([\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20, return_sequences=True)),\n",
    "        tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20)),\n",
    "        tf.keras.layers.Dense(6, activation='softmax')\n",
    "        ])\n",
    "    return shallow_mlp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ea818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "#5 para acelerar las primeras versiones, solo queremos ver que no explota\n",
    "opt = tf.optimizers.Adam()\n",
    "shallow_mlp_model = make_model()\n",
    "shallow_mlp_model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\",\"binary_accuracy\"])\n",
    "#categorical_crossentropy\n",
    "#sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0f196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = shallow_mlp_model.fit(train_dataset, validation_data=validation_dataset, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b9d6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_result(item):\n",
    "    plt.plot(history.history[item], label=item)\n",
    "    plt.plot(history.history[\"val_\" + item], label=\"val_\" + item)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(item)\n",
    "    plt.title(\"Train and Validation {} Over Epochs\".format(item), fontsize=14)\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_result(\"loss\")\n",
    "plot_result(\"accuracy\")\n",
    "plot_result(\"binary_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d359fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.models.save_model(shallow_mlp_model,'spring/radEd_model_v2.hdf5')\n",
    "#shallow_mlp_model = tf.keras.models.load_model('spring/radEd_model_v2.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983d0a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,accura, binary_acc  = shallow_mlp_model.evaluate(test_dataset)\n",
    "print(f\"Categorical accuracy on the test set: {round(binary_acc * 100, 2)}%.\")\n",
    "print(f\"Categorical accuracy on the test set: {round(accura * 100, 2)}%.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5bce1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a model for inference.\n",
    "model_for_inference = keras.Sequential([text_vectorizer, shallow_mlp_model])\n",
    "\n",
    "# Create a small dataset just for demoing inference.\n",
    "inference_dataset = make_dataset(test_df.sample(100), is_train=False)\n",
    "text_batch, label_batch = next(iter(inference_dataset))\n",
    "predicted_probabilities = model_for_inference.predict(text_batch)\n",
    "\n",
    "# Perform inference.\n",
    "for i, text in enumerate(text_batch[:10]):\n",
    "    label = label_batch[i].numpy()[None, ...]\n",
    "    #print(f\"Abstract: {text}\")\n",
    "    print(f\"Label(s): {invert_multi_hot(label[0])}\")\n",
    "    predicted_proba = [proba for proba in predicted_probabilities[i]]\n",
    "    top_3_labels = [\n",
    "        x\n",
    "        for _, x in sorted(\n",
    "            zip(predicted_probabilities[i], lookup.get_vocabulary()),\n",
    "            key=lambda pair: pair[0],\n",
    "            reverse=True,\n",
    "        )\n",
    "    ][:3]\n",
    "    print(f\"Predicted Label(s): ({', '.join([label for label in top_3_labels])})\")\n",
    "    print(\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55815ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "[\n",
    "        x\n",
    "        for  x in sorted(\n",
    "            zip(predicted_probabilities[60], lookup.get_vocabulary()),\n",
    "            key=lambda pair: pair[0],\n",
    "            reverse=True,\n",
    "        )\n",
    "    ][:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a67eba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
