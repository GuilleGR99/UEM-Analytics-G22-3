identifier,language,title,genre,abstract,subjects,abstract_limpio,keywords
doi:10.1007/978-3-031-16776-8_1,en,Introduction to Cooling Technologies,OriginalPaper,"This book provides background information, description, and analysis of four major cooling technologies—vapor compression cooling, evaporative cooling, absorption cooling, and gas cooling. Vapor compression systems are currently the primary technology used in most standard domestic, commercial, and industrial cooling applications, as they have both performance and economic advantages over the other competing cooling systems. However, there are many other applications in which evaporative cooling, absorption cooling, and gas cooling technologies are a preferred choice. The text is written as a tutorial for engineering students and practicing engineers who want to become more familiar with air conditioning and refrigeration systems. The level of the text is at the advanced mechanical engineering student level, as it assumes basic knowledge of thermodynamics, fluid mechanics, and heat transfer.","['Engineering', 'Mechanical Engineering', 'Building Physics, HVAC', 'Industrial Chemistry/Chemical Engineering']",this book provides background information description and analysis of four major cooling technologies—vapor compression cooling evaporative cooling absorption cooling and gas cooling vapor compression systems are currently the primary technology used in most standard domestic commercial and industrial cooling applications as they have both performance and economic advantages over the other competing cooling systems however there are many other applications in which evaporative cooling absorption cooling and gas cooling technologies are a preferred choice the text is written as a tutorial for engineering students and practicing engineers who want to become more familiar with air conditioning and refrigeration systems the level of the text is at the advanced mechanical engineering student level as it assumes basic knowledge of thermodynamics fluid mechanics and heat transfer,"['air conditioning' 'competing cooling systems' 'engineering'
 'evaporative cooling absorption' 'fluid mechanics'
 'gas cooling vapor compression systems' 'heat transfer' 'refrigeration'
 'thermodynamics' 'vapor compression cooling']"
doi:10.1007/978-981-19-6313-1_2,en,Production of Manufactured Sand,OriginalPaper,"The poor appearance, uneven size, and uncontrollable fines content of MS are the common quality problems in the present production of MS, which show a negative impact on the application of MS in engineering. However, the quality of MS is controllable and adjustable. If the appropriate production process and equipment are adopted and various indexes of MS are strictly controlled, the MS will meet the engineering requirements and is able to replace natural sand in construction. The production process of MS should be selected according to the methylene blue (MB) value and fines content of the MS. Moreover, appropriate vibrating feeder, crushing equipment, and fines removal equipment should be adopted based on factors such as environmental protection and type of parent rock. In addition, optimization methods have been proposed and developed on production process, equipments, and slurry recovery, which play an important role in the improvement of MS quality.","['Engineering', 'Building Materials', 'Structural Materials', 'Building Construction and Design']",the poor appearance uneven size and uncontrollable fines content of ms are the common quality problems in the present production of ms which show a negative impact on the application of ms in engineering however the quality of ms is controllable and adjustable if the appropriate production process and equipment are adopted and various indexes of ms are strictly controlled the ms will meet the engineering requirements and is able to replace natural sand in construction the production process of ms should be selected according to the methylene blue mb value and fines content of the ms moreover appropriate vibrating feeder crushing equipment and fines removal equipment should be adopted based on factors such as environmental protection and type of parent rock in addition optimization methods have been proposed and developed on production process equipments and slurry recovery which play an important role in the improvement of ms quality,"['engineering' 'engineering requirements' 'environmental protection'
 'fines content' 'fines removal equipment' 'ms' 'ms quality' 'parent rock'
 'production process equipments' 'slurry recovery'
 'uncontrollable fines content' 'vibrating feeder crushing equipment']"
doi:10.1007/978-3-031-13588-0_40,en,Le Corbusier’s Modulor and ‘le jeu des panneaux’: A Parametric Approach,OriginalPaper,"Historically, architecture gradually became controlled by modulation, proportion, rhythm, harmony, and orthogonality of regular forms. In his investigation, Le Corbusier renews this fact maintaining the precise orthogonality of the right angle and modulation as a means to achieve his mathematical ‘ vérités réconfortantes ’ . In recent years parametric modelling allows us to combine a great number of parameters, conducting us to explore and discover new possibilities to plan architectural forms. In this paper we study corbusian window panels using PM. The methodological procedures were: i) drawing of the grid of proportions; ii) parametric redrawing of the red and blue series; iii) geometric study of the so-called “ jeu des panneaux ”, with the reconstruction of the 2.26 m square and its golden section; iv) development of algorithms based on the values of the red and blue series; v) generation of combinations among parameters; vi) discussion of results and analysis. Using Grasshopper, the aim of this article is to report the parametric study of the red and blue series of the corbusian Modulor.","['Engineering', 'Engineering Mathematics', 'Computational Intelligence']",historically architecture gradually became controlled by modulation proportion rhythm harmony and orthogonality of regular forms in his investigation le corbusier renews this fact maintaining the precise orthogonality of the right angle and modulation as a means to achieve his mathematical ‘ vérités réconfortantes   in recent years parametric modelling allows us to combine a great number of parameters conducting us to explore and discover new possibilities to plan architectural forms in this paper we study corbusian window panels using pm the methodological procedures were: i drawing of the grid of proportions; ii parametric redrawing of the red and blue series; iii geometric study of the socalled  jeu des panneaux  with the reconstruction of the  m square and its golden section; iv development of algorithms based on the values of the red and blue series; v generation of combinations among parameters; vi discussion of results and analysis using grasshopper the aim of this article is to report the parametric study of the red and blue series of the corbusian modulor,"['blue series' 'corbusian modulor' 'corbusian window panels' 'forms'
 'geometric study' 'grasshopper' 'modulation proportion' 'of proportions'
 'parametric modelling' 'parametric study' 'precise orthogonality'
 'rhythm harmony' 'right' 'verites recon']"
doi:10.1007/978-981-19-1142-2_57,en,Algorithms of AI in Deciding Optimum Mix Design of Concrete: Review,OriginalPaper,"The preparation of mix design of concrete requires a knowledge of design mix proportioning. Various properties like slump value, compressive strength are considered while preparing mix design. This traditional mix proportion method is a time-consuming and costly process. It is also done manually which may lead to different errors. To overcome this, use of artificial intelligence has been brought into this field to predict the design mix of concrete in limited time, low cost and minimum error due to use of computational algorithms as compared to traditional methods. In this paper, the studies using different algorithms of artificial intelligence are reviewed. Estimation of properties like compressive strength, slump value of concrete is done. Further, this paper also presents comparative analysis between different algorithms of AI. This research paper will be of great help to concrete technologist to explore future possibilities of AI techniques in concrete industry.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Mobile and Network Security', 'Artificial Intelligence']",the preparation of mix design of concrete requires a knowledge of design mix proportioning various properties like slump value compressive strength are considered while preparing mix design this traditional mix proportion method is a timeconsuming and costly process it is also done manually which may lead to different errors to overcome this use of artificial intelligence has been brought into this field to predict the design mix of concrete in limited time low cost and minimum error due to use of computational algorithms as compared to traditional methods in this paper the studies using different algorithms of artificial intelligence are reviewed estimation of properties like compressive strength slump value of concrete is done further this paper also presents comparative analysis between different algorithms of ai this research paper will be of great help to concrete technologist to explore future possibilities of ai techniques in concrete industry,"['ai techniques' 'artificial intelligence'
 'compressive strength slump value' 'computational algorithms' 'concrete'
 'concrete industry' 'limited time low cost' 'minimum error' 'mix'
 'mix design' 'slump value compressive']"
doi:10.1007/978-3-031-18063-7_8,en,Horizontal Standards: Harmonizing Principles and Conflicts of Securities Regulation,OriginalPaper,"This chapter focuses on ‘horizontal standards’, i.e., standards concerning the characteristics of a regulatory authority, its enforcement powers, the leeway granted to self-regulatory organizations, and the minimum regulatory purview on market elements and players (such as issuers, information providers, mutual funds, market intermediaries, secondary markets, and clearing and settlement). Horizontal standards thus cross specific topics, cover the characterizing features of a domestic regulatory framework, and provide high-level principles for crucial topics, including the so-called regulatory deference between regulators. For this reason, the chapter analyzes and detects the roots of the most important policy document that IOSCO has ever produced, i.e., Objectives and Principles of Securities Regulation , also known as the IOSCO Principles . Subsequently, the chapter focuses on a different kind of horizontal guidelines, those contained in IOSCO’s Reports that cope with conflicts of regulatory securities law.","['Law', 'Private International Law, International & Foreign Law, Comparative Law', 'European Law', 'International Economic Law, Trade Law']",this chapter focuses on ‘horizontal standards ie standards concerning the characteristics of a regulatory authority its enforcement powers the leeway granted to selfregulatory organizations and the minimum regulatory purview on market elements and players such as issuers information providers mutual funds market intermediaries secondary markets and clearing and settlement horizontal standards thus cross specific topics cover the characterizing features of a domestic regulatory framework and provide highlevel principles for crucial topics including the socalled regulatory deference between regulators for this reason the chapter analyzes and detects the roots of the most important policy document that iosco has ever produced ie objectives and principles of securities regulation  also known as the iosco principles  subsequently the chapter focuses on a different kind of horizontal guidelines those contained in ioscos reports that cope with conflicts of regulatory securities law,"['##d' '##ries' 'domestic regulatory framework' 'horizontal standards'
 'ie objectives' 'ie standards' 'information providers' 'leeway'
 'minimum regulatory purview' 'mutual funds market inter' 'regulatory'
 'regulatory deference' 'securities law' 'securities regulation'
 'selfregulatory organizations']"
doi:10.1007/978-981-19-3590-9_58,en,Stock Prediction System Using an Integrated Fine Tune Stacked and Ensembled Activation LSTM Network,OriginalPaper,"Money is the essential commodity for the survival of human beings, irrespective of their social economic status. People attract towards easy money, one of the easy money earning is spending their money on shares. Every coin has two sides, similarly people invested in shares may get profit or loss. So, stock prediction is gaining more attention by the business people to forecast the value based on time series and recommend a good share to the investors. Traditional approaches solve the stock prediction problem using artificial networks which deal only with features associated with the dataset but the major decision element of any stock prediction system is previous transactional records. The model addresses this issue by designing LSTM network by using ensemble activation functions. Existing neural networks use static architecture, i.e. standard values for all the parameters which are not suitable to for all types of stock markets. The proposed system identifies the hyper-parameter values for each estimator and designs the neural network with these values and ensemble activators to suit for generalized stock and financial data.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security', 'Mobile and Network Security']",money is the essential commodity for the survival of human beings irrespective of their social economic status people attract towards easy money one of the easy money earning is spending their money on shares every coin has two sides similarly people invested in shares may get profit or loss so stock prediction is gaining more attention by the business people to forecast the value based on time series and recommend a good share to the investors traditional approaches solve the stock prediction problem using artificial networks which deal only with features associated with the dataset but the major decision element of any stock prediction system is previous transactional records the model addresses this issue by designing lstm network by using ensemble activation functions existing neural networks use static architecture ie standard values for all the parameters which are not suitable to for all types of stock markets the proposed system identifies the hyperparameter values for each estimator and designs the neural network with these values and ensemble activators to suit for generalized stock and financial data,"['##para' 'activators' 'artificial networks' 'data'
 'ensemble activation functions' 'generalized stock' 'human beings'
 'ie standard values' 'loss so stock prediction' 'lstm network'
 'neural networks' 'social economic status people' 'static architecture'
 'stock markets' 'stock prediction problem' 'time series']"
doi:10.1007/978-981-19-3679-1_52,en,Credit Card Fraud Detection Using Various Machine Learning and Deep Learning Approaches,OriginalPaper,"It is evident that the evolution in technology has surpassed expectations and reached different heights in a shorter span of time and with evolving technology; a lot of changes have been introduced in our lives, and one such change is the replacement of traditional payment methods with the credit card system. Credit card use increases the most during online shopping. With the huge demand for credit cards worldwide, credit card fraud cases to are increasing rapidly. In this paper, four machine learning algorithms that are decision tree, random forest, logistic regression, and Naïve Bayes have been used for training the models. Also, deep neural networks have been implemented for model training which is giving more promising results compared to the machine learning algorithms. The accuracy of each algorithm used in the implementation of the credit card fraud detection has been compared and analyzed.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']",it is evident that the evolution in technology has surpassed expectations and reached different heights in a shorter span of time and with evolving technology; a lot of changes have been introduced in our lives and one such change is the replacement of traditional payment methods with the credit card system credit card use increases the most during online shopping with the huge demand for credit cards worldwide credit card fraud cases to are increasing rapidly in this paper four machine learning algorithms that are decision tree random forest logistic regression and naïve bayes have been used for training the models also deep neural networks have been implemented for model training which is giving more promising results compared to the machine learning algorithms the accuracy of each algorithm used in the implementation of the credit card fraud detection has been compared and analyzed,"['credit card fraud cases' 'credit card fraud detection'
 'credit card system' 'credit card use' 'credit cards'
 'decision tree random forest logistic regression' 'deep neural networks'
 'machine learning algorithms' 'online shopping' 'surpassed expectations']"
doi:10.1007/978-3-031-16684-6_15,en,Review of Trends in Manufacturing Systems Based on Industry 4.0: The Opportunities,OriginalPaper,"The paper presents a review of current trends in Manufacturing Systems that could give developing countries opportunities to improve their economy and create jobs. This would allow creating or improving companies that would have greater efficiency, flexibility, productivity and process security. These companies would produce better quality products and more profitable production. Industry 4.0 criteria are used to accelerate the automation of manufacturing, giving rise to a completely new business model, which facilitates product diversification. There are some opportunities that would allow the integration of new technologies, improve production and achieve more profits.","['Engineering', 'Control and Systems Theory', 'Computational Intelligence']",the paper presents a review of current trends in manufacturing systems that could give developing countries opportunities to improve their economy and create jobs this would allow creating or improving companies that would have greater efficiency flexibility productivity and process security these companies would produce better quality products and more profitable production industry  criteria are used to accelerate the automation of manufacturing giving rise to a completely new business model which facilitates product diversification there are some opportunities that would allow the integration of new technologies improve production and achieve more profits,['business model' 'manufacturing systems' 'process security']
doi:10.1007/978-3-031-07422-6_14,en,Brazil,OriginalPaper,"Like the European Union and several other countries, Brazil has its own legal regulation on personal data, the General Data Protection Law (Portuguese acronym: LGPD). Enacted on 14 August 2018, the law entered into force in August 2020. Hence, since the mid-2020s, Brazil has had a Data Protection Law in place and a National Data Protection Authority (Portuguese acronym: ANPD) that regulates and supervises compliance with this law. The appointments for the board of the ANPD were approved by the Brazilian Senate on 20 October 2020, and the Authority is currently operational, including through its website, where anyone can file a complaint related to violations of personal data rights.","['Law', 'Private International Law, International & Foreign Law, Comparative Law', 'IT Law, Media Law, Intellectual Property', 'Artificial Intelligence', 'Online Marketing/Social Media', 'Big Data', 'International Economic Law, Trade Law']",like the european union and several other countries brazil has its own legal regulation on personal data the general data protection law portuguese acronym: lgpd enacted on  august  the law entered into force in august  hence since the mids brazil has had a data protection law in place and a national data protection authority portuguese acronym: anpd that regulates and supervises compliance with this law the appointments for the board of the anpd were approved by the brazilian senate on  october  and the authority is currently operational including through its website where anyone can file a complaint related to violations of personal data rights,"['anpd' 'brazil' 'compliance' 'data protection law' 'european union'
 'lgpd' 'national data protection authority' 'personal data rights']"
doi:10.1007/978-981-19-4676-9_55,en,Implementation of E2EE Using Python,OriginalPaper,"The need for cyber security is felt now more than ever. In an era of constant mass surveillance, illegal spying and cyber-attacks, it is extremely important to have a secure means of communication which cannot be intercepted. Several new protocols were introduced such as HTTPS to encrypt the connection between the client and the server. This made sure that no third person can read the data being transmitted to and from the client. This model of encryption had one major flaw: the server itself. Every message that was encrypted by the sender was decrypted at the server, encrypted again and sent to the receiver. Thus the server can read all the messages. The users of such chatting services had to trust the owners of the services with their privacy. Even if the owners were not involved in shady data deals, they still had the risk of their servers getting hacked or being pressured by the government to reveal the data of their users. All these issues paved the way for a new type of implementation of encryption known as end-to-end encryption often abbreviated as E2EE. The message to be sent is encrypted by the sender and is sent to the server which relays it to the receiver as it is. Since the keys used to encrypt and decrypt the data are available only to the users, the server cannot read the messages sent through it. This model quickly gained popularity and was implemented by many messaging applications, the most notable being WhatsApp, Signal, Telegram, and Wire. In this project, we are going to implement E2EE using Python. For encryption, we intend to use the AES algorithm. AES stands for advanced encryption standard which was introduced in 2001 by the NITS (U.S.A.). It was developed by Vincent Rijmen and Joan Daemen in response to the earlier broken algorithm DES. AES is a symmetric key encryption algorithm meaning that the same key is used for encryption as well as decryption of the messages. This algorithm has three key lengths—128,192 and 256 bits, whereas a single block size of 128 bits. The version we are going to implement is 128 bits key size.","['Engineering', 'Computational Intelligence', 'Systems and Data Security', 'Artificial Intelligence', 'Computer Imaging, Vision, Pattern Recognition and Graphics']",the need for cyber security is felt now more than ever in an era of constant mass surveillance illegal spying and cyberattacks it is extremely important to have a secure means of communication which cannot be intercepted several new protocols were introduced such as https to encrypt the connection between the client and the server this made sure that no third person can read the data being transmitted to and from the client this model of encryption had one major flaw: the server itself every message that was encrypted by the sender was decrypted at the server encrypted again and sent to the receiver thus the server can read all the messages the users of such chatting services had to trust the owners of the services with their privacy even if the owners were not involved in shady data deals they still had the risk of their servers getting hacked or being pressured by the government to reveal the data of their users all these issues paved the way for a new type of implementation of encryption known as endtoend encryption often abbreviated as eee the message to be sent is encrypted by the sender and is sent to the server which relays it to the receiver as it is since the keys used to encrypt and decrypt the data are available only to the users the server cannot read the messages sent through it this model quickly gained popularity and was implemented by many messaging applications the most notable being whatsapp signal telegram and wire in this project we are going to implement eee using python for encryption we intend to use the aes algorithm aes stands for advanced encryption standard which was introduced in  by the nits usa it was developed by vincent rijmen and joan daemen in response to the earlier broken algorithm des aes is a symmetric key encryption algorithm meaning that the same key is used for encryption as well as decryption of the messages this algorithm has three key lengths— and  bits whereas a single block size of  bits the version we are going to implement is  bits key size,"['advanced encryption standard' 'aes' 'aes algorithm' 'chatting services'
 'constant mass surveillance' 'cyber security' 'cyberattacks' 'dec'
 'endtoend encryption' 'illegal spying' 'joan da' 'messaging applications'
 'symmetric key encryption algorithm']"
doi:10.1007/978-3-031-16075-2_54,en,Commentary on Biological Assets Cataloging and AI in the Global South,OriginalPaper,"The Global South is rich in biodiversity, and with that richness of Biological Assets, the continued discovery of new agricultural products, pharmaceuticals, and other industrially beneficial bio-resources is possible. However, this biodiversity can also be a source of biologically dangerous materials. Key to gaining the ability to discover, sort, utilize, and properly evaluate these resources at pace with the Global North will require highly efficient means. This will likely rely on 4th Industrial Revolution technologies. One that is gaining traction is artificial intelligence. An under discussed topic is how the Global South is treating the intersection of their assets with AI, along with the capability to address this intersection. It is possible that vulnerabilities in cataloging endanger efforts which could obscure, misrepresent, or slow discovery and management of resources apparent. Herein, a commentary is provided on this potential, and possibly extant threat of academic distributed denial of service attacks (DDOS attacks), robbing the world of valuable insight and time in defending against novel threats.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']",the global south is rich in biodiversity and with that richness of biological assets the continued discovery of new agricultural products pharmaceuticals and other industrially beneficial bioresources is possible however this biodiversity can also be a source of biologically dangerous materials key to gaining the ability to discover sort utilize and properly evaluate these resources at pace with the global north will require highly efficient means this will likely rely on th industrial revolution technologies one that is gaining traction is artificial intelligence an under discussed topic is how the global south is treating the intersection of their assets with ai along with the capability to address this intersection it is possible that vulnerabilities in cataloging endanger efforts which could obscure misrepresent or slow discovery and management of resources apparent herein a commentary is provided on this potential and possibly extant threat of academic distributed denial of service attacks ddos attacks robbing the world of valuable insight and time in defending against novel threats,"['##anger efforts' 'academic distributed denial' 'artificial intelligence'
 'biodiversity' 'biological assets' 'ddos attacks' 'global south'
 'industrially beneficial bioresources'
 'new agricultural products pharmaceuticals' 'service attacks'
 'vulnerabilities']"
doi:10.1007/978-981-19-1142-2_71,en,"Correction to: T-Shaped MIMO Microstrip Patch Antenna for C-Band
Applications",CompoundObjectErratum,"Correction to: Chapter “T-Shaped MIMO Microstrip Patch Antenna for C-Band Applications” in: P. K. Singh et al. (eds.), Proceedings of Third International Conference on Computing, Communications, and Cyber-Security , Lecture Notes in Networks and Systems 421, https://doi.org/10.1007/978-981-19-1142-2_41","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Mobile and Network Security', 'Artificial Intelligence']",correction to: chapter tshaped mimo microstrip patch antenna for cband applications in: p k singh et al eds proceedings of third international conference on computing communications and cybersecurity  lecture notes in networks and systems  https:doiorg_,['##mo' '##strip' 'cband' 'cybersecurity']
doi:10.1007/978-3-031-16489-7_11,en,"Rethinking the US Strategic National Stockpile for Future Pandemics with Inventory, Capacity, and Capability",OriginalPaper,"The response to COVID-19 as a public health emergency raised questions about preparedness against future pandemics. The US Strategic National Stockpile (SNS) with medically critical items such as ventilators and personal protection equipment for major public health emergencies proved to be inadequate in the first half of 2020. We seek to address how governments or other disaster management organizations should modify their stockpile approach for a more robust response to disasters than was the case in 2020. To this end, we argue that a “strategic reserve” against rare public health emergencies must not only have inventory but also backup capacity and standby capability. With a highly skewed “demand” distribution reflecting a rarely occurring pandemic or other disasters, we present a three-tiered approach comprising stockpile inventory as the first tier, backup capacity as the second, and standby capability to manufacture as the third.","['Business and Management', 'Supply Chain Management', 'Risk Management', 'Operations Research/Decision Theory', 'Operations Management']",the response to covid as a public health emergency raised questions about preparedness against future pandemics the us strategic national stockpile sns with medically critical items such as ventilators and personal protection equipment for major public health emergencies proved to be inadequate in the first half of  we seek to address how governments or other disaster management organizations should modify their stockpile approach for a more robust response to disasters than was the case in  to this end we argue that a strategic reserve against rare public health emergencies must not only have inventory but also backup capacity and standby capability with a highly skewed demand distribution reflecting a rarely occurring pandemic or other disasters we present a threetiered approach comprising stockpile inventory as the first tier backup capacity as the second and standby capability to manufacture as the third,"['backup capacity' 'co' 'highly skewed demand distribution' 'inventory'
 'pandemics' 'personal protection equipment' 'public health emergency'
 'standby capability' 'stockpile inventory' 'us strategic national stock']"
doi:10.1007/978-981-19-6004-8_42,en,Multi-class IoT Botnet Attack Classification and Evaluation Using Various Classifiers and Validation Techniques,OriginalPaper,"The IoT security attacks are increasing because of the inefficiency of installed security mechanisms and growth in the industry. One of the prominent attacks is IoT botnet attacks (IBA). There are multiple types of botnet attacks. The detection of IBA will help to resolve the security breaches and limitations of the security mechanisms. The research work is the empirical evaluation of machine learning classifiers for multi-class classification of IBA with various cross-validation (CV) approaches. The occurrence of each class instance in the training phase makes a significant impact on model prediction. The participation of each class instance is ensured by CV techniques. The validation techniques used for performance evaluation are K-fold cross-validation (KCV) and stratified K-fold cross-validation (SKCV). Rather than doing the detection of IoT attacks on simulated or emulated data, the classifiers implement an experimental evaluation of real-time traffic data.","['Engineering', 'Computational Intelligence', 'Cognitive Psychology', 'Personality and Social Psychology', 'Cyber-physical systems, IoT', 'Professional Computing']",the iot security attacks are increasing because of the inefficiency of installed security mechanisms and growth in the industry one of the prominent attacks is iot botnet attacks iba there are multiple types of botnet attacks the detection of iba will help to resolve the security breaches and limitations of the security mechanisms the research work is the empirical evaluation of machine learning classifiers for multiclass classification of iba with various crossvalidation cv approaches the occurrence of each class instance in the training phase makes a significant impact on model prediction the participation of each class instance is ensured by cv techniques the validation techniques used for performance evaluation are kfold crossvalidation kcv and stratified kfold crossvalidation skcv rather than doing the detection of iot attacks on simulated or emulated data the classifiers implement an experimental evaluation of realtime traffic data,"['##a' 'botnet attacks' 'crossvalidation cv' 'iba'
 'installed security mechanisms' 'iot attacks' 'iot botnet attacks'
 'iot security attacks' 'kfold crossvalidation kcv'
 'machine learning classifiers' 'multiclass classification'
 'performance evaluation' 'realtime traffic data' 'security mechanisms'
 'skcv' 'stratified kfold crossvalidation' 'techniques']"
doi:10.1007/978-981-19-1412-6_1,en,IoT-Assisted Crop Monitoring Using Machine Learning Algorithms for Smart Farming,OriginalPaper,"Agriculture expansion is critical to the economic prosperity of any country. Agriculture employs more than 60% of the Indian population, either directly or indirectly. Nowadays, monitoring the crop is the challenging task in the world. In this article, data has been collected from various sensors to propose an IoT-assisted hybrid machine learning approach for obtaining an effective crop monitoring system. Crop monitoring system here means predicting as well as detecting diseases of crops. This study is about leveraging existing data and applying regression analysis, SVM, and decision tree to predict crop diseases in diverse crops such as rice, ragi, gram, potato, and onion. Among the applied methods, SVM outperforms regression, DT methods. The training and testing accuracy of Gram has 96.29% and 95.67%, respectively.","['Engineering', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence', 'Systems and Data Security']",agriculture expansion is critical to the economic prosperity of any country agriculture employs more than  of the indian population either directly or indirectly nowadays monitoring the crop is the challenging task in the world in this article data has been collected from various sensors to propose an iotassisted hybrid machine learning approach for obtaining an effective crop monitoring system crop monitoring system here means predicting as well as detecting diseases of crops this study is about leveraging existing data and applying regression analysis svm and decision tree to predict crop diseases in diverse crops such as rice ragi gram potato and onion among the applied methods svm outperforms regression dt methods the training and testing accuracy of gram has  and  respectively,"['crop monitoring' 'decision tree' 'diverse crops' 'dt methods'
 'indian population' 'iotassisted hybrid machine learning'
 'regression analysis' 'rice ragi gram potato' 'testing accuracy']"
doi:10.1007/978-981-19-2940-3_2,en,An Enhanced Model for Fake News Detection in Social Media Using Hybrid Text Representation,OriginalPaper,"In today’s digital age, the majority of people obtain their news via the Internet and social media. However, it is difficult to identify which sources are reliable and which are disseminating false information. So far, many models have been derived to detect fake news or misinformation from social media news using machine learning (ML) or deep learning (DL) techniques. This chapter aims to enhance the detection accuracy by representing the text of social media news in a hybrid format using Natural Language Processing (NLP) techniques. We model the input data of news text in a hybrid representation using TF-IDF with N -grams model combined with Latent Semantic Indexing. The main objective of the hybrid text representation is to represent news text by considering the three important factors of text, viz. the important words in the text, their sequence of occurrence, and their semantic meaning. We applied different ML and DL techniques for news classification and compared the performance of fake news detection models with and without hybrid text representation. The obtained results evidence that there is a significant improvement in detection accuracies when the news text is represented in a hybrid format as proposed in our approach.","['Computer Science', 'Artificial Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing', 'Sociology, general', 'Computational Intelligence', 'Machine Learning']",in todays digital age the majority of people obtain their news via the internet and social media however it is difficult to identify which sources are reliable and which are disseminating false information so far many models have been derived to detect fake news or misinformation from social media news using machine learning ml or deep learning dl techniques this chapter aims to enhance the detection accuracy by representing the text of social media news in a hybrid format using natural language processing nlp techniques we model the input data of news text in a hybrid representation using tfidf with n grams model combined with latent semantic indexing the main objective of the hybrid text representation is to represent news text by considering the three important factors of text viz the important words in the text their sequence of occurrence and their semantic meaning we applied different ml and dl techniques for news classification and compared the performance of fake news detection models with and without hybrid text representation the obtained results evidence that there is a significant improvement in detection accuracies when the news text is represented in a hybrid format as proposed in our approach,"['deep learning' 'digital age' 'dl techniques' 'fake news detection'
 'hybrid format' 'hybrid representation' 'hybrid text representation'
 'internet' 'latent semantic indexing' 'machine learning' 'ml'
 'n grams model' 'natural language processing' 'news classification'
 'news text' 'nlp techniques' 'social media' 'social media news']"
doi:10.1007/978-3-031-18311-9_5,en,Analysis and Improvement of Two Low-Cost Air Quality Sensor Measurements’ Uncertainty,OriginalPaper,"Measurements resulting from the operation of two different low-cost air quality monitoring devices (LCAQMD) are used as a basis for a data analytics and modelling procedure towards the improvement of the uncertainty of sensor readings. Α data processing method for missing value and outliers handling, followed by the implementation of computational intelligence-oriented algorithms aimed to the PM 10 modelling. Descriptive statistics and correlation coefficients are used for a primary evaluation of data analytics results, while modelling outcomes are compared with the aid of the relative expanded uncertainty, as well as via the model performance evaluation metrics, to determine the most efficient model. Results suggest that the advanced artificial neural network oriented computational intelligence algorithms, may lead to significant improvement of the performance of the two LCAQMD, this being applicable for a certain concentration range (18–65 μg/m 3 ), indicating that additional future work and more advanced computational techniques are required for further improvement of their performance.","['Business and Management', 'IT in Business', 'Environmental Management', 'Geotechnical Engineering & Applied Earth Sciences', 'Energy Policy, Economics and Management', 'Artificial Intelligence']",measurements resulting from the operation of two different lowcost air quality monitoring devices lcaqmd are used as a basis for a data analytics and modelling procedure towards the improvement of the uncertainty of sensor readings α data processing method for missing value and outliers handling followed by the implementation of computational intelligenceoriented algorithms aimed to the pm  modelling descriptive statistics and correlation coefficients are used for a primary evaluation of data analytics results while modelling outcomes are compared with the aid of the relative expanded uncertainty as well as via the model performance evaluation metrics to determine the most efficient model results suggest that the advanced artificial neural network oriented computational intelligence algorithms may lead to significant improvement of the performance of the two lcaqmd this being applicable for a certain concentration range – μgm   indicating that additional future work and more advanced computational techniques are required for further improvement of their performance,"['advanced artificial neural network oriented computational intelligence'
 'computational intelligenceoriented algorithms'
 'correlation coefficients' 'data analytics' 'data processing method'
 'descriptive statistics' 'lowcost air quality monitoring'
 'outliers handling' 'performance evaluation metrics' 'pm modelling'
 'relative expanded uncertainty' 'sensor readings' 'uncertainty']"
doi:10.1007/978-981-19-3804-7_7,en,Technology Readiness and Digital Transformation: A Case Study of Telework During COVID-19 Pandemic and Future Work in Vietnam,OriginalPaper,"The COVID-19 pandemic has highlighted how the adaptability to telework has become the key to resilience for businesses and workers. In this chapter, we study how organizations can implement telework effectively to both enhance organizational resilience and improve workers’ productivity and welfare. To that end, we conducted a self-administered survey in Vietnam with five-hundred and fifty-four employees across 52 companies based in Ho Chi Minh City and Ha Noi. The quantitative analysis is further supported by informal interviews with by mid-level managers and senior executives in the University of Hawaii—Shidler Vietnam EMBA program. We identify workers’ technology readiness as an important driver for the productivity telework in that technology readiness has a positive and statistically significant impact on working from home productivity. Furthermore, adequate equipment and training positively and significantly influenced working from home productivity. This increase in productivity leads to higher individual performance expectations and company performance. Given strong evidence presented in this study supporting telework, senior management and executives participated in the survey recommend digital transformation strategy to cope with the new normal must consider the following tasks: (1) Technical capacity enhancement; (2) Categorize employees into different groups; (3) Change the management mindset; (4) Build a corporate culture for telework; and (5) Organize periodic virtual events such as team building, and open forum.","['Business and Management', 'Business Information Systems', 'Computer Applications']",the covid pandemic has highlighted how the adaptability to telework has become the key to resilience for businesses and workers in this chapter we study how organizations can implement telework effectively to both enhance organizational resilience and improve workers productivity and welfare to that end we conducted a selfadministered survey in vietnam with fivehundred and fiftyfour employees across  companies based in ho chi minh city and ha noi the quantitative analysis is further supported by informal interviews with by midlevel managers and senior executives in the university of hawaii—shidler vietnam emba program we identify workers technology readiness as an important driver for the productivity telework in that technology readiness has a positive and statistically significant impact on working from home productivity furthermore adequate equipment and training positively and significantly influenced working from home productivity this increase in productivity leads to higher individual performance expectations and company performance given strong evidence presented in this study supporting telework senior management and executives participated in the survey recommend digital transformation strategy to cope with the new normal must consider the following tasks:  technical capacity enhancement;  categorize employees into different groups;  change the management mindset;  build a corporate culture for telework; and  organize periodic virtual events such as team building and open forum,"['businesses' 'company performance' 'corporate culture'
 'digital transformation strategy' 'fiftyfour employees'
 'higher individual performance expectations' 'ho chi minh city'
 'home productivity' 'management' 'management minds' 'midlevel managers'
 'open forum' 'organizational resilience' 'periodic virtual events'
 'productivity telework' 'quantitative' 'selfadministered survey' 'survey'
 'team building' 'technical capacity enhancement' 'technology readiness'
 'telework' 'welfare' 'workers' 'workers productivity']"
doi:10.1007/978-3-031-11170-9_7,en,The Use of Serious Games for Developing Social and Communication Skills in Children with Autism Spectrum Disorders—Review,OriginalPaper,"The rate of Autism Spectrum Disorder (ASD) diagnoses has peaked in recent years—2000 study found ASD birth-year prevalence of one in 150 eight-year-olds, or 0.67%—which at the time was considerably higher than previous findings. In 2021, the U.S. Centers for Disease Control issued alarming new data indicating that the rate of autism among American eight-year-old children had risen again, this time to 1 in 44, or about 2.3% (American Psychiatric Association in Diagnostic and statistical manual of mental disorders. Arlington [ 1 ]). Many studies prove the effectiveness and positive impact of using smart telephones, mobile apps, and computer games to practice skills as therapy for children with ASD (Meghan et al. in Pediatrics 141:335–345 [ 2 ]). This review summarizes some of the most interesting and accessible serious games described in the scientific literature and designed to improve the social and communication skills of infants and toddlers with ASD. Learning and playing games are fundamental to the development of children's social skills allowing them to form independent relationships with peers (Simonoff et al. in J Am Acad Child Adolesc Psychiatry 47(8):921–929 [ 3 ]). As autistic children often have difficulty with peer relationships (Gordon-Lipkin et al. in Pediatrics 141(4) [ 4 ]), developing game-based skills through computer-assisted solutions could be an essential tool for autistic children to improve their social performance. The results were identified through extensive literature search conducted in the Central and Eastern European Online Library (CEEOL), EBSCO: Academic Search Complete, EBSCO: eBook Academic Collection and ScienceDirect, Academic Search Complete, Health Source: Consumer Edition, ScienceDirect, Scopus, Web of Science and Wiley Online Library for a time period between 2006 and 2021 by using a combination of the following free-text terms: autism, ASD, social skills, serious games, computer games, education, communication, software, portable, computer-based. The search was limited to papers published in the English language. We finally highlight current common limitations and address new challenging research directions.","['Computer Science', 'Health Informatics', 'Artificial Intelligence']",the rate of autism spectrum disorder asd diagnoses has peaked in recent years— study found asd birthyear prevalence of one in  eightyearolds or —which at the time was considerably higher than previous findings in  the us centers for disease control issued alarming new data indicating that the rate of autism among american eightyearold children had risen again this time to  in  or about  american psychiatric association in diagnostic and statistical manual of mental disorders arlington [  ] many studies prove the effectiveness and positive impact of using smart telephones mobile apps and computer games to practice skills as therapy for children with asd meghan et al in pediatrics :– [  ] this review summarizes some of the most interesting and accessible serious games described in the scientific literature and designed to improve the social and communication skills of infants and toddlers with asd learning and playing games are fundamental to the development of childrens social skills allowing them to form independent relationships with peers simonoff et al in j am acad child adolesc psychiatry :– [  ] as autistic children often have difficulty with peer relationships gordonlipkin et al in pediatrics  [  ] developing gamebased skills through computerassisted solutions could be an essential tool for autistic children to improve their social performance the results were identified through extensive literature search conducted in the central and eastern european online library ceeol ebsco: academic search complete ebsco: ebook academic collection and sciencedirect academic search complete health source: consumer edition sciencedirect scopus web of science and wiley online library for a time period between  and  by using a combination of the following freetext terms: autism asd social skills serious games computer games education communication software portable computerbased the search was limited to papers published in the english language we finally highlight current common limitations and address new challenging research directions,"['##base' '##ct' 'academic search' 'adolesc psychiatry'
 'american eightyearold children' 'american psychiatric association' 'as'
 'asd diagnoses' 'autism' 'autism spectrum disorder' 'autistic children'
 'birthyear' 'childrens social skills' 'computer games'
 'computerassisted solutions' 'consumer edition sciencedirect scopus web'
 'disease control' 'eastern european online library'
 'ebook academic collection' 'english language'
 'extensive literature search' 'games' 'health' 'mental disorders'
 'mobile apps' 'portable computerbased' 'smart telephones' 'social'
 'statistical manual' 'wiley online library']"
doi:10.1007/978-3-031-16659-4_3,en,The OSCE ODIHR and Regional Organisations as Norm Entrepreneurs: The Case of Post-pandemic Kyrgyzstan,OriginalPaper,"The COVID-19 pandemic has intensified the illiberal trends already witnessed by experts and civil society in the OSCE region through increased corruption and lack of transparency in emergency response, as well as through abuses in terms of human rights and restricting civic participation. Building upon the existing literature on protective integration (Alexander Libman) and virtual regionalism (Roy Allison) in Central Asia, which argues that authoritarian leaders pursue various forms of regional cooperation in order to ensure regime survival, we intend to assess the place of the OSCE among the other regional organisations in which the Central Asian states are currently participating, as well as to evaluate how the OSCE Human Dimension has been transformed over the past few years. In this chapter, we intend to discuss the impact of the public health crisis on the democratic normative agenda. In this sense, we aim to analyse the OSCE-ODIHR Human Dimension agenda in Central Asia, specifically in Kyrgyzstan, during the COVID-19 pandemic, and the capacity of the OSCE to determine the respect for democratic standards in a contested area where multiple norm entrepreneurs are active.","['Political Science and International Relations', 'International Security Studies', 'Terrorism and Political Violence', 'Political Science', 'Development Studies', 'Comparative Politics']",the covid pandemic has intensified the illiberal trends already witnessed by experts and civil society in the osce region through increased corruption and lack of transparency in emergency response as well as through abuses in terms of human rights and restricting civic participation building upon the existing literature on protective integration alexander libman and virtual regionalism roy allison in central asia which argues that authoritarian leaders pursue various forms of regional cooperation in order to ensure regime survival we intend to assess the place of the osce among the other regional organisations in which the central asian states are currently participating as well as to evaluate how the osce human dimension has been transformed over the past few years in this chapter we intend to discuss the impact of the public health crisis on the democratic normative agenda in this sense we aim to analyse the osceodihr human dimension agenda in central asia specifically in kyrgyzstan during the covid pandemic and the capacity of the osce to determine the respect for democratic standards in a contested area where multiple norm entrepreneurs are active,"['central asia' 'central asian states' 'civic participation'
 'civil society' 'covid pandemic' 'democratic normative agenda'
 'democratic standards' 'emergency response' 'human dimension agenda'
 'illiberal trends' 'kyrgyzstan' 'osce human dimension' 'osce region'
 'protective integration' 'public health crisis' 'regime survival'
 'regional cooperation' 'transparency' 'virtual regionalism']"
doi:10.1007/978-3-031-15187-3_7,en,The Dark Side of Game Jams,OriginalPaper,"We have established that game jams are great—they’re great for building portfolios, team building and above all you get to make games! However, a number of issues can arise in running a jam, from small elements that can disrupt a jam to larger issues that are worth considering for their effects on games development as a wider field.","['Computer Science', 'Computers and Education', 'Game Development', 'Software Engineering/Programming and Operating Systems']",we have established that game jams are great—theyre great for building portfolios team building and above all you get to make games! however a number of issues can arise in running a jam from small elements that can disrupt a jam to larger issues that are worth considering for their effects on games development as a wider field,['game jams' 'games development']
doi:10.1007/978-981-16-9967-2_36,en,"Customer Perception, Expectation, and Experience Toward Services Provided by Public Sector Mutual Funds",OriginalPaper,"In recent years, mutual funds have gained popularity as a means of ensuring the financial security. Mutual funds have benefited families in capitalizing on India's wealth while also contributing to the country's economic record. As knowledge and understanding of mutual funds grow, most people are reaping the benefits of investing in them. This study is focused on the various customer perceptions, expectations, and experiences toward services provided by public sector mutual funds. This study mainly analyzed the main features and major factors affecting the public sector mutual fund’s customers’ experience, expectation, and their perception. A quantitative study was undertaken through a structured questionnaire to analyze major factors that attracted customers toward public sector mutual funds, and based on the analysis, it was found that customers are satisfied because they have got better responsiveness from public sector mutual funds to customer complaints. As part of the study, many customers’ opinions and reviews have been collected. This project will help public sector mutual funds to develop new strategies to create a more customer-friendly approach for increasing the sales and improving the customer satisfaction and their experience with public sector mutual funds.","['Computer Science', 'Computer Systems Organization and Communication Networks', 'Computational Intelligence', 'Artificial Intelligence', 'Wireless and Mobile Communication', 'Cyber-physical systems, IoT', 'Professional Computing']",in recent years mutual funds have gained popularity as a means of ensuring the financial security mutual funds have benefited families in capitalizing on indias wealth while also contributing to the countrys economic record as knowledge and understanding of mutual funds grow most people are reaping the benefits of investing in them this study is focused on the various customer perceptions expectations and experiences toward services provided by public sector mutual funds this study mainly analyzed the main features and major factors affecting the public sector mutual funds customers experience expectation and their perception a quantitative study was undertaken through a structured questionnaire to analyze major factors that attracted customers toward public sector mutual funds and based on the analysis it was found that customers are satisfied because they have got better responsiveness from public sector mutual funds to customer complaints as part of the study many customers opinions and reviews have been collected this project will help public sector mutual funds to develop new strategies to create a more customerfriendly approach for increasing the sales and improving the customer satisfaction and their experience with public sector mutual funds,"['##iendly approach' 'benefited families' 'customer complaints'
 'customer satisfaction' 'financial security' 'india' 'mutual funds'
 'public sector mutual funds' 'sales']"
doi:10.1007/978-981-19-4514-4_7,en,Autonomous Health and Assistive Rehabilitation and Safety Protection of Dynamic Machinery,OriginalPaper,"Artificial self-recovery technology can advance the struggle against faults to the design stage, and develop a new generation of autonomous health machines. Drawing lessons from the new concept of medical human body function “rehabilitation engineering and assistive technology”, the research and application of in-service equipment’s Recovery Assistive Engineering (RAE) and Recovery Assistive Technology Device (RATD) should be carried out. This chapter briefly introduces the engineering cases of the compressor unit and pipeline vibration fault tuning mass damping and the wholeness field dynamic balance assisted rehabilitation. With the advancement of source tracing diagnosis and risk assessment technology, the industrial dynamic machinery ESD overprotection and aero engine no any automatic speed reduction or emergency stop safety protection both should be changed.","['Engineering', 'Manufacturing, Machines, Tools, Processes', 'Vibration, Dynamical Systems, Control', 'Mechatronics']",artificial selfrecovery technology can advance the struggle against faults to the design stage and develop a new generation of autonomous health machines drawing lessons from the new concept of medical human body function rehabilitation engineering and assistive technology the research and application of inservice equipments recovery assistive engineering rae and recovery assistive technology device ratd should be carried out this chapter briefly introduces the engineering cases of the compressor unit and pipeline vibration fault tuning mass damping and the wholeness field dynamic balance assisted rehabilitation with the advancement of source tracing diagnosis and risk assessment technology the industrial dynamic machinery esd overprotection and aero engine no any automatic speed reduction or emergency stop safety protection both should be changed,"['aero engine' 'artificial selfrecovery technology'
 'automatic speed reduction' 'autonomous health machines'
 'compressor unit' 'emergency stop safety protection'
 'field dynamic balance assisted rehabilitation' 'inservice equipments'
 'medical human body function rehabilitation engineering' 'overprotection'
 'pipeline vibration fault tuning mass damping'
 'recovery assistive engineering' 'recovery assistive technology'
 'risk assessment' 'source tracing diagnosis']"
doi:10.1007/978-3-031-19904-2_3,en,Chinese Lecturers’ Pedagogical Position and Instructional Practice in EMI Teaching,OriginalPaper,"This Chapter reports the pedagogical alignment and instructional practices contributing to the Chinese lecturers’ EMI implementation as evidenced in this research data. It counters a predominance in the current literature highlighting EMI research on language with less concern on pedagogy. Evidence of the EMI lecturers’ actual classroom instructions and their pedagogical positions were collected and analyzed. Their instruction was identified as being on the continuum between expository and constructivist teaching, with more leaning towards an expository approach in their teaching. The data disclose that the reasons for this prevalence of expository teaching are based on the lecturers’ rational choice rather than any overall attribution to their educational culture. Perceiving undergraduate education as the foundational stage of tertiary education and their self-assessment of their role as the main knowledge resource contributed to their distinctive pedagogical view and instructional practices in EMI teaching.","['Education', 'Teaching and Teacher Education', 'Language Education', 'Curriculum Studies', 'International and Comparative Education']",this chapter reports the pedagogical alignment and instructional practices contributing to the chinese lecturers emi implementation as evidenced in this research data it counters a predominance in the current literature highlighting emi research on language with less concern on pedagogy evidence of the emi lecturers actual classroom instructions and their pedagogical positions were collected and analyzed their instruction was identified as being on the continuum between expository and constructivist teaching with more leaning towards an expository approach in their teaching the data disclose that the reasons for this prevalence of expository teaching are based on the lecturers rational choice rather than any overall attribution to their educational culture perceiving undergraduate education as the foundational stage of tertiary education and their selfassessment of their role as the main knowledge resource contributed to their distinctive pedagogical view and instructional practices in emi teaching,"['##ce' 'chinese lecturers' 'classroom instructions' 'educational culture'
 'emi implementation' 'expository teaching' 'instructional practices'
 'knowledge resource' 'pedagogical' 'pedagogical alignment'
 'pedagogical positions' 'pedagogy' 'tertiary education'
 'undergraduate education']"
doi:10.1007/978-3-031-13714-3_10,en,Population Management,OriginalPaper,"After having generated several solutions, we can seek to learn how to combine them. This chapter review techniques for generating new solution from existing ones and for managing a population of solution. The most popular method in this field is undoubtedly genetic algorithms. However, the latter are less advanced metaheuristics than memetic algorithms or scatter search. The path relinking technique is also part of this chapter. Finally, among the last metaheuristics invented, we find the particle swarm methods, which seem adapted to continuous optimization.","['Business and Management', 'Operations Research/Decision Theory', 'Optimization', 'Computational Mathematics and Numerical Analysis', 'Algorithms', 'Computational Science and Engineering', 'Artificial Intelligence']",after having generated several solutions we can seek to learn how to combine them this chapter review techniques for generating new solution from existing ones and for managing a population of solution the most popular method in this field is undoubtedly genetic algorithms however the latter are less advanced metaheuristics than memetic algorithms or scatter search the path relinking technique is also part of this chapter finally among the last metaheuristics invented we find the particle swarm methods which seem adapted to continuous optimization,"['##heuristics' 'continuous optimization' 'genetic algorithms'
 'last metaheuristics' 'memetic algorithms' 'particle swarm methods'
 'path relinking technique']"
doi:10.1007/978-981-19-3998-3_54,en,Bipartite Consensus for Discrete-Time Signed Networks Subject to Saturation Constraints,OriginalPaper,"The discrete-time bipartite consensus problem under signed network with saturation constraints is investigated. With the information of neighbors, a distributed control protocol is given. By the properties of the signed digraph, a model transformation is given. With the help of model transformation, the discrete bipartite consensus issue is converted into a discrete stability issue. By the Lyapunov stability theory, the discrete stability issues of the corresponding system are demonstrated. Through numerical simulation examples, we prove the validity of our results.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']",the discretetime bipartite consensus problem under signed network with saturation constraints is investigated with the information of neighbors a distributed control protocol is given by the properties of the signed digraph a model transformation is given with the help of model transformation the discrete bipartite consensus issue is converted into a discrete stability issue by the lyapunov stability theory the discrete stability issues of the corresponding system are demonstrated through numerical simulation examples we prove the validity of our results,"['discrete bipartite consensus' 'discrete stability issue'
 'discrete stability issues' 'discretetime bipartite consensus problem'
 'distributed control protocol' 'lyapunov stability theory'
 'model transformation' 'numerical simulation' 'saturation constraints'
 'signed digraph' 'signed network']"
doi:10.1007/978-981-16-2327-1_85-1,en,He ara e rua he whāinga kotahi: Walking Dual Pathways Toward Shared Goals in Initial Primary Sector Teacher Education,ReviewPaper,"What happens in teacher education when the sibling program of a long established and more institutionalized Initial Teacher Education (ITE) program has an opportunity to lead, challenge, and influence the processes of qualification redesign and development? What about when that sibling has emerged from indigenous worldviews and aspirations and begins to challenge its larger, more established sibling’s origins, firmly entrenched in a Western paradigm, higher education thinking, and practice? Can the balance of power and perspectives in an ITE program change? Can the institution change? And even, why should they, and how? Such are the questions addressed in this chapter written from the perspectives of teacher education colleagues who have recently collaborated over a program re-design project in Aotearoa, New Zealand, involving two programs of primary education sector ITE: a bicultural and a so-called mainstream program. Initiated by the promulgation of a new professional code and set of standards for teaching in Aotearoa, New Zealand, our collaborative autoethnographic account of teacher education development and change serves to illustrate how by listening to, learning from, and supporting an indigenous model of teacher education to flourish, the prospect of a more nuanced, locally relevant, and contemporary practice of teacher education serving a mainstream program approach, can promise change for all.","['Education', 'International and Comparative Education', 'Education, general']",what happens in teacher education when the sibling program of a long established and more institutionalized initial teacher education ite program has an opportunity to lead challenge and influence the processes of qualification redesign and development what about when that sibling has emerged from indigenous worldviews and aspirations and begins to challenge its larger more established siblings origins firmly entrenched in a western paradigm higher education thinking and practice can the balance of power and perspectives in an ite program change can the institution change and even why should they and how such are the questions addressed in this chapter written from the perspectives of teacher education colleagues who have recently collaborated over a program redesign project in aotearoa new zealand involving two programs of primary education sector ite: a bicultural and a socalled mainstream program initiated by the promulgation of a new professional code and set of standards for teaching in aotearoa new zealand our collaborative autoethnographic account of teacher education development and change serves to illustrate how by listening to learning from and supporting an indigenous model of teacher education to flourish the prospect of a more nuanced locally relevant and contemporary practice of teacher education serving a mainstream program approach can promise change for all,"['aotearoa' 'aotearoa new zealand' 'higher education' 'indigenous model'
 'indigenous worldviews' 'institutionalized initial teacher education'
 'ite program' 'ite program change' 'mainstream program'
 'primary education' 'program redesign project' 'qualification redesign'
 'siblings' 'teacher education' 'teacher education development']"
doi:10.1007/978-981-19-3951-8_50,en,The Effects of Feature Selection on the Forecast Accuracy of the South African Unemployment Rate,OriginalPaper,"The representation of macroeconomic data usually uses too many features, while only a few are relevant to the target. Forecasting using high-dimensional data without feature selection can be challenging for machine learning models. Thus, this study examines the effects of filter, wrapper, and embedded feature selection techniques on the forecast accuracy of the South African unemployment rate using data from the South African Reserve Bank. The experiments consisted of 15 feature selection techniques and three regression models. The Mean Absolute Percentage Error served as the evaluation metric. The filter, embedded, and wrapper methods, respectively, increased model performance by 41%, 32%, and 22% on average. Overall, feature selection methods offered a more accurate way to predict the South African unemployment rate with fewer features. Thus, it would be worthwhile for economic forecasters to consider incorporating these methods into future forecasts.","['Engineering', 'Computational Intelligence', 'Signal, Image and Speech Processing', 'Communications Engineering, Networks', 'Artificial Intelligence']",the representation of macroeconomic data usually uses too many features while only a few are relevant to the target forecasting using highdimensional data without feature selection can be challenging for machine learning models thus this study examines the effects of filter wrapper and embedded feature selection techniques on the forecast accuracy of the south african unemployment rate using data from the south african reserve bank the experiments consisted of  feature selection techniques and three regression models the mean absolute percentage error served as the evaluation metric the filter embedded and wrapper methods respectively increased model performance by   and  on average overall feature selection methods offered a more accurate way to predict the south african unemployment rate with fewer features thus it would be worthwhile for economic forecasters to consider incorporating these methods into future forecasts,"['absolute percentage error' 'embedded feature selection techniques'
 'evaluation metric' 'feature selection techniques' 'filter wrapper'
 'forecast accuracy' 'highdimensional data' 'machine learning models'
 'macroeconomic data' 'regression models'
 'south african unemployment rate']"
doi:10.1007/978-981-19-6068-0_41,en,A Comparative Analysis of Multivariate Statistical Time Series Models for Water Quality Forecasting of the River Ganga,OriginalPaper,"Water plays an important role in the livelihood of mankind. Hence, water that is used for agriculture, marine culture, human consumption, etc., should be in good condition to minimize the hazardous effect of water pollution on human health. Rapid unsustainable industrialization, improper huge waste disposal, excess amount fertilizer usage, etc., are responsible for the rapid deterioration of the water quality in rivers and other freshwater bodies. Manual continuous water quality measurement is risky, expensive, and time-consuming. Hence, it is essential to forecast the water quality using statistical time series models. In this paper, three widely used statistical multivariate techniques such as Vector Moving Average (VMA), Vector Auto Regression (VAR), and Vector Auto Regression Moving Average (VARMA), are investigated to forecast water quality parameters like Fecal Coliform (FC), Total Coliform (TC), Biological Oxygen Demand (BOD), Dissolved Oxygen (DO), and the associated Water Quality Index (WQI) of the Ganga River. Most of the previous methods worked on forecasting the future values based on past values of individual parameters without considering the interdependency among the water quality parameters. Here, correlation among each parameter is estimated. Subsequently, the future values of a parameter are estimated based on its previous values and the previous values of its correlated parameters. The proposed research work can help properly manage the water quality of the river Ganga by utilizing the forecasted results for the planning of the pollution control strategies. Finally, it helps improve the quality of human beings by minimizing the health issues caused by water pollution.","['Computer Science', 'Artificial Intelligence', 'Computational Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing']",water plays an important role in the livelihood of mankind hence water that is used for agriculture marine culture human consumption etc should be in good condition to minimize the hazardous effect of water pollution on human health rapid unsustainable industrialization improper huge waste disposal excess amount fertilizer usage etc are responsible for the rapid deterioration of the water quality in rivers and other freshwater bodies manual continuous water quality measurement is risky expensive and timeconsuming hence it is essential to forecast the water quality using statistical time series models in this paper three widely used statistical multivariate techniques such as vector moving average vma vector auto regression var and vector auto regression moving average varma are investigated to forecast water quality parameters like fecal coliform fc total coliform tc biological oxygen demand bod dissolved oxygen do and the associated water quality index wqi of the ganga river most of the previous methods worked on forecasting the future values based on past values of individual parameters without considering the interdependency among the water quality parameters here correlation among each parameter is estimated subsequently the future values of a parameter are estimated based on its previous values and the previous values of its correlated parameters the proposed research work can help properly manage the water quality of the river ganga by utilizing the forecasted results for the planning of the pollution control strategies finally it helps improve the quality of human beings by minimizing the health issues caused by water pollution,"['##cal coli' 'agriculture marine culture' 'auto' 'coliform'
 'continuous water quality' 'correlated' 'dissolved oxygen'
 'forecasted results' 'freshwater bodies' 'ganga river' 'health issues'
 'huge waste disposal excess amount fertilizer usage' 'human beings'
 'human consumption' 'human health' 'interdependency'
 'pollution control strategies' 'rapid deterioration'
 'rapid unsustainable industrialization'
 'statistical multivariate techniques' 'statistical time series models'
 'tc biological oxygen demand' 'vector auto regression'
 'vector moving average' 'water pollution' 'water quality'
 'water quality index' 'water quality parameters'
 'water quality parameters here correlation']"
doi:10.1007/978-3-031-12390-0_14,en,Functional Impairment of the Nervous System with Glycolipid Deficiencies,OriginalPaper,"Patients with nervous system disorders suffer from impaired cognitive, sensory and motor functions that greatly inconvenience their daily life and usually burdens their family and society. It is difficult to achieve functional recovery for the damaged central nervous system (CNS) because of its limited ability to regenerate. Glycosphingolipids (GSLs) are abundant in the CNS and are known to play essential roles in cell-cell recognition, adhesion, signal transduction, and cellular migration, that are crucial in all phases of neurogenesis. Despite intense investigation of CNS regeneration, the roles of GSLs in neural regeneration remain unclear. Here we focus on the respective potentials of glycolipids to promote regeneration and repair of the CNS. Mice lacking glucosylceramide, lactosylceramide or gangliosides show lethal phenotypes. More importantly, patients with ganglioside deficiencies exhibit severe clinical phenotypes. Further, neurodegenerative diseases and mental health disorders are associated with altered GSL expression. Accumulating studies demonstrate that GSLs not only delimit physical regions but also play central roles in the maintenance of the biological functions of neurons and glia. We anticipate that the ability of GSLs to modulate behavior of a variety of molecules will enable them to ameliorate biochemical and neurobiological defects in patients. The use of GSLs to treat such defects in the human CNS will be a paradigm-shift in approach since GSL-replacement therapy has not yet been achieved in this manner clinically.","['Biomedicine', 'Neurosciences', 'Neurobiology', 'Neurochemistry']",patients with nervous system disorders suffer from impaired cognitive sensory and motor functions that greatly inconvenience their daily life and usually burdens their family and society it is difficult to achieve functional recovery for the damaged central nervous system cns because of its limited ability to regenerate glycosphingolipids gsls are abundant in the cns and are known to play essential roles in cellcell recognition adhesion signal transduction and cellular migration that are crucial in all phases of neurogenesis despite intense investigation of cns regeneration the roles of gsls in neural regeneration remain unclear here we focus on the respective potentials of glycolipids to promote regeneration and repair of the cns mice lacking glucosylceramide lactosylceramide or gangliosides show lethal phenotypes more importantly patients with ganglioside deficiencies exhibit severe clinical phenotypes further neurodegenerative diseases and mental health disorders are associated with altered gsl expression accumulating studies demonstrate that gsls not only delimit physical regions but also play central roles in the maintenance of the biological functions of neurons and glia we anticipate that the ability of gsls to modulate behavior of a variety of molecules will enable them to ameliorate biochemical and neurobiological defects in patients the use of gsls to treat such defects in the human cns will be a paradigmshift in approach since gslreplacement therapy has not yet been achieved in this manner clinically,"['altered gsl expression' 'cellcell recognition adhesion signal trans'
 'cellular migration' 'functional recovery' 'ganglioside deficiencies'
 'human cn' 'impaired cognitive' 'inconvenience' 'maintenance'
 'mental health disorders' 'mice' 'nervous system disorders'
 'neural regeneration' 'patients' 'severe clinical phenotypes' 'therapy']"
doi:10.1007/s42757-022-0133-y,en,Assessment of simplified momentum equations for free surface flows through rigid porous media,"['OriginalPaper', 'Research Article']","In many applications, free surface flow through rigid porous media has to be modeled. Examples refer to coastal engineering applications as well as geotechnical or biomedical applications. Albeit the frequent applications, slight inconsistencies in the formulation of the governing equations can be found in the literature. The main goal of this paper is to identify these differences and provide a quantitative assessment of different approaches. Following a review of the different formulations, simulation results obtained from three alternative formulations are compared with experimental and numerical data. Results obtained by 2D and 3D test cases indicate that the predictive differences returned by the different formulations remain small for most applications, in particular for small porous Reynolds number Re P < 5000. Thus it seems justified to select a simplified formulation that supports an efficient algorithm and coding structure in a computational fluid dynamics environment. An estimated accuracy depending on the porous Reynolds number or the mean grain diameter is given for the simplified formulation.","['Engineering', 'Engineering Fluid Dynamics', 'Fluid- and Aerodynamics', 'Environmental Engineering/Biotechnology']",in many applications free surface flow through rigid porous media has to be modeled examples refer to coastal engineering applications as well as geotechnical or biomedical applications albeit the frequent applications slight inconsistencies in the formulation of the governing equations can be found in the literature the main goal of this paper is to identify these differences and provide a quantitative assessment of different approaches following a review of the different formulations simulation results obtained from three alternative formulations are compared with experimental and numerical data results obtained by d and d test cases indicate that the predictive differences returned by the different formulations remain small for most applications in particular for small porous reynolds number re p <  thus it seems justified to select a simplified formulation that supports an efficient algorithm and coding structure in a computational fluid dynamics environment an estimated accuracy depending on the porous reynolds number or the mean grain diameter is given for the simplified formulation,"['biomedical applications' 'coastal engineering applications'
 'computational fluid dynamics' 'estimated accuracy' 'free surface flow'
 'geotechnical' 'governing equations' 'inconsistencies'
 'mean grain diameter' 'numerical data' 'porous reynolds number'
 'predictive differences' 'rigid porous media']"
doi:10.1007/978-981-19-3575-6_71,en,Smart Congestion Control and Path Scheduling in MPTCP,OriginalPaper,"Featuring the recent rise of mobile technology, new devices with a variety of connection ports have become more popular. Multiple communication interfaces may now be usable over a single TCP connection thanks to the multi-path transmission control protocol (MPTCP), which was developed to speed up Internet use. There are three main design aims for the MPTCP congestion management algorithms: better performance, more fairness, and congestion balancing. MPTCP congestion control algorithms now in use cannot achieve these design goals. Due to its inability to leverage the network, an MPTCP congestion-control algorithm, such as OLIA, often results in poor performance. With the current Internet’s enormous volume of transient traffic, it is difficult to keep track of MPTCP congestion management techniques. MPTCP congestion control methods may benefit from being aware of current network delay conditions. There are various sub flows in an MPTCP connection, and the schedulers are employed to deal with this heterogeneity. MPTCP’s scheduler is an important part of the software. In this study, MPTCP congestion management and MPTCP schedulers are discussed.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']",featuring the recent rise of mobile technology new devices with a variety of connection ports have become more popular multiple communication interfaces may now be usable over a single tcp connection thanks to the multipath transmission control protocol mptcp which was developed to speed up internet use there are three main design aims for the mptcp congestion management algorithms: better performance more fairness and congestion balancing mptcp congestion control algorithms now in use cannot achieve these design goals due to its inability to leverage the network an mptcp congestioncontrol algorithm such as olia often results in poor performance with the current internets enormous volume of transient traffic it is difficult to keep track of mptcp congestion management techniques mptcp congestion control methods may benefit from being aware of current network delay conditions there are various sub flows in an mptcp connection and the schedulers are employed to deal with this heterogeneity mptcps scheduler is an important part of the software in this study mptcp congestion management and mptcp schedulers are discussed,"['##p connection' 'communication interfaces' 'congestion balancing'
 'congestion control' 'congestion control algorithms'
 'congestion management' 'congestion management algorithms' 'fairness'
 'heterogeneity mptcps scheduler' 'internet use' 'mptcp'
 'mptcp congestion management' 'mptcp congestioncontrol algorithm'
 'mptcp schedulers' 'multipath transmission control protocol' 'olia often'
 'transient traffic']"
doi:10.1007/978-981-19-7648-3_14,en,Introduction of Cooperative Resource and Information Sharing,OriginalPaper,"Recently, the Internet of Things (IoT) enabled 6G networks have penetrated many aspects of the physical world to realize different applications. Resulting from ubiquitous connections of 6G, data traffic from these applications is experiencing unprecedented increases. In addition, these applications generate, exchange, aggregate, and analyze a vast amount of security-critical and privacy-sensitive data, which makes them attractive targets of attacks.","['Computer Science', 'Computer Systems Organization and Communication Networks', 'Communications Engineering, Networks', 'Wireless and Mobile Communication']",recently the internet of things iot enabled g networks have penetrated many aspects of the physical world to realize different applications resulting from ubiquitous connections of g data traffic from these applications is experiencing unprecedented increases in addition these applications generate exchange aggregate and analyze a vast amount of securitycritical and privacysensitive data which makes them attractive targets of attacks,"['##sitive' 'g data traffic' 'g networks' 'securitycritical'
 'things iot enabled' 'ubiquitous connections']"
doi:10.1007/978-3-031-20601-6_55,en,Energy Efficiency Routing Algorithms in IoT: A Survey,OriginalPaper,"Internet of Things (IoT) is a new paradigm. IoT consists of a complex network of smart devices that frequently exchange data over the Internet. The aim of IoT is to make everything in our world under control and also keeping them up-to-date about the state of the things. IoT devices sense the environment and send the obtained information to the Internet cloud without the necessity of human-to-human or human-to-machine connection. Wireless sensors have limited energy resources due to the use of batteries to supply energy, and since it is usually not possible to replace the batteries of these sensors. In addition, the lifespan of the Wireless Sensor Network (WSN) is limited and short. Therefore, reducing the energy consumption of sensors in IoT networks for increasing network lifespan is one of the fundamental challenges and issues in these networks. The literature included here provides an overview of some of the most current research methodologies about the most popular protocols. Also, this paper identifies the major Machine learning (ML) models and bio-inspired algorithms for reducing energy consumption in IoT and a discussion on the evaluation of their effectiveness in energy consumption prediction and expanding network life.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']",internet of things iot is a new paradigm iot consists of a complex network of smart devices that frequently exchange data over the internet the aim of iot is to make everything in our world under control and also keeping them uptodate about the state of the things iot devices sense the environment and send the obtained information to the internet cloud without the necessity of humantohuman or humantomachine connection wireless sensors have limited energy resources due to the use of batteries to supply energy and since it is usually not possible to replace the batteries of these sensors in addition the lifespan of the wireless sensor network wsn is limited and short therefore reducing the energy consumption of sensors in iot networks for increasing network lifespan is one of the fundamental challenges and issues in these networks the literature included here provides an overview of some of the most current research methodologies about the most popular protocols also this paper identifies the major machine learning ml models and bioinspired algorithms for reducing energy consumption in iot and a discussion on the evaluation of their effectiveness in energy consumption prediction and expanding network life,"['bioinspired algorithms' 'energy consumption'
 'energy consumption prediction' 'humantohuman'
 'humantomachine connection wireless' 'internet' 'internet cloud'
 'internet of things iot' 'iot' 'iot networks' 'machine learning ml'
 'network life' 'protocols' 'smart devices' 'things iot devices'
 'wireless']"
doi:10.1007/978-3-031-08011-1_24,en,Hybrid Offline/Online Optimization for Energy Management via Reinforcement Learning,OriginalPaper,"Constrained decision problems in the real world are subject to uncertainty. If predictive information about the stochastic elements is available offline, recent works have shown that it is possible to rely on an (expensive) parameter tuning phase to improve the behavior of a simple online solver so that it roughly matches the solution quality of an anticipative approach but maintains its original efficiency. Here, we start from a state-of-the-art offline/online optimization method that relies on optimality conditions to inject knowledge of a (convex) online approach into an offline solver used for parameter tuning. We then propose to replace the offline step with (Deep) Reinforcement Learning (RL) approaches, which results in a simpler integration scheme with a higher potential for generalization. We introduce two hybrid methods that combine both learning and optimization: the first optimizes all the parameters at once, whereas the second exploits the sequential nature of the online problem via the Markov Decision Process framework. In a case study in energy management, we show the effectiveness of our hybrid approaches, w.r.t. the state-of-the-art and pure RL methods. The combination proves capable of faster convergence and naturally handles constraint satisfaction.","['Computer Science', 'Mathematics of Computing', 'Artificial Intelligence', 'Theory of Computation', 'Information Systems and Communication Service', 'Computer Systems Organization and Communication Networks']",constrained decision problems in the real world are subject to uncertainty if predictive information about the stochastic elements is available offline recent works have shown that it is possible to rely on an expensive parameter tuning phase to improve the behavior of a simple online solver so that it roughly matches the solution quality of an anticipative approach but maintains its original efficiency here we start from a stateoftheart offlineonline optimization method that relies on optimality conditions to inject knowledge of a convex online approach into an offline solver used for parameter tuning we then propose to replace the offline step with deep reinforcement learning rl approaches which results in a simpler integration scheme with a higher potential for generalization we introduce two hybrid methods that combine both learning and optimization: the first optimizes all the parameters at once whereas the second exploits the sequential nature of the online problem via the markov decision process framework in a case study in energy management we show the effectiveness of our hybrid approaches wrt the stateoftheart and pure rl methods the combination proves capable of faster convergence and naturally handles constraint satisfaction,"['##oft' 'constrained decision problems' 'constraint satisfaction'
 'convergence' 'convex online approach' 'deep reinforcement learning'
 'energy management' 'higher potential'
 'markov decision process framework' 'online solver'
 'optimality conditions' 'pure rl methods' 'solution quality'
 'stateoftheart offlineonline optimization' 'stochastic elements']"
doi:10.1007/978-3-031-08084-5_14,en,Stakeholders of Yogyakarta Special Region and the Way They Manage Privilege Fund,OriginalPaper,"This study aims to analyze the role of stakeholders in the Special Region of Yogyakarta, which consists of the palace and the Pakualaman, Kaprajan (local government and district/city government), Campus, Village, and Community. This study also analyzes how the stakeholders manage and understand the Yogyakarta privilege fund. This research uses the descriptive analysis qualitative method. Determination of the sample is done by sampling technique, Clustered random sampling. The number of samples in this survey is 462 respondents with a ±5% margin error at the 95% confidence level. The data collection method was that the selected respondents were interviewed face-to-face using a questionnaire by interviewers who had been trained. The results of this study provide evaluations and recommendations for stakeholders in optimizing the management of Yogyakarta’s privileged funds. This study provides a mapping of the management and performance of stakeholders in the Special Region of Yogyakarta.","['Engineering', 'Mathematical and Computational Engineering', 'Business Mathematics', 'Data Engineering']",this study aims to analyze the role of stakeholders in the special region of yogyakarta which consists of the palace and the pakualaman kaprajan local government and districtcity government campus village and community this study also analyzes how the stakeholders manage and understand the yogyakarta privilege fund this research uses the descriptive analysis qualitative method determination of the sample is done by sampling technique clustered random sampling the number of samples in this survey is  respondents with a ± margin error at the  confidence level the data collection method was that the selected respondents were interviewed facetoface using a questionnaire by interviewers who had been trained the results of this study provide evaluations and recommendations for stakeholders in optimizing the management of yogyakartas privileged funds this study provides a mapping of the management and performance of stakeholders in the special region of yogyakarta,"['clustered random sampling' 'descriptive analysis'
 'districtcity government campus village' 'government'
 'pakualaman kaprajan' 'qualitative method' 'questionnaire'
 'sampling technique' 'stakeholders' 'yogyakarta'
 'yogyakarta privilege fund' 'yogyakartas' '± margin error']"
doi:10.1007/978-3-031-17258-8_12,en,Innovation and Marketplace: A Vision for the European Language Grid,OriginalPaper,"This chapter provides a comprehensive overview of innovation and the ELG marketplace as core elements for the generation of value and the creation of an active, attractive and vibrant community surrounding the European Language Grid. Innovation is an essential element in making ELG a credible and sustainable undertaking. However, it does not happen by itself nor materialise in a vacuum. Consequently, ELG provides a habitat for various kinds of innovation and a home for the necessary community to put innovation into action. The marketplace is essential for attracting participants supplying and demanding services, resources, components and technologies on a European scale. Innovation and marketplace – as well as the overall business model – are tightly connected and need to be developed and managed in a joint manner. Clearly, this is not a one-off activity, but rather needs to be carried out continuously and extend into the future. ELG is designed and created to promote the excellence and growth of the European LT market, creating new jobs and business opportunities and supporting European digital sovereignty. Encompassing a wide array of technologies and resources for many languages spoken across Europe and in neighbouring regions, it contributes to the Multilingual Digital Single Market as a cross-European driver for innovation.","['Computer Science', 'Natural Language Processing (NLP)', 'Computational Linguistics', 'Artificial Intelligence', 'Knowledge based Systems', 'Computer Applications', 'Computer Science, general']",this chapter provides a comprehensive overview of innovation and the elg marketplace as core elements for the generation of value and the creation of an active attractive and vibrant community surrounding the european language grid innovation is an essential element in making elg a credible and sustainable undertaking however it does not happen by itself nor materialise in a vacuum consequently elg provides a habitat for various kinds of innovation and a home for the necessary community to put innovation into action the marketplace is essential for attracting participants supplying and demanding services resources components and technologies on a european scale innovation and marketplace – as well as the overall business model – are tightly connected and need to be developed and managed in a joint manner clearly this is not a oneoff activity but rather needs to be carried out continuously and extend into the future elg is designed and created to promote the excellence and growth of the european lt market creating new jobs and business opportunities and supporting european digital sovereignty encompassing a wide array of technologies and resources for many languages spoken across europe and in neighbouring regions it contributes to the multilingual digital single market as a crosseuropean driver for innovation,"['business model' 'business opportunities' 'crosseuropean driver'
 'european digital sovereignty' 'european language grid innovation'
 'european lt market' 'european scale innovation' 'innovation'
 'multilingual digital single market' 'resources' 'services resources']"
doi:10.1007/978-981-19-7100-6_14,en,Impact of Anthropocene on the Fluvial Sediment Supply: The Mahanadi River Basin Perspective,OriginalPaper,"The Mahanadi River basin is the third biggest in central India and the longest in the state of Odisha. The peninsular river basin has a significant history of watershed land use changes and human disturbances in the channel. The Mahanadi Delta, located on India’s east coast, is a hybrid delta formed by water, suspended and bed sediments, and minerals from a web of distributaries of the Mahanadi River system. The current state of research on the quantification of river sediment supply and its connection to human catchment disturbances is discussed in this chapter, with an emphasis on the physical characteristics of the river basin. Nonparametric time series assessment methods are used to examine the annual runoff and suspended sediment characteristics of the gauging stations of the basin. The function of various attributes influencing runoff and suspended sediment dynamics of the gauging stations is also investigated. The average correlation between the discharge and suspended sediment load (SSL) is studied using sediment rating curves (SRC). Also, the role of differential supply of sediments from the watershed is characterized using the hysteresis analysis of suspended sediments. The development of the Mahanadi coastline subjected to the regulated sediment supply from the catchment in terms of land loss and gain is evaluated using geospatial data. The statistics of hydrological data reveal a large seasonal variance, with the monsoon being the most dominant. The annual SSL distributions are more irregular and non-normal relative to yearly runoff. The investigation of hysteresis loops revealed that the supply of sediments also significantly affected the transport capacity of all the channels within the basin. A substantial loss in SSL is evident throughout the majority of the stations in comparison to a negligible change in water outflow. Besides, 81% of the stations show a 2-year periodicity in runoff and SSL. Also, the flow of SSL to the ocean has fallen nearly three times more than the annual runoff, which is alarming. It, therefore, shows the strong impact of artificial force relative to natural variations. The statistical estimates for seashore morphological changes on a volumetric basis show that coastal landscapes prone to erosion are susceptible. The rating parameters vary inversely due to intense human-induced activities throughout the catchment. The rise in withdrawal over time for non-monsoon irrigation and hydropower generation is observed from the release of water from the reservoirs. The demand for thermal power stations has increased fourfold in the recent decade, significantly increasing water utilization. Overall, large impoundments, excessive water distribution across multiple business sectors, and varying watershed soil management efforts are highlighted as critical anthropogenic attributes impacting the decline in catchment sediment transport and eventually causing the delta to retreat. Further studies in the basin should focus on the impact of future land use on the sediment budget of the Mahanadi delta. This study aims to shed light on the dynamics of runoff and suspended sediment load over the past five decades and to fill in shortcomings about the evolving nature of rivers in the Mahanadi River basin.","['Life Sciences', 'Ecosystems', 'Ecology']",the mahanadi river basin is the third biggest in central india and the longest in the state of odisha the peninsular river basin has a significant history of watershed land use changes and human disturbances in the channel the mahanadi delta located on indias east coast is a hybrid delta formed by water suspended and bed sediments and minerals from a web of distributaries of the mahanadi river system the current state of research on the quantification of river sediment supply and its connection to human catchment disturbances is discussed in this chapter with an emphasis on the physical characteristics of the river basin nonparametric time series assessment methods are used to examine the annual runoff and suspended sediment characteristics of the gauging stations of the basin the function of various attributes influencing runoff and suspended sediment dynamics of the gauging stations is also investigated the average correlation between the discharge and suspended sediment load ssl is studied using sediment rating curves src also the role of differential supply of sediments from the watershed is characterized using the hysteresis analysis of suspended sediments the development of the mahanadi coastline subjected to the regulated sediment supply from the catchment in terms of land loss and gain is evaluated using geospatial data the statistics of hydrological data reveal a large seasonal variance with the monsoon being the most dominant the annual ssl distributions are more irregular and nonnormal relative to yearly runoff the investigation of hysteresis loops revealed that the supply of sediments also significantly affected the transport capacity of all the channels within the basin a substantial loss in ssl is evident throughout the majority of the stations in comparison to a negligible change in water outflow besides  of the stations show a year periodicity in runoff and ssl also the flow of ssl to the ocean has fallen nearly three times more than the annual runoff which is alarming it therefore shows the strong impact of artificial force relative to natural variations the statistical estimates for seashore morphological changes on a volumetric basis show that coastal landscapes prone to erosion are susceptible the rating parameters vary inversely due to intense humaninduced activities throughout the catchment the rise in withdrawal over time for nonmonsoon irrigation and hydropower generation is observed from the release of water from the reservoirs the demand for thermal power stations has increased fourfold in the recent decade significantly increasing water utilization overall large impoundments excessive water distribution across multiple business sectors and varying watershed soil management efforts are highlighted as critical anthropogenic attributes impacting the decline in catchment sediment transport and eventually causing the delta to retreat further studies in the basin should focus on the impact of future land use on the sediment budget of the mahanadi delta this study aims to shed light on the dynamics of runoff and suspended sediment load over the past five decades and to fill in shortcomings about the evolving nature of rivers in the mahanadi river basin,"['##ound' '##st' 'activities' 'anthropogenic attributes' 'artificial'
 'attributes influencing runoff' 'capacity' 'central india' 'changes'
 'decade' 'demand' 'differential supply' 'erosion' 'geospatial' 'human'
 'human catchment disturbances' 'human disturbances' 'hysteresis'
 'hysteresis analysis' 'indias east coast' 'land loss'
 'mahanadi coastline' 'mahanadi delta' 'mahanadi river basin'
 'nonmonsoon irrigation' 'nonparametric time series' 'odisha'
 'peninsular river basin' 'rating' 'river basin' 'river sediment supply'
 'runoff' 'seasonal variance' 'ssl distributions' 'statistical estimates'
 'supply' 'suspended sediment characteristics'
 'suspended sediment dynamics' 'suspended sediment load'
 'suspended sediments' 'volumetric basis' 'water' 'water distribution'
 'watershed land use changes']"
doi:10.1007/978-981-19-1142-2_1,en,Enhancement of Energy Efficiency in Wireless Sensor Network with Mobile Sink: A Survey,OriginalPaper,"The energy consumed by any activity taking place in WSN should be controlled such that limited energy in terms of battery backup remains focus throughout. In the case of dying nodes, battery discharge may cause the network to get disconnected. WSN design issues, e.g., location of sensor nodes, scheduling activities, routes of data flow, mobile sink route, should be dealt with keeping energy limitation in mind. The sensor nodes sense the data from the area of concern and communicate the same to the sink for processing. Sensor nodes deployed in various application areas have limited memory, computational power, and battery backup. There is no defined topology of such network and frequently changing environment, very less amount of battery, and limited storage capability of the nodes. It is essential that each node in the network has knowledge about the routing path to the sink which is energy efficient. Since random placement of the nodes restrains coders from presuming routing table data at the sensor nodes, numerous methods have been suggested to create a dynamic path up to sink. Numerous researches are performed for WSN using the mobile sink. Most of the research activities focused on energy conservation in the background while proposing approaches for clustering, data flow paths, trajectory design, etc. In the WSN with a mobile sink, the trajectory of the sink node plays a vital role. Designing of trajectory is an NP-hard problem. With the use of nature-inspired techniques, e.g., particle swarm optimization (PSO), genetic algorithm (GA), etc., can be used for generating a nearly optimal paths for the mobile sink. In this current article, the authors make attempt to present the summary of various strategies for energy-efficient data collection methodology and energy-efficient path planning of mobile sink in wireless sensor networks.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Mobile and Network Security', 'Artificial Intelligence']",the energy consumed by any activity taking place in wsn should be controlled such that limited energy in terms of battery backup remains focus throughout in the case of dying nodes battery discharge may cause the network to get disconnected wsn design issues eg location of sensor nodes scheduling activities routes of data flow mobile sink route should be dealt with keeping energy limitation in mind the sensor nodes sense the data from the area of concern and communicate the same to the sink for processing sensor nodes deployed in various application areas have limited memory computational power and battery backup there is no defined topology of such network and frequently changing environment very less amount of battery and limited storage capability of the nodes it is essential that each node in the network has knowledge about the routing path to the sink which is energy efficient since random placement of the nodes restrains coders from presuming routing table data at the sensor nodes numerous methods have been suggested to create a dynamic path up to sink numerous researches are performed for wsn using the mobile sink most of the research activities focused on energy conservation in the background while proposing approaches for clustering data flow paths trajectory design etc in the wsn with a mobile sink the trajectory of the sink node plays a vital role designing of trajectory is an nphard problem with the use of natureinspired techniques eg particle swarm optimization pso genetic algorithm ga etc can be used for generating a nearly optimal paths for the mobile sink in this current article the authors make attempt to present the summary of various strategies for energyefficient data collection methodology and energyefficient path planning of mobile sink in wireless sensor networks,"['battery backup' 'battery discharge' 'clustering'
 'data flow paths trajectory design' 'dynamic path'
 'eg particle swarm optimization pso genetic algorithm'
 'energy conservation' 'energyefficient data collection methodology'
 'energyefficient path planning' 'flow' 'limited storage capability'
 'mobile sink' 'mobile sink route' 'mobile sink the trajectory'
 'nphard problem' 'random placement' 'research activities' 'routing path'
 'routing table data' 'scheduling activities' 'wireless sensor networks']"
doi:10.1007/978-981-19-3148-2_39,en,Detecting Hate Speech in Arabic Tweets During COVID-19 Using Machine Learning Approaches,OriginalPaper,"Content on the Web is increasing day by day, especially on social media, as all users can express their opinions freely and without restrictions. Accordingly, many negative activities have appeared, such as abusive language, racism, and hate speech. Hate speech is one of the negative social media manifestations that require tools to be detected. In this paper, we try to detect hate speech in Arabic tweets published during the COVID-19 pandemic. We compiled a dataset during the pandemic period from January 31 to March 6, 2021. We used a set of machine learning models, namely support vector machine (SVM), random forest (RF), logistic regression (DT), decision tree, AdaBoost, k -nearest neighbors (KNN), and Gaussian naïve Bayes (GNB). For feature extraction, we used TF-IDF, where we trained the dataset in three types: unigram, bigram, and trigram. The best results were achieved by LR, RF, and SVM, with an accuracy of 90.8% for LR.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Data Structures and Information Theory']",content on the web is increasing day by day especially on social media as all users can express their opinions freely and without restrictions accordingly many negative activities have appeared such as abusive language racism and hate speech hate speech is one of the negative social media manifestations that require tools to be detected in this paper we try to detect hate speech in arabic tweets published during the covid pandemic we compiled a dataset during the pandemic period from january  to march   we used a set of machine learning models namely support vector machine svm random forest rf logistic regression dt decision tree adaboost k nearest neighbors knn and gaussian naïve bayes gnb for feature extraction we used tfidf where we trained the dataset in three types: unigram bigram and trigram the best results were achieved by lr rf and svm with an accuracy of  for lr,"['abusive language racism' 'arabic tweets' 'feature extraction' 'gnb'
 'hate speech' 'hate speech hate speech' 'machine learning models'
 'negative social media manifestations' 'random forest'
 'rf logistic regression dt decision tree adaboost k nearest neighbors knn'
 'social media']"
doi:10.1007/978-3-031-16926-7_18,en,Suitable Evaluation Models for Resilient-Sustainable-Inclusive Cities,OriginalPaper,"The sustainability has a central role in the urban policies of cities in Europe and worldwide. The United Nations, Europe and Member States suggest guidelines to make cities and human settlements more inclusive, safe, resilient and sustainable. The European Commission upholds initiatives aimed at improving the city’s resilient status and the migrants’ inclusiveness by means of Eco-Resilient Projects for the economic development, community's well-being and safeguarding of urban ecosystems. To reduce the theoretical-practical gap between ERP planning and design in terms of “Resilient-Sustainable-Inclusive” (RSI) city development, the present contribution outlines a framework to arrange the main scientific contributions concerning the sustainability in its three components, and the evaluation of projects in view of urban resilience and social inclusiveness. The proposed framework is aimed at the identification of the most suitable evaluation models based on RSI principles. Following the systematic review, the main methods and evaluation tools are outlined and discussed with respect to resilience, inclusiveness and sustainability targets.","['Economics', 'Urban Economics', 'Real Estate Management', 'Urban Studies/Sociology']",the sustainability has a central role in the urban policies of cities in europe and worldwide the united nations europe and member states suggest guidelines to make cities and human settlements more inclusive safe resilient and sustainable the european commission upholds initiatives aimed at improving the citys resilient status and the migrants inclusiveness by means of ecoresilient projects for the economic development communitys wellbeing and safeguarding of urban ecosystems to reduce the theoreticalpractical gap between erp planning and design in terms of resilientsustainableinclusive rsi city development the present contribution outlines a framework to arrange the main scientific contributions concerning the sustainability in its three components and the evaluation of projects in view of urban resilience and social inclusiveness the proposed framework is aimed at the identification of the most suitable evaluation models based on rsi principles following the systematic review the main methods and evaluation tools are outlined and discussed with respect to resilience inclusiveness and sustainability targets,"['economic development community' 'erp planning' 'european commission'
 'human settlements' 'migrants' 'resilience inclusiveness'
 'sustainability' 'united nations' 'urban ecosystems' 'urban resilience']"
doi:10.1007/978-981-19-2535-1_17,en,Security Issues in the Routing Protocols of Flying Ad Hoc Networks,OriginalPaper,"Flying ad hoc networks (FANETs) empowered with unmanned aerial vehicles (UAVs) are a subset of mobile ad hoc networks (MANET). In a FANET, a swarm of mini-UAVs is deployed as per application scenarios to communicate critical data to ground control stations (GCSs). Owing to their distinct characteristics and unique features, FANETs pose numerous challenges making secure communication a cumbersome task. Security issues in FANETs may exist either from intrinsic design flaws or due to any extrinsic attacks performed by an attacker . Before designing the secure routing protocols, all existing security issues related to FANETs must be explored in detail. This paper explores security attacks feasible on FANETs’ routing protocols that may occur either due to network design flaws or perpetrated by a malicious attacker to gain unauthorized access to the network. The potential countermeasures against the possible routing attacks are also highlighted.","['Engineering', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing', 'Machine Learning', 'Artificial Intelligence']",flying ad hoc networks fanets empowered with unmanned aerial vehicles uavs are a subset of mobile ad hoc networks manet in a fanet a swarm of miniuavs is deployed as per application scenarios to communicate critical data to ground control stations gcss owing to their distinct characteristics and unique features fanets pose numerous challenges making secure communication a cumbersome task security issues in fanets may exist either from intrinsic design flaws or due to any extrinsic attacks performed by an attacker  before designing the secure routing protocols all existing security issues related to fanets must be explored in detail this paper explores security attacks feasible on fanets routing protocols that may occur either due to network design flaws or perpetrated by a malicious attacker to gain unauthorized access to the network the potential countermeasures against the possible routing attacks are also highlighted,"['counterme' 'critical data' 'extrinsic attacks'
 'fanets routing protocols' 'flying ad hoc networks fanets' 'gcss'
 'ground' 'malicious attacker' 'miniuavs' 'mobile ad hoc networks'
 'network design flaws' 'routing attacks' 'secure routing protocols'
 'security attacks' 'unmanned aerial vehicles']"
doi:10.1007/978-3-031-19467-2_2,en,Marine Solid Pollution—From Macroplastics to Nanoplastics,OriginalPaper,"It is not surprising that we are interested in plastics as one of the most prominent polluting agents of the twenty-first century. We have gone from producing less than 10 million tons in the 1960s to more than 300 million in the 2010s. That plastic has had time to distribute itself, fragment and enter food chains of the oceans. Studies related to the three phenomena are now one of the main objectives of various research projects and groups around the planet. The first is understanding how fragmentation is increasing the volume of macro and microplastics, how they are dispersed at the oceanic and local level, and what their chemical characteristics are. In line with these observations and quantifications, we have to understand what influence they have on organisms and how we can reduce their concentration. For example, the displacements of macroplastics are modeled relative to their dispersion according to global and local currents, giving importance to the phenomena of fouling and fragmentation, as well as understanding how the creation of microplastics is heterogeneous according to latitude, water temperatures or seasonal conditions. One of the biggest problems is, without a doubt, the chemical, morphological and size classification of plastics, especially micro and nanoplastics. This topic is crucial, as is the standardization of the measures that we consider to classify them in one way or another. This topic has been largely discussed during the last decade, and in this chapter there are cues to understand that the consensus is very close. Other issues are still pending in the complex agenda of the understanding of these pollutants. For example, the adherence of certain types of elements such as heavy metals is a relevant issue on which much information is lacking. But it is not the only knowledge gap that we have. Dynamics in the water column and in the sediment is also a main issue, since this sediment is a sink for microplastics and nanoplastics that is continually disturbed by organisms from the meiofauna. Some of these microplastics become airborne, and their range from likely emission sources is still poorly understood. The understanding of these fluxes from the land-river to the sediments passing through the water column is one of the main challenges to solve the problems derived from the presence of such macro, micro and nano items. Marine organisms are the ones that, apparently, are the most affected by this increase in solid contamination, especially microplastics. Today they are found at any latitude, from the poles to the equator, even in places as surprising as sea ice or abyssal depths. In fact, microplastics are found in very remote places, interfering with the diet of various planktonic and benthic organisms. There are many questions to be resolved, among others, how temperature affects the retention of microplastics in organisms, or which are the most vulnerable species. And we have to understand one important issue: many of those marine organisms affected by micro and nano plastics are part of our diet. Therefore, understanding the rate of transmission in food chains in general and in our consumption in particular is a major issue. That is why we looked for solutions, such as the use of bioremediators (active suspension feeders such as sponges, sea squirts, etc.) in areas where the abundance of microplastics is especially high. Bacteria are also beginning to be used as active decomposers of microplastics, a solution that could help eliminate a large amount of this material about which we still have too many knowledge gaps regarding the health of ecosystems and our own health. The synergy of efforts to understand all these different variables is crucial. During the next decade we do have to solve this plastic problem, with coordination, standardization and the application of different tools to execute the solutions of different associated problems.","['Earth Sciences', 'Oceanography', 'Sustainable Development', 'Water, general', 'Environmental Health']",it is not surprising that we are interested in plastics as one of the most prominent polluting agents of the twentyfirst century we have gone from producing less than  million tons in the s to more than  million in the s that plastic has had time to distribute itself fragment and enter food chains of the oceans studies related to the three phenomena are now one of the main objectives of various research projects and groups around the planet the first is understanding how fragmentation is increasing the volume of macro and microplastics how they are dispersed at the oceanic and local level and what their chemical characteristics are in line with these observations and quantifications we have to understand what influence they have on organisms and how we can reduce their concentration for example the displacements of macroplastics are modeled relative to their dispersion according to global and local currents giving importance to the phenomena of fouling and fragmentation as well as understanding how the creation of microplastics is heterogeneous according to latitude water temperatures or seasonal conditions one of the biggest problems is without a doubt the chemical morphological and size classification of plastics especially micro and nanoplastics this topic is crucial as is the standardization of the measures that we consider to classify them in one way or another this topic has been largely discussed during the last decade and in this chapter there are cues to understand that the consensus is very close other issues are still pending in the complex agenda of the understanding of these pollutants for example the adherence of certain types of elements such as heavy metals is a relevant issue on which much information is lacking but it is not the only knowledge gap that we have dynamics in the water column and in the sediment is also a main issue since this sediment is a sink for microplastics and nanoplastics that is continually disturbed by organisms from the meiofauna some of these microplastics become airborne and their range from likely emission sources is still poorly understood the understanding of these fluxes from the landriver to the sediments passing through the water column is one of the main challenges to solve the problems derived from the presence of such macro micro and nano items marine organisms are the ones that apparently are the most affected by this increase in solid contamination especially microplastics today they are found at any latitude from the poles to the equator even in places as surprising as sea ice or abyssal depths in fact microplastics are found in very remote places interfering with the diet of various planktonic and benthic organisms there are many questions to be resolved among others how temperature affects the retention of microplastics in organisms or which are the most vulnerable species and we have to understand one important issue: many of those marine organisms affected by micro and nano plastics are part of our diet therefore understanding the rate of transmission in food chains in general and in our consumption in particular is a major issue that is why we looked for solutions such as the use of bioremediators active suspension feeders such as sponges sea squirts etc in areas where the abundance of microplastics is especially high bacteria are also beginning to be used as active decomposers of microplastics a solution that could help eliminate a large amount of this material about which we still have too many knowledge gaps regarding the health of ecosystems and our own health the synergy of efforts to understand all these different variables is crucial during the next decade we do have to solve this plastic problem with coordination standardization and the application of different tools to execute the solutions of different associated problems,"['##fication' '##ing' 'chemical characteristics' 'emission sources'
 'food chains' 'knowledge gap' 'local currents' 'macro micro'
 'macroplastics' 'marine organisms' 'meiofauna' 'metals' 'microplastics'
 'organisms' 'places' 'plastics' 'sea ice' 'seasonal conditions'
 'standardization' 'water column' 'water temperatures']"
doi:10.1007/978-3-031-16075-2_43,en,Ambient Intelligence Security Checks: Identifying Integrity Vulnerabilities in Industry Scripts,OriginalPaper,"Organizations, small offices, and home offices are deploying ambient intelligent systems at an unprecedented rate. These systems can interface with automation and data science scripts for many different reasons. Scripts can be written in many different languages and may unknowingly include deprecated or vulnerable code. Static analysis has been increasingly adopted and developed to identify software vulnerabilities with trends towards security detections. Tools can assist in identifying faults in programs during different development phases of the secure Software Development Lifecycle (sSDLC); and, can thus be employed on the source, intermediate, and executable codes to identify different (security) concern categories. This research identifies both static analysis tools as well as a category of integrity risks useful to adopt for more secure scripting of PowerShell scripts. The research also builds foundational knowledge for extending future analyses of further language-specific integrity concerns as well as other security concerns in scripting languages.","['Engineering', 'Computational Intelligence', 'Control, Robotics, Mechatronics', 'Artificial Intelligence']",organizations small offices and home offices are deploying ambient intelligent systems at an unprecedented rate these systems can interface with automation and data science scripts for many different reasons scripts can be written in many different languages and may unknowingly include deprecated or vulnerable code static analysis has been increasingly adopted and developed to identify software vulnerabilities with trends towards security detections tools can assist in identifying faults in programs during different development phases of the secure software development lifecycle ssdlc; and can thus be employed on the source intermediate and executable codes to identify different security concern categories this research identifies both static analysis tools as well as a category of integrity risks useful to adopt for more secure scripting of powershell scripts the research also builds foundational knowledge for extending future analyses of further languagespecific integrity concerns as well as other security concerns in scripting languages,"['ambient intelligent systems' 'data science scripts' 'executable codes'
 'integrity risks' 'powershell scripts' 'reasons scripts'
 'scripting languages' 'secure scripting'
 'secure software development lifecycle ssdlc'
 'security concern categories' 'security concerns' 'security detections'
 'software vulnerabilities' 'static analysis tools'
 'vulnerable code static analysis']"
doi:10.1007/978-981-19-1610-6_4,en,Enterprise Architecture Quality Assessment,OriginalPaper,"The enterprise architecture (EA) assessment can be provided in different ways. In general, the EA assessment supports information communication technology (ICT) implementation. Beyond that, business organization stakeholders have an opportunity to monitor effectiveness and efficiency of business processes. They can modify the business structure, increase the business innovativeness, and ensure business strategy realization. Nowadays, EA stakeholders establish their own methodologies for EA quality assessment. This paper includes analyzes of the architecture frameworks, assessment models, and standards. This article aims to answer the question, if the design science research (DSR) paradigm is useful for EA quality assessment. Hence, this paper includes a proposal of new approach to EA quality assessment, based on emphasizing the relevance and rigor as key concepts.","['Engineering', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing', 'Computational Intelligence', 'Artificial Intelligence']",the enterprise architecture ea assessment can be provided in different ways in general the ea assessment supports information communication technology ict implementation beyond that business organization stakeholders have an opportunity to monitor effectiveness and efficiency of business processes they can modify the business structure increase the business innovativeness and ensure business strategy realization nowadays ea stakeholders establish their own methodologies for ea quality assessment this paper includes analyzes of the architecture frameworks assessment models and standards this article aims to answer the question if the design science research dsr paradigm is useful for ea quality assessment hence this paper includes a proposal of new approach to ea quality assessment based on emphasizing the relevance and rigor as key concepts,"['business organization' 'business strategy realization' 'ea assessment'
 'ea quality assessment' 'enterprise architecture' 'ict implementation'
 'information communication technology' 'innovative' 'relevance' 'rigor']"
doi:10.1007/978-981-19-7648-3_12,en,Priority-Aware Computational Resource Allocation,OriginalPaper,"Vehicular fog computing (VFC) has been expected as a promising scheme that can increase the computational capability of vehicles without relying on servers. Comparing with accessing the remote cloud, VFC is suitable for delay-sensitive tasks because of its low-latency vehicle-to-vehicle (V2V) transmission. However, due to the dynamic vehicular environment, how to motivate vehicles to share their idle computing resource while simultaneously evaluating the service availability of vehicles in terms of vehicle mobility and vehicular computational capability in heterogeneous vehicular networks is a main challenge. Meanwhile, tasks with different priorities of a vehicle should be processed with different efficiencies. In this work, we propose a task offloading scheme in the context of VFC, where vehicles are incentivized to share their idle computing resource by dynamic pricing, which comprehensively considers the mobility of vehicles, the task priority, and the service availability of vehicles. Given that the policy of task offloading depends on the state of the dynamic vehicular environment, we formulate the task offloading problem as a Markov decision process (MDP) aiming at maximizing the mean latency-aware utility of tasks in a period. To solve this problem, we develop a soft actor-critic (SAC) based deep reinforcement learning (DRL) algorithm for the sake of maximizing both the expected reward and the entropy of policy. Finally, extensive simulation results validate the effectiveness and superiority of our proposed scheme benchmarked with traditional algorithms.","['Computer Science', 'Computer Systems Organization and Communication Networks', 'Communications Engineering, Networks', 'Wireless and Mobile Communication']",vehicular fog computing vfc has been expected as a promising scheme that can increase the computational capability of vehicles without relying on servers comparing with accessing the remote cloud vfc is suitable for delaysensitive tasks because of its lowlatency vehicletovehicle vv transmission however due to the dynamic vehicular environment how to motivate vehicles to share their idle computing resource while simultaneously evaluating the service availability of vehicles in terms of vehicle mobility and vehicular computational capability in heterogeneous vehicular networks is a main challenge meanwhile tasks with different priorities of a vehicle should be processed with different efficiencies in this work we propose a task offloading scheme in the context of vfc where vehicles are incentivized to share their idle computing resource by dynamic pricing which comprehensively considers the mobility of vehicles the task priority and the service availability of vehicles given that the policy of task offloading depends on the state of the dynamic vehicular environment we formulate the task offloading problem as a markov decision process mdp aiming at maximizing the mean latencyaware utility of tasks in a period to solve this problem we develop a soft actorcritic sac based deep reinforcement learning drl algorithm for the sake of maximizing both the expected reward and the entropy of policy finally extensive simulation results validate the effectiveness and superiority of our proposed scheme benchmarked with traditional algorithms,"['actorcritic sac based' 'availability'
 'deep reinforcement learning drl algorithm' 'delaysensitive tasks'
 'dynamic pricing' 'dynamic vehicular environment'
 'heterogeneous vehicular networks' 'idle computing resource'
 'latencyaware utility' 'lowlatency vehicletovehicle vv transmission'
 'markov decision process mdp' 'mean' 'mobility' 'simulation results'
 'task offloading' 'task offloading problem' 'task priority'
 'vehicle mobility' 'vehicular computational capability'
 'vehicular fog computing']"
doi:10.1007/978-981-19-3998-3_17,en,Stability Analysis of Distributed Optimization for Multi-agent Systems Under Time-Varying Digraphs,OriginalPaper,"This paper investigates a distributed convex optimization problem for multi-agent systems over time-varying directed communication topologies. To explore this problem, the differential inclusion strategy is used to model the time-varying situation, and the average dwell-time automaton and the time-ratio monitor are utilized to constrain the switching law. Ground on these constraints and using the Lyapunov stability analysis method, our proposed algorithm converges exponentially to the optimal solution over time-varying digraphs. Finally, some simulation results are reported to illustrate the proposed algorithm.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Multiagent Systems', 'Systems Theory, Control']",this paper investigates a distributed convex optimization problem for multiagent systems over timevarying directed communication topologies to explore this problem the differential inclusion strategy is used to model the timevarying situation and the average dwelltime automaton and the timeratio monitor are utilized to constrain the switching law ground on these constraints and using the lyapunov stability analysis method our proposed algorithm converges exponentially to the optimal solution over timevarying digraphs finally some simulation results are reported to illustrate the proposed algorithm,"['average dwelltime automaton' 'differential inclusion strategy'
 'directed communication topologies'
 'distributed convex optimization problem' 'lyapunov stability analysis'
 'multiagent systems' 'switching law' 'timeratio monitor' 'timevarying'
 'timevarying digraphs']"
doi:10.1007/978-3-031-17746-0_1,en,Innovation in Digital Era: Transforming Trucking Industry for Operational Efficiency Through Digital Transformation,OriginalPaper,"The purpose of current study is to understand trucking industry and challenges associated with its operation and transform trucking industry through Digital Transformation taking help from Digital India Program started by Government of India to enhance digital transformation given its impact on operation efficiency of various businesses in general and trucking industry in particular with special reference to its operational efficiency. Having look at current scenario of trucking industry with reference to nature of operation, ownership profile, areas of operation, regulatory and legislative measures relating to trucking industry, enroute operation challenges, higher operating cost and delays in operation, and many more are not allowing the trucking industry to enjoy economies of scale with special reference to small operators. Thus, in other words, the study found that trucking operation has numerous challenges which hampers the growth of the sector as observed during conduct of the study. However, through penetration of technology via digital transformation in trucking segment especially with reference to its operation in particular we can provide some good relief and can transform the trucking sector into most appropriate segment from viability of operation i.e. operational efficiency. The major implication of the study is that the result is based on limited data and information due to Covid-19 pandemic (Second Wave). Nevertheless, this can form basis to understand the process of digital transformation and its application to transform trucking operation to solve its operational issue and many more. The utility of the study can be derived from the point that this paper is one of the few studies conducted recently that provides insight into process of transforming trucking industry through digital transformation and possible economic benefits derived from digital transformation.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Business Information Systems']",the purpose of current study is to understand trucking industry and challenges associated with its operation and transform trucking industry through digital transformation taking help from digital india program started by government of india to enhance digital transformation given its impact on operation efficiency of various businesses in general and trucking industry in particular with special reference to its operational efficiency having look at current scenario of trucking industry with reference to nature of operation ownership profile areas of operation regulatory and legislative measures relating to trucking industry enroute operation challenges higher operating cost and delays in operation and many more are not allowing the trucking industry to enjoy economies of scale with special reference to small operators thus in other words the study found that trucking operation has numerous challenges which hampers the growth of the sector as observed during conduct of the study however through penetration of technology via digital transformation in trucking segment especially with reference to its operation in particular we can provide some good relief and can transform the trucking sector into most appropriate segment from viability of operation ie operational efficiency the major implication of the study is that the result is based on limited data and information due to covid pandemic second wave nevertheless this can form basis to understand the process of digital transformation and its application to transform trucking operation to solve its operational issue and many more the utility of the study can be derived from the point that this paper is one of the few studies conducted recently that provides insight into process of transforming trucking industry through digital transformation and possible economic benefits derived from digital transformation,"['digital' 'digital india' 'digital transformation' 'economic'
 'ie operational efficiency' 'india' 'legislative measures'
 'operational efficiency' 'transform trucking industry'
 'trucking industry' 'trucking operation' 'trucking sector'
 'trucking segment']"
doi:10.1007/s00521-021-06738-5,en,Pipeline risk big data intelligent decision-making system based on machine learning and situation awareness,"['OriginalPaper', 'S.I: LSNC & OUAI']","Underground pipelines are an indispensable part of urban public facilities. However, the frequent occurrence of pipeline accidents in recent years has not only brought great inconvenience to people’s lives, but also affected people’s lives and property safety to a certain extent. Therefore, timely treatment and treatment are very important. Preventing sudden underground pipeline accidents plays an important role in improving urban livability. This article studies pipeline risk big data intelligent decision-making systems based on machine learning and situational awareness. In this paper, by analyzing the application scope of gas leakage and diffusion models under different modes, leakage, diffusion, fire and explosion models are determined, and a combined model framework of leakage accident consequence system analysis is formed. The system uses the pipeline failure probability model and the pipeline failure consequence analysis model to determine the pipeline failure probability, the probability and the consequences of each accident; it uses the spatial analysis ability of GIS technology to determine the accident impact area and displays the impact area in graphics form. Through the effect verification of the test set, the prediction result of the SVR model based on the grid search parameter, the relative percentage error of the predicted value of each sample and the true value fluctuate is in the range of 4%-36%, and the amplitude is not very large. Most of the error values are approximately 13.56% of the MAPE value. The results show that the optimization method using grid search parameters can have better prediction performances.","['Computer Science', 'Artificial Intelligence', 'Data Mining and Knowledge Discovery', 'Probability and Statistics in Computer Science', 'Computational Science and Engineering', 'Image Processing and Computer Vision', 'Computational Biology/Bioinformatics']",underground pipelines are an indispensable part of urban public facilities however the frequent occurrence of pipeline accidents in recent years has not only brought great inconvenience to peoples lives but also affected peoples lives and property safety to a certain extent therefore timely treatment and treatment are very important preventing sudden underground pipeline accidents plays an important role in improving urban livability this article studies pipeline risk big data intelligent decisionmaking systems based on machine learning and situational awareness in this paper by analyzing the application scope of gas leakage and diffusion models under different modes leakage diffusion fire and explosion models are determined and a combined model framework of leakage accident consequence system analysis is formed the system uses the pipeline failure probability model and the pipeline failure consequence analysis model to determine the pipeline failure probability the probability and the consequences of each accident; it uses the spatial analysis ability of gis technology to determine the accident impact area and displays the impact area in graphics form through the effect verification of the test set the prediction result of the svr model based on the grid search parameter the relative percentage error of the predicted value of each sample and the true value fluctuate is in the range of  and the amplitude is not very large most of the error values are approximately  of the mape value the results show that the optimization method using grid search parameters can have better prediction performances,"['accident impact' 'diffusion models' 'explosion models' 'gas leakage'
 'gis' 'grid' 'grid search' 'leakage accident consequence system analysis'
 'machine learning' 'modes leakage diffusion' 'pipeline accidents'
 'pipeline failure consequence analysis model'
 'pipeline failure probability' 'pipeline risk' 'predicted value'
 'property safety' 'search parameter' 'situational awareness'
 'spatial analysis' 'sudden underground pipeline accidents' 'svr model'
 'underground pipelines' 'urban livability' 'urban public facilities']"
doi:10.1007/978-3-031-15951-0_9,en,The Metaverse and the Real-World Universe,OriginalPaper,"Metaverse is undoubtedly a hot word in industry and academia since 2021, and has become a hot new concept in the global technology field recently. At the beginning of 2021, the pre-IPO campaign of the game company Roblox and Epic Games’ investment of $1 billion to create a “metaverse” made the concept of “metaverse” popular. Especially after the Facebook company in the United States changed its name to Meta [ 1 ], the Metaverse was instantly popular all over the world.","['Computer Science', 'Artificial Intelligence', 'Engineering/Technology Education', 'Computer Science, general']",metaverse is undoubtedly a hot word in industry and academia since  and has become a hot new concept in the global technology field recently at the beginning of  the preipo campaign of the game company roblox and epic games investment of $ billion to create a metaverse made the concept of metaverse popular especially after the facebook company in the united states changed its name to meta [  ] the metaverse was instantly popular all over the world,"['academia' 'company' 'epic games investment' 'facebook company' 'meta'
 'metaverse' 'preipo' 'roblox' 'united states']"
doi:10.1007/978-3-031-15168-2_9,en,Transformer-Based Deep Reinforcement Learning in VizDoom,OriginalPaper,"Transformers is a novel neural network architecture that is successfully used in natural language processing tasks and is starting to be used in other areas such as video processing and image processing. However, transformers are yet to be studied in different aspects of reinforcement learning scenarios. In this work we combine transformer architectures with reinforcement learning and train them in the VizDoom game environment, producing agents that play better in comparison to traditional neural network architectures.","['Computer Science', 'Data Mining and Knowledge Discovery', 'Artificial Intelligence', 'Information Systems Applications (incl. Internet)', 'Database Management', 'Computer Appl. in Social and Behavioral Sciences', 'Computer Imaging, Vision, Pattern Recognition and Graphics']",transformers is a novel neural network architecture that is successfully used in natural language processing tasks and is starting to be used in other areas such as video processing and image processing however transformers are yet to be studied in different aspects of reinforcement learning scenarios in this work we combine transformer architectures with reinforcement learning and train them in the vizdoom game environment producing agents that play better in comparison to traditional neural network architectures,"['image processing' 'natural language processing' 'reinforcement learning'
 'transformer' 'video processing' 'vizdoom game environment']"
doi:10.1007/978-981-19-3571-8_40,en,Cluster-Based Energy-Efficient Routing in Internet of Things,OriginalPaper,"Lot of improvements are taking place in the communication technology. The networks are becoming ubiquitous and pervasive. Devices connecting to the internet are increasing tremendously due to the inception of Internet of things (IoT) in the current technology domain, and this count is going to become very huge in the upcoming future. Majority of these devices are low power battery operated. These devices need to handle their energy efficiently while doing the communication with the rest of the neighboring devices. The adopted approach in this paper deals with such devices and their energy usage. This approach has used dragonfly algorithm for the selection of cluster heads. It changes the selection of cluster heads over the period of time regularly so that the usage of energy will be balanced across the network efficiently. The selection of cluster heads is done based on the specially designed fitness function. At the end, the experimental outcomes prove the outperformance of the proposed model over the conventional approaches.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Communications Engineering, Networks', 'Cyber-physical systems, IoT', 'Professional Computing']",lot of improvements are taking place in the communication technology the networks are becoming ubiquitous and pervasive devices connecting to the internet are increasing tremendously due to the inception of internet of things iot in the current technology domain and this count is going to become very huge in the upcoming future majority of these devices are low power battery operated these devices need to handle their energy efficiently while doing the communication with the rest of the neighboring devices the adopted approach in this paper deals with such devices and their energy usage this approach has used dragonfly algorithm for the selection of cluster heads it changes the selection of cluster heads over the period of time regularly so that the usage of energy will be balanced across the network efficiently the selection of cluster heads is done based on the specially designed fitness function at the end the experimental outcomes prove the outperformance of the proposed model over the conventional approaches,"['##t' 'cluster heads' 'communication technology' 'dragonfly algorithm'
 'fitness function' 'internet' 'pervasive devices']"
doi:10.1007/978-3-031-04524-0_13,en,Investigating Role of IoT in the Development of Smart Application for Security Enhancement,OriginalPaper,"IoT solutions enable customers to automate, analyze, and integrate their systems to a greater extent. They broaden the breadth and accuracy of these fields. The Internet of Things includes sensors, networks, and robotics, and it employs both old and new technology. The Internet of Things makes use of software breakthroughs, lower hardware costs, and a contemporary approach to technology (IoT). However, there have been several types of research in the field of IoT where the smart application is built. This research has focused on IoT-based smart applications that could be used for security enhancement in industries as well as homes. In another word, its research has introduced smart applications to maintain security from threats such as theft, fire, and other unexpected events that may result in financial loss.","['Engineering', 'Cyber-physical systems, IoT', 'Communications Engineering, Networks', 'Computer Communication Networks']",iot solutions enable customers to automate analyze and integrate their systems to a greater extent they broaden the breadth and accuracy of these fields the internet of things includes sensors networks and robotics and it employs both old and new technology the internet of things makes use of software breakthroughs lower hardware costs and a contemporary approach to technology iot however there have been several types of research in the field of iot where the smart application is built this research has focused on iotbased smart applications that could be used for security enhancement in industries as well as homes in another word its research has introduced smart applications to maintain security from threats such as theft fire and other unexpected events that may result in financial loss,"['customers' 'financial loss' 'fire' 'hardware costs' 'iot' 'iotbased'
 'security' 'security enhancement' 'sensors networks' 'smart application'
 'smart applications' 'unexpected events']"
doi:10.1007/978-3-031-17040-9_7,en,Dignity,OriginalPaper,"Dignity is a very prominent concept in human rights Human rights instruments, in particular constitutions. It is also a concept that has many critics, including those who argue that it is useless in ethical debates. How useful or not dignity can be in artificial intelligence Artificial intelligence (AI) ethics discussions is the question of this chapter. Is it a conversation stopper, or can it help explain or even resolve some of the ethical dilemmas related to AI? The three cases in this chapter deal with groundless dismissal by an automated system, sex robots Sex robots and care robots Care robots . The conclusion argues that it makes perfect sense for human rights Human rights proponents to treat dignity as a prime value, which takes precedence over others in the case of extreme dignity violations such as torture, human trafficking, slavery Slavery and reproductive manipulation Manipulation . However, in AI Artificial intelligence ethics debates, it is better seen as an equal among equals, so that the full spectrum of potential benefits and harms Harm are considered for AI technologies using all relevant ethical values.","['Philosophy', 'Engineering Ethics', 'Artificial Intelligence', 'Philosophy of Technology', 'Computers and Society']",dignity is a very prominent concept in human rights human rights instruments in particular constitutions it is also a concept that has many critics including those who argue that it is useless in ethical debates how useful or not dignity can be in artificial intelligence artificial intelligence ai ethics discussions is the question of this chapter is it a conversation stopper or can it help explain or even resolve some of the ethical dilemmas related to ai the three cases in this chapter deal with groundless dismissal by an automated system sex robots sex robots and care robots care robots  the conclusion argues that it makes perfect sense for human rights human rights proponents to treat dignity as a prime value which takes precedence over others in the case of extreme dignity violations such as torture human trafficking slavery slavery and reproductive manipulation manipulation  however in ai artificial intelligence ethics debates it is better seen as an equal among equals so that the full spectrum of potential benefits and harms harm are considered for ai technologies using all relevant ethical values,"['##s' 'ai' 'ai ethics discussions' 'ai technologies'
 'artificial intelligence' 'artificial intelligence ethics'
 'automated system sex robots sex robots' 'care robots care robots'
 'conversation stopper' 'ethical debates' 'ethical dilemmas'
 'ethical values' 'extreme dignity violations' 'groundless dismissal'
 'human rights human rights instruments'
 'human rights human rights proponents'
 'reproductive manipulation manipulation'
 'torture human trafficking slavery slavery']"
doi:10.1007/978-3-031-14859-0_23,en,Population-Based Methods to Reduce the Colors of an Image,OriginalPaper,"The color quantization problem consists of reducing the number of different colors used to represent an image. Although current devices can render images with many different colors, this is not necessary for many image processing applications. On the contrary, many of these processes require as an initial step to reduce the number of colors in the image. This work describes several color quantization methods based on the use of populations of individuals that collaborate in the resolution of a complex problem. These methods mimic the social behavior observed in various types of animals. Each of the individuals is only capable of performing very simple operations, but when a group of individuals is considered they can perform complex tasks. This solution approach is interesting because it has been shown to yield better quality images than many of the classic color reduction methods. This document briefly describes some of the most interesting methods and shows computational results of their application.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']",the color quantization problem consists of reducing the number of different colors used to represent an image although current devices can render images with many different colors this is not necessary for many image processing applications on the contrary many of these processes require as an initial step to reduce the number of colors in the image this work describes several color quantization methods based on the use of populations of individuals that collaborate in the resolution of a complex problem these methods mimic the social behavior observed in various types of animals each of the individuals is only capable of performing very simple operations but when a group of individuals is considered they can perform complex tasks this solution approach is interesting because it has been shown to yield better quality images than many of the classic color reduction methods this document briefly describes some of the most interesting methods and shows computational results of their application,"['color quantization' 'color quantization problem' 'color reduction'
 'image processing' 'social behavior']"
doi:10.1007/978-981-19-3035-5_41,en,The Application of Cyclostationary Malware Detection Using Boruta and PCA,OriginalPaper,"An analysis of cyclostationary malware is introduced. The most important cyclostationary features used for network intrusion detection systems (NIDS) are then detected with a feature extractor algorithm, such as Boruta and principal component analysis (PCA). These feature patterns are classified to determine the most cyclostationary ones. In particular, this article shows the relevance of detecting cyclostationary malware for a NIDS by using legacy datasets, such as the KDD99 and NSL-KDD. This research has also used the UGRansome cyclostationary dataset intended to support research on anomaly detection. This dataset is subdivided into normal and abnormal classes of network threats. A comparative analysis based on random forest and support vector machine algorithms is undertaken, and the performance of Boruta and PCA was also evaluated. The research suggests the utilization of PCA in terms of extracting cyclostationary network feature patterns as a viable proposition compared to Boruta. The Internet Protocol (IP), malware financial damages, class C of IP addresses, and signature malware were also found to be the most cyclostationary feature pattern. The UGRansome dataset outperformed the KDD99 and NSL-KDD in terms of detecting signature malware with an accuracy of 99% using the random forest algorithm, while the support vector machine achieved 68%. This research proposes the UGRansome as a suitable choice to reduce the computational time of cyclostationary malware classification. Lastly, the research suggests the utilization of random forest to stratify and detect cyclostationary malware.","['Engineering', 'Communications Engineering, Networks', 'Control, Robotics, Mechatronics', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Statistics, general']",an analysis of cyclostationary malware is introduced the most important cyclostationary features used for network intrusion detection systems nids are then detected with a feature extractor algorithm such as boruta and principal component analysis pca these feature patterns are classified to determine the most cyclostationary ones in particular this article shows the relevance of detecting cyclostationary malware for a nids by using legacy datasets such as the kdd and nslkdd this research has also used the ugransome cyclostationary dataset intended to support research on anomaly detection this dataset is subdivided into normal and abnormal classes of network threats a comparative analysis based on random forest and support vector machine algorithms is undertaken and the performance of boruta and pca was also evaluated the research suggests the utilization of pca in terms of extracting cyclostationary network feature patterns as a viable proposition compared to boruta the internet protocol ip malware financial damages class c of ip addresses and signature malware were also found to be the most cyclostationary feature pattern the ugransome dataset outperformed the kdd and nslkdd in terms of detecting signature malware with an accuracy of  using the random forest algorithm while the support vector machine achieved  this research proposes the ugransome as a suitable choice to reduce the computational time of cyclostationary malware classification lastly the research suggests the utilization of random forest to stratify and detect cyclostationary malware,"['##a' '##cl' '##tionary' 'anomaly detection' 'boruta' 'cycl'
 'cyclostationary features' 'cyclostationary mal'
 'cyclostationary malware' 'cyclostationary network'
 'feature extractor algorithm' 'internet protocol' 'ip addresses'
 'ip malware financial damages class c' 'legacy datasets'
 'machine algorithms' 'network intrusion detection systems'
 'network threats' 'nids' 'principal component analysis' 'random forest'
 'random forest algorithm' 'signature malware' 'support vector'
 'ugransome cyclostationary dataset' 'ugransome dataset']"
doi:10.1007/978-3-031-04524-0_12,en,"Role of IoT in Smart Homes and Smart Cities: Challenges, Benefits, and Applications",OriginalPaper,"IoT represents the Internet of Things which is a completely new concept, and there is a lack of scientific understanding of what IoT is and what its programs work on Smart Homes and Smart Cities. Smart Homes and Smart Cities based on IoT are considered one of the most important IoT applications. These days, the popular Smart Home Systems give us many types of applications that make our lives easier and simpler. IoT-based Smart Homes allow us to control and use our home appliances on mobile phones. Smart Home Systems notify the user of anonymous intrusion whenever the door is opened and notify the user immediately via SMS or email. After receiving the notification, the user can take the necessary steps against it. IoT-based Smart Cities enable us to perform various types of activities such as crime prevention and public safety, natural disaster management, environmental management or ecosystem, etc. Smart homes are considered an important part of building Smart Cities. With the advent of a large number of IoT devices in the coming years, privacy breaches and information leaks are likely to increase. This paper describes IoT and its application to Smart Homes and Smart Cities, how to create and use these applications using IoT, the various hardware and software features required for IoT use, the challenges and weaknesses of IoT usage for Smart Homes and Smart Cities, and benefits of using IoT in Smart Homes and Smart Cities. This chapter will examine current and future examples of IoT. And it will show us about how the IoT will interact with our lives in the future.","['Engineering', 'Cyber-physical systems, IoT', 'Communications Engineering, Networks', 'Computer Communication Networks']",iot represents the internet of things which is a completely new concept and there is a lack of scientific understanding of what iot is and what its programs work on smart homes and smart cities smart homes and smart cities based on iot are considered one of the most important iot applications these days the popular smart home systems give us many types of applications that make our lives easier and simpler iotbased smart homes allow us to control and use our home appliances on mobile phones smart home systems notify the user of anonymous intrusion whenever the door is opened and notify the user immediately via sms or email after receiving the notification the user can take the necessary steps against it iotbased smart cities enable us to perform various types of activities such as crime prevention and public safety natural disaster management environmental management or ecosystem etc smart homes are considered an important part of building smart cities with the advent of a large number of iot devices in the coming years privacy breaches and information leaks are likely to increase this paper describes iot and its application to smart homes and smart cities how to create and use these applications using iot the various hardware and software features required for iot use the challenges and weaknesses of iot usage for smart homes and smart cities and benefits of using iot in smart homes and smart cities this chapter will examine current and future examples of iot and it will show us about how the iot will interact with our lives in the future,"['anonymous intrusion' 'homes' 'information leaks' 'io' 'iot'
 'iot devices' 'iot usage' 'iot use' 'iotbased smart cities'
 'iotbased smart homes' 'mobile phones' 'prevention' 'privacy breaches'
 'public safety natural disaster management environmental management'
 'smart' 'smart cities' 'smart home systems' 'smart homes']"
doi:10.1007/978-3-031-11051-1_132,en,Application of Ventilation Systems with Increased Efficiency,OriginalPaper,"The general purpose of the work was a feasibility study of the use of energy-saving measures based on optimal design solutions of engineering systems in the development of ventilation systems with the use of energy-saving measures in the building of the Educational and Laboratory Building in St. Petersburg. The use of “passive” and “active” (“zero static pressure chamber” together with “fan-closers”) ways to increase the efficiency of ventilation systems have led to different indicators in the consumption of electrical energy. Therefore, it was necessary to estimate the cost of electricity and the total discounted costs. A one-time investment for an active impact solution is 3.5% more expensive than a standard design practice solution. The combined use of the “zero static pressure chamber” and “fan-closers” is cost-effective, and the system is quickly recouped compared to the estimated equipment life of 20 years, and the non-discount payback period was 2.7 years. When designing branched air ducts, you should leave the branches with approximately the same aerodynamic losses. On the floor branches, it is advisable to use “fan-closers”. The use of “active” methods to increase the efficiency of ventilation systems as energy-saving equipment is appropriate.","['Engineering', 'Control and Systems Theory', 'Control, Robotics, Mechatronics', 'Communications Engineering, Networks']",the general purpose of the work was a feasibility study of the use of energysaving measures based on optimal design solutions of engineering systems in the development of ventilation systems with the use of energysaving measures in the building of the educational and laboratory building in st petersburg the use of passive and active zero static pressure chamber together with fanclosers ways to increase the efficiency of ventilation systems have led to different indicators in the consumption of electrical energy therefore it was necessary to estimate the cost of electricity and the total discounted costs a onetime investment for an active impact solution is  more expensive than a standard design practice solution the combined use of the zero static pressure chamber and fanclosers is costeffective and the system is quickly recouped compared to the estimated equipment life of  years and the nondiscount payback period was  years when designing branched air ducts you should leave the branches with approximately the same aerodynamic losses on the floor branches it is advisable to use fanclosers the use of active methods to increase the efficiency of ventilation systems as energysaving equipment is appropriate,"['##ed costs' '##rs' 'active impact solution' 'active methods'
 'active zero static pressure chamber' 'aerodynamic losses' 'air ducts'
 'energysaving measures' 'equipment life' 'fancl' 'fanclosers'
 'st petersburg' 'ventilation systems' 'zero static pressure chamber']"
doi:10.1007/978-981-19-5607-2_6,en,Modality,OriginalPaper,"The notion of modality is almost inextricably intertwined with metaphysics, some kind of theory of what is real, what exists, and why (a theory of ‘first causes’). At the center of the commonsensical theory is the real world, but the idea is that there exist, or at least there can exist, other worlds.","['Computer Science', 'Natural Language Processing (NLP)', 'Computational Linguistics', 'Artificial Intelligence', 'Machine Learning', 'Knowledge based Systems', 'Digital Humanities']",the notion of modality is almost inextricably intertwined with metaphysics some kind of theory of what is real what exists and why a theory of ‘first causes at the center of the commonsensical theory is the real world but the idea is that there exist or at least there can exist other worlds,['commonsensical theory' 'metaphysics' 'modality']
doi:10.1007/978-981-16-8274-2_36,en,Experimental Analysis of Freeze Drying and Estimating the Transient Moisture Contents of Food Products,OriginalPaper,"Freeze drying is an advanced dehydration technology with many advantages over other traditional drying methods. The present work deals with development of an experimental model for freeze drying. The sample products used were skimmed milk and egg white. Experiments were performed with skimmed milk and egg white to estimate the transient moisture content. The experiments were performed with a laboratory lyophilizer setup and deep freezing was performed using a domestic refrigerator. The milk lost its 50% mass during the first 2.5 h freeze-drying process. It took 12 h to reach its solid powdered state. The egg white lost its mass very vigorously in the first 6 h of drying, and after that, a constant drying rate was noticed. The constant drying time continued up to 10 h. The egg white reached its solid state at 10 h. The obtained results were compared with existing numerical study, and a reasonable match was observed.","['Energy', 'Energy Policy, Economics and Management', 'Engineering Thermodynamics, Heat and Mass Transfer', 'Engineering Fluid Dynamics', 'Environmental Policy', 'Sociology, general']",freeze drying is an advanced dehydration technology with many advantages over other traditional drying methods the present work deals with development of an experimental model for freeze drying the sample products used were skimmed milk and egg white experiments were performed with skimmed milk and egg white to estimate the transient moisture content the experiments were performed with a laboratory lyophilizer setup and deep freezing was performed using a domestic refrigerator the milk lost its  mass during the first  h freezedrying process it took  h to reach its solid powdered state the egg white lost its mass very vigorously in the first  h of drying and after that a constant drying rate was noticed the constant drying time continued up to  h the egg white reached its solid state at  h the obtained results were compared with existing numerical study and a reasonable match was observed,"['constant drying rate' 'constant drying time' 'deep freezing'
 'dehydration' 'domestic refrigerator' 'egg white' 'egg white experiments'
 'egg white lost' 'freeze drying' 'h freezedrying process'
 'lyophilizer setup' 'skimmed milk' 'solid powdered state'
 'transient moisture content']"
doi:10.1007/s10207-021-00554-7,en,The Agent Web Model: modeling web hacking for reinforcement learning,"['OriginalPaper', 'Regular contribution']","Website hacking is a frequent attack type used by malicious actors to obtain confidential information, modify the integrity of web pages or make websites unavailable. The tools used by attackers are becoming more and more automated and sophisticated, and malicious machine learning agents seem to be the next development in this line. In order to provide ethical hackers with similar tools, and to understand the impact and the limitations of artificial agents, we present in this paper a model that formalizes web hacking tasks for reinforcement learning agents. Our model, named Agent Web Model , considers web hacking as a capture-the-flag style challenge, and it defines reinforcement learning problems at seven different levels of abstraction. We discuss the complexity of these problems in terms of actions and states an agent has to deal with, and we show that such a model allows to represent most of the relevant web vulnerabilities. Aware that the driver of advances in reinforcement learning is the availability of standardized challenges, we provide an implementation for the first three abstraction layers, in the hope that the community would consider these challenges in order to develop intelligent web hacking agents.","['Computer Science', 'Cryptology', 'Computer Communication Networks', 'Operating Systems', 'Coding and Information Theory', 'Management of Computing and Information Systems', 'Communications Engineering, Networks']",website hacking is a frequent attack type used by malicious actors to obtain confidential information modify the integrity of web pages or make websites unavailable the tools used by attackers are becoming more and more automated and sophisticated and malicious machine learning agents seem to be the next development in this line in order to provide ethical hackers with similar tools and to understand the impact and the limitations of artificial agents we present in this paper a model that formalizes web hacking tasks for reinforcement learning agents our model named agent web model  considers web hacking as a capturetheflag style challenge and it defines reinforcement learning problems at seven different levels of abstraction we discuss the complexity of these problems in terms of actions and states an agent has to deal with and we show that such a model allows to represent most of the relevant web vulnerabilities aware that the driver of advances in reinforcement learning is the availability of standardized challenges we provide an implementation for the first three abstraction layers in the hope that the community would consider these challenges in order to develop intelligent web hacking agents,"['abstraction layers' 'artificial agents' 'ethical hackers'
 'intelligent web hacking agents' 'machine learning agents'
 'malicious actors' 'reinforcement learning'
 'reinforcement learning agents' 'web hacking' 'web hacking tasks'
 'web pages' 'web vulnerabilities' 'website hacking']"
doi:10.1007/978-3-030-98546-2_28,en,Defining Artificial Intelligence,OriginalPaper,Artificial Intelligence (AI) has grown to become a research area that provides key technologies relevant across many disciplines and applications. This chapter briefly outlines the history of AI. The main areas of today's AI research landscape are described and their relation to each other is pointed out.,"['Engineering', 'Biomedical Engineering and Bioengineering', 'Health Informatics', 'Health Psychology', 'User Interfaces and Human Computer Interaction']",artificial intelligence ai has grown to become a research area that provides key technologies relevant across many disciplines and applications this chapter briefly outlines the history of ai the main areas of todays ai research landscape are described and their relation to each other is pointed out,['artificial intelligence' 'history']
doi:10.1007/978-981-19-2065-3_64,en,Risk and Challenges in Intelligent Systems,OriginalPaper,"Intelligent systems are those technologically advanced machines that identify and react to the world around them. These can take various structures, from automated gifts like Roomba to face recognition programs to Amazon’s personalized shopping suggestions. It can be defined as a system that incorporates intelligence into automated operating systems. Intelligent programs enable search and optimization and learning skills. Various types of machine learnings such as supervised and reinforced learning can be modeled on building intelligent programs. Intelligent programs also perform complex automated tasks that do not occur with the traditional paradigm. AI is a subject that can be challenged and misrepresented; some may call it an asset to conceal trading, but for others it is a technology that threatens the very presence of humanity as it has the power to take over and dominate man, but in actuality, this technology has influenced our way of daily routine discursively and shapes the future. AI is an important part of our daily lives already and has profoundly affected our way of life despite the important use of digital mobile assistants, driver assistance systems, bots, text and speech translators, as well as programs that promote customized products and services and learning. All emerging technologies are a source of interest and skepticism. AI is the cause of both pros and cons in different ways. However, we need to find some solutions for certain challenges before we can see the great power of truth and the great power to transform this emerging technology.","['Engineering', 'Communications Engineering, Networks', 'Artificial Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing', 'Wireless and Mobile Communication', 'Machine Learning']",intelligent systems are those technologically advanced machines that identify and react to the world around them these can take various structures from automated gifts like roomba to face recognition programs to amazons personalized shopping suggestions it can be defined as a system that incorporates intelligence into automated operating systems intelligent programs enable search and optimization and learning skills various types of machine learnings such as supervised and reinforced learning can be modeled on building intelligent programs intelligent programs also perform complex automated tasks that do not occur with the traditional paradigm ai is a subject that can be challenged and misrepresented; some may call it an asset to conceal trading but for others it is a technology that threatens the very presence of humanity as it has the power to take over and dominate man but in actuality this technology has influenced our way of daily routine discursively and shapes the future ai is an important part of our daily lives already and has profoundly affected our way of life despite the important use of digital mobile assistants driver assistance systems bots text and speech translators as well as programs that promote customized products and services and learning all emerging technologies are a source of interest and skepticism ai is the cause of both pros and cons in different ways however we need to find some solutions for certain challenges before we can see the great power of truth and the great power to transform this emerging technology,"['ai' 'amazons' 'automated operating systems' 'customized products'
 'digital mobile assistants' 'intelligent programs' 'machine learnings'
 'personalized shopping' 'recognition programs' 'reinforced learning'
 'roomba' 'speech translators']"
doi:10.1007/978-981-19-6068-0_20,en,Detection of COVID-19 Infection from Clinical Findings Using Machine Learning Algorithm,OriginalPaper,"COVID-19 infection is a transmissible virus causing acute respiratory syndrome spreading worldwide. The number of patients infected by this deadly virus increases steadily, causing a high mortality rate. Hence, it is crucial to diagnose and identify the COVID-19 infection for earlier treatment of the patients. This study has applied four algorithms, namely, Logistic Regression (LR), Nu-Support Vector Machine (Nu-SVM), Multi-layer perceptron (MLP) and Naive Bayes (NB) to identify COVID-19 infection. The clinical laboratory findings of 600 individuals were taken from Hospital Isrelita Albert Einstein, Sao Paulo, Brazil, used in this study. We have selected significant features using Random forest-based recursive feature elimination for predicting the infection. Experiments are conducted with 90% training and 10% testing data. The performance result shows that the Nu-SVM algorithm obtained the prediction accuracy of 95% with 100% sensitivity and 94.23% specificity in predicting the infection. To our knowledge, the result achieved by Nu-SVM is the highest in the literature. Hence, the model can be used as a tool for the initial prediction of COVID-19 disease.","['Computer Science', 'Artificial Intelligence', 'Computational Intelligence', 'Cyber-physical systems, IoT', 'Professional Computing']",covid infection is a transmissible virus causing acute respiratory syndrome spreading worldwide the number of patients infected by this deadly virus increases steadily causing a high mortality rate hence it is crucial to diagnose and identify the covid infection for earlier treatment of the patients this study has applied four algorithms namely logistic regression lr nusupport vector machine nusvm multilayer perceptron mlp and naive bayes nb to identify covid infection the clinical laboratory findings of  individuals were taken from hospital isrelita albert einstein sao paulo brazil used in this study we have selected significant features using random forestbased recursive feature elimination for predicting the infection experiments are conducted with  training and  testing data the performance result shows that the nusvm algorithm obtained the prediction accuracy of  with  sensitivity and  specificity in predicting the infection to our knowledge the result achieved by nusvm is the highest in the literature hence the model can be used as a tool for the initial prediction of covid disease,"['acute respiratory syndrome' 'covid disease' 'covid infection'
 'high mortality rate' 'logistic regression lr' 'multilayer perceptron'
 'nusupport vector machine nusvm' 'nusvm' 'prediction accuracy'
 'random forestbased recursive feature elimination' 'sensitivity'
 'transmissible virus']"
doi:10.1007/978-3-031-19958-5_42,en,Challenges in Corpus Construction for Thai-English Machine Translation,OriginalPaper,"This paper presents the challenges identified during research into the construction of a parallel text corpus of 18,000 sentences for Thai-English machine translation (MT). The research approach was to perform the essential tasks of locating, extracting, and formatting web text suitable for the corpus whilst identifying the primary issues. The project included the creation and development of core components to extract web text, segment the text into sentences, and align these sentences into the parallel text corpus. Despite the success of several techniques related to these stages of corpus construction, their performance is often poor when applied to text from languages that are considerably different from English, although these issues are not always reported. The primary challenge to corpus construction for Thai-English machine translation was identified as the segmentation of text into sentences. Sentence segmentation tools did not split Thai text into sentences that corresponded to the English sentences. Machine translation is reliant on parallel text having corresponding sentences with the same meaning. This issue was further compounded by the nature of web text, which made the text difficult to segment correctly when there were source-specific idiosyncrasies. Traditional alignment approaches are not as effective when applied independently to Thai text due to its nature and a lack of linguistic resources. Despite this, a combination of approaches for both the text extraction and alignment was successful when the sentence segmentation was not problematic.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']",this paper presents the challenges identified during research into the construction of a parallel text corpus of  sentences for thaienglish machine translation mt the research approach was to perform the essential tasks of locating extracting and formatting web text suitable for the corpus whilst identifying the primary issues the project included the creation and development of core components to extract web text segment the text into sentences and align these sentences into the parallel text corpus despite the success of several techniques related to these stages of corpus construction their performance is often poor when applied to text from languages that are considerably different from english although these issues are not always reported the primary challenge to corpus construction for thaienglish machine translation was identified as the segmentation of text into sentences sentence segmentation tools did not split thai text into sentences that corresponded to the english sentences machine translation is reliant on parallel text having corresponding sentences with the same meaning this issue was further compounded by the nature of web text which made the text difficult to segment correctly when there were sourcespecific idiosyncrasies traditional alignment approaches are not as effective when applied independently to thai text due to its nature and a lack of linguistic resources despite this a combination of approaches for both the text extraction and alignment was successful when the sentence segmentation was not problematic,"['english sentences' 'locating extracting' 'parallel text corpus'
 'sentence segmentation' 'sourcespecific idiosyncrasies' 'text'
 'thaienglish machine translation' 'translation' 'web text']"
doi:10.1007/978-3-031-18645-5_28,en,Smart Tourism as a Strategic Response to Challenges of Tourism in the Post-COVID Era,OriginalPaper,"Many scholars have emphasised the importance of tourism for global economies. However, contemporary business paradigms in tourism have changed due to the COVID-19 pandemic, which made a tremendous negative impact on tourism hitherto and affected certain positive aspects, such as boosting digital transformation. Despite the considerable increase in the inquisitiveness to the influence of COVID-19 on different industries and digital transformation and a myriad of notable studies concerning this subject, the interdependence between the impact of the pandemic on digital transformation in tourism is understudied. Building on the previous studies, this paper aims to address this issue, narrow the existing theoretical gap, and provide how to use new technologies to strategically approach future tourism challenges. The paper particularly investigates smart tourism as a new and effective method to cope with challenges in tourism. The goal of the article is to contribute to understanding the impact of the COVID-19 pandemic and other crises on the acceleration of digital transformation and the role of new technologies in tourism. This study sheds new light on the strategical approach to contemporary and future tourism challenges.","['Engineering', 'Mathematical and Computational Engineering', 'Business and Management, general', 'Data Engineering']",many scholars have emphasised the importance of tourism for global economies however contemporary business paradigms in tourism have changed due to the covid pandemic which made a tremendous negative impact on tourism hitherto and affected certain positive aspects such as boosting digital transformation despite the considerable increase in the inquisitiveness to the influence of covid on different industries and digital transformation and a myriad of notable studies concerning this subject the interdependence between the impact of the pandemic on digital transformation in tourism is understudied building on the previous studies this paper aims to address this issue narrow the existing theoretical gap and provide how to use new technologies to strategically approach future tourism challenges the paper particularly investigates smart tourism as a new and effective method to cope with challenges in tourism the goal of the article is to contribute to understanding the impact of the covid pandemic and other crises on the acceleration of digital transformation and the role of new technologies in tourism this study sheds new light on the strategical approach to contemporary and future tourism challenges,"['##penden' 'digital transformation' 'global economies' 'smart tourism'
 'strategical approach' 'tourism']"
doi:10.1007/978-3-030-96154-1_11,en,TMSLedger: A Transactions Management System Through Integrated Odoo Hyperledger Smart Contracts,OriginalPaper,"Ever since their big impact in the financial sector, blockchains have never ceased to make disruptions in collaborative applications. Blockchains are considered nowadays the go-to solution for developing critical data exchange platforms. Unfortunately, their interaction with existing and already established platforms is still limited due to many reasons such as legacy platforms complexity and resistance to change. Through this chapter, we aim at addressing this gap by proposing an end-to-end solution for managing business workflows using blockchain smart contracts. We propose a proof of concept of a manufacturing supply chain scenario integration between Odoo (supply chain processes) and Hyperledger Fabric (blockchain development platform). We demonstrate how Odoo workflows can be optimized, secured, and made trustworthy using smart contracts and highlight the impact of this solution on current and future applications especially in the Industry 4.0 context where data is an abundant and critical resource.","['Engineering', 'Engineering Economics, Organization, Logistics, Marketing', 'Supply Chain Management', 'Professional Computing', 'Industrial and Production Engineering', 'Logistics']",ever since their big impact in the financial sector blockchains have never ceased to make disruptions in collaborative applications blockchains are considered nowadays the goto solution for developing critical data exchange platforms unfortunately their interaction with existing and already established platforms is still limited due to many reasons such as legacy platforms complexity and resistance to change through this chapter we aim at addressing this gap by proposing an endtoend solution for managing business workflows using blockchain smart contracts we propose a proof of concept of a manufacturing supply chain scenario integration between odoo supply chain processes and hyperledger fabric blockchain development platform we demonstrate how odoo workflows can be optimized secured and made trustworthy using smart contracts and highlight the impact of this solution on current and future applications especially in the industry  context where data is an abundant and critical resource,"['blockchain smart contracts' 'blockchains' 'business workflows'
 'collaborative applications' 'critical resource'
 'data exchange platforms' 'endtoend solution' 'fabric blockchain'
 'legacy platforms' 'manufacturing supply chain scenario integration'
 'odoo workflows' 'smart contracts' 'trustworthy']"
doi:10.1007/978-3-658-38931-4_3,en,"Live Vaccines, Vector Vaccines and Virus-Like Particles",OriginalPaper,"Classically attenuated live vaccines were among the first vaccines developed against infectious diseases. This type of vaccine dates back to early research at the end of the eighteenth century. Although the principle had been practiced earlier, an English physician, Edward Jenner , was the first to publish the findings in a scientific journal. He administered a cowpox preparation to a boy and later infected the boy with the smallpox virus, which is dangerous to humans.","['Chemistry', 'Chemistry/Food Science, general', 'Biotechnology', 'Biomaterials', 'Pharmacy', 'Medicinal Chemistry']",classically attenuated live vaccines were among the first vaccines developed against infectious diseases this type of vaccine dates back to early research at the end of the eighteenth century although the principle had been practiced earlier an english physician edward jenner  was the first to publish the findings in a scientific journal he administered a cowpox preparation to a boy and later infected the boy with the smallpox virus which is dangerous to humans,"['classically attenuated live vaccines' 'cowpox preparation'
 'infectious diseases' 'smallpox virus']"
doi:10.1007/978-3-031-11051-1_99,en,Resource-Efficient Use of Hydrocarbon Raw Materials as a Factor in the Transition to a “Green” Economy,OriginalPaper,"The relevance of the study is determined by the fact that the current environmental situation necessitates the transition of sectors of the national economy from technogenic to sustainable environmentally balanced development, which will allow the transition of the industry to the principles of “green economy”. Resource conservation and increasing the level of resource efficiency in the use of hydrocarbon raw materials are priority issues, the solution of which will help to implement a set of energy, environmental and economic tasks for the transition to “green” development. Increasing resource efficiency will have a positive impact on the environment, as reducing the consumption of raw materials will significantly reduce waste and emissions. In the context of the growing shortage of non-renewable resources, the aggravation of environmental problems, the introduction of resource-saving and resource-efficient innovative “green” technologies aimed at the production of new types of “green” products is a necessary condition for the successful development of the economy and the preservation of the environment. In this regard, it is necessary to achieve the effect of “decoupling”, which implies an increase in the resource efficiency of the use of raw materials while reducing environmental risks. The most important direction of Russia's transition to “green development” is to increase the complexity of the use of raw materials, increase the depth of processing, processing and disposal of by-products, production waste through their recycling. The novelty of the study is the reduction of the burden on the environment, based on the comprehensive use of environmentally friendly low-waste technologies.","['Engineering', 'Control and Systems Theory', 'Control, Robotics, Mechatronics', 'Communications Engineering, Networks']",the relevance of the study is determined by the fact that the current environmental situation necessitates the transition of sectors of the national economy from technogenic to sustainable environmentally balanced development which will allow the transition of the industry to the principles of green economy resource conservation and increasing the level of resource efficiency in the use of hydrocarbon raw materials are priority issues the solution of which will help to implement a set of energy environmental and economic tasks for the transition to green development increasing resource efficiency will have a positive impact on the environment as reducing the consumption of raw materials will significantly reduce waste and emissions in the context of the growing shortage of nonrenewable resources the aggravation of environmental problems the introduction of resourcesaving and resourceefficient innovative green technologies aimed at the production of new types of green products is a necessary condition for the successful development of the economy and the preservation of the environment in this regard it is necessary to achieve the effect of decoupling which implies an increase in the resource efficiency of the use of raw materials while reducing environmental risks the most important direction of russias transition to green development is to increase the complexity of the use of raw materials increase the depth of processing processing and disposal of byproducts production waste through their recycling the novelty of the study is the reduction of the burden on the environment based on the comprehensive use of environmentally friendly lowwaste technologies,"['##du' 'environmentally friendly lowwaste technologies'
 'green economy resource conservation' 'hydrocarbon raw materials'
 'national economy' 'nonrenewable resources' 'processing processing'
 'production' 'raw materials' 'resource efficiency'
 'sustainable environmentally balanced development']"
doi:10.1007/978-3-031-21203-1_5,en,On Normative Reinforcement Learning via Safe Reinforcement Learning,OriginalPaper,"Reinforcement learning (RL) has proven a successful technique for teaching autonomous agents goal-directed behaviour. As RL agents further integrate with our society, they must learn to comply with ethical, social, or legal norms. Defeasible deontic logics are natural formal frameworks to specify and reason about such norms in a transparent way. However, their effective and efficient integration in RL agents remains an open problem. On the other hand, linear temporal logic (LTL) has been successfully employed to synthesize RL policies satisfying, e.g., safety requirements. In this paper, we investigate the extent to which the established machinery for safe reinforcement learning can be leveraged for directing normative behaviour for RL agents. We analyze some of the difficulties that arise from attempting to represent norms with LTL, provide an algorithm for synthesizing LTL specifications from certain normative systems, and analyze its power and limits with a case study.","['Computer Science', 'Artificial Intelligence']",reinforcement learning rl has proven a successful technique for teaching autonomous agents goaldirected behaviour as rl agents further integrate with our society they must learn to comply with ethical social or legal norms defeasible deontic logics are natural formal frameworks to specify and reason about such norms in a transparent way however their effective and efficient integration in rl agents remains an open problem on the other hand linear temporal logic ltl has been successfully employed to synthesize rl policies satisfying eg safety requirements in this paper we investigate the extent to which the established machinery for safe reinforcement learning can be leveraged for directing normative behaviour for rl agents we analyze some of the difficulties that arise from attempting to represent norms with ltl provide an algorithm for synthesizing ltl specifications from certain normative systems and analyze its power and limits with a case study,"['##g' '##tive systems' 'autonomous agents' 'deontic logics'
 'goaldirected behaviour' 'linear temporal logic' 'ltl'
 'normative behaviour' 'reinforcement learning' 'requirements'
 'safe reinforcement learning']"
doi:10.1007/978-3-031-09719-5_38,en,Intraoperative Neuromonitoring in Pediatric Surgery,OriginalPaper,"The use of intraoperative neurophysiological monitoring (IONM) in children was first described in 1979 (Neurosurgery 4(2):146–51, 1979), just 2 years after the first descriptions of the use of somatosensory-evoked potentials (SSEPs) in adult spine surgery (Clin Orthop Rel Res 126:100–5, 1977). Since then, surgeons from many countries have integrated the use of IONM into the surgical care of pediatric patients. The modalities used and the types of procedures for which IONM is utilized have expanded greatly since 1979. Today, the most common pediatric procedures for which IONM is used are those that may place the corticospinal and corticobulbar tracts, brainstem auditory pathways, dorsal columns, cranial nerves, and/or somatic nerve roots at risk. It is important to understand how the immature nervous system interacts with common IONM modalities to monitor young children effectively. It is also important to optimize the anesthetic technique to minimize signal variability. We describe techniques and considerations for anesthetizing and monitoring young children.","['Medicine & Public Health', 'Anesthesiology', 'Neurosurgery', 'Pain Medicine']",the use of intraoperative neurophysiological monitoring ionm in children was first described in  neurosurgery :–  just  years after the first descriptions of the use of somatosensoryevoked potentials sseps in adult spine surgery clin orthop rel res :–  since then surgeons from many countries have integrated the use of ionm into the surgical care of pediatric patients the modalities used and the types of procedures for which ionm is utilized have expanded greatly since  today the most common pediatric procedures for which ionm is used are those that may place the corticospinal and corticobulbar tracts brainstem auditory pathways dorsal columns cranial nerves andor somatic nerve roots at risk it is important to understand how the immature nervous system interacts with common ionm modalities to monitor young children effectively it is also important to optimize the anesthetic technique to minimize signal variability we describe techniques and considerations for anesthetizing and monitoring young children,"['##est' 'adult spine surgery' 'children' 'cranial nerves'
 'dorsal columns' 'intraoperative neurophysiological monitoring' 'ionm'
 'neurosurgery' 'somatosensoryevoked potentials' 'surgical care']"
doi:10.1007/978-3-031-16485-9_1,en,"Why do companies become similar, but performance is different?: Understanding of Corporate isomorphism through Self-determination",OriginalPaper,"This study inferred that those various individual innovative behaviors expressed to survive social environmental changes are the result of individual’s subjective intrinsic behaviors. The study was conducted with the aim of empirically identifying the operating principles of innovative behavior, developing universally applicable theories and models for innovative behavior, and providing an important theoretical basis for applying numerous management techniques to the reality. Due to the nature of individual’s intrinsic behavior research, it was prepared using an electronic self-report survey. Outliers were removed from the collected data and normality checks were accomplished to perform confirmatory factor analysis, and the causal relationship was verified using the structural equation model. As an analysis method, reliability was verified using the Cronbach alpha coefficient, and factor analysis was conducted to test the validity of the measurement variable. Competence, relationship, and autonomy, which are the main constituents of self-determination, play significant role on innovative behavior, while competence having a mediating effect on relationship and autonomy. Similarly, autonomy was found to have a moderating effect on relationship and competence. The results of this study provided an opportunity to identify the fundamental principles of innovative behavior and understand the phenomenon of corporate isomorphization. The coercive and normative isomorphism caused by changes in external systems and norms is understood as a simple adaptation rather than an innovation. On the other hand, the act of self-awareness and imitation of new standards in exchange with others presupposes the acceptance of more innovative ideas, so if only an autonomous environment is continuously provided, the expression of innovative behavior can be continuously induced.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence']",this study inferred that those various individual innovative behaviors expressed to survive social environmental changes are the result of individuals subjective intrinsic behaviors the study was conducted with the aim of empirically identifying the operating principles of innovative behavior developing universally applicable theories and models for innovative behavior and providing an important theoretical basis for applying numerous management techniques to the reality due to the nature of individuals intrinsic behavior research it was prepared using an electronic selfreport survey outliers were removed from the collected data and normality checks were accomplished to perform confirmatory factor analysis and the causal relationship was verified using the structural equation model as an analysis method reliability was verified using the cronbach alpha coefficient and factor analysis was conducted to test the validity of the measurement variable competence relationship and autonomy which are the main constituents of selfdetermination play significant role on innovative behavior while competence having a mediating effect on relationship and autonomy similarly autonomy was found to have a moderating effect on relationship and competence the results of this study provided an opportunity to identify the fundamental principles of innovative behavior and understand the phenomenon of corporate isomorphization the coercive and normative isomorphism caused by changes in external systems and norms is understood as a simple adaptation rather than an innovation on the other hand the act of selfawareness and imitation of new standards in exchange with others presupposes the acceptance of more innovative ideas so if only an autonomous environment is continuously provided the expression of innovative behavior can be continuously induced,"['autonomy' 'causal relationship' 'confirmatory factor analysis'
 'corporate isomorphization' 'cronbach alpha coefficient'
 'electronic selfreport survey outliers' 'external systems'
 'factor analysis' 'individuals intrinsic behavior research'
 'individuals subjective intrinsic behaviors' 'innovative behavior'
 'innovative behaviors' 'measurement variable competence relationship'
 'normality checks' 'normative isomorphism' 'operating principles'
 'reliability' 'selfawareness' 'selfdetermination'
 'social environmental changes' 'structural equation model']"
doi:10.1007/978-981-16-9967-2_38,en,Revamping an E-Application for User Experience: A Case Study of eSanjeevaniOPD App,OriginalPaper,"Menon, Remya Vivek Rejikumar, G. E-governance initiatives are likely to succeed only if the applications created for those purposes offer an excellent user experience (UX). For UX to improve, many components associated with the application should meet expectations and make user interactions easier, intuitive, and relaxing. This study aimed to verify the user experience developed by the ‘eSanjeevaniOPD’ app and suggest ways to improve it. The sequential incident technique (SIT) revealed user concerns in every stage of the user journey and, therefore, improvement opportunities. Accordingly, a few attributes were chosen to improve UX by providing them in the best possible manner. The Taguchi experiment with ten selected attributes by capturing user perceptions identified an optimum combination of these attributes for maximum UX.","['Computer Science', 'Computer Systems Organization and Communication Networks', 'Computational Intelligence', 'Artificial Intelligence', 'Wireless and Mobile Communication', 'Cyber-physical systems, IoT', 'Professional Computing']",menon remya vivek rejikumar g egovernance initiatives are likely to succeed only if the applications created for those purposes offer an excellent user experience ux for ux to improve many components associated with the application should meet expectations and make user interactions easier intuitive and relaxing this study aimed to verify the user experience developed by the ‘esanjeevaniopd app and suggest ways to improve it the sequential incident technique sit revealed user concerns in every stage of the user journey and therefore improvement opportunities accordingly a few attributes were chosen to improve ux by providing them in the best possible manner the taguchi experiment with ten selected attributes by capturing user perceptions identified an optimum combination of these attributes for maximum ux,"['maximum ux' 'sequential incident technique' 'taguchi'
 'user interactions']"
doi:10.1007/978-981-19-7398-7_1,en,Sustainable Qatar,OriginalPaper,"The Qatar National Vision of 2030 has identified bold and transformational goals for the country. As envisioned by the State of Qatar, the transition to sustainable Qatar weaves together four pillars of economic, social, human, and environmental development. Yet, the country faces significant challenges, and with these challenges a range of options for future pathways. With the National Vision 2030 being launched in 2008, this volume provides an update on the key sustainability issues, focusing on environmental sustainability from a socio-political perspective.","['Political Science and International Relations', 'Public Policy', 'Sustainable Development', 'Development Studies', 'Middle Eastern Politics']",the qatar national vision of  has identified bold and transformational goals for the country as envisioned by the state of qatar the transition to sustainable qatar weaves together four pillars of economic social human and environmental development yet the country faces significant challenges and with these challenges a range of options for future pathways with the national vision  being launched in  this volume provides an update on the key sustainability issues focusing on environmental sustainability from a sociopolitical perspective,"['environmental sustainability' 'national vision' 'qatar'
 'qatar national vision']"
doi:10.1007/s10489-022-03470-y,en,Modeling multi-scale sub-group context for group activity recognition,OriginalPaper,"Group activity recognition is a challenging task for complex motion and relation between actors. To utilize similar action of actors, this paper proposes a novel multi-scale Sub-group Context Block (SCB) for group Activity Recognition. Node embedding matrix and adjacent matrix are constructed and fed into SCB. In SCB, we use an assignment matrix to learn the mapping from actors to sub-groups, so the representation and interaction of sub-group can be learned automatically. Then Graph Convolution is used for further feature representation refine. In order to emphasize effect of different sub-groups, a reinforcement learning based module Sub-group Attention Block (SAB) is designed, which models it as a Markov decision process and gives each sub-group an importance value for further procedure. Multi-scale context for group activity in different levels is adopted by fusing features obtained with various clustering numbers. Finally, temporal information is integrated by multiple frames merging. Extensive experiments are performed on two standard group activity recognition datasets: the Volleyball and the Collective Activity. Our proposed method gets outstanding performance. The results also validate that SCB and SAB are effective for group activity recognition.","['Computer Science', 'Artificial Intelligence', 'Mechanical Engineering', 'Manufacturing, Machines, Tools, Processes']",group activity recognition is a challenging task for complex motion and relation between actors to utilize similar action of actors this paper proposes a novel multiscale subgroup context block scb for group activity recognition node embedding matrix and adjacent matrix are constructed and fed into scb in scb we use an assignment matrix to learn the mapping from actors to subgroups so the representation and interaction of subgroup can be learned automatically then graph convolution is used for further feature representation refine in order to emphasize effect of different subgroups a reinforcement learning based module subgroup attention block sab is designed which models it as a markov decision process and gives each subgroup an importance value for further procedure multiscale context for group activity in different levels is adopted by fusing features obtained with various clustering numbers finally temporal information is integrated by multiple frames merging extensive experiments are performed on two standard group activity recognition datasets: the volleyball and the collective activity our proposed method gets outstanding performance the results also validate that scb and sab are effective for group activity recognition,"['adjacent matrix' 'assignment matrix' 'attention block sab'
 'collective activity' 'context block' 'graph convolution'
 'group activity' 'group activity recognition'
 'group activity recognition datasets' 'markov decision process'
 'multiscale subgroup' 'reinforcement learning based module subgroup']"
doi:10.1007/978-981-19-4990-6_49,en,Tool-Based Prediction of SQL Injection Vulnerabilities and Attacks on Web Applications,OriginalPaper,"In today’s present time, SQL injection has become a significant security threat over the web for diverse dynamic web applications and websites. SQL Injection may be a sort of associate injection attack that produces it doable to execute malicious SQL statements into an online application consisting of SQL information. Attackers use these SQL Injection Queries or Statements specified if an Internet site or an application hosted on web contain SQL vulnerabilities to bypass application security measures. The Attacker will even go around authentication associated with authorization of an online page or Internet application and might bypass these methods and retrieve the content of the whole SQL information of an online application. The purpose of the proposed system is to predict the occurrence of a SQL injection attack on a particular server where an application is deployed from a given supply at a particular point in time. This predictive experiment is managed using the JMeter tool. From network logs, you can now pre-measure, exclude choices, analyze, and feed machine learning models to predict SQLIA.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Wireless and Mobile Communication']",in todays present time sql injection has become a significant security threat over the web for diverse dynamic web applications and websites sql injection may be a sort of associate injection attack that produces it doable to execute malicious sql statements into an online application consisting of sql information attackers use these sql injection queries or statements specified if an internet site or an application hosted on web contain sql vulnerabilities to bypass application security measures the attacker will even go around authentication associated with authorization of an online page or internet application and might bypass these methods and retrieve the content of the whole sql information of an online application the purpose of the proposed system is to predict the occurrence of a sql injection attack on a particular server where an application is deployed from a given supply at a particular point in time this predictive experiment is managed using the jmeter tool from network logs you can now premeasure exclude choices analyze and feed machine learning models to predict sqlia,"['associate injection attack' 'diverse dynamic web applications' 'feed'
 'internet application' 'jmeter' 'machine learning' 'network logs you'
 'online application' 'security' 'security threat'
 'sql information attackers' 'sql injection' 'sql injection attack'
 'sql statements' 'sql vulnerabilities' 'sqlia' 'websites']"
doi:10.1007/978-981-19-0105-8_25,en,U-Shaped Xception-Residual Network for Polyps Region Segmentation,OriginalPaper,"Segmenting the region of interest helps gastroenterologists for removing polyps during the surgery in the gastrointestinal tract. We propose a segmentation system to segment the area of the polyp from the informative frames. Informative frames are the frames that contain at least a polyp in colonoscopy still frames. Our proposed U-shaped convolution neural network model utilizes the concept of residual connection and Xception as a backbone structure. We consider colonoscopy still frames as input to the segmentation model and achieved a Dice and Jaccard score of 86.3 and 79, respectively. It outperformed the conventional U-net with a 3.7% performance gain with respect to Dice score. This proposed method can be used as a reliable alternative system to identify a region of polyps during colonoscopy analysis.","['Engineering', 'Communications Engineering, Networks', 'Artificial Intelligence', 'Computational Intelligence', 'Bioinformatics']",segmenting the region of interest helps gastroenterologists for removing polyps during the surgery in the gastrointestinal tract we propose a segmentation system to segment the area of the polyp from the informative frames informative frames are the frames that contain at least a polyp in colonoscopy still frames our proposed ushaped convolution neural network model utilizes the concept of residual connection and xception as a backbone structure we consider colonoscopy still frames as input to the segmentation model and achieved a dice and jaccard score of  and  respectively it outperformed the conventional unet with a  performance gain with respect to dice score this proposed method can be used as a reliable alternative system to identify a region of polyps during colonoscopy analysis,"['backbone structure' 'colonosco' 'colonoscopy analysis'
 'colonoscopy still frames' 'convolution neural network' 'dice score'
 'gastroenterologists' 'gastrointestinal tract'
 'informative frames informative frames' 'jaccard score'
 'performance gain' 'polyp' 'polyps' 'region of interest'
 'residual connection' 'segmentation system' 'ushaped' 'xception']"
doi:10.1007/978-981-19-2225-1_15,en,A Novel Application of HPSOGWO Trained ANN in Nonlinear Channel Equalization,OriginalPaper,"In a communication channel, there is a possibility of distortions such as ISI, CCI, and another source of noise that interfere with useful signals, and the signal becomes corrupted. Therefore, equalizers are needed to counter such types of distortions. In this paper, we presented a nature-inspired hybrid algorithm which is an amalgamation of PSO and GWO. The proposed algorithm is called HPSOGWO. During this work, we pertain to ANN trained with the proposed HPSOGWO in the channel equalization. The foremost initiative is to boost the flexibility of the variants of the proposed algorithm and the utilization of proper weight, topology, and transfer function of ANN in the channel equalization. The performance of the proposed equalizer can be evaluated by estimating MSE and BER by considering popular nonlinear channels and added with nonlinearities. Extensive simulations show the performance of our proposed equalizer, better than existing NN-based equalizers also as neuro-fuzzy equalizers.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Statistics, general', 'Mobile and Network Security']",in a communication channel there is a possibility of distortions such as isi cci and another source of noise that interfere with useful signals and the signal becomes corrupted therefore equalizers are needed to counter such types of distortions in this paper we presented a natureinspired hybrid algorithm which is an amalgamation of pso and gwo the proposed algorithm is called hpsogwo during this work we pertain to ann trained with the proposed hpsogwo in the channel equalization the foremost initiative is to boost the flexibility of the variants of the proposed algorithm and the utilization of proper weight topology and transfer function of ann in the channel equalization the performance of the proposed equalizer can be evaluated by estimating mse and ber by considering popular nonlinear channels and added with nonlinearities extensive simulations show the performance of our proposed equalizer better than existing nnbased equalizers also as neurofuzzy equalizers,"['##ities' 'gwo' 'hpsogwo' 'natureinspired hybrid algorithm'
 'neurofuzzy equalizers' 'nnbased' 'nonlinear channels' 'pso'
 'transfer function' 'weight topology']"
doi:10.1007/978-981-19-2545-0_8,en,Application of CO2 Injection in the Steelmaking Process,OriginalPaper,"Through the theoretical research that has been carried out on the application of carbon dioxide (CO 2 ) in the field of steelmaking, it has been found that CO 2 gas can be used as a coolant, stirring gas, and oxidizing gas in steelmaking or refining. By studying the recycling of CO 2 in steelmaking, a large amount of field data has been obtained. The industrial processing of CO 2 resource utilization in the steelmaking field will be introduced.","['Engineering', 'Building Materials', 'Energy Policy, Economics and Management', 'Industrial Chemistry/Chemical Engineering', 'Sustainable Development']",through the theoretical research that has been carried out on the application of carbon dioxide co   in the field of steelmaking it has been found that co  gas can be used as a coolant stirring gas and oxidizing gas in steelmaking or refining by studying the recycling of co  in steelmaking a large amount of field data has been obtained the industrial processing of co  resource utilization in the steelmaking field will be introduced,"['carbon dioxide co' 'co gas' 'co resource utilization'
 'coolant stirring gas' 'oxidizing gas' 'recycling' 'steelmaking']"
doi:10.1007/978-3-031-16237-4_8,en,Security and Privacy of IoT Devices for Aging in Place,OriginalPaper,"The rising cost of elderly living and care facilities prompts for other solutions for the elderly people where aging in place is one of the ways to solve this issue using emerging technologies centered around smart IoT devices. To ensure security and privacy for a smart home for aging in place, different aspects of the IoT devices have to be considered. This chapter seeks to provide a categorical review and analysis of age-tech IoT device technologies, and discuss the underlying security and privacy challenges and available solutions.","['Engineering', 'Cyber-physical systems, IoT', 'Data Engineering', 'Computational Intelligence', 'Big Data', 'Artificial Intelligence']",the rising cost of elderly living and care facilities prompts for other solutions for the elderly people where aging in place is one of the ways to solve this issue using emerging technologies centered around smart iot devices to ensure security and privacy for a smart home for aging in place different aspects of the iot devices have to be considered this chapter seeks to provide a categorical review and analysis of agetech iot device technologies and discuss the underlying security and privacy challenges and available solutions,"['agetech iot' 'aging' 'care facilities' 'elderly living' 'elderly people'
 'iot devices' 'security' 'smart iot devices']"
doi:10.1007/978-3-031-16237-4_7,en,Attack Detection by Using Deep Learning for Cyber-Physical System,OriginalPaper,"With a cyber-physical system (CPS), physical components like industries are handled with an automated system. With the booming of cyber-attacks, detecting these attacks remains challenging. In order to protect the system from being hacked, we need to have CPS security measures implemented. Machine Learning (ML) has an important role to play in the detection of security attacks, which is the first step to protecting the CPS system. Cutting edge Deep Learning (DL) techniques have widely been applied to various domains like image processing and speech recognition. As part of a review of detecting cyber-attacks in CPSs, this chapter outlines the roles of DL and Deep Reinforcement Learning (DRL). Also, we present state-of-the-art solutions without sacrificing technical details. Additionally, we describe common datasets used for DL in CPSs. Finally, we express research opportunities and challenges in the CPSs with respect to DL.","['Engineering', 'Cyber-physical systems, IoT', 'Data Engineering', 'Computational Intelligence', 'Big Data', 'Artificial Intelligence']",with a cyberphysical system cps physical components like industries are handled with an automated system with the booming of cyberattacks detecting these attacks remains challenging in order to protect the system from being hacked we need to have cps security measures implemented machine learning ml has an important role to play in the detection of security attacks which is the first step to protecting the cps system cutting edge deep learning dl techniques have widely been applied to various domains like image processing and speech recognition as part of a review of detecting cyberattacks in cpss this chapter outlines the roles of dl and deep reinforcement learning drl also we present stateoftheart solutions without sacrificing technical details additionally we describe common datasets used for dl in cpss finally we express research opportunities and challenges in the cpss with respect to dl,"['common datasets' 'cyberattacks' 'cyberphysical system' 'deep learning'
 'deep reinforcement learning' 'image processing' 'machine learning'
 'security attacks' 'security measures' 'speech recognition'
 'stateoftheart' 'system cutting edge']"
doi:10.1007/978-981-19-3842-9_18,en,Design and Development of Automobile Hydraulic Servo Test System,OriginalPaper,"The test bench driven by hydraulic servo has been widely used in the test of vehicle and parts, and plays an important role in automobile material test, new material research and development, product part structure design and quality monitoring. The mainstream suppliers in the field of automotive high-end hydraulic servo test equipment are foreign manufacturers, with serious technical blockade, difficult maintenance, long procurement cycle and high price of equipment body and accessories; in order to improve the test efficiency of automotive products and reduce the test cost, a set of high-precision automotive hydraulic servo test system is developed independently. Based on the basic principle of hydraulic servo control, the test system independently developed the test software, control accuracy reached the level of first-class hydraulic servo equipment, completed the fatigue life test of truck saddle, and provided guarantee for the performance and life test of subsequent vehicle and parts.","['Engineering', 'Mechanical Engineering', 'Automotive Engineering', 'Transportation Technology and Traffic Engineering']",the test bench driven by hydraulic servo has been widely used in the test of vehicle and parts and plays an important role in automobile material test new material research and development product part structure design and quality monitoring the mainstream suppliers in the field of automotive highend hydraulic servo test equipment are foreign manufacturers with serious technical blockade difficult maintenance long procurement cycle and high price of equipment body and accessories; in order to improve the test efficiency of automotive products and reduce the test cost a set of highprecision automotive hydraulic servo test system is developed independently based on the basic principle of hydraulic servo control the test system independently developed the test software control accuracy reached the level of firstclass hydraulic servo equipment completed the fatigue life test of truck saddle and provided guarantee for the performance and life test of subsequent vehicle and parts,"['automobile material' 'automotive'
 'automotive highend hydraulic servo test equipment' 'fatigue life test'
 'hydraulic servo' 'hydraulic servo control' 'hydraulic servo test system'
 'material research' 'test software control accuracy' 'truck saddle']"
doi:10.1007/978-3-031-20105-9_3,en,Comparison of Metaheuristics for Chaotic Systems Estimation,OriginalPaper,In recent years Parameter Estimation (PE) has attracted the attention of the scientific community.,"['Engineering', 'Computational Intelligence', 'Artificial Intelligence']",in recent years parameter estimation pe has attracted the attention of the scientific community,['parameter estimation']
doi:10.1007/978-981-19-1142-2_34,en,A Review on Service Delivery in Tourism and Hospitality Industry Through Artificial Intelligence,OriginalPaper,"AI in service industry like tourism and hospitality is changing at an impressive pace and has uncovered new research opportunities. It has been progressively reshaping the service industry and has led to significant innovations in this sector. This study focuses on the systematic review of artificial intelligence in delivery of service in the field of tourism and hospitality. The purpose of the paper is to explore and signify the relevance of artificial intelligence in tourism and hospitality industry in the contemporary times to meet the challenges posed by the pandemic and to ensure speed and accuracy in service delivery for enriching guest experience and sustaining competition. Paper mainly discusses about the optimum use of artificial intelligence through the adoption of AI technology in service delivery in tourism and hospitality industry. The use of AI-enabled tools like chatbots, smart rooms with voice control system, facial recognition technology, robots, operational analysis, and virtual reality in hospitality industry has been analyzed. This study also explores the acceptance of AI by the customer in the tourism and hospitality industry.","['Engineering', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing', 'Mobile and Network Security', 'Artificial Intelligence']",ai in service industry like tourism and hospitality is changing at an impressive pace and has uncovered new research opportunities it has been progressively reshaping the service industry and has led to significant innovations in this sector this study focuses on the systematic review of artificial intelligence in delivery of service in the field of tourism and hospitality the purpose of the paper is to explore and signify the relevance of artificial intelligence in tourism and hospitality industry in the contemporary times to meet the challenges posed by the pandemic and to ensure speed and accuracy in service delivery for enriching guest experience and sustaining competition paper mainly discusses about the optimum use of artificial intelligence through the adoption of ai technology in service delivery in tourism and hospitality industry the use of aienabled tools like chatbots smart rooms with voice control system facial recognition technology robots operational analysis and virtual reality in hospitality industry has been analyzed this study also explores the acceptance of ai by the customer in the tourism and hospitality industry,"['##bled tools' 'artificial intelligence' 'chatbots'
 'facial recognition technology' 'hospitality' 'hospitality industry'
 'operational analysis' 'research opportunities' 'robots'
 'service delivery' 'service industry' 'smart rooms' 'tourism' 'use'
 'virtual reality' 'voice control system']"
doi:10.1007/978-981-19-1550-5_132-1,en,Use of Metrological Characteristics in Ultrasound Imaging and Artificial Intelligence Techniques for Disease Prediction in Soft Tissue Organs,ReviewPaper,"The global population nowadays is severely affected by various diseases of the soft tissue organs caused mainly because of some infection, heredity, change of lifestyle, etc. The timely detection and accurate diagnosis of these health conditions are of utmost importance in order to improve the chances of recovery and survival. Many medical imaging modalities have proven to effectively diagnose these diseases and their progression in a noninvasive way. Out of all the available modalities, ultrasound is the preferred mode of examination for imaging soft tissue organs for disease prediction because of its ease of use, low cost, portability, and lack of ionizing radiation. The radiologists manually study these scans for making an accurate diagnosis of the underlying condition. However, ultrasound imaging is highly operator-dependent and its effectiveness is adversely affected because of the presence of speckle noise. Therefore, to overcome these issues and for an efficient disease diagnosis, different computer-aided diagnostic (CAD) systems have been developed by researchers using artificial intelligence techniques along with the metrological characteristics of the diseased part as visible on the ultrasound scan of the organ under study. The main purpose of the present chapter is to shed light on the different types of diseases that affect the soft tissue organs like kidney, liver, thyroid, breast and their sonographic appearances, and characteristics. The chapter further describes methodologies developed in recent existing literature (year 2017 onwards) for the classification of diseases using ultrasound images of these organs through a CAD system using state-of-the-art deep learning and machine learning methods. The chapter also gives an insight into designing an efficient CAD system for the classification of breast tumors. The authors in the chapter have used nonsubsampled contourlet transform (NSCT) for multiresolution analysis of the original tumor images. From the subimages obtained using NSCT, extraction of texture features has been carried out using gray level co-occurrence matrix (GLCM), whereas shape features have been computed from the preprocessed tumor images. The computed feature set (texture + shape) has been used for classifying breast tumors using an adaptive neuro-fuzzy classifier with linguistic hedges (ANFC-LH) classifier based on the optimal features selected on the basis of the hedge values associated with the fuzzy rules.","['Physics', 'Measurement Science and Instrumentation', 'Nanotechnology']",the global population nowadays is severely affected by various diseases of the soft tissue organs caused mainly because of some infection heredity change of lifestyle etc the timely detection and accurate diagnosis of these health conditions are of utmost importance in order to improve the chances of recovery and survival many medical imaging modalities have proven to effectively diagnose these diseases and their progression in a noninvasive way out of all the available modalities ultrasound is the preferred mode of examination for imaging soft tissue organs for disease prediction because of its ease of use low cost portability and lack of ionizing radiation the radiologists manually study these scans for making an accurate diagnosis of the underlying condition however ultrasound imaging is highly operatordependent and its effectiveness is adversely affected because of the presence of speckle noise therefore to overcome these issues and for an efficient disease diagnosis different computeraided diagnostic cad systems have been developed by researchers using artificial intelligence techniques along with the metrological characteristics of the diseased part as visible on the ultrasound scan of the organ under study the main purpose of the present chapter is to shed light on the different types of diseases that affect the soft tissue organs like kidney liver thyroid breast and their sonographic appearances and characteristics the chapter further describes methodologies developed in recent existing literature year  onwards for the classification of diseases using ultrasound images of these organs through a cad system using stateoftheart deep learning and machine learning methods the chapter also gives an insight into designing an efficient cad system for the classification of breast tumors the authors in the chapter have used nonsubsampled contourlet transform nsct for multiresolution analysis of the original tumor images from the subimages obtained using nsct extraction of texture features has been carried out using gray level cooccurrence matrix glcm whereas shape features have been computed from the preprocessed tumor images the computed feature set texture  shape has been used for classifying breast tumors using an adaptive neurofuzzy classifier with linguistic hedges anfclh classifier based on the optimal features selected on the basis of the hedge values associated with the fuzzy rules,"['##ifier' 'adaptive neurofuzzy' 'artificial intelligence techniques'
 'breast tumors' 'classification' 'computeraided diagnostic cad'
 'disease diagnosis' 'features' 'fuzzy rules' 'glc' 'global population'
 'gray level cooccurrence' 'imaging soft tissue organs'
 'infection heredity change' 'ionizing radiation'
 'kidney liver thyroid breast' 'low cost portability' 'machine learning'
 'medical imaging modalities' 'metrological characteristics'
 'multiresolution analysis' 'nonsubsampled contourlet transform nsct'
 'preprocessed tumor images' 'soft tissue organs' 'speckle noise'
 'stateoftheart deep learning' 'ultrasound' 'ultrasound images'
 'ultrasound scan']"
doi:10.1007/978-3-031-12081-7_2,en,Fire for heat,OriginalPaper,"In the beginning it was the campfire, which is still very popular for our “high-tech spoiled” fellow citizens. Over time, people had dwellings, with open fires in closed grottoes. This remained the case later, in built rooms. Nothing has been handed down about fires and gas poisoning from this time.","['Engineering', 'Engineering Thermodynamics, Heat and Mass Transfer', 'Fossil Fuels (incl. Carbon Capture)', 'Renewable and Green Energy']",in the beginning it was the campfire which is still very popular for our hightech spoiled fellow citizens over time people had dwellings with open fires in closed grottoes this remained the case later in built rooms nothing has been handed down about fires and gas poisoning from this time,['campfire' 'closed grottoes' 'gas poisoning' 'open fires']
doi:10.1007/978-981-19-5331-6_6,en,Empirical Analysis of Crop Yield Prediction and Disease Detection Systems: A Statistical Perspective,OriginalPaper,"Crop-imagery is categorized into three different types, which are near-field images, satellite images and drone-based images. All these image types can be processed in order to determine crop growth, crop diseases and finally crop yield. Different algorithms have been proposed over the years which determine one or more of these parameters using a series of image segmentation, feature extraction, feature selection, classification and post-processing steps. Each of these steps requires a specialized set of algorithms to be employed in order to design an effective crop-image processing system. Due to the wide variety of algorithms present in the given field of work, selection of the most optimum algorithm set for a given application is often ambiguous. For instance, if an application is trying to process satellite imagery, then identification of best image-fusion methods for effective classification requires a lot of research, and thus increases delay for designing the system. In order to reduce this ambiguity, this paper reviews these algorithm sets which identify the best techniques in terms of statistical parameters for a given application. Accuracy and error rate have been compared between different algorithms in order to give a clear idea about the performance of these algorithms.","['Engineering', 'Computational Intelligence', 'Communications Engineering, Networks', 'Science and Technology Studies', 'Cyber-physical systems, IoT', 'Professional Computing']",cropimagery is categorized into three different types which are nearfield images satellite images and dronebased images all these image types can be processed in order to determine crop growth crop diseases and finally crop yield different algorithms have been proposed over the years which determine one or more of these parameters using a series of image segmentation feature extraction feature selection classification and postprocessing steps each of these steps requires a specialized set of algorithms to be employed in order to design an effective cropimage processing system due to the wide variety of algorithms present in the given field of work selection of the most optimum algorithm set for a given application is often ambiguous for instance if an application is trying to process satellite imagery then identification of best imagefusion methods for effective classification requires a lot of research and thus increases delay for designing the system in order to reduce this ambiguity this paper reviews these algorithm sets which identify the best techniques in terms of statistical parameters for a given application accuracy and error rate have been compared between different algorithms in order to give a clear idea about the performance of these algorithms,"['application accuracy' 'best' 'classification'
 'crop growth crop diseases' 'cropimagery' 'delay' 'dronebased images'
 'effective classification' 'error rate' 'identification'
 'image segmentation feature extraction' 'image types'
 'imagefusion methods' 'nearfield images satellite images'
 'postprocessing steps' 'process satellite imagery'
 'statistical parameters' 'work selection']"
doi:10.1007/978-981-19-4676-9_23,en,An Exploration of Machine Learning and Deep Learning-Based Diabetes Prediction Techniques,OriginalPaper,"Diabetes is now one of the world’s leading chronic diseases, affecting the middle-aged and elderly in most cases. This disease will gradually transform a person into death. There is an imbalance in blood glucose with the consequence of this disease that prompts the production of lower insulin. Medical science for the treatment of this disease is now advancing steadily. In addition to this, research focused on artificial intelligence (AI) is now advancing to define the stage of diabetes so that steps can be taken by everyone. A state-of-the-art analysis of various techniques for predicting diabetes is seen in this paper. For the last decade, several techniques based on machine learning (ML) and deep learning (DL) have been focusing on diabetes prediction. This research shows a summary of the published literature on the prediction of diabetes in the last six years. A recommendation system for observing the health of a patient through a web portal is proposed at the end of this article.","['Engineering', 'Computational Intelligence', 'Systems and Data Security', 'Artificial Intelligence', 'Computer Imaging, Vision, Pattern Recognition and Graphics']",diabetes is now one of the worlds leading chronic diseases affecting the middleaged and elderly in most cases this disease will gradually transform a person into death there is an imbalance in blood glucose with the consequence of this disease that prompts the production of lower insulin medical science for the treatment of this disease is now advancing steadily in addition to this research focused on artificial intelligence ai is now advancing to define the stage of diabetes so that steps can be taken by everyone a stateoftheart analysis of various techniques for predicting diabetes is seen in this paper for the last decade several techniques based on machine learning ml and deep learning dl have been focusing on diabetes prediction this research shows a summary of the published literature on the prediction of diabetes in the last six years a recommendation system for observing the health of a patient through a web portal is proposed at the end of this article,"['##oftheart analysis' 'artificial intelligence' 'chronic diseases'
 'deep learning' 'diabetes' 'diabetes prediction' 'elderly' 'glucose'
 'lower insulin medical science' 'machine learning' 'predicting diabetes']"
doi:10.1007/978-981-19-4162-7_26,en,Text Recognition from Images Using Deep Learning Techniques,OriginalPaper,"One of the most significant methods utilized in the deep learning approach is text recognition. Text recognition is now a very significant activity that is utilized in many applications of current gadgets to recognize images in a detailed manner. Automatic number plate recognition, for example, is an image processing approach that detects the vehicle's number (license) plate. The automatic number plate recognition system (ANPR) is a key feature that is used to manage traffic congestion. The goal of ANPR is to devise a method for automatically identifying permitted vehicles using vehicle numbers. Automatic number plate recognition (ANPR) is utilized in a variety of applications, including traffic control, vehicle tracking, and automatic payment of tolls on roads and bridges, as well as monitoring systems, parking management systems, and toll collecting stations. The established approach first recognizes the vehicle before taking a picture of it. After that, the number plate region in the car is localized using a neural network, and the image is segmented. Using a character recognition approach, characters are retrieved from the plate. The results, together with the time stamp, are then saved in the database. It is implemented and performed in Python, and the results are tested on a real picture.","['Engineering', 'Computational Intelligence', 'Data Mining and Knowledge Discovery', 'Systems and Data Security', 'Mobile and Network Security', 'Information Systems Applications (incl. Internet)']",one of the most significant methods utilized in the deep learning approach is text recognition text recognition is now a very significant activity that is utilized in many applications of current gadgets to recognize images in a detailed manner automatic number plate recognition for example is an image processing approach that detects the vehicles number license plate the automatic number plate recognition system anpr is a key feature that is used to manage traffic congestion the goal of anpr is to devise a method for automatically identifying permitted vehicles using vehicle numbers automatic number plate recognition anpr is utilized in a variety of applications including traffic control vehicle tracking and automatic payment of tolls on roads and bridges as well as monitoring systems parking management systems and toll collecting stations the established approach first recognizes the vehicle before taking a picture of it after that the number plate region in the car is localized using a neural network and the image is segmented using a character recognition approach characters are retrieved from the plate the results together with the time stamp are then saved in the database it is implemented and performed in python and the results are tested on a real picture,"['automatic number plate recognition' 'automatic payment' 'bridges'
 'character recognition' 'deep learning' 'image processing approach'
 'neural network' 'parking management systems' 'text recognition'
 'time stamp' 'toll collecting stations' 'traffic congestion'
 'traffic control vehicle tracking'
 'vehicle numbers automatic number plate recognition'
 'vehicles number license plate']"
doi:10.1007/978-981-19-0108-9_28,en,Role of Artificial Intelligence in Energy and Power Engineering,OriginalPaper,"Over the last decade, the energy issue has been a major source of concern in many countries, and the usage of renewable energy has risen in importance internationally. Wind speed prediction is required to enhance the quantity of energy generated. The wind speed forecast balances the energy required and the energy generated. Voltage stability has recently received a lot of attention from academics due to the fact that it has become a key concern for modern power system operators. Several countries have experienced widespread blackouts as a result of voltage instability issues. Accurate forecasting of power demand and price is considered as one of the most significant research topics in electrical engineering in the present and future, with academics placing a strong focus on demand and price prediction in deregulated markets. The predictive nature of various machine learning algorithms makes them most suitable tool to deal with problems related to energy and power engineering. Machine learning techniques are capable of analyzing past data and on the basis of that analysis, these algorithms are capable of predicting future results. This article provides applications of machine learning in energy and power engineering.","['Engineering', 'Manufacturing, Machines, Tools, Processes', 'Renewable and Green Energy', 'Materials Science, general', 'Nanotechnology']",over the last decade the energy issue has been a major source of concern in many countries and the usage of renewable energy has risen in importance internationally wind speed prediction is required to enhance the quantity of energy generated the wind speed forecast balances the energy required and the energy generated voltage stability has recently received a lot of attention from academics due to the fact that it has become a key concern for modern power system operators several countries have experienced widespread blackouts as a result of voltage instability issues accurate forecasting of power demand and price is considered as one of the most significant research topics in electrical engineering in the present and future with academics placing a strong focus on demand and price prediction in deregulated markets the predictive nature of various machine learning algorithms makes them most suitable tool to deal with problems related to energy and power engineering machine learning techniques are capable of analyzing past data and on the basis of that analysis these algorithms are capable of predicting future results this article provides applications of machine learning in energy and power engineering,"['deregulated markets' 'electrical engineering'
 'energy generated voltage stability' 'machine learning' 'power demand'
 'power engineering' 'price prediction' 'renewable energy'
 'voltage instability']"
doi:10.1007/978-3-031-13702-0_3,en,Explainable AI and Slime Mould Algorithm for Classification of Pistachio Species,OriginalPaper,"The safety and quality of the food are considered an essential issue in the entire world. This is due to food being the basis of human health. Nowadays, machine learning algorithms have embodied the recent technology in all stages of food processing such as food grading, food quality determination, and food classification. Pistachio nuts have an important role in the agricultural economy. To increase the efficiency of post-harvest industrial processes, there is a need to introduce technologies for classifying different species of pistachio. This study considers an automated model to separate pistachio species. The proposed pistachio species classification consists of three main phases; features selection based on slime mould algorithm phase, feature interpretation based on explainable artificial intelligence phase, and finally classification of pistachio species using logistic regression phase. The proposed pistachio species classification model obtained overall 90% classification accuracy, 90% precision, and 91% f1-score.","['Engineering', 'Computational Intelligence', 'Data Engineering', 'Artificial Intelligence', 'Food Science']",the safety and quality of the food are considered an essential issue in the entire world this is due to food being the basis of human health nowadays machine learning algorithms have embodied the recent technology in all stages of food processing such as food grading food quality determination and food classification pistachio nuts have an important role in the agricultural economy to increase the efficiency of postharvest industrial processes there is a need to introduce technologies for classifying different species of pistachio this study considers an automated model to separate pistachio species the proposed pistachio species classification consists of three main phases; features selection based on slime mould algorithm phase feature interpretation based on explainable artificial intelligence phase and finally classification of pistachio species using logistic regression phase the proposed pistachio species classification model obtained overall  classification accuracy  precision and  fscore,"['agricultural economy' 'artificial intelligence phase' 'automated model'
 'classification accuracy' 'food classification'
 'food grading food quality determination' 'food processing' 'fscore'
 'human health' 'logistic regression phase' 'machine learning algorithms'
 'pistachio nuts' 'pistachio species' 'pistachio species classification'
 'pistachio species classification model'
 'postharvest industrial processes' 'slime mould algorithm']"
doi:10.1007/978-981-19-7842-5_14,en,Truss Structure Optimization Design Based on FE-PSO-SQP Algorithm,OriginalPaper,"Compared with other structural optimization design algorithms, particle swarm optimization (PSO) gains many superiorities, like being easy to understand the principle and fewer parameters in the calculation model. When we use the PSO to deal with truss structure optimization problems, this algorithm usually has low computational accuracy, slow rates of convergence, and poor population varieties in the further model calculation. To overcome these shortcomings and better solve the truss structure optimization problem, FE-PSO-SQP algorithm, a new structure optimization method, is proposed herein by combining the PSO algorithm with the sequential quadratic programming (SQP) algorithm and finite element method (FE). In addition, a set of calculation program is developed by ANSYS software. When the self-made program is used to conduct simulation calculation on the truss structure optimization problem, the calculation results show that FE-PSO-SQP algorithm has faster convergence speed and higher calculation accuracy than FE-PSO algorithm, and can be used for structure optimization design.","['Engineering', 'Signal, Image and Speech Processing', 'Computational Intelligence', 'Artificial Intelligence']",compared with other structural optimization design algorithms particle swarm optimization pso gains many superiorities like being easy to understand the principle and fewer parameters in the calculation model when we use the pso to deal with truss structure optimization problems this algorithm usually has low computational accuracy slow rates of convergence and poor population varieties in the further model calculation to overcome these shortcomings and better solve the truss structure optimization problem fepsosqp algorithm a new structure optimization method is proposed herein by combining the pso algorithm with the sequential quadratic programming sqp algorithm and finite element method fe in addition a set of calculation program is developed by ansys software when the selfmade program is used to conduct simulation calculation on the truss structure optimization problem the calculation results show that fepsosqp algorithm has faster convergence speed and higher calculation accuracy than fepso algorithm and can be used for structure optimization design,"['##s software' 'accuracy' 'calculation accuracy' 'calculation model'
 'calculation program' 'convergence speed' 'fepso algorithm' 'fepsosqp'
 'fepsosqp algorithm' 'finite element method'
 'particle swarm optimization' 'pso' 'selfmade program'
 'sequential quadratic programming sqp algorithm'
 'structural optimization design algorithms' 'structure optimization'
 'structure optimization design' 'truss structure optimization problem'
 'truss structure optimization problems']"
doi:10.1007/978-3-030-85383-9_9,en,Anomaly Detection in Industrial IoT Applications Using Deep Learning Approach,OriginalPaper,"Internet of Things (IoT) becomes popular in last two decade as it provides many advantages such as flexibility, autonomous, cost effective and productivity. Many industries adopted IoT to improve the efficiency, security and predictive maintenance. To improve the quality of service (QoS), it is essential to identify various types of anomalies in productive maintenance. An anomaly is a value, a status of resources or outcome that deviates from expected or normal values and it affects QoS of production. In this paper, a multi-agent based anomaly detection scheme is introduced to improve the QoS. The fog computing infrastructure is used to reduce the latency of communication. Multiple agents are deployed in fog node to perform the various operations of detecting anomalies. The proposed anomaly detection scheme uses a multi-step prediction technique and applies an anomaly detection algorithm to detect anomalies. The Gated Recurrent Unit (GRU) model is used for Multi-step time series prediction and a bio-inspired Artificial Bee Colony algorithm is used for tuning the GRU model hyperparameters to improve the accuracy. The proposed model detects various types of anomalies in the fog computing environment. The Google Colab using TensorFlow library Keras is used for experimental evaluation. The proposed model increases accuracy over existing approaches, according to the experiment evaluation.","['Engineering', 'Computational Intelligence', 'Industrial and Production Engineering', 'Artificial Intelligence']",internet of things iot becomes popular in last two decade as it provides many advantages such as flexibility autonomous cost effective and productivity many industries adopted iot to improve the efficiency security and predictive maintenance to improve the quality of service qos it is essential to identify various types of anomalies in productive maintenance an anomaly is a value a status of resources or outcome that deviates from expected or normal values and it affects qos of production in this paper a multiagent based anomaly detection scheme is introduced to improve the qos the fog computing infrastructure is used to reduce the latency of communication multiple agents are deployed in fog node to perform the various operations of detecting anomalies the proposed anomaly detection scheme uses a multistep prediction technique and applies an anomaly detection algorithm to detect anomalies the gated recurrent unit gru model is used for multistep time series prediction and a bioinspired artificial bee colony algorithm is used for tuning the gru model hyperparameters to improve the accuracy the proposed model detects various types of anomalies in the fog computing environment the google colab using tensorflow library keras is used for experimental evaluation the proposed model increases accuracy over existing approaches according to the experiment evaluation,"['bioinspired artificial bee colony algorithm'
 'communication multiple agents' 'flexibility autonomous cost effective'
 'fog computing' 'fog computing infrastructure' 'gated recurrent unit'
 'google colab' 'gru model' 'gru model hyperparameter' 'keras' 'latency'
 'multiagent based' 'multistep prediction technique'
 'multistep time series prediction' 'predictive maintenance'
 'productive maintenance' 'security' 'tensorflow library']"
doi:10.1007/978-981-19-4162-7_29,en,AI-Based Mental Fatigue Recognition and Responsive Recommendation System,OriginalPaper,"Complete comfort is considered the definite one among all the foremost concerns in the present scenario. The organization has been proceeding with more contemplation in upgrading their work comfort. The workers also proceed with many perspectives to enhance their ongoing comfort status. However, comfort is generally related to their everyday activity and conduct, mainly in the worksites where it influences both the levels of stress and mood, resulting in mental fatigue. Specifically, the characteristic of the person’s comfort will be affected by the conduct in a worksite. We suggested a mental fatigue identification system that embraced deep learning techniques for supplying non-intrusive observing systems. The comfort level has been classified based on surveys: pressure and mood. This preparatory study instructs the model to generalized and personalized models of classifications. The model as personalized perspective has been taken as one of the steps to supply a personalized health resolution support system that helps in elevating the awareness in customers and motivates them to upgrade their conduct and eventually put up to the best comfort system. We have attained an accuracy of 87% on the model generic and 94% on the model personalized.","['Engineering', 'Computational Intelligence', 'Data Mining and Knowledge Discovery', 'Systems and Data Security', 'Mobile and Network Security', 'Information Systems Applications (incl. Internet)']",complete comfort is considered the definite one among all the foremost concerns in the present scenario the organization has been proceeding with more contemplation in upgrading their work comfort the workers also proceed with many perspectives to enhance their ongoing comfort status however comfort is generally related to their everyday activity and conduct mainly in the worksites where it influences both the levels of stress and mood resulting in mental fatigue specifically the characteristic of the persons comfort will be affected by the conduct in a worksite we suggested a mental fatigue identification system that embraced deep learning techniques for supplying nonintrusive observing systems the comfort level has been classified based on surveys: pressure and mood this preparatory study instructs the model to generalized and personalized models of classifications the model as personalized perspective has been taken as one of the steps to supply a personalized health resolution support system that helps in elevating the awareness in customers and motivates them to upgrade their conduct and eventually put up to the best comfort system we have attained an accuracy of  on the model generic and  on the model personalized,"['comfort' 'comfort level' 'complete comfort' 'deep learning techniques'
 'mental fatigue' 'mental fatigue identification system'
 'nonintrusive observing systems' 'personalized health resolution'
 'personalized models']"
doi:10.1007/978-981-19-3632-6_50,en,Technology of Radial Fluid Enhanced Diffusion Based on Machine Learning,OriginalPaper,"In the 1990s, it became easier for people to obtain digital information and to spread the information through the Internet. Against this background, machine learning has begun to develop vigorously, focusing more on solving practical problems. The phenomenon of radial fluid enhanced diffusion has always been the focus of attention in the field of fluid mechanics. However, due to the limitations of various actual physical conditions, convection dominates the radial fluid enhanced diffusion problem. The classic solution method will cause serious non-physical oscillations when solving the problem, and no more accurate numerical results can be obtained. Based on this, this paper proposes a radial fluid-enhanced diffusion technology based on machine learning. The logarithmic increment method is proposed to improve the non-parametric estimation of the drift coefficient. Experiments show that in the two typical models, the mean value of the logarithmic increment method fluctuates between 0.4–0.6, which is closer to the actual value of 0.495, indicating that the mean value of the logarithmic increment method is closer to the true value and the variance is smaller. The effect is better than that of the direct incremental method.","['Engineering', 'Cyber-physical systems, IoT', 'Communications Engineering, Networks', 'Signal, Image and Speech Processing']",in the s it became easier for people to obtain digital information and to spread the information through the internet against this background machine learning has begun to develop vigorously focusing more on solving practical problems the phenomenon of radial fluid enhanced diffusion has always been the focus of attention in the field of fluid mechanics however due to the limitations of various actual physical conditions convection dominates the radial fluid enhanced diffusion problem the classic solution method will cause serious nonphysical oscillations when solving the problem and no more accurate numerical results can be obtained based on this this paper proposes a radial fluidenhanced diffusion technology based on machine learning the logarithmic increment method is proposed to improve the nonparametric estimation of the drift coefficient experiments show that in the two typical models the mean value of the logarithmic increment method fluctuates between – which is closer to the actual value of  indicating that the mean value of the logarithmic increment method is closer to the true value and the variance is smaller the effect is better than that of the direct incremental method,"['##ct' 'drift coefficient' 'fluid mechanics' 'internet'
 'logarithmic increment method' 'machine learning' 'mean value'
 'nonparametric estimation' 'radial fluid enhanced diffusion'
 'radial fluid enhanced diffusion problem'
 'radial fluidenhanced diffusion technology']"
doi:10.1007/978-981-19-3391-2_3,en,Dynamic Multi-objective Optimization Using Computational Intelligence Algorithms,OriginalPaper,"Multi-objective optimization problems (MOPs) have multiple, often conflicting objectives where an improvement in one objective leads to the worsening of at least one other objective. The goal of a multi-objective algorithm (MOA) is to find a set of optimal trade-off solutions that is both accurate and diverse. However, many real-world problems are dynamic in nature where at least one objective and/or constraint changes over time. A dynamic multi-objective algorithm (DMOA) must therefore be able to track the changing set of optimal trade-off solutions over time. This chapter highlights issues that have to be addressed when evaluating the performance of DMOAs. It discusses areas that require further research, including decision making and analyzing the behavior of DMOAs. Emerging areas, and how they can impact on research in the field of dynamic multi-objective optimization (DMOO), are also highlighted.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Statistics, general', 'Cyber-physical systems, IoT', 'Professional Computing', 'Communications Engineering, Networks']",multiobjective optimization problems mops have multiple often conflicting objectives where an improvement in one objective leads to the worsening of at least one other objective the goal of a multiobjective algorithm moa is to find a set of optimal tradeoff solutions that is both accurate and diverse however many realworld problems are dynamic in nature where at least one objective andor constraint changes over time a dynamic multiobjective algorithm dmoa must therefore be able to track the changing set of optimal tradeoff solutions over time this chapter highlights issues that have to be addressed when evaluating the performance of dmoas it discusses areas that require further research including decision making and analyzing the behavior of dmoas emerging areas and how they can impact on research in the field of dynamic multiobjective optimization dmoo are also highlighted,"['dmoas' 'dynamic multiobjective algorithm'
 'dynamic multiobjective optimization' 'multiobjective algorithm'
 'multiobjective optimization problems' 'optimal tradeoff solutions']"
doi:10.1007/978-981-19-4990-6_41,en,Deviation and Cluster Analysis Using Inductive Alpha Miner in Process Mining,OriginalPaper,"Process mining is an effective method to discover information about the sequence of event execution in the business. Process mining helps interconnect event logs data and find any patterns in the process flows. Process mining (PM) provides a simple visualization to identify and organize data available in the healthcare system. We collected information from the hospital and applied PM methods. We processed structured and unstructured data and models using PM algorithms. Hospitals generate events logs that are considered complex and inconsistent. We found deviations and inconsistencies by comparing an existing process model with the event logs. In this paper, we created the design of Petri nets and analyzed the abnormality of the process flow. We propose an effective model to detect deviations using the event logs. Then, the abnormal activities are identified and displayed on the Petri nets. The Petri nets create clusters of dependent activities. The healthcare information from the hospital is used in the research process to convey our work. Experimental results show improvement in the effectiveness and efficiency of the proposed hospital information system.","['Engineering', 'Communications Engineering, Networks', 'Computational Intelligence', 'Wireless and Mobile Communication']",process mining is an effective method to discover information about the sequence of event execution in the business process mining helps interconnect event logs data and find any patterns in the process flows process mining pm provides a simple visualization to identify and organize data available in the healthcare system we collected information from the hospital and applied pm methods we processed structured and unstructured data and models using pm algorithms hospitals generate events logs that are considered complex and inconsistent we found deviations and inconsistencies by comparing an existing process model with the event logs in this paper we created the design of petri nets and analyzed the abnormality of the process flow we propose an effective model to detect deviations using the event logs then the abnormal activities are identified and displayed on the petri nets the petri nets create clusters of dependent activities the healthcare information from the hospital is used in the research process to convey our work experimental results show improvement in the effectiveness and efficiency of the proposed hospital information system,"['abnormality' 'business process mining' 'dependent activities'
 'event execution' 'healthcare information' 'healthcare system'
 'hospital information system' 'inconsistencies'
 'interconnect event logs data' 'logs' 'petri nets'
 'pm algorithms hospitals' 'pm methods' 'process flow'
 'process flows process mining' 'process mining']"
doi:10.1007/978-981-19-6347-6_10,en,Meta-Heuristic LQI Bio-regulator Benchmark for a Permanent Magnet DC Motor on ARM Platform,OriginalPaper,"There are controllers such as the Linear Quadratic Controller plus Integral part (LQI) that have presented favorable results in critical and complex processes, however, one of the disadvantages of this controller is the parameterization of the Q and R matrices, since they are obtained based on the cost of the controller and a trial and error method. Therefore, the present study aims to optimize these parameters through meta-heuristic algorithms such as: Genetic Algorithms (GA), Bacterial Foraging Optimization (BFO) and Ant Colony Optimization (ACO). In the MATLAB/SIMULINK software, the control loop programming is performed, using the control blocks of the Waijung library and with the STM32F407 card with Advanced Risk Machine (ARM) processor, the capture, reading and processing of data from the plant containing the DC motor for control is obtained. To validate the efficiency of the controller, the Integral of the Absolute Value of the Time Weighted Error (ITAE) is used and together with the Wilcoxon statistical method, it compares the optimization methods or techniques performed in the LQI controller. Interesting and favorable results were obtained for the stability and viability of each bio-controller at the moment of applying them in the speed control of the DC motor.","['Engineering', 'Computational Intelligence', 'Artificial Intelligence', 'Health Informatics', 'Statistics, general']",there are controllers such as the linear quadratic controller plus integral part lqi that have presented favorable results in critical and complex processes however one of the disadvantages of this controller is the parameterization of the q and r matrices since they are obtained based on the cost of the controller and a trial and error method therefore the present study aims to optimize these parameters through metaheuristic algorithms such as: genetic algorithms ga bacterial foraging optimization bfo and ant colony optimization aco in the matlabsimulink software the control loop programming is performed using the control blocks of the waijung library and with the stmf card with advanced risk machine arm processor the capture reading and processing of data from the plant containing the dc motor for control is obtained to validate the efficiency of the controller the integral of the absolute value of the time weighted error itae is used and together with the wilcoxon statistical method it compares the optimization methods or techniques performed in the lqi controller interesting and favorable results were obtained for the stability and viability of each biocontroller at the moment of applying them in the speed control of the dc motor,"['advanced risk' 'ant colony optimization'
 'bacterial foraging optimization bfo' 'capture reading'
 'control loop programming' 'genetic algorithms'
 'linear quadratic controller' 'machine arm processor'
 'metaheuristic algorithms' 'part l' 'stability' 'statistical method'
 'time weighted error' 'waijung library' 'wilcoxon']"
doi:10.1007/978-981-19-0105-8_58,en,Influential Node Detection in Online Social Network for Influence Minimization of Rumor,OriginalPaper,"In any online social media platform, it is necessary to reduce the effect of rumor data from original information as it may cause harm to society. Influential users can be detected through different centrality measures. When the rumor is generated through some influential users, they have more impact on society. Here, we have proposed a prognostic method to distinguish those influential users of online social media, based on network analysis. The susceptible-infectious-recovered (SIR) model has been used for simulation of the propagation of information. For the particular seed nodes which have been chosen by practicing different centrality measures, detailed relative learning in terms of infected nodes is also exhibited. Selection of seed nodes through centrality measure is computationally exhaustive; therefore, we form a composite model, where the original social network is decomposed using the k-core, and centrality nodes are obtained from that decomposed network. Centrality measurements thus derived from the generated network are used as the seed of information propagation. Another important result derived from the empirical study is that not only the influential nodes, but neighbors of the influential nodes also have a greater impact on maximizing the effect of rumors.","['Engineering', 'Communications Engineering, Networks', 'Artificial Intelligence', 'Computational Intelligence', 'Bioinformatics']",in any online social media platform it is necessary to reduce the effect of rumor data from original information as it may cause harm to society influential users can be detected through different centrality measures when the rumor is generated through some influential users they have more impact on society here we have proposed a prognostic method to distinguish those influential users of online social media based on network analysis the susceptibleinfectiousrecovered sir model has been used for simulation of the propagation of information for the particular seed nodes which have been chosen by practicing different centrality measures detailed relative learning in terms of infected nodes is also exhibited selection of seed nodes through centrality measure is computationally exhaustive; therefore we form a composite model where the original social network is decomposed using the kcore and centrality nodes are obtained from that decomposed network centrality measurements thus derived from the generated network are used as the seed of information propagation another important result derived from the empirical study is that not only the influential nodes but neighbors of the influential nodes also have a greater impact on maximizing the effect of rumors,"['##ity measure' 'centrality measurements' 'centrality measures'
 'composite model' 'decomposed network' 'infected nodes'
 'information propagation' 'network analysis' 'online social media'
 'online social media platform' 'prognostic method' 'relative learning'
 'rumor data' 'rumors' 'susceptibleinfectiousrecovered sir model']"
doi:10.1007/s10489-022-03317-6,en,Improving indoor visual navigation generalization with scene priors and Markov relational reasoning,OriginalPaper,"The problem of visual navigation is the poor generalization to find the given target object in unexplored environment without the help of auxiliary sensors. We propose solving the visual navigation problem by incorporating object spatial scene priors and visible object relational reasoning. To get more accurate ground truth environment priors, we construct specific scene graph priors for indoor navigation, which provides rich object spatial relationships for helping finding the target objects by object relation detection. Furthermore, to imitate human’s reasonability in searching objects, we encode our scene graph priors with Markov model for relational reasoning and fuse them into reinforcement learning policy network, which improves model generalization in novel scenes. Moreover, we perform experiments on the AI2THOR virtual environment and outperform the current most state-of-the-art both in SPL (Success weighted by Path Length) and success rate on average.","['Computer Science', 'Artificial Intelligence', 'Mechanical Engineering', 'Manufacturing, Machines, Tools, Processes']",the problem of visual navigation is the poor generalization to find the given target object in unexplored environment without the help of auxiliary sensors we propose solving the visual navigation problem by incorporating object spatial scene priors and visible object relational reasoning to get more accurate ground truth environment priors we construct specific scene graph priors for indoor navigation which provides rich object spatial relationships for helping finding the target objects by object relation detection furthermore to imitate humans reasonability in searching objects we encode our scene graph priors with markov model for relational reasoning and fuse them into reinforcement learning policy network which improves model generalization in novel scenes moreover we perform experiments on the aithor virtual environment and outperform the current most stateoftheart both in spl success weighted by path length and success rate on average,"['aithor virtual environment' 'humans reasonability' 'indoor navigation'
 'markov model' 'object spatial relationships' 'object spatial scene'
 'path length' 'reinforcement learning' 'relation detection'
 'relational reasoning' 'scene graph' 'searching objects'
 'unexplored environment' 'visible object relational reasoning'
 'visual navigation' 'visual navigation problem' 'weighted']"
